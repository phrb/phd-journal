# -*- mode: org -*-
# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages logdrawer
#+TITLE:  Pedro's Journal
#+AUTHOR:      Pedro H R Bruel
#+LANGUAGE:    en
#+TAGS: LIG(L) HOME(H) Europe(E) Blog(B) noexport(n) Stats(S)
#+TAGS: Epistemology(E) Vulgarization(V) Teaching(T) R(R) OrgMode(O) Python(P)
#+TAGS: Book(b) DOE(D) Code(C) NODAL(N)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w@) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

* 2017
** November 
*** [2017-11-28 Tue]
**** Install and Configure Emacs
- Attempted to use vim-orgmode but gave up: not enough features
- Switch to Emacs
**** Start an OrgMode Journal
- Use template from webinars
- Populate with some tasks
**** Advance on Reconfig Presentation
- Should add presentation notes for Alfredo
*** [2017-11-29 Wed]
- Complete Reconfig Presentation
- Read Fisher's Design of Experiments
**** Meeting with Alfredo
- Present our work for Brice and his research center
- Finish slides for Reconfig
*** [2017-11-30 Thu]
- Fix OFII form error and post it
- Start working on NODAL poster
**** Amélie's Presentation
- She is the author of Johanne's NIPS paper
- Two bandit cases: bandit and semi-bandit
- It is possible to achieve Nash Equilibria with both, given certain
  conditions
- I sent her an e-mail, asking for her C++ implementation of her work
- She already sent her code
- Print and read Amélie's paper
** December
*** Reading Fisher's Design & Montgomery's Design                :Book:DOE:
**** Quotes for key concepts
- "Every experiment may be said to exist only in order to give the
    facts a chance of disproving the null hypothesis"
- "The null hypothesis must be exact, that is free from vagueness and
    ambiguity"
**** A null hipothesis for autotuning techniques
***** Definitions
- A base autotuning technique t_b
- A new autotuning technique t_n
- A set of autotuning problems P
- A metric M
***** An exact null hipothesis H 
- We can state H as: The improvement of M produced by t_n is equal to t_b for all
  problems p \in P, that is, t_n performance is equal to t_b for P.
***** Problems 
- What is the chance of disproving H? In other words, to be considered better for P,
  for how many problems p \in P must t_n perform better than t_b?
- The set P must be very well chosen for this experiment to make sense. 
*** Studying "Learning with Bandit Feedback in Potential Games"      :Code:
**** Reading "Learning with Bandit Feedback in Potential Games" 
The [[file:~/Dropbox/papers/bandit-problem/cohen2017learning.pdf][pdf file]] is in my paper library.
***** Managing Autotuning Techniques as an N-Player Game
- Understanding applicability will require studying the implementation
  in C++ shared by Amélie.
- The players are distributed processes
- The actions are changing, keeping, restarting or reconfiguring
  search techniques
- The payoff is finding better configurations
  - Related to the Area Under the Curve Credit Assignment
  - The 'full bandit' case is very similar to MAB AUC
- Gaming strategies could consist of policies to select
  techniques based on the number of processes, past results,
  and maybe characteristics of the search space
- In this context, what would be equivalent to the *Nash Equilibrium*?
  - No process "wants" to change its policy for selecting techniques
  - No process "wants" to change its current technique
**** Studying the code from "Learning with Bandit Feedback in Potential Games"
The [[file:~/code/bandit-johanne/][source code]] is located in my code library.  
***** General Questions & Considerations
It seems the game has only 2 players, but the paper considers N-player
games. From the paper, it seems that the N-player implementation would
work without much change.

Payoffs seem to be pre-computed for each strategy but this does not,
at first, imply that needing to compute the payoffs would change
anything.

To adapt this code to the selection of search algorithms by Julia
processes we would need a way to implement the strategies.
***** Questions about specific points in code
****** =main.cpp=
Questions and execution flow related to the [[file:~/code/bandit-johanne/code/main.cpp][main file]].

******* Questions

- Why weren't random payoffs used?
- How are strategies represented in the =evol= array?

******* Execution Flow

1. Declare payoff and strategy arrays
2. Initialize pre-computed payoffs
3. Initialize seeds array
4. Instantiate a new =Game=
5. Call =Game->Play=
6. Save output to file
   
****** =game.h= & =game.cpp=
Questions and execution flow related to the [[file:~/code/bandit-johanne/code/game.h][header]] and the [[file:~/code/bandit-johanne/code/game.cpp][implementation]].

******* Questions

Re-read [[file:~/Dropbox/papers/bandit-problem/cohen2017learning.pdf][the paper]] to understand:

- What is a potential game?
- What does the =potential_function= do?
- What are the constraints on payoff arrays?
- What are =gamma= & =utility=?
- What is =res= used for inside =Game->play=? And inside =Game=?

******* Execution Flow

1. Instantiated by =main.cpp=
2. =void Game->play= is called by =main.cpp=
3. Open output file
4. Loop for the number of steps:
   1. Registers player strategies in =evol= for step =i= such that:
      #+BEGIN_SRC C
evol[i][(int)floor(P1->proba_strat[0]*100)][(int)floor(P2->proba_strat[0]*100)]++;
      #+END_SRC
   
      Where =P1= and =P2= are =Player= objects and the =proba_strat= arrays store
      the current strategy of each player.
   2. Calls =play_one_turn= (see below)
5. Save output to file

******** Execution Flow of =play_one_turn=

1. Called by =Game->play=
2. Initializes =epsilon=, =gamma= and =utility=
3. Set strategies for each player with =P->setStrat()= and
   =P->draw_proba()=
4. Update =utility= arrays with =P1->utility(P2->getStrat())=
   and =P2->utility(P1->getStrat())=
5. Update =y_strat= arrays with =utility= and =gamma=
6. Calls =P->update_proba(epsilon)= for each player

****** =player.h= & =player.cpp=
Questions and execution flow related to the
[[file:~/code/bandit-johanne/code/player.h][header]] and the
[[file:~/code/bandit-johanne/code/player.cpp][implementation]].

******* Questions

- What are the arrays =proba_strat= & =y_strat=?

*** NODAL Development                                          :Code:NODAL:
**** Installing NODAL in Julia Nightly
[[https://github.com/phrb/NODAL.jl][NODAL]] is the autotuning library I am developing in the [[https://julialang.org][Julia]]
language. The idea is to provide tools for the implementation of
parallel and distributed autotuners for various problem domains.
***** Download Julia Nightly
****** [[https://julialang.org/downloads][Download Generic Binary]] 
****** Downloading from the CLI
You can run the following to install the latest *Julia* version:
#+BEGIN_SRC bash
cd ~ && mkdir .bin && cd .bin
wget https://julialangnightlies-s3.julialang.org/bin/linux/x64/julia-latest-linux64.tar.gz
tar xvf julia-latest-linux64.tar.gz
mv julia-* julia
rm julia-latest-linux64.tar.gz
#+END_SRC
This will put the *Julia* binary at =~/.bin/julia/bin/julia=.
You can use it like that or add an =alias= to your shell.
***** Installing the unregistered version
This will not be needed after registering NODAL to METADATA.
****** [[https://docs.julialang.org/en/latest/manual/packages/#Installing-Unregistered-Packages-1][Documentation]]
****** Julia Commands
#+BEGIN_SRC julia
Pkg.clone("https://github.com/phrb/NODAL.jl")
Pkg.build("NODAL")
Pkg.test("NODAL")
#+END_SRC
***** Installing from the Julia package manager
****** Julia commands
#+BEGIN_SRC julia
Pkg.add("NODAL")
Pkg.build("NODAL")
Pkg.test("NODAL")
#+END_SRC
**** Setting up a new Release
***** Using Attobot
[[https://github.com/attobot][Attobot]] integrates with *GitHub* to automatically register a new package
or a package version to *Julia*'s =METADATA= package repository.  Attobot
only needs a new *GitHub* release to work.
***** Using *Julia*'s =PkgDev=
Check the [[https://docs.julialang.org/en/latest/manual/packages/#Tagging-and-Publishing-Your-Package-1][documentation]] to learn how to register and publish user
packages to =METADATA=.
**** Development Workflow
The process of fixing an [[https://github.com/phrb/NODAL.jl/issues][issue]] or submitting a new
feature is:
0. Fork [[https://github.com/phrb/NODAL.jl][NODAL on GitHub]]
   
   You will need a GitHub account for this.

1. Make sure you have the latest version
   #+BEGIN_SRC bash
git checkout master
git fetch
   #+END_SRC

   New branches must be made from the =dev= branch:
   #+BEGIN_SRC bash
git checkout dev
   #+END_SRC
2. Checkout a new branch
   #+BEGIN_SRC bash
git checkout -b fix-or-feature
   #+END_SRC
3. Write code and commit to your new branch
   
   Make sure you write short and descriptive commit
   messages. Something similar to [[https://udacity.github.io/git-styleguide/][Udacity's guidelines]] is preferred
   but not strictly necessary.

4. Open a [[https://github.com/phrb/NODAL.jl/pulls][pull request]] to the =dev= bran
*** Creating a Data Frame for FPGA Autotuning Samples              :R:Code:
**** Installing R Dependencies
The next code block install all =R= dependencies.
We are not using =ggplot2= to create the =csv= files,
but it will be used later for plotting.

We are installing =rjson= because part of the data files were generated
by OpenTuner in the =JSON= format.  The other packages are from Arnaud's
[[https://github.com/alegrand/SMPE#learning-r][guidelines]] for the SMPE course.

#+BEGIN_SRC R
install.packages(c("ggplot2", "dplyr", "tidyr", "rjson"),
                 repos = "https://mirror.ibcp.fr/pub/CRAN/")
#+END_SRC

**** Generating =csv= Files with the Data
The following script is hosted at the [[https://github.com/phrb/legup-tuner/blob/master/post_place_and_route/py/results/r_scripts/generate_csv_files.r][LegUp autotuner repository]].

To run it, you first need to clone the repository to get the data:

#+BEGIN_SRC sh
git clone https://github.com/phrb/legup-tuner.git
#+END_SRC

Then, replace the contents of the variable =repository= with the path
into which you cloned the repository.
The following script is hosted at [[https://raw.githubusercontent.com/phrb/legup-tuner/master/post_place_and_route/py/results/r_scripts/generate_csv_files.r][GitHub]]:

#+BEGIN_SRC sh :results output code :wrap "SRC R"
cat ~/code/legup-tuner/post_place_and_route/py/results/r_scripts/generate_csv_files.r
#+END_SRC

#+RESULTS:
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(jsonlite)

runs         <- 10
tuning_time  <- 5400

repository   <- "~/code/legup-tuner"
results      <- "post_place_and_route/py/results"

output_dir   <- paste(repository, results, "r_scripts/data", sep = "/")

experiments  <- c("default_stratixV_perf", "default_stratixV_perflat",
                  "default_stratixV_area", "default_stratixV_balanced")

applications <- c("dfadd", "dfdiv", "dfmul", "sha", "motion", "adpcm",
                  "dfsin", "aes", "blowfish", "gsm", "mips")

txt_measurements <- c("log_details.txt", "best_cycles_log.txt",
                      "best_fmax_log.txt", "best_lu_log.txt",
                      "best_pins_log.txt", "best_regs_log.txt",
                      "best_block_log.txt", "best_ram_log.txt",
                      "best_dps_log.txt")

json_configurations <- "best_log.json"

headers <- c("WNS", "Cycles", "FMax", "LUs", "Pins", "Regs", "Blocks", "RAM",
             "DPS")

#
# This function merges columns and fills missing rows with 'NA'.
# This happens in this dataset because of unsynchronized logging,
# where the last configuration was saved twice in one of the log
# files. Will require to later clean the lines with 'NA's.
#
# Function from:
#
#    https://stackoverflow.com/questions/7962267/cbind-a-df-with-an-empty-df-cbind-fill
#
#
cbind.fill <- function(...){
    nm <- list(...)
    nm <- lapply(nm, as.matrix)
    n <- max(sapply(nm, nrow))
    do.call(cbind, lapply(nm, function (x)
        rbind(x, matrix(, n-nrow(x), ncol(x)))))
}

dir.create(output_dir)

for (experiment in experiments) {
    dir.create(paste(output_dir, strsplit(experiment, "_")[[1]][3], sep = "/"))

    for (application in applications) {
        data <- data.frame()

        for (iteration in 1:runs) {
            target_file <- (paste(repository, results, experiment,
                                  paste(application, tuning_time, iteration,
                                        sep = "_"), json_configurations,
                                  sep = "/"))

            if (file.exists(target_file)) {
                configuration <- fromJSON(target_file)
            }

            columns <- data.frame()

            for (measurement in txt_measurements) {
                target_file <- paste(repository, results, experiment,
                                     paste(application, tuning_time, iteration,
                                           sep = "_"), measurement,
                                     sep = "/")

                if (file.exists(target_file)) {
                    new_column <- read.table(target_file, header = FALSE)[2]

                    if (ncol(columns) == 0) {
                        columns <- new_column
                    } else {
                        columns = cbind.fill(columns, new_column)
                    }
                }
            }

            if (ncol(columns) != 0) {
                colnames(columns) <- headers

                columns = cbind.fill(configuration, columns)

                if (nrow(data) == 0) {
                    data <- columns
                } else {
                    data = bind_rows(as.data.frame(data),
                                     as.data.frame(columns))
                }
            }
        }

        data <- data[complete.cases(data), ]

        write.csv(data, file = paste(paste(output_dir, strsplit(experiment,
                                                                "_")[[1]][3],
                                           application, sep = "/"), ".csv",
                                     sep = ""))
    }
}
#+END_SRC

#+RESULTS:

*** Analysing FPGA Autotuning Samples                              :R:Code:
The generated =csv= files live in the [[https://github.com/phrb/legup-tuner/tree/master/post_place_and_route/py/results/r_scripts/data][repository]], and are organized by
*experiment* and CHStone *application*. The *experiments* are the autotuning
runs targeting different optimization objectives. The *applications*
are the different programs that were autotuned.

It makes sense to combine data from different *experiments*, for a
same *application*, because the search space is the same and the
individual hardware metrics refer to the same FPGA circuit.

The =WNS= column is not directly comparable between different
*experiments*, even for the same *application*, because it represents a
different computation over the absolute metric values for each
*application*.  To compare =WNS= columns it would be necessary to
recompute =WNS= with different weights using the other hardware metrics.

Combining data from different *applications* would be more complicated.
The search spaces are not the same, but the *target FPGA* is the same.
We could try to understand some property of the hardware by looking
at the variability of the hardware metrics.

**** Multivariate Analysis
Implementing some ideas from [[https://little-book-of-r-for-multivariate-analysis.readthedocs.io/en/latest/src/multivariateanalysis.html][The Little Book of R for Multivariate
Analysis]].

***** Introduction
To run the code in this section you first need to clone the repository
to get the data and the R scripts:

#+BEGIN_SRC sh
git clone https://github.com/phrb/legup-tuner.git
#+END_SRC

#+RESULTS:

Then, you must replace the directory into which you cloned the
repository in all scripts. The variable that contains the repository
path is always at the top of each script.

***** Summary Statistics
First, we will combine all *experiments* with the *dfdiv* application. In
this case, the =WNS= columns are not directly comparable so I am not
removing the rows where ~WNS == Inf~. This indicates a penalty that
happened when there was some problem during HLS, synthesis, or
testing. The following script, hosted at [[https://raw.githubusercontent.com/phrb/legup-tuner/master/post_place_and_route/py/results/r_scripts/mean_sd.r][GitHub]], will print the *mean*
and *standard deviation* for the FPGA *hardware metrics* and *WNS*:
#+name: my_path
#+begin_src sh :results output :exports both
pwd
#+end_src

#+RESULTS: my_path
: /home/alegrand/Work/Documents/Articles/2017/Pedro/journal


#+begin_src R :results output :session *R* :exports both :var mypath=my_path
print(mypath)
#+end_src

#+RESULTS:
: [1] "/home/alegrand/Work/Documents/Articles/2017/Pedro/journal\n"

#+BEGIN_SRC sh :results output code :wrap "SRC R :results output :session *R* :var mypath=my_path" :var mypath=my_path
for i in $mypath; do cat $i/legup-tuner/post_place_and_route/py/results/r_scripts/mean_sd.r ; done
#+END_SRC

#+RESULTS:
#+BEGIN_SRC R :results output :session *R* :var mypath=my_path
library(dplyr)

chomp <- function (x) sub("\\s+$", "", x) # This was manually added

csv_dir <- c(paste0(chomp(mypath),"/legup-tuner/"),     # This was manually added
             "post_place_and_route/py/results/r_scripts/",
             "data")

experiments <- c("balanced", "area", "perf", "perflat")

applications <- c("dfadd", "dfdiv", "dfmul", "sha", "motion", "adpcm",
                  "dfsin", "aes", "blowfish", "gsm", "mips")

data       <- data.frame()
clean_data <- data.frame()

application <- applications[2]

for (experiment in experiments) {
    new_data <- read.csv(paste(paste(csv_dir, collapse = ""),
                               experiment, paste(application,
                                                 ".csv",
                                                 sep = ""),
                               sep = "/"),
                         header = TRUE, sep = ",")

    new_data       <- as.data.frame(new_data)
    new_clean_data <- new_data[is.finite(new_data$WNS),]

    if (ncol(data) == 0) {
        data <- new_data
    } else {
        data <- rbind(data, new_data)
    }

    if (ncol(clean_data) == 0) {
        clean_data <- new_clean_data
    } else {
        clean_data <- rbind(clean_data, new_clean_data)
    }
}

names <- c("WNS","RAM")

idx <- match(names, names(data))

print("Data with 'WNS == Inf' rows:")

print("Mean:")
sapply(data[idx[1]:idx[2]], mean)

print("Standard Deviation:")
sapply(data[idx[1]:idx[2]], sd)

print("Data without 'WNS == Inf' rows:")

print("Mean:")
sapply(clean_data[idx[1]:idx[2]], mean)

print("Standard Deviation:")
sapply(clean_data[idx[1]:idx[2]], sd)
#+END_SRC

#+RESULTS:
#+begin_example
[1] "Data with 'WNS == Inf' rows:"
[1] "Mean:"
         WNS       Cycles         FMax          LUs         Pins         Regs 
         Inf  587.1083650   24.1486882    1.0000000    3.2813688 4153.5665399 
      Blocks          RAM 
   0.8992395    0.8992395
[1] "Standard Deviation:"
         WNS       Cycles         FMax          LUs         Pins         Regs 
         NaN  227.1528406   13.1032536    0.0000000    0.4500950 1123.2949061 
      Blocks          RAM 
   0.3012978    0.3012978
[1] "Data without 'WNS == Inf' rows:"
[1] "Mean:"
         WNS       Cycles         FMax          LUs         Pins         Regs 
   1.0651531  564.3596215   23.6492429    1.0000000    3.2492114 4032.5268139 
      Blocks          RAM 
   0.9116719    0.9116719
[1] "Standard Deviation:"
         WNS       Cycles         FMax          LUs         Pins         Regs 
   0.3079517  207.3545319   12.8765244    0.0000000    0.4332403 1049.1423668 
      Blocks          RAM 
   0.2842201    0.2842201
#+end_example

***** Attempts at Computing Correlations
Following [[https://little-book-of-r-for-multivariate-analysis.readthedocs.io/en/latest/src/multivariateanalysis.html#calculating-correlations-for-multivariate-data][this guide]], I attempted to compute and plot the largest
correlations between *parameters* and *hardware metrics*.  The largest
correlations might not be really signficant, because the relationship
between variables might not be linear, as illustrated [[http://www.dummies.com/education/math/statistics/how-to-interpret-a-correlation-coefficient-r/][here]]. Therefore,
the following script plots the 30 largest correlations, for all
*applications* in all *experiments*, so that we can look at the
relationships between variables. The script also generates =csv= files
with the 120 strongest correlations. The script is hosted at [[https://raw.githubusercontent.com/phrb/legup-tuner/master/post_place_and_route/py/results/r_scripts/correlations.r][GitHub]].

#+BEGIN_SRC sh :results output code :wrap "SRC R :results output"
cat ~/code/legup-tuner/post_place_and_route/py/results/r_scripts/correlations.r 
#+END_SRC

#+RESULTS:
#+BEGIN_SRC R :results output
library(dplyr)

setEPS()

#
# Function adapted from:
#
#   https://little-book-of-r-for-multivariate-analysis.readthedocs.io/en/latest/src/multivariateanalysis.html#calculating-correlations-for-multivariate-data
#
sorted_correlations <- function(data, datapoints) {
    cormatrix <- cor(data)

    diag(cormatrix) <- 0
    cormatrix[lower.tri(cormatrix)] <- 0

    fm <- as.data.frame(as.table(cormatrix))

    names(fm) <- c("First.Variable", "Second.Variable","Correlation")

    hardware_metrics <- c("WNS", "Cycles", "FMax", "LUs", "Pins", "Regs",
                          "Blocks", "RAM", "DPS")

    #
    # Restricting comparisons to correlations that contain a hardware metric
    #
    fm <- dplyr::filter(fm, grepl(paste(hardware_metrics, collapse = "|"),
                                  fm$Second.Variable))

    head(fm[order(abs(fm$Correlation), decreasing = T), ], n = datapoints)
}

csv_dir <- c("~/code/legup-tuner/",
             "post_place_and_route/py/results/r_scripts/",
             "data")

plot_dir <- c("~/code/legup-tuner/",
             "post_place_and_route/py/results/r_scripts/",
             "correlations")

experiments <- c("balanced", "area", "perf", "perflat")

applications <- c("dfadd", "dfdiv", "dfmul", "sha", "motion", "adpcm",
                  "dfsin", "aes", "blowfish", "gsm", "mips")

plot_application_correlations <- function() {
    dir.create(paste(plot_dir, collapse = ""))

    for (application in applications) {
        data       <- data.frame()
        clean_data <- data.frame()

        for (experiment in experiments) {
            new_data <- read.csv(paste(paste(csv_dir, collapse = ""),
                                       experiment, paste(application,
                                                         ".csv",
                                                         sep = ""),
                                       sep = "/"),
                                 header = TRUE, sep = ",")

            new_data <- as.data.frame(new_data)
            new_data <- new_data[is.finite(new_data$WNS),]

            if (ncol(data) == 0) {
                data <- new_data
            } else {
                data <- rbind(data, new_data)
            }
        }

        data  <- sapply(data, as.numeric)

        correlation <- sorted_correlations(data, 120)

        print(paste("Generating 120 strongest correlations for '", application,
                    "'...", sep = ""))

        write.csv(correlation, file = paste(paste(plot_dir, collapse = ""),
                                            paste("correlations_", application,
                                                  ".csv", sep = ""), sep = "/"))
        print(paste("Generating scatter plots of the 30 strongest correlations for '",
                    application, "'...", sep = ""))

        print(paste(paste("CSV generated at ", plot_dir, collapse = "",
                          sep = ""), paste("correlations_", application,
                                           ".csv", sep = ""),
                    sep = "/"))

        short_correlation <- correlation[1:30, ]

        postscript(paste(paste(plot_dir, collapse = ""), paste("correlations_",
                                                               application,
                                                               ".eps",
                                                               sep = ""),
                         sep = "/"),
                   width = 16, height = 11)

        old.par <- par(mfrow = c(5, 6))

        for (i in 1:nrow(short_correlation)) {
            first  <- as.character(short_correlation[i, 'First.Variable'])
            second <- as.character(short_correlation[i, 'Second.Variable'])

            plot(data[, first], data[, second], xlab = first, ylab = second)
        }

        print(paste(paste("Plot generated at ", plot_dir, collapse = "",
                          sep = ""), paste("correlations_", application,
                                           ".eps", sep = ""),
                    sep = "/"))

        par(old.par)
        dev.off()
    }
}

plot_application_correlations()
#+END_SRC

#+RESULTS:
#+begin_example
[1] "Generating 120 strongest correlations for 'dfadd'..."
[1] "Generating scatter plots of the 30 strongest correlations for 'dfadd'..."
[1] "CSV generated at ~/code/legup-tuner/CSV generated at post_place_and_route/py/results/r_scripts/CSV generated at correlations/correlations_dfadd.csv"
[1] "Plot generated at ~/code/legup-tuner/Plot generated at post_place_and_route/py/results/r_scripts/Plot generated at correlations/correlations_dfadd.eps"
[1] "Generating 120 strongest correlations for 'dfdiv'..."
[1] "Generating scatter plots of the 30 strongest correlations for 'dfdiv'..."
[1] "CSV generated at ~/code/legup-tuner/CSV generated at post_place_and_route/py/results/r_scripts/CSV generated at correlations/correlations_dfdiv.csv"
[1] "Plot generated at ~/code/legup-tuner/Plot generated at post_place_and_route/py/results/r_scripts/Plot generated at correlations/correlations_dfdiv.eps"
[1] "Generating 120 strongest correlations for 'dfmul'..."
[1] "Generating scatter plots of the 30 strongest correlations for 'dfmul'..."
[1] "CSV generated at ~/code/legup-tuner/CSV generated at post_place_and_route/py/results/r_scripts/CSV generated at correlations/correlations_dfmul.csv"
[1] "Plot generated at ~/code/legup-tuner/Plot generated at post_place_and_route/py/results/r_scripts/Plot generated at correlations/correlations_dfmul.eps"
[1] "Generating 120 strongest correlations for 'sha'..."
[1] "Generating scatter plots of the 30 strongest correlations for 'sha'..."
[1] "CSV generated at ~/code/legup-tuner/CSV generated at post_place_and_route/py/results/r_scripts/CSV generated at correlations/correlations_sha.csv"
[1] "Plot generated at ~/code/legup-tuner/Plot generated at post_place_and_route/py/results/r_scripts/Plot generated at correlations/correlations_sha.eps"
[1] "Generating 120 strongest correlations for 'motion'..."
[1] "Generating scatter plots of the 30 strongest correlations for 'motion'..."
[1] "CSV generated at ~/code/legup-tuner/CSV generated at post_place_and_route/py/results/r_scripts/CSV generated at correlations/correlations_motion.csv"
[1] "Plot generated at ~/code/legup-tuner/Plot generated at post_place_and_route/py/results/r_scripts/Plot generated at correlations/correlations_motion.eps"
[1] "Generating 120 strongest correlations for 'adpcm'..."
[1] "Generating scatter plots of the 30 strongest correlations for 'adpcm'..."
[1] "CSV generated at ~/code/legup-tuner/CSV generated at post_place_and_route/py/results/r_scripts/CSV generated at correlations/correlations_adpcm.csv"
[1] "Plot generated at ~/code/legup-tuner/Plot generated at post_place_and_route/py/results/r_scripts/Plot generated at correlations/correlations_adpcm.eps"
[1] "Generating 120 strongest correlations for 'dfsin'..."
[1] "Generating scatter plots of the 30 strongest correlations for 'dfsin'..."
[1] "CSV generated at ~/code/legup-tuner/CSV generated at post_place_and_route/py/results/r_scripts/CSV generated at correlations/correlations_dfsin.csv"
[1] "Plot generated at ~/code/legup-tuner/Plot generated at post_place_and_route/py/results/r_scripts/Plot generated at correlations/correlations_dfsin.eps"
[1] "Generating 120 strongest correlations for 'aes'..."
[1] "Generating scatter plots of the 30 strongest correlations for 'aes'..."
[1] "CSV generated at ~/code/legup-tuner/CSV generated at post_place_and_route/py/results/r_scripts/CSV generated at correlations/correlations_aes.csv"
[1] "Plot generated at ~/code/legup-tuner/Plot generated at post_place_and_route/py/results/r_scripts/Plot generated at correlations/correlations_aes.eps"
[1] "Generating 120 strongest correlations for 'blowfish'..."
[1] "Generating scatter plots of the 30 strongest correlations for 'blowfish'..."
[1] "CSV generated at ~/code/legup-tuner/CSV generated at post_place_and_route/py/results/r_scripts/CSV generated at correlations/correlations_blowfish.csv"
[1] "Plot generated at ~/code/legup-tuner/Plot generated at post_place_and_route/py/results/r_scripts/Plot generated at correlations/correlations_blowfish.eps"
[1] "Generating 120 strongest correlations for 'gsm'..."
[1] "Generating scatter plots of the 30 strongest correlations for 'gsm'..."
[1] "CSV generated at ~/code/legup-tuner/CSV generated at post_place_and_route/py/results/r_scripts/CSV generated at correlations/correlations_gsm.csv"
[1] "Plot generated at ~/code/legup-tuner/Plot generated at post_place_and_route/py/results/r_scripts/Plot generated at correlations/correlations_gsm.eps"
[1] "Generating 120 strongest correlations for 'mips'..."
[1] "Generating scatter plots of the 30 strongest correlations for 'mips'..."
[1] "CSV generated at ~/code/legup-tuner/CSV generated at post_place_and_route/py/results/r_scripts/CSV generated at correlations/correlations_mips.csv"
[1] "Plot generated at ~/code/legup-tuner/Plot generated at post_place_and_route/py/results/r_scripts/Plot generated at correlations/correlations_mips.eps"
#+end_example

***** Attempts at PCA
Following [[https://little-book-of-r-for-multivariate-analysis.readthedocs.io/en/latest/src/multivariateanalysis.html#principal-component-analysis][this guide]] I attempted to perform Principal Component
Analysis for the data combining all *experiments* for all
*applications*. The following script generates [[https://stat.ethz.ch/R-manual/R-devel/library/stats/html/screeplot.html][scree plots]] for the PCA
of each *application*. The script is hosted at [[https://raw.githubusercontent.com/phrb/legup-tuner/master/post_place_and_route/py/results/r_scripts/pca.r][GitHub]].

#+BEGIN_SRC sh :results output code :wrap "SRC R :results output"
cat ~/code/legup-tuner/post_place_and_route/py/results/r_scripts/pca.r
#+END_SRC

#+RESULTS:
#+BEGIN_SRC R :results output
library(dplyr)

setEPS()

csv_dir <- c("~/code/legup-tuner/",
             "post_place_and_route/py/results/r_scripts/",
             "data")

plot_dir <- c("~/code/legup-tuner/",
             "post_place_and_route/py/results/r_scripts/",
             "scree_plots")

experiments <- c("balanced", "area", "perf", "perflat")

applications <- c("dfadd", "dfdiv", "dfmul", "sha", "motion", "adpcm",
                  "dfsin", "aes", "blowfish", "gsm", "mips")

hardware_metrics <- c("WNS", "Cycles", "FMax", "LUs", "Pins", "Regs", "Blocks",
                      "RAM", "DPS")

plot_scree_pca <- function() {
    dir.create(paste(plot_dir, collapse = ""))

    for (application in applications) {
        data <- data.frame()

        for (experiment in experiments) {
            new_data <- read.csv(paste(paste(csv_dir, collapse = ""),
                                       experiment, paste(application,
                                                         ".csv",
                                                         sep = ""),
                                       sep = "/"),
                                 header = TRUE, sep = ",")

            new_data <- as.data.frame(new_data)
            new_data <- new_data[is.finite(new_data$WNS),]

            if (ncol(data) == 0) {
                data <- new_data
            } else {
                data <- rbind(data, new_data)
            }
        }

        headers <- names(data)
        data  <- as.data.frame(sapply(data, as.numeric))

        standardised_data <- as.data.frame(scale(data[, !(names(data) %in% hardware_metrics)]))

        data.pca <- prcomp(t(na.omit(t(standardised_data))))

        print(paste("Generating scree plots of PCA for '",
                    application, "'...", sep = ""))

        postscript(paste(paste(plot_dir, collapse = ""), paste("scree_",
                                                               application,
                                                               ".eps",
                                                               sep = ""),
                         sep = "/"),
                   width = 16, height = 11)

        screeplot(data.pca, type = "lines")

        dev.off()
    }
}

plot_scree_pca()
#+END_SRC

#+RESULTS:
#+begin_example
[1] "Generating scree plots of PCA for 'dfadd'..."
[1] "Generating scree plots of PCA for 'dfdiv'..."
[1] "Generating scree plots of PCA for 'dfmul'..."
[1] "Generating scree plots of PCA for 'sha'..."
[1] "Generating scree plots of PCA for 'motion'..."
[1] "Generating scree plots of PCA for 'adpcm'..."
[1] "Generating scree plots of PCA for 'dfsin'..."
[1] "Generating scree plots of PCA for 'aes'..."
[1] "Generating scree plots of PCA for 'blowfish'..."
[1] "Generating scree plots of PCA for 'gsm'..."
[1] "Generating scree plots of PCA for 'mips'..."
#+end_example

***** Looking at data with Arnaud. Not sure where we were heading though.

#+begin_src R :results output :session *R* :exports both
dim(data)
str(data, list.len = 999) # only allows to see the first hundred of parameters, not what was measured
#+end_src

#+RESULTS:
#+begin_example
[1] 526 151
'data.frame':	526 obs. of  151 variables:
 $ X                                           : int  1 2 3 4 5 6 7 8 9 10 ...
 $ set_operation_latency.altfp_divide_16       : int  33 33 33 33 33 33 33 33 33 33 ...
 $ set_resource_constraint.signed_divide_16    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.mem_dual_port         : int  2 2 2 2 2 2 2 2 2 2 ...
 $ set_operation_latency.altfp_truncate_16     : int  3 3 3 3 3 3 3 3 3 4 ...
 $ set_resource_constraint.altfp_multiply_64   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.NO_ROMS                       : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_resource_constraint.signed_multiply_8   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_fptosi          : int  6 6 6 6 6 6 6 6 6 6 ...
 $ set_resource_constraint.unsigned_modulus_16 : int  1 1 1 1 1 1 1 1 1 5 ...
 $ set_resource_constraint.unsigned_multiply_32: int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.altfp_add_8         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.unsigned_multiply_32  : int  1 1 1 1 1 1 1 3 3 3 ...
 $ set_resource_constraint.unsigned_add_32     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.unsigned_divide_16    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.signed_multiply_16  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.signed_modulus_32     : int  1 1 1 1 1 1 1 1 1 0 ...
 $ set_operation_latency.signed_multiply_32    : int  1 1 1 1 1 1 1 1 1 5 ...
 $ set_operation_latency.altfp_add_64          : int  14 14 14 14 14 14 14 14 14 14 ...
 $ set_operation_latency.altfp_subtract_32     : int  14 14 14 14 14 14 14 14 14 14 ...
 $ set_parameter.PS_MIN_SIZE                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.altfp_add_64        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_multiply_64     : int  11 11 11 11 11 11 11 11 11 11 ...
 $ set_operation_latency.unsigned_multiply_8   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.unsigned_add_32       : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_truncate_8      : int  3 3 3 3 3 3 3 3 3 3 ...
 $ set_resource_constraint.signed_multiply_64  : int  1 1 1 1 1 1 1 6 6 6 ...
 $ set_operation_latency.signed_divide_64      : int  1 1 1 1 1 1 1 1 1 2 ...
 $ set_resource_constraint.altfp_subtract_16   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.MB_MINIMIZE_HW                : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_parameter.PATTERN_SHARE_ADD             : Factor w/ 3 levels " TRUE","FALSE",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ set_resource_constraint.signed_add_16       : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.MULTIPLIER_NO_CHAIN           : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_resource_constraint.unsigned_multiply_8 : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.reg                   : int  2 2 2 2 2 2 2 2 2 2 ...
 $ set_operation_latency.unsigned_modulus_64   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.unsigned_divide_16  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.unsigned_divide_64  : int  1 1 1 1 1 1 1 1 1 7 ...
 $ set_resource_constraint.signed_divide_8     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_extend_32       : int  2 2 2 2 2 2 2 2 2 2 ...
 $ set_resource_constraint.altfp_add_16        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.signed_modulus_32   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.DONT_CHAIN_GET_ELEM_PTR       : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_resource_constraint.unsigned_modulus_64 : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.unsigned_modulus_8    : int  1 1 1 1 1 1 1 1 1 0 ...
 $ set_resource_constraint.mem_dual_port       : int  2 2 2 2 2 2 2 2 2 2 ...
 $ set_parameter.SDC_MULTIPUMP                 : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_operation_latency.signed_multiply_16    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_multiply_16     : int  11 11 11 11 11 11 11 11 11 6 ...
 $ set_operation_latency.unsigned_modulus_16   : int  1 1 1 1 1 1 1 4 4 6 ...
 $ set_resource_constraint.altfp_subtract_64   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.signed_add_8          : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.unsigned_add_16       : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.PATTERN_SHARE_SUB             : Factor w/ 3 levels " TRUE","FALSE",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ set_parameter.CLOCK_PERIOD                  : int  10 10 10 10 10 10 10 24 24 24 ...
 $ set_resource_constraint.altfp_subtract_8    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.NO_LOOP_PIPELINING            : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_operation_latency.altfp_divide_64       : int  64 64 64 64 64 64 64 64 64 64 ...
 $ set_parameter.INCREMENTAL_SDC               : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_operation_latency.signed_divide_8       : int  1 1 1 1 1 1 1 4 4 4 ...
 $ set_resource_constraint.altfp_multiply_8    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.unsigned_multiply_16: int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.signed_modulus_64     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.unsigned_multiply_64  : int  1 1 1 1 1 1 1 1 1 3 ...
 $ set_resource_constraint.unsigned_multiply_64: int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.signed_add_32         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.DISABLE_REG_SHARING           : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_operation_latency.unsigned_divide_64    : int  1 1 1 1 1 1 1 1 1 5 ...
 $ set_resource_constraint.unsigned_modulus_8  : int  1 1 1 1 1 1 1 1 1 4 ...
 $ set_combine_basicblock                      : int  0 0 0 0 0 0 0 0 0 0 ...
 $ set_parameter.ENABLE_PATTERN_SHARING        : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_parameter.PIPELINE_RESOURCE_SHARING     : Factor w/ 3 levels " TRUE","FALSE",..: 1 1 1 1 1 1 1 1 1 2 ...
 $ set_parameter.MULTIPUMPING                  : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_resource_constraint.signed_add_32       : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_add_32          : int  14 14 14 14 14 14 14 14 14 14 ...
 $ set_resource_constraint.altfp_divide_64     : int  1 1 1 1 1 1 1 3 3 2 ...
 $ set_operation_latency.signed_modulus_8      : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.PIPELINE_ALL                  : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_parameter.SDC_NO_CHAINING               : chr  "FALSE" "FALSE" "FALSE" "FALSE" ...
 $ set_resource_constraint.altfp_add_32        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.PS_MIN_WIDTH                  : int  2 2 2 2 2 2 2 2 2 2 ...
 $ set_operation_latency.altfp_subtract_8      : int  14 14 14 14 14 14 14 14 14 14 ...
 $ set_operation_latency.signed_multiply_8     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_extend_64       : int  2 2 2 2 2 2 2 7 7 7 ...
 $ set_operation_latency.local_mem_dual_port   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_subtract_64     : int  14 14 14 14 14 14 14 14 14 14 ...
 $ set_resource_constraint.signed_divide_32    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.signed_multiply_32  : int  1 1 1 1 1 1 1 1 1 7 ...
 $ set_operation_latency.signed_divide_16      : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.signed_multiply_64    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.PATTERN_SHARE_BITOPS          : Factor w/ 3 levels " TRUE","FALSE",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ set_resource_constraint.signed_add_8        : int  1 1 1 1 1 1 1 4 4 4 ...
 $ set_parameter.SDC_PRIORITY                  : Factor w/ 3 levels " TRUE","FALSE",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.altfp_multiply_32   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.altfp_divide_16     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.signed_modulus_16   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.signed_add_64         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.unsigned_modulus_32 : int  1 1 1 1 1 1 1 7 7 7 ...
 $ set_operation_latency.altfp_multiply_8      : int  11 11 11 11 11 11 11 11 11 11 ...
 $ set_resource_constraint.signed_modulus_64   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.signed_comp_o         : int  1 1 1 1 1 1 1 5 5 5 ...
 $ set_parameter.PS_MAX_SIZE                   : int  10 10 10 10 10 10 10 10 10 10 ...
 $ set_operation_latency.signed_comp_u         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.DUAL_PORT_BINDING             : Factor w/ 3 levels " TRUE","FALSE",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.unsigned_divide_32  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_multiply_32     : int  11 11 11 11 11 11 11 11 11 11 ...
 $ set_operation_latency.altfp_add_16          : int  14 14 14 14 14 14 14 14 14 14 ...
 $ set_operation_latency.altfp_truncate_32     : int  3 3 3 3 3 3 3 3 3 3 ...
 $ set_operation_latency.unsigned_add_64       : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.signed_add_16         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.PS_BIT_DIFF_THRESHOLD         : int  10 10 10 10 10 10 10 10 10 10 ...
 $ set_operation_latency.altfp_add_8           : int  14 14 14 14 14 14 14 14 14 14 ...
 $ set_operation_latency.altfp_divide_32       : int  33 33 33 33 33 33 33 33 33 33 ...
 $ set_operation_latency.altfp_sitofp          : int  6 6 6 6 6 6 6 6 6 6 ...
 $ set_resource_constraint.unsigned_add_64     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.signed_add_64       : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.signed_divide_32      : int  1 1 1 1 1 1 1 7 7 4 ...
 $ set_parameter.MODULO_SCHEDULER              : Factor w/ 3 levels "ITERATIVE","SDC_BACKTRACKING",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ set_resource_constraint.unsigned_add_16     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_divide_8        : int  33 33 33 33 33 33 33 33 33 33 ...
 $ set_parameter.EXPLICIT_LPM_MULTS            : Factor w/ 2 levels " TRUE","FALSE": 2 2 2 2 2 2 2 2 2 2 ...
 $ set_parameter.MB_MAX_BACK_PASSES            : int  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
 $ set_operation_latency.signed_modulus_16     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.unsigned_multiply_16  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_extend_8        : int  2 2 2 2 2 2 2 2 2 2 ...
 $ set_operation_latency.unsigned_divide_32    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_subtract_16     : int  14 14 14 14 14 14 14 14 14 14 ...
 $ set_resource_constraint.unsigned_add_8      : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_parameter.PATTERN_SHARE_SHIFT           : Factor w/ 3 levels " TRUE","FALSE",..: 3 3 3 3 3 3 3 3 3 3 ...
 $ set_operation_latency.unsigned_divide_8     : int  1 1 1 1 1 1 1 7 7 7 ...
 $ set_resource_constraint.altfp_multiply_16   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.altfp_divide_32     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.unsigned_divide_8   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_truncate_64     : int  3 3 3 3 3 3 3 0 0 0 ...
 $ set_operation_latency.unsigned_modulus_32   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.unsigned_add_8        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_operation_latency.altfp_extend_16       : int  2 2 2 2 2 2 2 1 1 1 ...
 $ set_resource_constraint.altfp_divide_8      : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.altfp_subtract_32   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.signed_modulus_8    : int  1 1 1 1 1 1 1 1 1 5 ...
 $ set_resource_constraint.signed_divide_64    : int  1 1 1 1 1 1 1 1 1 1 ...
 $ set_resource_constraint.shared_mem_dual_port: int  1 1 1 1 1 1 1 5 5 5 ...
 $ WNS                                         : num  1 1 Inf Inf 1.12 ...
 $ Cycles                                      : int  486 486 486 486 486 486 486 458 458 554 ...
 $ FMax                                        : num  15.7 15.7 15.7 15.7 15.7 15.7 15.7 15.9 15.9 38 ...
 $ LUs                                         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ Pins                                        : int  3 3 3 3 3 3 3 3 3 3 ...
 $ Regs                                        : int  3949 3949 3949 3949 3949 3949 3949 3968 3968 4299 ...
 $ Blocks                                      : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RAM                                         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ DPS                                         : int  16 16 16 16 16 16 16 16 16 16 ...
#+end_example

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R* 
library(GGally)
hw_metrics = tail(names(data),n=9)
hw_parameters = head(names(data),n=151-9)
ggpairs(data, columns=hw_metrics)
#+end_src

#+RESULTS:
[[file:/tmp/babel-2610olo/figure2610ztH.png]]


#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 1600 :height 1400 :session *R* 
plot(data[c(sample(hw_parameters,size=5),hw_metrics)])
#+end_src

#+RESULTS:
[[file:/tmp/babel-2610olo/figure2610nWg.png]]

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 1600 :height 1400 :session *R* 
ggpairs(data[c(sample(hw_parameters,size=5),hw_metrics)])
#+end_src

#+RESULTS:
[[file:/tmp/babel-2610olo/figure26100gm.png]]


#+begin_src R :results output :session *R* :exports both
lm(data=head(data[!names(data) %in% (hw_metrics[hw_metrics!="FMax"])]), 
   FMax ~ .)
#+end_src

#+RESULTS:
: Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
:   les contrastes ne peuvent être appliqués qu'aux facteurs ayant au moins deux niveaux

Damn, we need to get rid of "useless" parameters. Let's go dirty!
#+begin_src R :results output :session *R* :exports both
data_bak = data
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
data=data_bak
# data=data[c(sample(hw_parameters,size=10),hw_metrics)]
#+end_src

#+RESULTS:

#+begin_src R :results output :session *R* :exports both
fixed_param = c()
for(i in names(data)) {
    if(dim(unique(data[i]))[1]==1) { fixed_param = c(fixed_param,i) }
}
fixed_param;
for(i in names(data)) {
    data = data[!is.na(data[,i]),]
    data = data[!is.infinite(data[,i]),]
#    data[,i]=as.numeric(data[,i])
}
data = data[!names(data) %in% (c(fixed_param,hw_metrics[hw_metrics!="FMax"]))]
dim(data)
#+end_src

#+RESULTS:
: [1] "LUs"
: [1] 317 143

#+begin_src R :results output :session *R* :exports both
summary(lm(data=data, FMax ~ .))
#+end_src

#+RESULTS:
#+begin_example

Call:
lm(formula = FMax ~ ., data = data)

Residuals:
       Min         1Q     Median         3Q        Max 
-4.822e-13 -9.070e-15  0.000e+00  7.680e-15  1.801e-12 

Coefficients: (66 not defined because of singularities)
                                                 Estimate Std. Error    t value
(Intercept)                                    -3.350e+01  3.918e-12 -8.550e+12
X                                              -1.959e-15  4.425e-16 -4.427e+00
set_operation_latency.altfp_divide_16           2.741e-01  2.699e-14  1.016e+13
set_resource_constraint.signed_divide_16        3.297e+00  2.363e-13  1.395e+13
set_operation_latency.mem_dual_port             2.306e+00  2.753e-13  8.378e+12
set_operation_latency.altfp_truncate_16        -5.863e+00  4.866e-13 -1.205e+13
set_resource_constraint.altfp_multiply_64      -3.912e+00  1.994e-13 -1.962e+13
set_parameter.NO_ROMSFALSE                      4.187e+00  3.109e-13  1.347e+13
set_resource_constraint.signed_multiply_8      -2.258e+00  1.740e-13 -1.298e+13
set_operation_latency.altfp_fptosi              2.887e+00  2.297e-13  1.257e+13
set_resource_constraint.unsigned_modulus_16    -2.169e+00  1.216e-13 -1.784e+13
set_resource_constraint.unsigned_multiply_32    1.999e+00  9.936e-14  2.012e+13
set_resource_constraint.altfp_add_8             1.224e+00  1.551e-13  7.891e+12
set_operation_latency.unsigned_multiply_32      4.697e+00  2.916e-13  1.611e+13
set_resource_constraint.unsigned_add_32         3.584e+00  2.549e-13  1.406e+13
set_operation_latency.unsigned_divide_16       -4.621e+00  3.104e-13 -1.489e+13
set_resource_constraint.signed_multiply_16      3.372e+00  2.927e-13  1.152e+13
set_operation_latency.signed_modulus_32        -4.647e+00  2.282e-13 -2.036e+13
set_operation_latency.signed_multiply_32        3.799e+00  1.495e-13  2.542e+13
set_operation_latency.altfp_add_64             -3.168e-01  1.781e-14 -1.779e+13
set_operation_latency.altfp_subtract_32         6.568e-01  2.457e-14  2.673e+13
set_parameter.PS_MIN_SIZE                      -1.248e+00  5.167e-14 -2.414e+13
set_resource_constraint.altfp_add_64            2.305e+00  1.566e-13  1.472e+13
set_operation_latency.altfp_multiply_64         8.586e-01  5.604e-14  1.532e+13
set_operation_latency.unsigned_multiply_8       2.663e+00  1.031e-13  2.582e+13
set_operation_latency.unsigned_add_32          -2.404e+00  1.510e-13 -1.592e+13
set_operation_latency.altfp_truncate_8          3.291e+00  2.624e-13  1.254e+13
set_resource_constraint.signed_multiply_64     -1.978e+00  1.698e-13 -1.165e+13
set_operation_latency.signed_divide_64         -8.317e-01  1.222e-13 -6.807e+12
set_resource_constraint.altfp_subtract_16      -1.196e+00  1.421e-13 -8.415e+12
set_parameter.MB_MINIMIZE_HWFALSE              -9.746e+00  2.943e-13 -3.311e+13
set_parameter.PATTERN_SHARE_ADDFALSE           -3.516e-01  1.536e-13 -2.290e+12
set_parameter.PATTERN_SHARE_ADDTRUE             2.426e-14  4.863e-14  4.990e-01
set_resource_constraint.signed_add_16           4.671e+00  3.277e-13  1.425e+13
set_parameter.MULTIPLIER_NO_CHAINFALSE         -6.361e+00  3.855e-13 -1.650e+13
set_resource_constraint.unsigned_multiply_8    -6.640e-01  3.168e-14 -2.096e+13
set_operation_latency.reg                      -9.704e-02  1.025e-13 -9.467e+11
set_operation_latency.unsigned_modulus_64       3.998e+00  2.018e-13  1.981e+13
set_resource_constraint.unsigned_divide_16      2.121e+00  1.674e-13  1.267e+13
set_resource_constraint.unsigned_divide_64      2.000e+00  1.066e-13  1.877e+13
set_resource_constraint.signed_divide_8         5.216e+00  4.076e-13  1.280e+13
set_operation_latency.altfp_extend_32          -2.484e+00  1.352e-13 -1.837e+13
set_resource_constraint.altfp_add_16            2.324e+00  1.143e-13  2.034e+13
set_resource_constraint.signed_modulus_32       1.627e+00  1.954e-13  8.328e+12
set_parameter.DONT_CHAIN_GET_ELEM_PTRFALSE      1.401e+00  1.424e-13  9.839e+12
set_resource_constraint.unsigned_modulus_64    -4.417e+00  1.895e-13 -2.330e+13
set_operation_latency.unsigned_modulus_8        9.075e+00  5.162e-13  1.758e+13
set_resource_constraint.mem_dual_port          -8.059e+00  3.535e-13 -2.280e+13
set_parameter.SDC_MULTIPUMPFALSE                5.620e+00  2.770e-13  2.029e+13
set_operation_latency.signed_multiply_16       -7.908e-01  1.052e-13 -7.515e+12
set_operation_latency.altfp_multiply_16         3.498e-01  4.716e-14  7.417e+12
set_operation_latency.unsigned_modulus_16       1.220e+00  1.195e-13  1.021e+13
set_resource_constraint.altfp_subtract_64       1.447e+00  1.867e-13  7.748e+12
set_operation_latency.signed_add_8             -7.823e-01  5.439e-14 -1.438e+13
set_operation_latency.unsigned_add_16          -9.417e-01  1.005e-13 -9.372e+12
set_parameter.PATTERN_SHARE_SUBFALSE            4.180e+00  2.350e-13  1.779e+13
set_parameter.PATTERN_SHARE_SUBTRUE             2.096e-15  4.523e-14  4.600e-02
set_parameter.CLOCK_PERIOD                     -1.022e+00  7.080e-14 -1.443e+13
set_resource_constraint.altfp_subtract_8        3.380e+00  1.711e-13  1.976e+13
set_parameter.NO_LOOP_PIPELININGFALSE           1.173e+01  6.083e-13  1.928e+13
set_operation_latency.altfp_divide_64           1.933e-03  3.803e-15  5.082e+11
set_parameter.INCREMENTAL_SDCFALSE             -8.475e+00  2.873e-13 -2.950e+13
set_operation_latency.signed_divide_8          -4.216e+00  1.338e-13 -3.151e+13
set_resource_constraint.altfp_multiply_8        5.653e-01  7.867e-14  7.185e+12
set_resource_constraint.unsigned_multiply_16    3.539e+00  1.550e-13  2.283e+13
set_operation_latency.signed_modulus_64        -4.142e+00  2.579e-13 -1.606e+13
set_operation_latency.unsigned_multiply_64      8.460e-01  9.711e-14  8.711e+12
set_resource_constraint.unsigned_multiply_64    7.761e-01  1.073e-13  7.232e+12
set_operation_latency.signed_add_32            -4.348e+00  3.093e-13 -1.406e+13
set_parameter.DISABLE_REG_SHARINGFALSE          3.101e+00  1.713e-13  1.810e+13
set_operation_latency.unsigned_divide_64        3.573e+00  1.341e-13  2.664e+13
set_resource_constraint.unsigned_modulus_8      8.893e-02  1.006e-13  8.844e+11
set_combine_basicblock                         -2.222e+00  3.434e-13 -6.470e+12
set_parameter.ENABLE_PATTERN_SHARINGFALSE      -2.650e+00  1.986e-13 -1.334e+13
set_parameter.PIPELINE_RESOURCE_SHARINGFALSE    9.754e+00  5.767e-13  1.691e+13
set_parameter.PIPELINE_RESOURCE_SHARINGTRUE    -1.482e-13  4.372e-14 -3.389e+00
set_parameter.MULTIPUMPINGFALSE                 5.025e+00  3.121e-13  1.610e+13
set_resource_constraint.signed_add_32          -2.429e+00  1.703e-13 -1.426e+13
set_operation_latency.altfp_add_32             -2.815e-02  2.073e-14 -1.358e+12
set_resource_constraint.altfp_divide_64         1.199e+01  5.991e-13  2.002e+13
set_operation_latency.signed_modulus_8         -1.588e+00  2.420e-13 -6.561e+12
set_parameter.PIPELINE_ALLFALSE                        NA         NA         NA
set_parameter.SDC_NO_CHAININGFALSE                     NA         NA         NA
set_resource_constraint.altfp_add_32                   NA         NA         NA
set_parameter.PS_MIN_WIDTH                             NA         NA         NA
set_operation_latency.altfp_subtract_8                 NA         NA         NA
set_operation_latency.signed_multiply_8                NA         NA         NA
set_operation_latency.altfp_extend_64                  NA         NA         NA
set_operation_latency.local_mem_dual_port              NA         NA         NA
set_operation_latency.altfp_subtract_64                NA         NA         NA
set_resource_constraint.signed_divide_32               NA         NA         NA
set_resource_constraint.signed_multiply_32             NA         NA         NA
set_operation_latency.signed_divide_16                 NA         NA         NA
set_operation_latency.signed_multiply_64               NA         NA         NA
set_parameter.PATTERN_SHARE_BITOPSFALSE                NA         NA         NA
set_parameter.PATTERN_SHARE_BITOPSTRUE          2.143e-13  6.965e-14  3.077e+00
set_resource_constraint.signed_add_8                   NA         NA         NA
set_parameter.SDC_PRIORITYFALSE                        NA         NA         NA
set_parameter.SDC_PRIORITYTRUE                 -2.206e-13  6.706e-14 -3.290e+00
set_resource_constraint.altfp_multiply_32              NA         NA         NA
set_resource_constraint.altfp_divide_16                NA         NA         NA
set_resource_constraint.signed_modulus_16              NA         NA         NA
set_operation_latency.signed_add_64                    NA         NA         NA
set_resource_constraint.unsigned_modulus_32            NA         NA         NA
set_operation_latency.altfp_multiply_8                 NA         NA         NA
set_resource_constraint.signed_modulus_64              NA         NA         NA
set_operation_latency.signed_comp_o                    NA         NA         NA
set_parameter.PS_MAX_SIZE                              NA         NA         NA
set_operation_latency.signed_comp_u                    NA         NA         NA
set_parameter.DUAL_PORT_BINDINGFALSE                   NA         NA         NA
set_parameter.DUAL_PORT_BINDINGTRUE             3.661e-14  6.362e-14  5.750e-01
set_resource_constraint.unsigned_divide_32             NA         NA         NA
set_operation_latency.altfp_multiply_32                NA         NA         NA
set_operation_latency.altfp_add_16                     NA         NA         NA
set_operation_latency.altfp_truncate_32                NA         NA         NA
set_operation_latency.unsigned_add_64                  NA         NA         NA
set_operation_latency.signed_add_16                    NA         NA         NA
set_parameter.PS_BIT_DIFF_THRESHOLD                    NA         NA         NA
set_operation_latency.altfp_add_8                      NA         NA         NA
set_operation_latency.altfp_divide_32                  NA         NA         NA
set_operation_latency.altfp_sitofp                     NA         NA         NA
set_resource_constraint.unsigned_add_64                NA         NA         NA
set_resource_constraint.signed_add_64                  NA         NA         NA
set_operation_latency.signed_divide_32                 NA         NA         NA
set_parameter.MODULO_SCHEDULERSDC_BACKTRACKING         NA         NA         NA
set_parameter.MODULO_SCHEDULERSDC_GREEDY               NA         NA         NA
set_resource_constraint.unsigned_add_16                NA         NA         NA
set_operation_latency.altfp_divide_8                   NA         NA         NA
set_parameter.EXPLICIT_LPM_MULTSFALSE                  NA         NA         NA
set_parameter.MB_MAX_BACK_PASSES                       NA         NA         NA
set_operation_latency.signed_modulus_16                NA         NA         NA
set_operation_latency.unsigned_multiply_16             NA         NA         NA
set_operation_latency.altfp_extend_8                   NA         NA         NA
set_operation_latency.unsigned_divide_32               NA         NA         NA
set_operation_latency.altfp_subtract_16                NA         NA         NA
set_resource_constraint.unsigned_add_8                 NA         NA         NA
set_parameter.PATTERN_SHARE_SHIFTFALSE                 NA         NA         NA
set_parameter.PATTERN_SHARE_SHIFTTRUE           5.481e-14  5.077e-14  1.080e+00
set_operation_latency.unsigned_divide_8                NA         NA         NA
set_resource_constraint.altfp_multiply_16              NA         NA         NA
set_resource_constraint.altfp_divide_32                NA         NA         NA
set_resource_constraint.unsigned_divide_8              NA         NA         NA
set_operation_latency.altfp_truncate_64                NA         NA         NA
set_operation_latency.unsigned_modulus_32              NA         NA         NA
set_operation_latency.unsigned_add_8                   NA         NA         NA
set_operation_latency.altfp_extend_16                  NA         NA         NA
set_resource_constraint.altfp_divide_8                 NA         NA         NA
set_resource_constraint.altfp_subtract_32              NA         NA         NA
set_resource_constraint.signed_modulus_8               NA         NA         NA
set_resource_constraint.signed_divide_64               NA         NA         NA
set_resource_constraint.shared_mem_dual_port           NA         NA         NA
                                               Pr(>|t|)    
(Intercept)                                     < 2e-16 ***
X                                              1.47e-05 ***
set_operation_latency.altfp_divide_16           < 2e-16 ***
set_resource_constraint.signed_divide_16        < 2e-16 ***
set_operation_latency.mem_dual_port             < 2e-16 ***
set_operation_latency.altfp_truncate_16         < 2e-16 ***
set_resource_constraint.altfp_multiply_64       < 2e-16 ***
set_parameter.NO_ROMSFALSE                      < 2e-16 ***
set_resource_constraint.signed_multiply_8       < 2e-16 ***
set_operation_latency.altfp_fptosi              < 2e-16 ***
set_resource_constraint.unsigned_modulus_16     < 2e-16 ***
set_resource_constraint.unsigned_multiply_32    < 2e-16 ***
set_resource_constraint.altfp_add_8             < 2e-16 ***
set_operation_latency.unsigned_multiply_32      < 2e-16 ***
set_resource_constraint.unsigned_add_32         < 2e-16 ***
set_operation_latency.unsigned_divide_16        < 2e-16 ***
set_resource_constraint.signed_multiply_16      < 2e-16 ***
set_operation_latency.signed_modulus_32         < 2e-16 ***
set_operation_latency.signed_multiply_32        < 2e-16 ***
set_operation_latency.altfp_add_64              < 2e-16 ***
set_operation_latency.altfp_subtract_32         < 2e-16 ***
set_parameter.PS_MIN_SIZE                       < 2e-16 ***
set_resource_constraint.altfp_add_64            < 2e-16 ***
set_operation_latency.altfp_multiply_64         < 2e-16 ***
set_operation_latency.unsigned_multiply_8       < 2e-16 ***
set_operation_latency.unsigned_add_32           < 2e-16 ***
set_operation_latency.altfp_truncate_8          < 2e-16 ***
set_resource_constraint.signed_multiply_64      < 2e-16 ***
set_operation_latency.signed_divide_64          < 2e-16 ***
set_resource_constraint.altfp_subtract_16       < 2e-16 ***
set_parameter.MB_MINIMIZE_HWFALSE               < 2e-16 ***
set_parameter.PATTERN_SHARE_ADDFALSE            < 2e-16 ***
set_parameter.PATTERN_SHARE_ADDTRUE            0.618352    
set_resource_constraint.signed_add_16           < 2e-16 ***
set_parameter.MULTIPLIER_NO_CHAINFALSE          < 2e-16 ***
set_resource_constraint.unsigned_multiply_8     < 2e-16 ***
set_operation_latency.reg                       < 2e-16 ***
set_operation_latency.unsigned_modulus_64       < 2e-16 ***
set_resource_constraint.unsigned_divide_16      < 2e-16 ***
set_resource_constraint.unsigned_divide_64      < 2e-16 ***
set_resource_constraint.signed_divide_8         < 2e-16 ***
set_operation_latency.altfp_extend_32           < 2e-16 ***
set_resource_constraint.altfp_add_16            < 2e-16 ***
set_resource_constraint.signed_modulus_32       < 2e-16 ***
set_parameter.DONT_CHAIN_GET_ELEM_PTRFALSE      < 2e-16 ***
set_resource_constraint.unsigned_modulus_64     < 2e-16 ***
set_operation_latency.unsigned_modulus_8        < 2e-16 ***
set_resource_constraint.mem_dual_port           < 2e-16 ***
set_parameter.SDC_MULTIPUMPFALSE                < 2e-16 ***
set_operation_latency.signed_multiply_16        < 2e-16 ***
set_operation_latency.altfp_multiply_16         < 2e-16 ***
set_operation_latency.unsigned_modulus_16       < 2e-16 ***
set_resource_constraint.altfp_subtract_64       < 2e-16 ***
set_operation_latency.signed_add_8              < 2e-16 ***
set_operation_latency.unsigned_add_16           < 2e-16 ***
set_parameter.PATTERN_SHARE_SUBFALSE            < 2e-16 ***
set_parameter.PATTERN_SHARE_SUBTRUE            0.963071    
set_parameter.CLOCK_PERIOD                      < 2e-16 ***
set_resource_constraint.altfp_subtract_8        < 2e-16 ***
set_parameter.NO_LOOP_PIPELININGFALSE           < 2e-16 ***
set_operation_latency.altfp_divide_64           < 2e-16 ***
set_parameter.INCREMENTAL_SDCFALSE              < 2e-16 ***
set_operation_latency.signed_divide_8           < 2e-16 ***
set_resource_constraint.altfp_multiply_8        < 2e-16 ***
set_resource_constraint.unsigned_multiply_16    < 2e-16 ***
set_operation_latency.signed_modulus_64         < 2e-16 ***
set_operation_latency.unsigned_multiply_64      < 2e-16 ***
set_resource_constraint.unsigned_multiply_64    < 2e-16 ***
set_operation_latency.signed_add_32             < 2e-16 ***
set_parameter.DISABLE_REG_SHARINGFALSE          < 2e-16 ***
set_operation_latency.unsigned_divide_64        < 2e-16 ***
set_resource_constraint.unsigned_modulus_8      < 2e-16 ***
set_combine_basicblock                          < 2e-16 ***
set_parameter.ENABLE_PATTERN_SHARINGFALSE       < 2e-16 ***
set_parameter.PIPELINE_RESOURCE_SHARINGFALSE    < 2e-16 ***
set_parameter.PIPELINE_RESOURCE_SHARINGTRUE    0.000824 ***
set_parameter.MULTIPUMPINGFALSE                 < 2e-16 ***
set_resource_constraint.signed_add_32           < 2e-16 ***
set_operation_latency.altfp_add_32              < 2e-16 ***
set_resource_constraint.altfp_divide_64         < 2e-16 ***
set_operation_latency.signed_modulus_8          < 2e-16 ***
set_parameter.PIPELINE_ALLFALSE                      NA    
set_parameter.SDC_NO_CHAININGFALSE                   NA    
set_resource_constraint.altfp_add_32                 NA    
set_parameter.PS_MIN_WIDTH                           NA    
set_operation_latency.altfp_subtract_8               NA    
set_operation_latency.signed_multiply_8              NA    
set_operation_latency.altfp_extend_64                NA    
set_operation_latency.local_mem_dual_port            NA    
set_operation_latency.altfp_subtract_64              NA    
set_resource_constraint.signed_divide_32             NA    
set_resource_constraint.signed_multiply_32           NA    
set_operation_latency.signed_divide_16               NA    
set_operation_latency.signed_multiply_64             NA    
set_parameter.PATTERN_SHARE_BITOPSFALSE              NA    
set_parameter.PATTERN_SHARE_BITOPSTRUE         0.002345 ** 
set_resource_constraint.signed_add_8                 NA    
set_parameter.SDC_PRIORITYFALSE                      NA    
set_parameter.SDC_PRIORITYTRUE                 0.001157 ** 
set_resource_constraint.altfp_multiply_32            NA    
set_resource_constraint.altfp_divide_16              NA    
set_resource_constraint.signed_modulus_16            NA    
set_operation_latency.signed_add_64                  NA    
set_resource_constraint.unsigned_modulus_32          NA    
set_operation_latency.altfp_multiply_8               NA    
set_resource_constraint.signed_modulus_64            NA    
set_operation_latency.signed_comp_o                  NA    
set_parameter.PS_MAX_SIZE                            NA    
set_operation_latency.signed_comp_u                  NA    
set_parameter.DUAL_PORT_BINDINGFALSE                 NA    
set_parameter.DUAL_PORT_BINDINGTRUE            0.565530    
set_resource_constraint.unsigned_divide_32           NA    
set_operation_latency.altfp_multiply_32              NA    
set_operation_latency.altfp_add_16                   NA    
set_operation_latency.altfp_truncate_32              NA    
set_operation_latency.unsigned_add_64                NA    
set_operation_latency.signed_add_16                  NA    
set_parameter.PS_BIT_DIFF_THRESHOLD                  NA    
set_operation_latency.altfp_add_8                    NA    
set_operation_latency.altfp_divide_32                NA    
set_operation_latency.altfp_sitofp                   NA    
set_resource_constraint.unsigned_add_64              NA    
set_resource_constraint.signed_add_64                NA    
set_operation_latency.signed_divide_32               NA    
set_parameter.MODULO_SCHEDULERSDC_BACKTRACKING       NA    
set_parameter.MODULO_SCHEDULERSDC_GREEDY             NA    
set_resource_constraint.unsigned_add_16              NA    
set_operation_latency.altfp_divide_8                 NA    
set_parameter.EXPLICIT_LPM_MULTSFALSE                NA    
set_parameter.MB_MAX_BACK_PASSES                     NA    
set_operation_latency.signed_modulus_16              NA    
set_operation_latency.unsigned_multiply_16           NA    
set_operation_latency.altfp_extend_8                 NA    
set_operation_latency.unsigned_divide_32             NA    
set_operation_latency.altfp_subtract_16              NA    
set_resource_constraint.unsigned_add_8               NA    
set_parameter.PATTERN_SHARE_SHIFTFALSE               NA    
set_parameter.PATTERN_SHARE_SHIFTTRUE          0.281396    
set_operation_latency.unsigned_divide_8              NA    
set_resource_constraint.altfp_multiply_16            NA    
set_resource_constraint.altfp_divide_32              NA    
set_resource_constraint.unsigned_divide_8            NA    
set_operation_latency.altfp_truncate_64              NA    
set_operation_latency.unsigned_modulus_32            NA    
set_operation_latency.unsigned_add_8                 NA    
set_operation_latency.altfp_extend_16                NA    
set_resource_constraint.altfp_divide_8               NA    
set_resource_constraint.altfp_subtract_32            NA    
set_resource_constraint.signed_modulus_8             NA    
set_resource_constraint.signed_divide_64             NA    
set_resource_constraint.shared_mem_dual_port         NA    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.316e-13 on 232 degrees of freedom
Multiple R-squared:      1,	Adjusted R-squared:      1 
F-statistic: 3.603e+28 on 84 and 232 DF,  p-value: < 2.2e-16
#+end_example

Hmmm, pretty hard to interpret.

Let's look at something more specific for a change!

#+begin_src R :results output :session *R* :exports both
data=data_bak
summary(lm(data=data,Regs~ set_operation_latency.signed_multiply_64))
#+end_src

#+RESULTS:
#+begin_example

Call:
lm(formula = Regs ~ set_operation_latency.signed_multiply_64, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-1490.06  -505.08    26.94    26.94  2578.74 

Coefficients:
                                         Estimate Std. Error t value Pr(>|t|)
(Intercept)                               3534.26      47.16   74.94   <2e-16
set_operation_latency.signed_multiply_64   387.80      18.78   20.65   <2e-16
                                            
(Intercept)                              ***
set_operation_latency.signed_multiply_64 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 834.8 on 524 degrees of freedom
Multiple R-squared:  0.4487,	Adjusted R-squared:  0.4477 
F-statistic: 426.5 on 1 and 524 DF,  p-value: < 2.2e-16
#+end_example

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R* 
library(ggplot2)
ggplot(data=data, aes(y=Regs, x=set_operation_latency.signed_multiply_64, color=set_operation_latency.signed_add_64)) + 
    geom_jitter(aes(x=as.factor(set_operation_latency.signed_multiply_64))) + 
    geom_smooth(aes(x=as.numeric(set_operation_latency.signed_multiply_64)), method="lm", formula=y~x+I(1/(x+1))) +
    theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-2610olo/figure2610OKP.png]]

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R* 
library(ggplot2)
ggplot(data=data, aes(y=Regs, x=set_operation_latency.signed_add_64, color=set_operation_latency.signed_multiply_64)) + 
    geom_jitter(aes(x=as.factor(set_operation_latency.signed_add_64))) + 
    geom_smooth(aes(x=as.numeric(set_operation_latency.signed_add_64)), method="lm", formula=y~x) +
    theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-2610olo/figure2610Czn.png]]

#+begin_src R :results output graphics :file (org-babel-temp-file "figure" ".png") :exports both :width 600 :height 400 :session *R* 
library(ggplot2)
ggplot(data=data[data$set_operation_latency.signed_multiply_64 ==1,], aes(y=Regs, x=set_operation_latency.signed_add_64)) + 
    geom_jitter(aes(x=as.factor(set_operation_latency.signed_add_64))) + 
    geom_smooth(aes(x=as.numeric(set_operation_latency.signed_add_64)), method="lm", formula=y~x) +
    theme_bw() 
#+end_src

#+RESULTS:
[[file:/tmp/babel-2610olo/figure2610P9t.png]]

In the end, it's very hard to know what's good, why such or such
parameter was used, etc.

- We discussed about the difficulties in multi-dimension setups:
  https://blog.acolyer.org/2017/10/31/same-stats-different-graphs-generating-datasets-with-varied-appearance-and-identical-statistics-through-simulated-annealing/
- The analysis (lm or aov) is really hard when mixing factors and
  continuous variables.
- It's possible to sort parameters by importance (for aov) but I'm not
  sure how to do this in a systematic way in such a high dimension.

*** [2017-12-01 Fri]
- Finish the Reconfig poster
- Converge to final Reconfig presentation
*** [2017-12-04 Mon]
- Set up build environment for latest Julia version
- Apply Sai's corrections to presentation
**** Fix NODAL's status in Julia pkg Manager
- Fixed warnings and deprecations
- Tagged new version 'v0.3.5'
- Released new version
- Made new pull request to METADATA
- Waiting for merge
*** [2017-12-05 Tue]
- Started using new us-layout keyboard.
- Study the Bandit's code and paper
**** Start NODAL's 'dev' branch
- Pushed 'dev' branch to GitHub repository.
- Added development workflow to Journal
*** [2017-12-06 Wed]
- Describe Hedge's code exec flow ([[Studying "Learning with Bandit Feedback in Potential Games"][Main Section]])
- Elaborate concrete bandit implementation plan for autotuning ([[Studying "Learning with Bandit Feedback in Potential Games"][Main Section]])
- Resume study of Fisher's and Montgomer's books ([[Reading Fisher's Design & Montgomery's Design][Main Section]])
**** Discussion with Brice and Arnaud
Meeting notes kindly taken by Arnaud.
***** Questions left open in Pedro's journal
- Bandits: This would clearly be useful for auto-tuning as we may not
  know in advance what would work better on a given instance.
  - Bandit algorithms could be used to select which algorithms work better.
  - They could also be used to select which areas to explore.
  A possibly interesting question is "How does parallel bandit work?".

- Game Theory: branch of mathematics for
  1. modeling/studying situations where agents compete with each others.
  2. improving situation where agents compete with each others
  3. design fully distributed algorithms/protocols
  It's not clear yet how game theory would help in our auto-tuning
  context but we can keep this in mind.

- Design of Experiments: Master 2 lecture on
[[https://github.com/alegrand/SMPE][SMPE]]. Description and
  rooms are
[[http://mescal.imag.fr/membres/arnaud.legrand/teaching/2017/M2R_SMPE.php][here]].

- Quick discussions about Julia and how it compares with other
  languages (compiled on the fly, FFI, ...).
***** Autotuning context:
  - So far, with FPGAs, what was distinctive was:
    1. Many many compilation parameters
    2. Several parameters to optimize
    3. Extremely long experiments
    4. Parallel exploration
    Can we keep all these research challenges open or should we focus
    on one or two of them ?
  - Brice thinks there is:
    - The structure of the code is also important for the compiler and
      it may be worth looking at code transformation. Changing the
      code may have a lot of impact on performance and this
      variability may contain a lot of useful information. BOAST
      (meta-programming rather than code transformation) can help to
      investigate this.

      Actually, the fact some gain can be obtained by tweaking the
      compiler option may mean we're far from the peak performance,
      which may be caused by an ineffective code structure. *This could
      be explored with BOAST and* *we should probably check this before
      going into compiler flag exploration*.
  - Discussions about compiler passes (LLVM) and the importance of
    unroll/jam.
  - Questions:
    - Do we have FPGAs to play with ?
      - Some of the recent Intel Skylake CPUs have FPGAs. They were
        released in Spring but Google and Amazon bought them all so we
        have to wait for new ones to be produced.
    - Do we have the right compilers/toolchain ? Is it functional ?
      - Maybe. :) Intel is supposed to provide us with an OpenCL to
        FPGA compiler with their Skylake chips.
      - Before, Pedro used an open-source High Level Synthesis tool.
    - Can we explore application structures for FPGAs with BOAST ?
      - Sure, why not ?

  - Arnaud mentions http://www.exanest.eu/ and Fabien Chaix he knows
    quite well.
  - Pedro's work was published at ReConfig (Cancun) and Alfredo's
    currently presenting it.
    - https://github.com/phrb/slides-reconfig-2017-autotuning
    -
https://github.com/phrb/slides-reconfig-2017-autotuning/raw/master/src/presentation.pdf
      - Slide 9: We have a quick discussion on why there is a single
        configuration file controlling all the knobs/parameters of the
        blue workflow compared to being able to obtain intermediary
        information and possibly perform selections at each step
        before moving to the next one.
      - Slide 9: This phase is fast. It's the compiling from the
        Verilog format to the hardware synthesis that is really
        slow. They use Quartus. Quartus also has parameters but this
        parameter space was not explored yet in this work.
        - LegUp is supposed to have a cost model that allows to guide
          the optimization without going all the way down to the
          hardware synthesis to evaluate configurations but it was not
          functional.
      - Slide 11: summarizes the whole workflow. 6+ compilation passes
      - Brice wonders if peak performance models exists for such
        app/systems. It would be worth knowing how far we are from the
        optimal to decide whether further optimizations are needed.
      - Quick discussion about multi-criteria optimization and Pareto
        front.
***** Stuff to do
- Create a big data frame with all the samples you obtained during the
  exploration of the autotuner. We'll try to explore (metric
  variability, parameter space exploration, criteria Pareto structure)
  it together.
- The same could be done for GPU experiments.
*** [2017-12-07 Thu]
- Creating data frames for FPGA data ([[Creating a Data Frame for FPGA Autotuning Samples][Main Section]])
**** Arnaud's Lecture on Linear Regression
The slides and code are hosted at
[[https://github.com/alegrand/SMPE][GitHub]].
*** [2017-12-08 Fri]
- Finish the data frames for FPGA data ([[Creating a Data Frame for FPGA Autotuning Samples][Main Section]])
- Initial FPGA Data Analysis ([[Analysing FPGA Autotuning Samples][Main Section]])
- Ask for help to complete ADUM Registration
*** [2017-12-11 Mon]
- Explore correlations between FPGA metrics and parameters ([[Attempts at Computing Correlations][Main Section]])
- Use Vinicius' info to complete ADUM registration
- Read [[file:~/Dropbox/papers/stochastic-search/schkufza2016stochastic.pdf][Schkufza]]'s paper
**** Reading the [[file:~/Dropbox/papers/autotuning/cronsioe2013boast.pdf][BOAST]] paper
- BOAST: Bringing Optimization through Automatic
  Source-to-source Transformations
- Optimizes loop structures for different HPC architectures
  - Loop unrolling and tiling
***** Questions
1. Why loop tiling with PIPS was not performed and measured?
2. What would be the improvements of appling unrolling and
   tiling to the same loop?
3. Can "search-based" strategies help for larger loops?
2. What would be the improvements of appling unrolling and
   tiling to the same loop?
3. Can "search-based" strategies help for larger loops?
***** Optimization Methodology
- Compare BOAST with PIPS, another code transformation tool
- Benchmark transformed code to find the best version
  - Objective: Perform loop unrolling and tiling using PIPS
    - Did not perform loop tiling with PIPS
  - Independently measured hardware counters
  - Hardware counters:
    - Cache accesses and misses
    - Instruction cache misses
    - TLB data and instruction misses
    - Total CPU cycles

