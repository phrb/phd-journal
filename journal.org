#+STARTUP: overview indent inlineimages logdrawer
#+TITLE:  Pedro's Journal
#+AUTHOR:      Pedro Bruel
#+LANGUAGE:    en
#+TAGS: noexport(n) Stats(S)
#+TAGS: Teaching(T) R(R) OrgMode(O) Python(P)
#+TAGS: Book(b) DOE(D) Code(C) NODAL(N) FPGA(F) Autotuning(A) Arnaud(r)
#+TAGS: ExportableReports(E)
#+TAGS: FAPESP(f)
#+TAGS: DataVis(v) PaperReview(W)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w@) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

#+LATEX_CLASS_OPTIONS: [a4paper]
#+LATEX_HEADER: \usepackage[margin=2cm]{geometry}
#+LATEX_HEADER: \usepackage{amsmath,amsfonts,amssymb,amsthm}
#+LATEX_HEADER: \usepackage[dvipsnames]{xcolor}
#+LATEX_HEADER: \usepackage{sourcecodepro}
#+LATEX_HEADER: \usepackage{forest}
#+LATEX_HEADER: \usepackage{rotating}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{array}
#+LATEX_HEADER: \usepackage{colortbl}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usepackage{tikz-qtree}
#+LATEX_HEADER: \usepackage{algpseudocode}
#+LATEX_HEADER: \usepackage{algorithm}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \usepackage[scale=2]{ccicons}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{relsize}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{bm}
#+LATEX_HEADER: \usepackage{amsfonts}
#+LATEX_HEADER: \usepackage{wasysym}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \usepackage{ragged2e}
#+LATEX_HEADER: \usepackage{textcomp}
#+LATEX_HEADER: \usepackage{pgfplots}
#+LATEX_HEADER: \usepackage{todonotes}
#+LATEX_HEADER: \usepgfplotslibrary{dateplot}
#+LATEX_HEADER: \lstdefinelanguage{Julia}%
#+LATEX_HEADER:   {morekeywords={abstract,struct,break,case,catch,const,continue,do,else,elseif,%
#+LATEX_HEADER:       end,export,false,for,function,immutable,mutable,using,import,importall,if,in,%
#+LATEX_HEADER:       macro,module,quote,return,switch,true,try,catch,type,typealias,%
#+LATEX_HEADER:       while,<:,+,-,::,/},%
#+LATEX_HEADER:    sensitive=true,%
#+LATEX_HEADER:    alsoother={$},%
#+LATEX_HEADER:    morecomment=[l]\#,%
#+LATEX_HEADER:    morecomment=[n]{\#=}{=\#},%
#+LATEX_HEADER:    morestring=[s]{"}{"},%
#+LATEX_HEADER:    morestring=[m]{'}{'},%
#+LATEX_HEADER: }[keywords,comments,strings]%
#+LATEX_HEADER: \lstset{ %
#+LATEX_HEADER:   backgroundcolor={},
#+LATEX_HEADER:   basicstyle=\ttfamily\scriptsize,
#+LATEX_HEADER:   breakatwhitespace=true,
#+LATEX_HEADER:   breaklines=true,
#+LATEX_HEADER:   captionpos=n,
# #+LATEX_HEADER:   escapeinside={\%*}{*)},
#+LATEX_HEADER:   extendedchars=true,
#+LATEX_HEADER:   frame=n,
#+LATEX_HEADER:   language=R,
#+LATEX_HEADER:   rulecolor=\color{black},
#+LATEX_HEADER:   showspaces=false,
#+LATEX_HEADER:   showstringspaces=false,
#+LATEX_HEADER:   showtabs=false,
#+LATEX_HEADER:   stepnumber=2,
#+LATEX_HEADER:   stringstyle=\color{gray},
#+LATEX_HEADER:   tabsize=2,
#+LATEX_HEADER: }
#+LATEX_HEADER: \renewcommand*{\UrlFont}{\ttfamily\smaller\relax}

* Setup
** Julia
#+NAME: install_julia_deps
#+HEADER: :results output :session *julia*
#+BEGIN_SRC julia
Pkg.add("Plots")
Pkg.add("Lint")
Pkg.add("Gadfly")
Pkg.add("ProfileView")
Pkg.add("CSV")
Pkg.add("StatsBase")
Pkg.add("StatsModels")
Pkg.add("GLM")
Pkg.add("RDatasets")
Pkg.add("IterTools")
Pkg.add("Missings")
Pkg.add("RCall")
Pkg.add("DataFrames")
#+END_SRC

#+RESULTS: install_julia_deps
#+begin_example
INFO: Package Plots is already installed
INFO: Package Lint is already installed
INFO: Package Gadfly is already installed
INFO: Cloning cache of Gtk from https://github.com/JuliaGraphics/Gtk.jl.git
INFO: Cloning cache of GtkReactive from https://github.com/JuliaGizmos/GtkReactive.jl.git
INFO: Cloning cache of IntervalSets from https://github.com/JuliaMath/IntervalSets.jl.git
INFO: Cloning cache of ProfileView from https://github.com/timholy/ProfileView.jl.git
INFO: Cloning cache of Reactive from https://github.com/JuliaGizmos/Reactive.jl.git
INFO: Cloning cache of RoundingIntegers from https://github.com/JuliaMath/RoundingIntegers.jl.git
INFO: Installing Gtk v0.13.1
INFO: Installing GtkReactive v0.4.0
INFO: Installing IntervalSets v0.1.1
INFO: Installing ProfileView v0.3.0
INFO: Installing Reactive v0.6.0
INFO: Installing RoundingIntegers v0.0.3
INFO: Building Cairo
INFO: Building Gtk
INFO: Package database updated
INFO: Package CSV is already installed
INFO: Package StatsBase is already installed
INFO: Package StatsModels is already installed
INFO: Package GLM is already installed
INFO: Package RDatasets is already installed
#+end_example

#+NAME: update_julia_pkg
#+HEADER:  :results output :session *julia*
#+BEGIN_SRC julia
Pkg.update()
#+END_SRC

#+RESULTS: update_julia_pkg
: INFO: Updating METADATA...
: WARNING: Package ASTInterpreter: skipping update (dirty)...
: INFO: Updating Gallium master...
: INFO: Computing changes...
: INFO: No packages to install, update or remove

** R
Installing *R* dependencies:
#+NAME: install_r_deps
#+HEADER: :results output :exports both :session *R*
#+BEGIN_SRC R
install.packages(c("ggplot2", "dplyr", "tidyr", "rjson", "GGally",
                 "plotly", "rPref", "pracma", "FrF2", "AlgDesign",
                 "quantreg"),
                 repos = "https://mirror.ibcp.fr/pub/CRAN/")
#+END_SRC

#+RESULTS: install_r_deps

** Modifying & Analysing the FPGA Data Set
Cloning and updating the =legup-tuner= repository:

#+NAME: update_legup_tuner
#+BEGIN_SRC sh :results output
git clone https://github.com/phrb/legup-tuner.git || (cd legup-tuner && git pull)
#+END_SRC

Export your path to =repository_dir= variable:

#+name: repository_dir
#+begin_src sh :results output :exports both
pwd | tr -d "\n"
#+end_src

** Updating & Cloning Repositories
*** GPU Autotuning Screening Experiment
#+NAME: update_screening_experiment
#+BEGIN_SRC sh :results output
git clone https://github.com/phrb/autotuning_screening_experiment.git || (cd autotuning_screening_experiment && git pull)
#+END_SRC
* 2019
** August
*** [2019-08-05 Mon]
**** Performance Modeling and Optimization of the =bicg= SPAPT kernel :ExportableReports:
:PROPERTIES:
:EXPORT_FILE_NAME: report.pdf
:END:
#+LATEX: \tableofcontents
***** Initial Setup                                            :noexport:
****** Cloning/Pulling the Repository                         :noexport:
#+HEADER: :results output :eval no-export :exports none
#+BEGIN_SRC shell
git clone https://github.com/phrb/dlmt_spapt_experiments.git || (cd dlmt_spapt_experiments && git pull)
#+END_SRC

#+RESULTS:
: Already up to date.
***** Introduction
The objective  of this  report is  to analyze  data from  our CCGRID  paper, and
perform new experiments  as needed, in order to better  understand the statiscal
analysis and the performance achieved by  our DoE-based approach.  We would like
to understand how a user could  interfere and guide search space restriction and
exploration, by intervening at each ANOVA step, for example.

We are also interested in exploring new design construction metrics, in order to
understand which  factors are best estimated  at each step and  possibly discard
designs not capable of estimating parameters of interest.

We chose to  start with the =bicg= SPAPT  kernel. It was one of  the kernels where
our approach  achieved similar-performing  solutions using less  experiments, in
comparison with a uniform random sampling  approach, across 10 repetitions of an
experiment with a fixed  budget of 400 experiments and a  limit of 4 iterations,
or steps, of our approach.

The  following sections  describe  our ongoing  exploration  of the  performance
modeling and optimization of the =bicg= kernel.
***** Original Results
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/results"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)
#+end_SRC

#+RESULTS:
#+begin_example

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Warning message:
replacing previous import ‘vctrs::data_frame’ by ‘tibble::data_frame’ when loading ‘dplyr’
'data.frame':	75530 obs. of  138 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ SCR1                        : chr  "False" "True" "False" "True" ...
 $ SCR2                        : chr  "False" "True" "False" "True" ...
 $ T1_I1                       : int  32 1 32 256 8 16 1 2 1 32 ...
 $ T1_I2a                      : int  1 64 2 2 4 256 512 32 64 1 ...
 $ RT2_I2                      : int  32 1 16 8 2 2 4 8 8 2 ...
 $ RT2_I1                      : int  2 8 4 16 2 2 1 8 8 1 ...
 $ mean_confidence_interval_inf: num  6.23 5.83 5.84 11.44 5.68 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ technique                   : chr  "RS" "RS" "RS" "RS" ...
 $ VEC2                        : chr  "False" "False" "True" "False" ...
 $ U1_I2                       : int  1 1 1 23 1 20 1 13 27 1 ...
 $ U1_I1                       : int  2 18 24 1 9 1 30 1 1 22 ...
 $ T2_I2a                      : int  512 1024 512 2048 512 256 256 512 128 2048 ...
 $ VEC1                        : chr  "False" "True" "True" "False" ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ T1_I1a                      : int  128 8 1024 2048 1 512 128 512 32 2048 ...
 $ U2_I2                       : int  26 1 30 25 5 15 16 17 18 1 ...
 $ U2_I1                       : int  1 1 1 1 1 1 1 1 1 4 ...
 $ RT1_I2                      : int  32 4 1 16 16 8 1 1 1 1 ...
 $ RT1_I1                      : int  4 32 4 4 1 4 8 4 8 1 ...
 $ cost_std                    : num  0.000435 0.002837 0.00016 0.000402 0.000257 ...
 $ cost_mean                   : num  6.23 5.84 5.84 11.44 5.68 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_I2                       : int  32 4 2 128 64 16 4 128 128 256 ...
 $ T2_I1                       : int  512 16 64 1024 64 2 8 8 16 256 ...
 $ T1_I2                       : int  2 8 2 1 4 128 8 1 4 2 ...
 $ mean_confidence_interval_sup: num  6.23 5.84 5.84 11.44 5.68 ...
 $ T2_I1a                      : int  2048 2048 1024 1024 1024 256 1024 64 128 1 ...
 $ experiment_id               : chr  NA NA NA NA ...
 $ cost_baseline               : num  4.41 4.41 4.41 4.41 4.41 ...
 $ speedup                     : num  0.708 0.756 0.756 0.386 0.777 ...
 $ max_run_speedup             : num  1.36 1.36 1.36 1.36 1.36 ...
 $ min_run_cost                : num  3.24 3.24 3.24 3.24 3.24 ...
 $ best_iteration              : num  39 39 39 39 39 39 39 39 39 39 ...
 $ points                      : int  300 300 300 300 300 300 300 300 300 300 ...
 $ application                 : chr  "adi" "adi" "adi" "adi" ...
 $ T2_K                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T2_J                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T2_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ RT_K                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T1_J                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T1_K                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ SCR                         : chr  NA NA NA NA ...
 $ ACOPY_x                     : chr  NA NA NA NA ...
 $ ACOPY_y                     : chr  NA NA NA NA ...
 $ U1_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ RT_J                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T1_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U_J                         : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U_I                         : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U_K                         : int  NA NA NA NA NA NA NA NA NA NA ...
 $ RT_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ OMP                         : chr  NA NA NA NA ...
 $ T3_J                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T3_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T2_Ja                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T2_Ia                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T3_Ja                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ VEC3                        : chr  NA NA NA NA ...
 $ U2_J                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ SCREP                       : chr  NA NA NA NA ...
 $ RT2_I                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U2_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ RT2_J                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ OMP3                        : chr  NA NA NA NA ...
 $ RT3_I                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ OMP2                        : chr  NA NA NA NA ...
 $ RT3_J                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T3_Ia                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U3_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U3_J                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T5_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T1_Ja                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ RT1_J                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ RT7_I                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ VEC10                       : chr  NA NA NA NA ...
 $ RT7_J                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T5_J                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ VEC9                        : chr  NA NA NA NA ...
 $ RT1_I                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ VEC6                        : chr  NA NA NA NA ...
 $ T5_Ia                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ VEC7                        : chr  NA NA NA NA ...
 $ VEC4                        : chr  NA NA NA NA ...
 $ VEC5                        : chr  NA NA NA NA ...
 $ T7_J                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T7_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T7_Ia                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ VEC8                        : chr  NA NA NA NA ...
 $ U10_I                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U6_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ T1_Ia                       : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U5_J                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U5_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U1_J                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U8_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U7_I                        : int  NA NA NA NA NA NA NA NA NA NA ...
 $ U7_J                        : int  NA NA NA NA NA NA NA NA NA NA ...
  [list output truncated]
tibble [360 × 141] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:360] 39 239 202 192 161 43 251 266 78 37 ...
 $ SCR1                        : chr [1:360] "True" "True" "True" "True" ...
 $ SCR2                        : chr [1:360] "True" "True" "True" "False" ...
 $ T1_I1                       : int [1:360] 2 1 8 32 8 32 64 2 1 16 ...
 $ T1_I2a                      : int [1:360] 1 1024 64 32 64 2048 2048 64 2048 2048 ...
 $ RT2_I2                      : int [1:360] 2 4 1 1 2 1 2 2 1 1 ...
 $ RT2_I1                      : int [1:360] 1 1 1 4 1 1 1 8 16 16 ...
 $ mean_confidence_interval_inf: num [1:360] 3.23 3.11 4.36 4.36 3.12 ...
 $ baseline                    : chr [1:360] "False" "False" "False" "False" ...
 $ technique                   : chr [1:360] "RS" "DLMT" "DLMT" "RS" ...
 $ VEC2                        : chr [1:360] "True" "True" "True" "True" ...
 $ U1_I2                       : int [1:360] 21 6 1 1 1 11 1 1 1 1 ...
 $ U1_I1                       : int [1:360] 1 1 29 6 21 1 30 22 19 21 ...
 $ T2_I2a                      : int [1:360] 16 1 2048 1 1 512 2048 1024 1024 1 ...
 $ VEC1                        : chr [1:360] "True" "True" "True" "False" ...
 $ runs                        : int [1:360] 10 10 10 10 10 10 10 10 10 10 ...
 $ T1_I1a                      : int [1:360] 2 2048 1 256 2048 2048 1 2 512 16 ...
 $ U2_I2                       : int [1:360] 1 29 17 25 1 1 3 1 1 30 ...
 $ U2_I1                       : int [1:360] 13 1 1 1 11 21 1 12 10 1 ...
 $ RT1_I2                      : int [1:360] 32 16 4 32 16 16 1 16 4 16 ...
 $ RT1_I1                      : int [1:360] 4 1 32 4 1 1 2 8 2 1 ...
 $ cost_std                    : num [1:360] 1.02e-02 5.16e-03 1.89e-03 6.92e-05 5.25e-03 ...
 $ cost_mean                   : num [1:360] 3.24 3.11 4.36 4.36 3.12 ...
 $ correct_result              : chr [1:360] "True" "True" "True" "True" ...
 $ T2_I2                       : int [1:360] 16 2048 2 2 2048 512 1 32 1024 1024 ...
 $ T2_I1                       : int [1:360] 2 8 1 2 1 2 1 4 4 1 ...
 $ T1_I2                       : int [1:360] 128 1 4 2 64 1 2048 1 128 1 ...
 $ mean_confidence_interval_sup: num [1:360] 3.25 3.12 4.36 4.36 3.13 ...
 $ T2_I1a                      : int [1:360] 512 32 2048 256 4 2 1 2048 8 4 ...
 $ experiment_id               : chr [1:360] NA NA NA NA ...
 $ cost_baseline               : num [1:360] 4.41 4.41 4.41 4.42 4.41 ...
 $ speedup                     : num [1:360] 1.36 1.42 1.01 1.01 1.41 ...
 $ max_run_speedup             : num [1:360] 1.36 1.42 1.01 1.01 1.41 ...
 $ min_run_cost                : num [1:360] 3.24 3.11 4.36 4.36 3.12 ...
 $ best_iteration              : num [1:360] 39 239 202 192 161 43 251 266 78 37 ...
 $ points                      : int [1:360] 300 342 386 300 383 300 339 300 350 416 ...
 $ application                 : chr [1:360] "adi" "adi" "adi" "adi" ...
 $ T2_K                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T2_J                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T2_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ RT_K                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T1_J                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T1_K                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ SCR                         : chr [1:360] NA NA NA NA ...
 $ ACOPY_x                     : chr [1:360] NA NA NA NA ...
 $ ACOPY_y                     : chr [1:360] NA NA NA NA ...
 $ U1_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ RT_J                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T1_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U_J                         : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U_I                         : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U_K                         : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ RT_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ OMP                         : chr [1:360] NA NA NA NA ...
 $ T3_J                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T3_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T2_Ja                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T2_Ia                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T3_Ja                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ VEC3                        : chr [1:360] NA NA NA NA ...
 $ U2_J                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ SCREP                       : chr [1:360] NA NA NA NA ...
 $ RT2_I                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U2_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ RT2_J                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ OMP3                        : chr [1:360] NA NA NA NA ...
 $ RT3_I                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ OMP2                        : chr [1:360] NA NA NA NA ...
 $ RT3_J                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T3_Ia                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U3_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U3_J                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T5_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T1_Ja                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ RT1_J                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ RT7_I                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ VEC10                       : chr [1:360] NA NA NA NA ...
 $ RT7_J                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T5_J                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ VEC9                        : chr [1:360] NA NA NA NA ...
 $ RT1_I                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ VEC6                        : chr [1:360] NA NA NA NA ...
 $ T5_Ia                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ VEC7                        : chr [1:360] NA NA NA NA ...
 $ VEC4                        : chr [1:360] NA NA NA NA ...
 $ VEC5                        : chr [1:360] NA NA NA NA ...
 $ T7_J                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T7_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T7_Ia                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ VEC8                        : chr [1:360] NA NA NA NA ...
 $ U10_I                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U6_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ T1_Ia                       : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U5_J                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U5_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U1_J                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U8_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U7_I                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
 $ U7_J                        : int [1:360] NA NA NA NA NA NA NA NA NA NA ...
  [list output truncated]
#+end_example

****** Update File
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)

it_data = complete_plot_data %>%
    filter(application == "bicgkernel",
           technique != "RS") %>%
    mutate(mean_cost_baseline = unique(mean_cost_baseline),
           technique = gsub(pattern = "DLMT",
                            replacement = "Original",
                            x = technique,
                            fixed = TRUE)) %>%
    select(min_run_cost,
           technique,
           mean_cost_baseline,
           best_iteration,
           application)

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

mixed_data  =  read.csv("data/complete_bicgkernel_data.csv") %>%
    select(min_run_cost,
           technique,
           mean_cost_baseline,
           best_iteration,
           application)


mixed_plot_data = bind_rows(mixed_data, it_data)

write.csv(mixed_plot_data,
          "data/complete_bicgkernel_data.csv",
          row.names = FALSE)
#+END_SRC

#+RESULTS:

***** Removing Cubic Terms
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/formula_log_encoded"
#current_experiment <- "dlmt_spapt_experiments/data/tests/threshold_0.01_16x_nocube_logged"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

data_dir <- "dlmt_spapt_experiments/data/results"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][5], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS",
                              application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	61 obs. of  3 variables:
 $ removed_variables: Factor w/ 12 levels "","OMP","SCR",..: 2 3 1 1 1 1 1 2 7 4 ...
  ..- attr(*, "names")= chr [1:61] "['OMP'" "'SCR']" "[]" "[]" ...
 $ step             : int  1 1 2 3 4 1 2 3 4 4 ...
 $ experiment_id    : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
'data.frame':	520 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->64" "T1_J->32" "U_J->18" "U_I->1" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ experiment_id          : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
------------------------------------------------------------------------------
You have loaded plyr after dplyr - this is likely to cause problems.
If you need functions from both plyr and dplyr, please load plyr first, then dplyr:
library(plyr); library(dplyr)
------------------------------------------------------------------------------

Attaching package: ‘plyr’

The following objects are masked from ‘package:rPref’:

    empty, true

The following objects are masked from ‘package:dplyr’:

    arrange, count, desc, failwith, id, mutate, rename, summarise,
    summarize

Attaching package: ‘reshape2’

The following object is masked from ‘package:tidyr’:

    smiths
Registering fonts with R
'data.frame':	999 obs. of  31 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  2048 1024 1024 512 1 1 1 2048 1 32 ...
 $ T2_I                        : int  512 128 512 2048 32 2048 16 1 256 2048 ...
 $ RT_I                        : int  8 32 1 32 1 32 1 2 1 4 ...
 $ mean_confidence_interval_inf: num  0.873 4.582 0.831 0.834 4.575 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  2 1024 128 128 64 2048 1024 1024 1 4 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "False" "True" "True" ...
 $ VEC1                        : chr  "True" "False" "True" "False" ...
 $ SCR                         : chr  "True" "False" "True" "False" ...
 $ U1_I                        : int  30 1 9 17 29 6 14 12 9 12 ...
 $ RT_J                        : int  2 2 8 1 1 2 32 1 32 32 ...
 $ T1_I                        : int  2 4 1 1 1 1 16 16 32 1 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.065226 0.000207 0.058666 0.118338 0.000682 ...
 $ cost_mean                   : num  0.913 4.582 0.868 0.907 4.576 ...
 $ U_J                         : int  1 18 1 29 6 1 1 1 30 1 ...
 $ U_I                         : int  20 1 30 1 1 2 11 11 1 21 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "False" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.954 4.582 0.904 0.981 4.576 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
 $ cost_baseline               : num  4.86 4.86 4.86 4.86 4.86 ...
 $ speedup                     : num  5.32 1.06 5.6 5.35 1.06 ...
 $ max_run_speedup             : num  9.26 9.26 9.26 9.26 9.26 ...
 $ min_run_cost                : num  0.524 0.524 0.524 0.524 0.524 ...
 $ best_iteration              : num  86 86 86 86 86 86 86 86 86 86 ...
 $ points                      : int  101 101 101 101 101 101 101 101 101 101 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
tibble [10 × 34] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:10] 86 104 64 78 57 109 93 69 73 43
 $ T2_J                        : int [1:10] 1 2048 1024 256 2048 1024 128 1024 2048 256
 $ T2_I                        : int [1:10] 1 2048 1 2048 2048 2048 2048 2048 2048 1
 $ RT_I                        : int [1:10] 1 4 4 8 8 4 1 8 1 1
 $ mean_confidence_interval_inf: num [1:10] 0.493 0.409 0.437 0.477 0.45 ...
 $ baseline                    : chr [1:10] "False" "False" "False" "False" ...
 $ T1_J                        : int [1:10] 64 2 1024 256 1 1 2 1 2048 128
 $ technique                   : chr [1:10] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr [1:10] "True" "True" "False" "False" ...
 $ VEC1                        : chr [1:10] "False" "False" "False" "False" ...
 $ SCR                         : chr [1:10] "True" "True" "True" "False" ...
 $ U1_I                        : int [1:10] 25 2 16 1 4 7 15 2 4 19
 $ RT_J                        : int [1:10] 1 32 4 4 4 8 1 1 8 1
 $ T1_I                        : int [1:10] 2048 8 2048 1 2048 2048 2048 1024 1 2048
 $ runs                        : int [1:10] 10 10 10 10 10 10 10 10 10 10
 $ cost_std                    : num [1:10] 0.0505 0.24 0.0625 0.0394 0.1464 ...
 $ cost_mean                   : num [1:10] 0.524 0.558 0.475 0.502 0.54 ...
 $ U_J                         : int [1:10] 1 1 30 21 1 29 1 1 1 1
 $ U_I                         : int [1:10] 30 9 1 1 13 1 13 1 12 16
 $ step                        : int [1:10] 4 4 3 3 3 4 4 3 3 2
 $ correct_result              : chr [1:10] "True" "True" "True" "True" ...
 $ OMP                         : chr [1:10] "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num [1:10] 0.556 0.706 0.514 0.526 0.631 ...
 $ experiment_id               : chr [1:10] "parasilo-1" "parasilo-10" "parasilo-11" "parasilo-13" ...
 $ cost_baseline               : num [1:10] 4.86 4.85 4.75 4.75 4.86 ...
 $ speedup                     : num [1:10] 9.26 8.7 10 9.48 8.99 ...
 $ max_run_speedup             : num [1:10] 9.26 8.7 10 9.48 8.99 ...
 $ min_run_cost                : num [1:10] 0.524 0.558 0.475 0.502 0.54 ...
 $ best_iteration              : num [1:10] 86 104 64 78 57 109 93 69 73 43
 $ points                      : int [1:10] 101 106 94 102 103 106 91 103 98 95
 $ application                 : chr [1:10] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:10] 4.8 4.8 4.8 4.8 4.8 ...
 $ label_center_x              : num [1:10] 1.47 1.47 1.47 1.47 1.47 ...
 $ label_center_y              : num [1:10] 78 78 78 78 78 ...
tibble [20 × 34] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:20] 86 104 64 78 57 109 93 69 73 43 ...
 $ T2_J                        : int [1:20] 1 2048 1024 256 2048 1024 128 1024 2048 256 ...
 $ T2_I                        : int [1:20] 1 2048 1 2048 2048 2048 2048 2048 2048 1 ...
 $ RT_I                        : int [1:20] 1 4 4 8 8 4 1 8 1 1 ...
 $ mean_confidence_interval_inf: num [1:20] 0.493 0.409 0.437 0.477 0.45 ...
 $ baseline                    : chr [1:20] "False" "False" "False" "False" ...
 $ T1_J                        : int [1:20] 64 2 1024 256 1 1 2 1 2048 128 ...
 $ technique                   : chr [1:20] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr [1:20] "True" "True" "False" "False" ...
 $ VEC1                        : chr [1:20] "False" "False" "False" "False" ...
 $ SCR                         : chr [1:20] "True" "True" "True" "False" ...
 $ U1_I                        : int [1:20] 25 2 16 1 4 7 15 2 4 19 ...
 $ RT_J                        : int [1:20] 1 32 4 4 4 8 1 1 8 1 ...
 $ T1_I                        : int [1:20] 2048 8 2048 1 2048 2048 2048 1024 1 2048 ...
 $ runs                        : int [1:20] 10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num [1:20] 0.0505 0.24 0.0625 0.0394 0.1464 ...
 $ cost_mean                   : num [1:20] 0.524 0.558 0.475 0.502 0.54 ...
 $ U_J                         : int [1:20] 1 1 30 21 1 29 1 1 1 1 ...
 $ U_I                         : int [1:20] 30 9 1 1 13 1 13 1 12 16 ...
 $ step                        : int [1:20] 4 4 3 3 3 4 4 3 3 2 ...
 $ correct_result              : chr [1:20] "True" "True" "True" "True" ...
 $ OMP                         : chr [1:20] "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num [1:20] 0.556 0.706 0.514 0.526 0.631 ...
 $ experiment_id               : chr [1:20] "parasilo-1" "parasilo-10" "parasilo-11" "parasilo-13" ...
 $ cost_baseline               : num [1:20] 4.86 4.85 4.75 4.75 4.86 ...
 $ speedup                     : num [1:20] 9.26 8.7 10 9.48 8.99 ...
 $ max_run_speedup             : num [1:20] 9.26 8.7 10 9.48 8.99 ...
 $ min_run_cost                : num [1:20] 0.524 0.558 0.475 0.502 0.54 ...
 $ best_iteration              : num [1:20] 86 104 64 78 57 109 93 69 73 43 ...
 $ points                      : int [1:20] 101 106 94 102 103 106 91 103 98 95 ...
 $ application                 : chr [1:20] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:20] 4.8 4.8 4.8 4.8 4.8 ...
 $ label_center_x              : num [1:20] 1.47 1.47 1.47 1.47 1.47 ...
 $ label_center_y              : num [1:20] 78 78 78 78 78 ...
'data.frame':	36 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ valid_configurations   : int  37440 37440 37440 37440 37440 37440 37440 37440 37440 37440 ...
 $ D                      : num  0.203 0.203 0.205 0.205 0.205 ...
 $ used_budget            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ model_size             : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best           : num  0.53 0.53 0.659 0.659 0.636 ...
 $ trials                 : int  26 26 26 26 26 26 26 26 26 26 ...
 $ current_best_coordinate: chr  "{'T1_I': 64, 'T1_J': 32, 'U_J': 18, 'U_I': 1, 'T2_I': 2048, 'T2_J': 1, 'U1_I': 28, 'OMP': True, 'VEC2': True, '"| __truncated__ "{'T1_I': 64, 'T1_J': 32, 'U_J': 18, 'U_I': 1, 'T2_I': 2048, 'T2_J': 1, 'U1_I': 28, 'OMP': True, 'VEC2': True, '"| __truncated__ "{'T1_I': 32, 'T1_J': 64, 'U_J': 1, 'U_I': 17, 'T2_I': 2048, 'T2_J': 64, 'U1_I': 29, 'OMP': True, 'VEC2': False,"| __truncated__ "{'T1_I': 32, 'T1_J': 64, 'U_J': 1, 'U_I': 17, 'T2_I': 2048, 'T2_J': 64, 'U1_I': 29, 'OMP': True, 'VEC2': False,"| __truncated__ ...
 $ tested_configurations  : int  1789293 1789293 1796907 1796907 1793026 1788535 1790630 1790630 1796726 1796726 ...
 $ fixed_factors          : chr  "{'OMP': 1, 'SCR': 1}" "{'OMP': 1, 'SCR': 1}" "{'OMP': 1, 'SCR': 1}" "{'OMP': 1, 'SCR': 1}" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ design_best            : num  0.53 0.53 0.659 0.659 0.636 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "OMP" "SCR" "OMP" "SCR" ...
 $ model                  : chr  "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  0.74 0.74 0.742 0.742 0.727 ...
 $ experiment_id          : chr  "parasilo-1" "parasilo-1" "parasilo-11" "parasilo-11" ...
'data.frame':	1028 obs. of  24 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  2048 1024 1024 512 1 1 1 2048 1 32 ...
 $ T2_I                        : int  512 128 512 2048 32 2048 16 1 256 2048 ...
 $ RT_I                        : int  8 32 1 32 1 32 1 2 1 4 ...
 $ mean_confidence_interval_inf: num  0.873 4.582 0.831 0.834 4.575 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  2 1024 128 128 64 2048 1024 1024 1 4 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "False" "True" "True" ...
 $ VEC1                        : chr  "True" "False" "True" "False" ...
 $ SCR                         : chr  "True" "False" "True" "False" ...
 $ U1_I                        : int  30 1 9 17 29 6 14 12 9 12 ...
 $ RT_J                        : int  2 2 8 1 1 2 32 1 32 32 ...
 $ T1_I                        : int  2 4 1 1 1 1 16 16 32 1 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.065226 0.000207 0.058666 0.118338 0.000682 ...
 $ cost_mean                   : num  0.913 4.582 0.868 0.907 4.576 ...
 $ U_J                         : int  1 18 1 29 6 1 1 1 30 1 ...
 $ U_I                         : int  20 1 30 1 1 2 11 11 1 21 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "False" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.954 4.582 0.904 0.981 4.576 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
Loading required package: DoE.base
Loading required package: grid
Loading required package: conf.design

Attaching package: ‘conf.design’

The following object is masked from ‘package:plyr’:

    join

Registered S3 method overwritten by 'DoE.base':
  method           from
  factorize.factor conf.design

Attaching package: ‘DoE.base’

The following objects are masked from ‘package:stats’:

    aov, lm

The following object is masked from ‘package:graphics’:

    plot.design

The following object is masked from ‘package:base’:

    lengths
There were 40 warnings (use warnings() to see them)
Joining, by = c("id", "step")
tibble [860 × 4] (S3: tbl_df/tbl/data.frame)
 $ metric_value: num [1:860] 0.019 0.0906 0.0788 0.0683 0.071 ...
 $ factors     : chr [1:860] "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr [1:860] "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
 $ step        : num [1:860] 1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
Figure\nbsp[[fig:best-found]] shows the iterations where  the best configuration of each
of the 10 runs was found, for uniform sampling and for our approach.

The results are  the same as the ones  presented in the paper, but  the data are
not the same.  The data for the figures  in this report were obtained with a new
set of  10 repetitions the same  experiment, but using a  performance model with
only linear  and quadratic terms, removing  the cubic terms used  in the paper's
experiments.

#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file "./img/iterations_no_cubic.pdf"
#+HEADER: :width 12 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 4, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.9) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 30) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          #text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 30) +
                theme(text = element_text(family = "serif"),
                      legend.position = c(0.2, 0.5),
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}


mixed_plot_data = it_data %>%
    mutate(technique = gsub(pattern = "DLMT",
                            replacement = "No Cubic Terms",
                            x = technique, fixed = TRUE))

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-no-cubic
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:./img/iterations_no_cubic.pdf]]

The results are very similar from the  ones in the paper, but our approach found
slightly better  configurations slightly  faster. Random  sampling also  found a
much better configuration much faster than before in one experiment.

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J, OMP, SCR, VEC1, VEC2), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "tiny")
#+end_SRC

#+RESULTS:
#+begin_export latex

% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Jan 18, 2021 - 04:05:55 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\tiny
\begin{tabular}{@{\extracolsep{0pt}} ccccccccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & step & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J & OMP & SCR & VEC1 & VEC2 \\
\hline \\[-1.8ex]
parasilo-1 & DLMT & 4 & 0.5244322 & 2048 & 64 & 1 & 30 & 1 & 1 & 25 & 1 & 1 & True & True & False & True \\
parasilo-10 & DLMT & 4 & 0.55769 & 8 & 2 & 1 & 9 & 2048 & 2048 & 2 & 4 & 32 & True & True & False & True \\
parasilo-11 & DLMT & 3 & 0.4753558 & 2048 & 1024 & 30 & 1 & 1 & 1024 & 16 & 4 & 4 & True & True & False & False \\
parasilo-13 & DLMT & 3 & 0.5016148 & 1 & 256 & 21 & 1 & 2048 & 256 & 1 & 8 & 4 & True & False & False & False \\
parasilo-14 & DLMT & 3 & 0.5404449 & 2048 & 1 & 1 & 13 & 2048 & 2048 & 4 & 8 & 4 & True & True & False & True \\
parasilo-17 & DLMT & 4 & 0.5371861 & 2048 & 1 & 29 & 1 & 2048 & 1024 & 7 & 4 & 8 & True & True & True & False \\
parasilo-19 & DLMT & 4 & 0.5507874 & 2048 & 2 & 1 & 13 & 2048 & 128 & 15 & 1 & 1 & True & True & True & True \\
parasilo-2 & DLMT & 3 & 0.5229024 & 1024 & 1 & 1 & 1 & 2048 & 1024 & 2 & 8 & 1 & True & True & True & False \\
parasilo-20 & DLMT & 3 & 0.5643309 & 1 & 2048 & 1 & 12 & 2048 & 2048 & 4 & 1 & 8 & True & True & False & True \\
parasilo-9 & DLMT & 2 & 0.4685077 & 2048 & 128 & 1 & 16 & 1 & 256 & 19 & 1 & 1 & True & True & True & True \\
paravance-50 & RS & NA & 0.5685274 & 512 & 512 & 19 & 1 & 2048 & 1024 & 27 & 4 & 1 & True & True & True & False \\
paravance-51 & RS & NA & 0.5467725 & 1024 & 32 & 10 & 1 & 2048 & 512 & 9 & 8 & 8 & True & True & True & True \\
paravance-52 & RS & NA & 0.5417953 & 2048 & 8 & 9 & 1 & 2048 & 128 & 30 & 8 & 16 & True & True & True & True \\
paravance-53 & RS & NA & 0.5612387 & 2048 & 64 & 16 & 1 & 2048 & 256 & 9 & 16 & 2 & True & True & True & True \\
paravance-54 & RS & NA & 0.5322531 & 2048 & 8 & 1 & 9 & 1 & 1 & 19 & 1 & 1 & True & True & True & False \\
paravance-55 & RS & NA & 0.5540684 & 32 & 4 & 1 & 5 & 2048 & 256 & 4 & 16 & 1 & True & True & False & False \\
paravance-56 & RS & NA & 0.4648199 & 2048 & 1 & 1 & 23 & 1 & 512 & 25 & 8 & 1 & True & True & False & True \\
paravance-57 & RS & NA & 0.5463944 & 256 & 16 & 1 & 15 & 2048 & 512 & 2 & 2 & 2 & True & True & False & False \\
paravance-58 & RS & NA & 0.5496127 & 32 & 1 & 1 & 14 & 2048 & 2048 & 24 & 8 & 4 & True & True & True & True \\
paravance-59 & RS & NA & 0.4758884 & 64 & 16 & 29 & 1 & 2048 & 1 & 27 & 16 & 4 & True & True & True & True \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
Figure\nbsp{}[[fig:eliminated-terms]] shows the /count of  model terms/ that were eliminated
at each color-coded DLMT step.  As before, we see that =OMP= and =SCR= were the most
eliminated factors, especially on the first step.

#+HEADER: :results graphics :session *R*
#+HEADER: :file "./img/eliminated_terms_no_cubic.pdf"
#+HEADER: :width 12 :height 10 :exports results
#+begin_SRC R
base_size <- 25

ggplot(subset(eliminated_terms, removed_variables != ""),
       aes(x = removed_variables,
           fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = c(0.8, 0.95),
        legend.background = element_blank(),
        legend.direction = "horizontal",
        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(name = "Step", palette = "Set2")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:./img/eliminated_terms_no_cubic.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-VnHilA/figurejynTYx.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
Figure\nbsp{}[[fig:encpnc-ff-ss-be]]  shows  the  factors   that  were  identified  as
significant by ANOVA, with significance threshold  of $0.01$, at each DLMT step.
Identifying  a  factor  removes  the corresponding  parameter  from  the  model,
regardless of the  model term that was identified.  Figures  are grouped by each
of the 10 experiments.  Figure headers  identify each run, and correspond to the
names of the Grid5000 machines where experiments were run.

It is interesting that only  /parasilo-19/, /parasilo-20/, and /parasilo-9/ eliminated
any  factor other  than =OMP=  and =SCR=  on  the first  step where  any factor  was
eliminated, and also  that those runs fixed  the factor =RT_I= to  the same value.

We can  also see  that =OMP=  seems to be  the parameter  behind the  most extreme
changes in the execution time of  tested configurations. This is specially clear
at  /parasilo-13/   and  /parasilo-10/,  where  the   explored  configurations  have
relatively high execution time until after step 3, where =OMP= is fixed.

A very slight worsening of execution times, an increase, that is, can be seen at
the fourth step at /parasilo-11/, after =RT_I= was fixed. The minimum execution time
seems to be higher than in the third step.

#+begin_SRC R :results graphics output :session *R* :file "./img/explored_space_no_cubic.pdf" :width 13 :height 12 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 2) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.8) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              size = 3, width = 0.1, height = 0, alpha = 0.2) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            angle = 0,
            color = "white",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = c(1, 2, 3, 4),
                   expand = c(0.3, 0.3)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 25) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        strip.background = element_rect(size = 1, fill = "white"),
        strip.text = element_text(size = 15),
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:explored_space_no_cubic
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:./img/explored_space_no_cubic.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
         RT_J, T1_I, SCR) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-cKpmYZ/figure1ZhJ27.pdf]]

#+begin_SRC R :results graphics output :session *R* :file "./img/models_no_cubic.pdf" :width 15 :height 13 :exports results
all_parameters_plot_data <- full_data %>%
    mutate(RT_I = log2(RT_I)) %>%
    mutate(RT_J = log2(RT_J)) %>%
    mutate(T1_I = log2(T1_I)) %>%
    mutate(T2_I = log2(T2_I)) %>%
    mutate(T1_J = log2(T1_J)) %>%
    mutate(T2_J = log2(T2_J)) %>%
    gather("factor", "level", T2_I, T2_J, RT_I,
           T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
           RT_J, T1_I, SCR) %>%
    mutate(level = str_replace(level, "True", "1")) %>%
    mutate(level = str_replace(level, "False", "0")) %>%
    mutate(level = as.numeric(level)) %>%
    subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
    facet_wrap(factor ~ .,
               ncol = 4,
               scale = "free") +
    geom_point(alpha = 0.4,
               stat = "unique") +
    geom_quantile(formula = y ~ poly(x, 2),
                  quantiles = c(0.05, 0.25, 0.5),
                  size = 1,
                  alpha = 0.6,
                  color = "darkgreen") +
    geom_smooth(method = "lm",
                color = "blue") +
    # geom_smooth(method = "lm",
    #             color = "purple",
    #             formula = y ~ poly(x, 2),
    #             alpha = 0.6) +
    geom_point(data = subset(all_parameters_plot_data,
                             cost_mean == min(cost_mean)),
               size = 2,
               color = "red",
               stat = "unique") +
    ylab("Execution Time (s)") +
    xlab("Factor Levels") +
    theme_bw(base_size = 20) +
    theme(strip.background = element_rect(fill = "white"))
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:./img/models_no_cubic.pdf]]

#+begin_SRC R :results graphics output :session *R* :file "./img/models_fixed_omp_no_cubic.pdf" :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
    mutate(RT_I = log2(RT_I)) %>%
    mutate(RT_J = log2(RT_J)) %>%
    mutate(T1_I = log2(T1_I)) %>%
    mutate(T2_I = log2(T2_I)) %>%
    mutate(T1_J = log2(T1_J)) %>%
    mutate(T2_J = log2(T2_J)) %>%
    subset(OMP == "True") %>%
    gather("factor", "level", T2_I, T2_J, RT_I,
           T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
           RT_J, T1_I, SCR) %>%
    mutate(level = str_replace(level, "True", "1")) %>%
    mutate(level = str_replace(level, "False", "0")) %>%
    mutate(level = as.numeric(level)) %>%
    subset(technique == "RS") %>%
    filter(factor != "OMP")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
    facet_wrap(factor ~ ., ncol = 4, scale = "free") +
    geom_point(alpha = 0.4,
               stat = "unique") +
    geom_quantile(formula = y ~ poly(x, 2),
                  quantiles = c(0.05, 0.25, 0.5),
                  size = 1,
                  alpha = 0.6,
                  color = "darkgreen") +
    geom_smooth(method = "lm", color = "blue") +
    # geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
    geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)),
               size = 2, color = "red",
               stat = "unique") +
    ylab("Execution Time (s)") +
    xlab("Factor Levels") +
    theme_bw(base_size = 20) +
    theme(strip.background = element_rect(fill = "white"))
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, with \texttt{OMP} fixed to \texttt{true}
#+LABEL: fig:lm-rs-nobin
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:./img/models_fixed_omp_no_cubic.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  subset(OMP == "False") %>%
  subset(SCR == "True") %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
         RT_J, T1_I, SCR) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  ylim(c(NA, 2.0)) +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, with \texttt{OMP} fixed to \texttt{false}
#+LABEL: fig:lm-rs-nobin-false
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-cKpmYZ/figurePIKjIp.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-58"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-58"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, with \texttt{OMP} fixed to \texttt{true}, for \texttt{paravance-58}
#+LABEL: fig:lm-rs-nobin-p58
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureva5tXz.pdf]]

******* Re-running =aov= and =lm= on =parasilo-14=                 :noexport:
We are interested in  what would happen with =aov= and =lm=  analyses if we selected
only binary or  numeric factors, respectively, in the problems  where no factors
were identified as significant.

#+begin_SRC R :results output :session *R* :exports none
p14_designs <- subset(design_data, id == "parasilo-14")
str(p14_designs)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	104 obs. of  16 variables:
 $ T1_Ie  : num  -0.167 -0.333 -1 0.833 0.833 ...
 $ T1_Je  : num  0.833 -0.167 -0.5 0.833 -0.167 ...
 $ T2_Ie  : num  0 -1 -1 -1 -1 ...
 $ T2_Je  : num  0.833 0.833 0.833 0.833 -0.167 ...
 $ U1_Ie  : num  0.267 0.867 0.867 -0.733 -1 ...
 $ U_Ie   : num  -0.333 -1 0.133 0.333 -1 ...
 $ U_Je   : num  -1 0.9333 -1 -1 -0.0667 ...
 $ RT_Ie  : num  -0.333 0.667 -1 0.667 -0.333 ...
 $ RT_Je  : num  -1 -0.333 -0.333 -0.333 0.667 ...
 $ SCRe   : int  -1 -1 0 0 0 -1 0 0 0 -1 ...
 $ VEC1e  : int  0 0 0 -1 0 0 0 0 0 -1 ...
 $ VEC2e  : int  -1 -1 0 0 -1 0 0 -1 -1 0 ...
 $ OMPe   : int  -1 -1 0 0 -1 0 -1 0 0 0 ...
 $ id     : chr  "parasilo-14" "parasilo-14" "parasilo-14" "parasilo-14" ...
 $ step   : num  1 1 1 1 1 1 1 1 1 1 ...
 $ formula: chr  "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ ...
#+end_example

******** First Step:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 1 &
                                   correct_result == "True")

p14_step1 <- subset(p14_designs, step == 1)
p14_step1$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step1$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below  is  listed the  =aov=  summary  using the  formula  from  step 1,  for  the
 =parasilo-14= experiment:

#+begin_SRC R :results output latex :session *R* :exports results
library(xtable)
reg <- aov(step_formula, data = select(p14_step1, -id, -step, -formula))

print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:44:42 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.07 & 0.07 & 0.02 & 0.9006 \\
  I(T1\_Je\verb|^|2) & 1 & 0.12 & 0.12 & 0.03 & 0.8671 \\
  I(T2\_Ie\verb|^|2) & 1 & 1.13 & 1.13 & 0.30 & 0.6196 \\
  I(T2\_Je\verb|^|2) & 1 & 0.16 & 0.16 & 0.04 & 0.8470 \\
  I(U1\_Ie\verb|^|2) & 1 & 0.20 & 0.20 & 0.05 & 0.8306 \\
  I(U\_Ie\verb|^|2) & 1 & 3.03 & 3.03 & 0.82 & 0.4321 \\
  I(U\_Je\verb|^|2) & 1 & 1.82 & 1.82 & 0.49 & 0.5338 \\
  I(RT\_Ie\verb|^|2) & 1 & 1.67 & 1.67 & 0.45 & 0.5503 \\
  I(RT\_Je\verb|^|2) & 1 & 0.18 & 0.18 & 0.05 & 0.8406 \\
  T1\_Ie & 1 & 4.16 & 4.16 & 1.12 & 0.3669 \\
  T1\_Je & 1 & 0.08 & 0.08 & 0.02 & 0.8914 \\
  T2\_Ie & 1 & 0.62 & 0.62 & 0.17 & 0.7088 \\
  T2\_Je & 1 & 0.00 & 0.00 & 0.00 & 0.9814 \\
  U1\_Ie & 1 & 1.44 & 1.44 & 0.39 & 0.5765 \\
  U\_Ie & 1 & 1.78 & 1.78 & 0.48 & 0.5384 \\
  U\_Je & 1 & 0.20 & 0.20 & 0.05 & 0.8320 \\
  RT\_Ie & 1 & 1.86 & 1.86 & 0.50 & 0.5299 \\
  RT\_Je & 1 & 0.51 & 0.51 & 0.14 & 0.7357 \\
  SCRe & 1 & 0.11 & 0.11 & 0.03 & 0.8756 \\
  VEC1e & 1 & 0.38 & 0.38 & 0.10 & 0.7703 \\
  VEC2e & 1 & 11.14 & 11.14 & 3.01 & 0.1811 \\
  OMPe & 1 & 10.41 & 10.41 & 2.81 & 0.1922 \\
  Residuals & 3 & 11.11 & 3.70 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the corresponding =lm= summary, using all factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:45:14 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & -0.5839 & 2.4374 & -0.24 & 0.8261 \\
  I(T1\_Ie\verb|^|2) & -0.2431 & 1.3278 & -0.18 & 0.8664 \\
  I(T1\_Je\verb|^|2) & 0.4758 & 1.1416 & 0.42 & 0.7049 \\
  I(T2\_Ie\verb|^|2) & 0.0730 & 1.3430 & 0.05 & 0.9600 \\
  I(T2\_Je\verb|^|2) & 0.0590 & 1.5563 & 0.04 & 0.9721 \\
  I(U1\_Ie\verb|^|2) & -0.5001 & 1.2198 & -0.41 & 0.7093 \\
  I(U\_Ie\verb|^|2) & 0.1348 & 1.4173 & 0.10 & 0.9302 \\
  I(U\_Je\verb|^|2) & 0.9153 & 1.4447 & 0.63 & 0.5714 \\
  I(RT\_Ie\verb|^|2) & -1.0011 & 1.4857 & -0.67 & 0.5487 \\
  I(RT\_Je\verb|^|2) & -0.6684 & 1.4761 & -0.45 & 0.6814 \\
  T1\_Ie & -0.4607 & 0.7685 & -0.60 & 0.5911 \\
  T1\_Je & 0.1903 & 0.8235 & 0.23 & 0.8321 \\
  T2\_Ie & -0.6126 & 0.7159 & -0.86 & 0.4551 \\
  T2\_Je & 0.0893 & 0.6485 & 0.14 & 0.8992 \\
  U1\_Ie & 0.1033 & 0.6584 & 0.16 & 0.8852 \\
  U\_Ie & -0.4396 & 0.7991 & -0.55 & 0.6206 \\
  U\_Je & -0.4164 & 0.8970 & -0.46 & 0.6741 \\
  RT\_Ie & -0.5819 & 1.0100 & -0.58 & 0.6049 \\
  RT\_Je & -0.7700 & 1.0608 & -0.73 & 0.5204 \\
  SCRe & -0.1850 & 0.9460 & -0.20 & 0.8574 \\
  VEC1e & -0.5071 & 0.8662 & -0.59 & 0.5994 \\
  VEC2e & -1.5946 & 0.9118 & -1.75 & 0.1786 \\
  OMPe & -1.4164 & 0.8447 & -1.68 & 0.1922 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that no  factors were  within the filter  threshold. If  we run  the =aov=
analysis  again, but  using a  formula  with only  linear terms  for the  binary
factors, we get the following:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:45:42 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 11.76 & 11.76 & 8.57 & 0.0080 \\
  SCRe & 1 & 0.18 & 0.18 & 0.13 & 0.7188 \\
  VEC1e & 1 & 2.35 & 2.35 & 1.71 & 0.2051 \\
  VEC2e & 1 & 9.08 & 9.08 & 6.62 & 0.0177 \\
  Residuals & 21 & 28.80 & 1.37 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We  see that  =OMP= and  =VEC2= appear  to be  significant, but  only =OMP=  is within
filtering threshold.  If we  had done  this analysis,  we would  have eliminated
=OMP=. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:02 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 1.2879 & 2.5429 & 0.51 & 0.6281 \\
  I(T1\_Ie\verb|^|2) & -0.3443 & 1.3733 & -0.25 & 0.8092 \\
  I(T1\_Je\verb|^|2) & 0.4895 & 1.2750 & 0.38 & 0.7124 \\
  I(T2\_Ie\verb|^|2) & 0.7388 & 1.4653 & 0.50 & 0.6296 \\
  I(T2\_Je\verb|^|2) & -0.1231 & 1.7055 & -0.07 & 0.9445 \\
  I(U1\_Ie\verb|^|2) & -0.1326 & 1.3013 & -0.10 & 0.9217 \\
  I(U\_Ie\verb|^|2) & -0.7352 & 1.5086 & -0.49 & 0.6409 \\
  I(U\_Je\verb|^|2) & 1.1241 & 1.6087 & 0.70 & 0.5073 \\
  I(RT\_Ie\verb|^|2) & -1.4597 & 1.5992 & -0.91 & 0.3917 \\
  I(RT\_Je\verb|^|2) & -0.2175 & 1.6104 & -0.14 & 0.8964 \\
  T1\_Ie & -0.5276 & 0.8441 & -0.63 & 0.5518 \\
  T1\_Je & 0.1608 & 0.9158 & 0.18 & 0.8656 \\
  T2\_Ie & -0.3984 & 0.7922 & -0.50 & 0.6305 \\
  T2\_Je & -0.0715 & 0.7149 & -0.10 & 0.9232 \\
  U1\_Ie & 0.3409 & 0.7285 & 0.47 & 0.6540 \\
  U\_Ie & -0.4304 & 0.8801 & -0.49 & 0.6398 \\
  U\_Je & 0.0087 & 0.9420 & 0.01 & 0.9929 \\
  RT\_Ie & -0.7724 & 1.1074 & -0.70 & 0.5080 \\
  RT\_Je & -0.3787 & 1.1563 & -0.33 & 0.7529 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Nothing seems to substantially change for this case.

******** Second Step:                                       :noexport:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 2 &
                                   correct_result == "True")

p14_step2 <- subset(p14_designs, step == 2)
p14_step2 <- p14_step2[-nrow(p14_step2), ] # Remove extra row
p14_step2$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step2$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below is the =aov= summary using the formula from step 1, at =parasilo-14=:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(step_formula, data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:25 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.00 & 0.00 & 0.00 & 0.9929 \\
  I(T1\_Je\verb|^|2) & 1 & 0.28 & 0.28 & 0.03 & 0.8874 \\
  I(T2\_Ie\verb|^|2) & 1 & 4.25 & 4.25 & 0.39 & 0.5947 \\
  I(T2\_Je\verb|^|2) & 1 & 3.15 & 3.15 & 0.29 & 0.6435 \\
  I(U1\_Ie\verb|^|2) & 1 & 3.11 & 3.11 & 0.29 & 0.6455 \\
  I(U\_Ie\verb|^|2) & 1 & 0.15 & 0.15 & 0.01 & 0.9167 \\
  I(U\_Je\verb|^|2) & 1 & 0.03 & 0.03 & 0.00 & 0.9609 \\
  I(RT\_Ie\verb|^|2) & 1 & 2.25 & 2.25 & 0.21 & 0.6934 \\
  I(RT\_Je\verb|^|2) & 1 & 1.67 & 1.67 & 0.15 & 0.7322 \\
  T1\_Ie & 1 & 10.18 & 10.18 & 0.94 & 0.4344 \\
  T1\_Je & 1 & 5.14 & 5.14 & 0.47 & 0.5621 \\
  T2\_Ie & 1 & 0.38 & 0.38 & 0.04 & 0.8684 \\
  T2\_Je & 1 & 5.43 & 5.43 & 0.50 & 0.5523 \\
  U1\_Ie & 1 & 0.04 & 0.04 & 0.00 & 0.9582 \\
  U\_Ie & 1 & 6.10 & 6.10 & 0.56 & 0.5310 \\
  U\_Je & 1 & 7.02 & 7.02 & 0.65 & 0.5052 \\
  RT\_Ie & 1 & 0.03 & 0.03 & 0.00 & 0.9607 \\
  RT\_Je & 1 & 7.53 & 7.53 & 0.70 & 0.4920 \\
  SCRe & 1 & 0.00 & 0.00 & 0.00 & 0.9893 \\
  VEC1e & 1 & 2.15 & 2.15 & 0.20 & 0.6993 \\
  VEC2e & 1 & 3.20 & 3.20 & 0.30 & 0.6413 \\
  OMPe & 1 & 7.91 & 7.91 & 0.73 & 0.4827 \\
  Residuals & 2 & 21.65 & 10.82 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the =lm= summary:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:43 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & -0.1916 & 7.9828 & -0.02 & 0.9830 \\
  I(T1\_Ie\verb|^|2) & 1.4679 & 2.6477 & 0.55 & 0.6350 \\
  I(T1\_Je\verb|^|2) & 0.6987 & 2.1667 & 0.32 & 0.7777 \\
  I(T2\_Ie\verb|^|2) & 0.6289 & 3.3176 & 0.19 & 0.8672 \\
  I(T2\_Je\verb|^|2) & 1.1182 & 2.3876 & 0.47 & 0.6856 \\
  I(U1\_Ie\verb|^|2) & -0.9683 & 2.5026 & -0.39 & 0.7361 \\
  I(U\_Ie\verb|^|2) & -0.2207 & 2.2762 & -0.10 & 0.9316 \\
  I(U\_Je\verb|^|2) & -0.0863 & 3.2873 & -0.03 & 0.9814 \\
  I(RT\_Ie\verb|^|2) & 1.9707 & 3.1592 & 0.62 & 0.5964 \\
  I(RT\_Je\verb|^|2) & 2.5392 & 3.1931 & 0.80 & 0.5099 \\
  T1\_Ie & 1.2481 & 1.3655 & 0.91 & 0.4572 \\
  T1\_Je & -1.1113 & 1.4826 & -0.75 & 0.5317 \\
  T2\_Ie & 0.5828 & 1.8955 & 0.31 & 0.7875 \\
  T2\_Je & -0.1342 & 1.2659 & -0.11 & 0.9253 \\
  U1\_Ie & -0.2203 & 1.2447 & -0.18 & 0.8758 \\
  U\_Ie & 1.1803 & 1.3740 & 0.86 & 0.4808 \\
  U\_Je & 1.5185 & 2.1771 & 0.70 & 0.5577 \\
  RT\_Ie & 0.8978 & 2.1430 & 0.42 & 0.7160 \\
  RT\_Je & 1.1568 & 1.5989 & 0.72 & 0.5446 \\
  SCRe & -0.5007 & 1.7698 & -0.28 & 0.8038 \\
  VEC1e & 0.5100 & 1.8784 & 0.27 & 0.8114 \\
  VEC2e & -0.1665 & 2.5713 & -0.06 & 0.9543 \\
  OMPe & -1.6240 & 1.8997 & -0.85 & 0.4827 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Now, let's run =aov= again, using only binary factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:59 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 17.13 & 17.13 & 4.92 & 0.0383 \\
  SCRe & 1 & 1.13 & 1.13 & 0.32 & 0.5754 \\
  VEC1e & 1 & 3.14 & 3.14 & 0.90 & 0.3533 \\
  VEC2e & 1 & 0.63 & 0.63 & 0.18 & 0.6758 \\
  Residuals & 20 & 69.64 & 3.48 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that =OMP= and  =VEC2= appear to be  significant, but none  within filtering
threshold. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:18 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 0.7130 & 3.3215 & 0.21 & 0.8371 \\
  I(T1\_Ie\verb|^|2) & 1.3356 & 1.6327 & 0.82 & 0.4446 \\
  I(T1\_Je\verb|^|2) & 0.5249 & 1.5495 & 0.34 & 0.7463 \\
  I(T2\_Ie\verb|^|2) & 0.8102 & 1.7446 & 0.46 & 0.6587 \\
  I(T2\_Je\verb|^|2) & 0.9339 & 1.6036 & 0.58 & 0.5815 \\
  I(U1\_Ie\verb|^|2) & -0.8610 & 1.6098 & -0.53 & 0.6120 \\
  I(U\_Ie\verb|^|2) & -0.3170 & 1.6663 & -0.19 & 0.8554 \\
  I(U\_Je\verb|^|2) & -0.2912 & 1.9952 & -0.15 & 0.8887 \\
  I(RT\_Ie\verb|^|2) & 1.7247 & 1.8927 & 0.91 & 0.3973 \\
  I(RT\_Je\verb|^|2) & 2.3937 & 1.9275 & 1.24 & 0.2606 \\
  T1\_Ie & 1.4526 & 0.9706 & 1.50 & 0.1851 \\
  T1\_Je & -1.2926 & 1.0546 & -1.23 & 0.2662 \\
  T2\_Ie & 0.5029 & 0.9618 & 0.52 & 0.6198 \\
  T2\_Je & -0.3537 & 0.8138 & -0.43 & 0.6790 \\
  U1\_Ie & -0.3135 & 0.7890 & -0.40 & 0.7049 \\
  U\_Ie & 0.9988 & 0.9220 & 1.08 & 0.3203 \\
  U\_Je & 1.3131 & 1.1489 & 1.14 & 0.2966 \\
  RT\_Ie & 0.5144 & 1.2978 & 0.40 & 0.7055 \\
  RT\_Je & 1.2674 & 1.1140 & 1.14 & 0.2986 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

******** Third Step:                                        :noexport:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 3 &
                                   correct_result == "True")

p14_step3 <- subset(p14_designs, step == step)
p14_step3$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step3$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below is the =aov= summary using the formula from step 1, at =parasilo-14=:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(step_formula, data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:37 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.44 & 0.44 & 0.16 & 0.6935 \\
  I(T1\_Je\verb|^|2) & 1 & 8.21 & 8.21 & 2.92 & 0.0915 \\
  I(T2\_Ie\verb|^|2) & 1 & 0.27 & 0.27 & 0.09 & 0.7594 \\
  I(T2\_Je\verb|^|2) & 1 & 2.33 & 2.33 & 0.83 & 0.3656 \\
  I(U1\_Ie\verb|^|2) & 1 & 0.08 & 0.08 & 0.03 & 0.8631 \\
  I(U\_Ie\verb|^|2) & 1 & 8.76 & 8.76 & 3.11 & 0.0815 \\
  I(U\_Je\verb|^|2) & 1 & 1.91 & 1.91 & 0.68 & 0.4120 \\
  I(RT\_Ie\verb|^|2) & 1 & 0.76 & 0.76 & 0.27 & 0.6056 \\
  I(RT\_Je\verb|^|2) & 1 & 0.60 & 0.60 & 0.21 & 0.6462 \\
  T1\_Ie & 1 & 0.15 & 0.15 & 0.05 & 0.8201 \\
  T1\_Je & 1 & 2.10 & 2.10 & 0.75 & 0.3900 \\
  T2\_Ie & 1 & 3.09 & 3.09 & 1.10 & 0.2975 \\
  T2\_Je & 1 & 3.37 & 3.37 & 1.20 & 0.2771 \\
  U1\_Ie & 1 & 4.70 & 4.70 & 1.67 & 0.1999 \\
  U\_Ie & 1 & 4.40 & 4.40 & 1.56 & 0.2150 \\
  U\_Je & 1 & 1.34 & 1.34 & 0.47 & 0.4930 \\
  RT\_Ie & 1 & 0.27 & 0.27 & 0.09 & 0.7597 \\
  RT\_Je & 1 & 0.00 & 0.00 & 0.00 & 0.9859 \\
  SCRe & 1 & 4.27 & 4.27 & 1.52 & 0.2217 \\
  VEC1e & 1 & 2.81 & 2.81 & 1.00 & 0.3206 \\
  VEC2e & 1 & 14.00 & 14.00 & 4.97 & 0.0285 \\
  OMPe & 1 & 0.00 & 0.00 & 0.00 & 0.9945 \\
  Residuals & 81 & 228.03 & 2.82 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the =lm= summary:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:49 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 2.0901 & 1.0424 & 2.01 & 0.0483 \\
  I(T1\_Ie\verb|^|2) & 0.2033 & 0.4877 & 0.42 & 0.6779 \\
  I(T1\_Je\verb|^|2) & 0.5684 & 0.4720 & 1.20 & 0.2320 \\
  I(T2\_Ie\verb|^|2) & 0.3079 & 0.5326 & 0.58 & 0.5649 \\
  I(T2\_Je\verb|^|2) & -0.6988 & 0.5206 & -1.34 & 0.1833 \\
  I(U1\_Ie\verb|^|2) & 0.0450 & 0.4556 & 0.10 & 0.9216 \\
  I(U\_Ie\verb|^|2) & 0.1611 & 0.5254 & 0.31 & 0.7599 \\
  I(U\_Je\verb|^|2) & -0.2009 & 0.5551 & -0.36 & 0.7183 \\
  I(RT\_Ie\verb|^|2) & -0.2769 & 0.5636 & -0.49 & 0.6245 \\
  I(RT\_Je\verb|^|2) & -0.0111 & 0.5453 & -0.02 & 0.9838 \\
  T1\_Ie & 0.0966 & 0.2955 & 0.33 & 0.7446 \\
  T1\_Je & -0.1229 & 0.3069 & -0.40 & 0.6900 \\
  T2\_Ie & 0.1918 & 0.2483 & 0.77 & 0.4422 \\
  T2\_Je & -0.2739 & 0.2579 & -1.06 & 0.2913 \\
  U1\_Ie & 0.3403 & 0.2506 & 1.36 & 0.1783 \\
  U\_Ie & -0.3597 & 0.3078 & -1.17 & 0.2460 \\
  U\_Je & 0.2037 & 0.3048 & 0.67 & 0.5059 \\
  RT\_Ie & -0.0513 & 0.3739 & -0.14 & 0.8913 \\
  RT\_Je & 0.1400 & 0.3690 & 0.38 & 0.7053 \\
  SCRe & -0.3981 & 0.3432 & -1.16 & 0.2495 \\
  VEC1e & -0.2706 & 0.3425 & -0.79 & 0.4319 \\
  VEC2e & 0.7631 & 0.3438 & 2.22 & 0.0293 \\
  OMPe & -0.0023 & 0.3377 & -0.01 & 0.9945 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Now, let's run =aov= again, using only binary factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:48:17 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 0.58 & 0.58 & 0.21 & 0.6482 \\
  SCRe & 1 & 3.32 & 3.32 & 1.20 & 0.2758 \\
  VEC1e & 1 & 2.63 & 2.63 & 0.95 & 0.3320 \\
  VEC2e & 1 & 11.25 & 11.25 & 4.06 & 0.0466 \\
  Residuals & 99 & 274.11 & 2.77 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that =VEC2= appear to be  significant, but not  within filtering
threshold. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:48:15 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 1.8998 & 0.9851 & 1.93 & 0.0571 \\
  I(T1\_Ie\verb|^|2) & 0.3154 & 0.4957 & 0.64 & 0.5264 \\
  I(T1\_Je\verb|^|2) & 0.5832 & 0.4810 & 1.21 & 0.2287 \\
  I(T2\_Ie\verb|^|2) & 0.3367 & 0.5397 & 0.62 & 0.5343 \\
  I(T2\_Je\verb|^|2) & -0.5854 & 0.5283 & -1.11 & 0.2709 \\
  I(U1\_Ie\verb|^|2) & 0.1221 & 0.4630 & 0.26 & 0.7926 \\
  I(U\_Ie\verb|^|2) & 0.1803 & 0.5352 & 0.34 & 0.7371 \\
  I(U\_Je\verb|^|2) & -0.1887 & 0.5649 & -0.33 & 0.7392 \\
  I(RT\_Ie\verb|^|2) & -0.3288 & 0.5693 & -0.58 & 0.5650 \\
  I(RT\_Je\verb|^|2) & -0.0976 & 0.5542 & -0.18 & 0.8606 \\
  T1\_Ie & 0.0194 & 0.2963 & 0.07 & 0.9480 \\
  T1\_Je & -0.1595 & 0.3123 & -0.51 & 0.6108 \\
  T2\_Ie & 0.2132 & 0.2504 & 0.85 & 0.3971 \\
  T2\_Je & -0.3121 & 0.2623 & -1.19 & 0.2374 \\
  U1\_Ie & 0.3361 & 0.2550 & 1.32 & 0.1910 \\
  U\_Ie & -0.2641 & 0.3112 & -0.85 & 0.3984 \\
  U\_Je & 0.2105 & 0.3107 & 0.68 & 0.5000 \\
  RT\_Ie & -0.1031 & 0.3808 & -0.27 & 0.7873 \\
  RT\_Je & 0.0064 & 0.3704 & 0.02 & 0.9861 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
Figure\nbsp{}[[fig:nc-predicted-best]] compares  the performance  /predicted by  the fitted
model/, represented  by the green  line, with the  performance of /the  best point
found at each design/, represented by the  blue line. The red line marks the best
point found so far.

#+begin_SRC R :results graphics output :session *R* :file "./img/predictions_no_cubic.pdf" :width 17 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

colors = c("Best step prediction",
           "Best in step design",
           "Best measurement")

point_size = 3.5
line_size = 2

ggplot(summaries) +
    geom_path(aes(x = step,
                  y = predicted_best,
                  color = colors[1]),
              size = line_size) +
    geom_point(aes(x = step,
                   y = predicted_best,
                   color = colors[1]),
               size = point_size) +
    geom_path(aes(x = step,
                  y = design_best,
                  color = colors[2]),
              size = line_size) +
    geom_point(aes(x = step,
                   y = design_best,
                   color = colors[2]),
               size = point_size) +
    geom_path(aes(x = step,
                  y = current_best,
                  color = colors[3]),
              linetype = 2,
              size = line_size) +
    geom_point(aes(x = step,
                   y = current_best,
                   color = colors[3]),
               size = point_size) +
    facet_wrap(experiment_id ~ ., ncol = 5) +
    ylab("Execution Time (s)") +
    xlab("Step") +
    scale_x_discrete(limits = unique(spread_data$step)) +
    theme_bw(base_size = 22) +
    theme(text = element_text(family = "sans"),
          legend.position = c(0.09, 0.95),
          legend.direction = "vertical",
          legend.background = element_blank(),
          legend.title = element_blank(),
          strip.background = element_rect(fill = "white")) +
    scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:./img/predictions_no_cubic.pdf]]

It  is only  at the  fourth step  of /parasilo-17/  that the  point with  the best
predicted performance  was better  than the  best point on  the design  for that
step, while also being better than the best point found so far. Although we seem
to be  effectively restricting the search  space with our exploration,  which is
evidenced  by the  improvement that  occurs as  steps progress  and by  the best
points being found inside designs, the  models fit using experiment data are not
able to improve the current best on the majority of cases.

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Fixing Binary Factors
****** Loading Data                                           :noexport:
******* Loading Data for Eliminated Factors                  :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/no_binary"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)
#+end_SRC

#+RESULTS:
: 'data.frame':	54 obs. of  3 variables:
:  $ removed_variables: Factor w/ 7 levels "","I(T1_I^2)",..: 1 4 2 1 3 1 1 2 3 7 ...
:  $ step             : int  1 2 2 3 4 1 2 3 4 4 ...
:  $ experiment_id    : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
: 'data.frame':	396 obs. of  3 variables:
:  $ current_best_coordinate: chr  "T1_I->2048" "T1_J->1024" "U_J->1" "U_I->8" ...
:  $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
:  $ experiment_id          : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...

******* Loading Data for Histograms and Iterations           :noexport:
#+HEADER: :results output :session *R*
#+BEGIN_SRC R
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)
#+END_SRC

#+RESULTS:
#+begin_example
'data.frame':	832 obs. of  27 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1024 1 1 1 32 256 8 1 2048 2048 ...
 $ T1_J                        : int  1 128 16 2048 1 2048 32 1 128 2 ...
 $ cost_mean                   : num  4.58 3.58 6.21 3.68 3.34 ...
 $ U_J                         : int  14 22 15 1 12 1 30 30 1 2 ...
 $ U_I                         : int  1 1 1 29 1 1 1 1 30 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 32 32 2048 2048 256 1 256 2048 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  32 1 2048 1 128 1 128 1 1 512 ...
 $ U1_I                        : int  1 17 30 27 14 10 30 1 3 30 ...
 $ mean_confidence_interval_inf: num  4.58 3.58 6.21 3.66 3.34 ...
 $ mean_confidence_interval_sup: num  4.58 3.58 6.21 3.7 3.34 ...
 $ cost_std                    : num  0.000187 0.000144 0.000764 0.035888 0.000108 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 2 32 2 8 32 16 1 32 1 ...
 $ RT_J                        : int  1 1 4 16 8 1 1 16 2 32 ...
 $ experiment_id               : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-11" ...
 $ cost_baseline               : num  4.96 4.96 4.96 4.96 4.96 ...
 $ speedup                     : num  1.082 1.385 0.799 1.347 1.484 ...
 $ max_run_speedup             : num  1.56 1.56 1.56 1.56 1.56 ...
 $ min_run_cost                : num  3.18 3.18 3.18 3.18 3.18 ...
 $ best_iteration              : num  19 19 19 19 19 19 19 19 19 19 ...
 $ points                      : int  84 84 84 84 84 84 84 84 84 84 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
tibble [10 × 30] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:10] 19 2 11 62 31 25 14 78 65 12
 $ runs                        : int [1:10] 10 10 10 10 10 10 10 10 10 10
 $ baseline                    : chr [1:10] "False" "False" "False" "False" ...
 $ T1_I                        : int [1:10] 512 256 1 1 32 1 1 32 128 32
 $ T1_J                        : int [1:10] 512 1 2 1 2048 1 2048 1 1 64
 $ cost_mean                   : num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ U_J                         : int [1:10] 1 1 1 1 1 1 1 1 1 1
 $ U_I                         : int [1:10] 15 18 15 14 29 30 30 1 1 10
 $ technique                   : chr [1:10] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int [1:10] 512 2048 1 128 2048 256 2048 2048 128 32
 $ correct_result              : chr [1:10] "True" "True" "True" "True" ...
 $ T2_J                        : int [1:10] 1 64 128 2048 2048 2048 2048 1 1 2048
 $ U1_I                        : int [1:10] 30 30 21 30 2 1 30 14 28 1
 $ mean_confidence_interval_inf: num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ mean_confidence_interval_sup: num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ cost_std                    : num [1:10] 1.30e-04 1.79e-04 1.71e-04 1.36e-04 9.59e-05 ...
 $ step                        : int [1:10] 1 1 1 3 2 2 1 4 3 1
 $ RT_I                        : int [1:10] 1 1 4 4 16 16 16 4 4 1
 $ RT_J                        : int [1:10] 4 8 1 2 8 2 4 2 2 2
 $ experiment_id               : chr [1:10] "paravance-11" "paravance-14" "paravance-19" "paravance-25" ...
 $ cost_baseline               : num [1:10] 4.96 4.75 5.06 4.75 4.85 ...
 $ speedup                     : num [1:10] 1.56 1.49 1.66 1.49 1.54 ...
 $ max_run_speedup             : num [1:10] 1.56 1.49 1.66 1.49 1.54 ...
 $ min_run_cost                : num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ best_iteration              : num [1:10] 19 2 11 62 31 25 14 78 65 12
 $ points                      : int [1:10] 84 83 80 86 83 79 84 84 83 86
 $ application                 : chr [1:10] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:10] 4.85 4.85 4.85 4.85 4.85 ...
 $ label_center_x              : num [1:10] 4.16 4.16 4.16 4.16 4.16 ...
 $ label_center_y              : num [1:10] 32.1 32.1 32.1 32.1 32.1 ...
#+end_example

#+HEADER: :results output :session *R*
#+BEGIN_SRC R
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

str(complete_plot_data)

data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        #target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  mutate(technique = "RS_no_bin") %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)
#+END_SRC

#+RESULTS:
#+begin_example
tibble [10 × 30] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:10] 19 2 11 62 31 25 14 78 65 12
 $ runs                        : int [1:10] 10 10 10 10 10 10 10 10 10 10
 $ baseline                    : chr [1:10] "False" "False" "False" "False" ...
 $ T1_I                        : int [1:10] 512 256 1 1 32 1 1 32 128 32
 $ T1_J                        : int [1:10] 512 1 2 1 2048 1 2048 1 1 64
 $ cost_mean                   : num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ U_J                         : int [1:10] 1 1 1 1 1 1 1 1 1 1
 $ U_I                         : int [1:10] 15 18 15 14 29 30 30 1 1 10
 $ technique                   : chr [1:10] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int [1:10] 512 2048 1 128 2048 256 2048 2048 128 32
 $ correct_result              : chr [1:10] "True" "True" "True" "True" ...
 $ T2_J                        : int [1:10] 1 64 128 2048 2048 2048 2048 1 1 2048
 $ U1_I                        : int [1:10] 30 30 21 30 2 1 30 14 28 1
 $ mean_confidence_interval_inf: num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ mean_confidence_interval_sup: num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ cost_std                    : num [1:10] 1.30e-04 1.79e-04 1.71e-04 1.36e-04 9.59e-05 ...
 $ step                        : int [1:10] 1 1 1 3 2 2 1 4 3 1
 $ RT_I                        : int [1:10] 1 1 4 4 16 16 16 4 4 1
 $ RT_J                        : int [1:10] 4 8 1 2 8 2 4 2 2 2
 $ experiment_id               : chr [1:10] "paravance-11" "paravance-14" "paravance-19" "paravance-25" ...
 $ cost_baseline               : num [1:10] 4.96 4.75 5.06 4.75 4.85 ...
 $ speedup                     : num [1:10] 1.56 1.49 1.66 1.49 1.54 ...
 $ max_run_speedup             : num [1:10] 1.56 1.49 1.66 1.49 1.54 ...
 $ min_run_cost                : num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ best_iteration              : num [1:10] 19 2 11 62 31 25 14 78 65 12
 $ points                      : int [1:10] 84 83 80 86 83 79 84 84 83 86
 $ application                 : chr [1:10] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:10] 4.85 4.85 4.85 4.85 4.85 ...
 $ label_center_x              : num [1:10] 4.16 4.16 4.16 4.16 4.16 ...
 $ label_center_y              : num [1:10] 32.1 32.1 32.1 32.1 32.1 ...
tibble [21 × 30] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:21] 19 2 11 62 31 25 14 78 65 12 ...
 $ runs                        : int [1:21] 10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr [1:21] "False" "False" "False" "False" ...
 $ T1_I                        : int [1:21] 512 256 1 1 32 1 1 32 128 32 ...
 $ T1_J                        : int [1:21] 512 1 2 1 2048 1 2048 1 1 64 ...
 $ cost_mean                   : num [1:21] 3.18 3.2 3.05 3.18 3.15 ...
 $ U_J                         : int [1:21] 1 1 1 1 1 1 1 1 1 1 ...
 $ U_I                         : int [1:21] 15 18 15 14 29 30 30 1 1 10 ...
 $ technique                   : chr [1:21] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int [1:21] 512 2048 1 128 2048 256 2048 2048 128 32 ...
 $ correct_result              : chr [1:21] "True" "True" "True" "True" ...
 $ T2_J                        : int [1:21] 1 64 128 2048 2048 2048 2048 1 1 2048 ...
 $ U1_I                        : int [1:21] 30 30 21 30 2 1 30 14 28 1 ...
 $ mean_confidence_interval_inf: num [1:21] 3.18 3.2 3.05 3.18 3.15 ...
 $ mean_confidence_interval_sup: num [1:21] 3.18 3.2 3.05 3.18 3.15 ...
 $ cost_std                    : num [1:21] 1.30e-04 1.79e-04 1.71e-04 1.36e-04 9.59e-05 ...
 $ step                        : int [1:21] 1 1 1 3 2 2 1 4 3 1 ...
 $ RT_I                        : int [1:21] 1 1 4 4 16 16 16 4 4 1 ...
 $ RT_J                        : int [1:21] 4 8 1 2 8 2 4 2 2 2 ...
 $ experiment_id               : chr [1:21] "paravance-11" "paravance-14" "paravance-19" "paravance-25" ...
 $ cost_baseline               : num [1:21] 4.96 4.75 5.06 4.75 4.85 ...
 $ speedup                     : num [1:21] 1.56 1.49 1.66 1.49 1.54 ...
 $ max_run_speedup             : num [1:21] 1.56 1.49 1.66 1.49 1.54 ...
 $ min_run_cost                : num [1:21] 3.18 3.2 3.05 3.18 3.15 ...
 $ best_iteration              : num [1:21] 19 2 11 62 31 25 14 78 65 12 ...
 $ points                      : int [1:21] 84 83 80 86 83 79 84 84 83 86 ...
 $ application                 : chr [1:21] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:21] 4.85 4.85 4.85 4.85 4.85 ...
 $ label_center_x              : num [1:21] 4.16 4.16 4.16 4.16 4.16 ...
 $ label_center_y              : num [1:21] 32.1 32.1 32.1 32.1 32.1 ...
#+end_example
******* Loading Data Step-by-step Plots                      :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	25 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 2 2 2 ...
 $ valid_configurations   : int  46080 46080 46080 46080 46080 46080 46080 46080 46080 46080 ...
 $ D                      : num  0.0862 0.0862 0.0866 0.0866 0.087 ...
 $ used_budget            : int  0 0 0 0 0 0 0 31 31 29 ...
 $ model_size             : int  27 27 27 27 27 27 27 27 27 27 ...
 $ current_best           : num  0.541 0.541 0.585 0.585 0.537 ...
 $ trials                 : int  32 32 32 32 32 32 32 32 32 32 ...
 $ current_best_coordinate: chr  "{'T1_I': 2048, 'T1_J': 64, 'U_J': 1, 'U_I': 2, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 24, 'RT_I': 8, 'RT_J': 1}" "{'T1_I': 2048, 'T1_J': 64, 'U_J': 1, 'U_I': 2, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 24, 'RT_I': 8, 'RT_J': 1}" "{'T1_I': 64, 'T1_J': 1, 'U_J': 1, 'U_I': 6, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 19, 'RT_I': 1, 'RT_J': 32}" "{'T1_I': 64, 'T1_J': 1, 'U_J': 1, 'U_I': 6, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 19, 'RT_I': 1, 'RT_J': 32}" ...
 $ tested_configurations  : int  2211505 2211505 2217801 2217801 2203665 2203665 2203665 2222185 2222185 2207980 ...
 $ fixed_factors          : chr  "{'T2_I': 11, 'T1_I': 11}" "{'T2_I': 11, 'T1_I': 11}" "{'T2_I': 11, 'T1_I': 11}" "{'T2_I': 11, 'T1_I': 11}" ...
 $ step                   : int  1 1 1 1 1 1 1 2 2 2 ...
 $ design_best            : num  0.541 0.541 0.585 0.585 0.537 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "I(T1_I^2)" "I(T2_I^2)" "I(T2_I^2)" "I(T1_I^2)" ...
 $ model                  : chr  "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  0.709 0.709 0.597 0.597 0.552 ...
 $ experiment_id          : chr  "parasilo-21" "parasilo-21" "parasilo-25" "parasilo-25" ...
'data.frame':	1328 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  1 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 2048 8 8 2048 1024 1 1 1 2048 ...
 $ T1_J                        : int  256 4 512 1 128 1 2048 16 1 16 ...
 $ cost_mean                   : num  Inf 0.747 0.916 0.83 0.642 ...
 $ U_J                         : int  1 27 10 1 1 1 18 30 20 8 ...
 $ U_I                         : int  17 1 1 20 27 2 1 1 1 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 1 8 128 2048 2048 2048 16 16 1 ...
 $ correct_result              : chr  "False" "True" "True" "True" ...
 $ T2_J                        : int  2048 2048 1 8 256 256 1 1 256 16 ...
 $ U1_I                        : int  21 29 5 12 10 12 8 19 24 21 ...
 $ mean_confidence_interval_inf: num  Inf 0.607 0.904 0.774 0.492 ...
 $ mean_confidence_interval_sup: num  Inf 0.886 0.928 0.885 0.793 ...
 $ cost_std                    : num  Inf 0.2251 0.0194 0.089 0.2431 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  4 1 1 32 16 2 8 32 32 16 ...
 $ RT_J                        : int  32 4 32 4 2 32 16 2 1 1 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
#+end_example

******* Loading Data for D-Optimality and ANOVA              :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
: There were 44 warnings (use warnings() to see them)
: Joining, by = c("id", "step")
: tibble [1,103 × 4] (S3: tbl_df/tbl/data.frame)
:  $ metric_value: num [1:1103] 0.0141 0.046 0.0596 0.0544 0.0651 ...
:  $ factors     : chr [1:1103] "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
:  $ id          : chr [1:1103] "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
:  $ step        : num [1:1103] 1 1 1 1 1 1 1 1 1 1 ...

****** Iterations that found the Best Configuration
Since =OMP= was  quickly fixed at most iterations of  the previous experiment, and
had the largest  impact on performance we  could observe, we decided  to fix it,
along with  all other  binary parameters.

In the experiments shown on this section, all binary parameters are turned on by
default,     including      on     the     random      sampling     experiments.
Figure\nbsp[[fig:nobin-best-found]] shows the iterations where the best configuration of
each of the 10 runs was found, for uniform sampling and for our approach. We see
that random  sampling found an extremely  fast point right at  the second tested
configuration.

#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(subset(it_data, technique == "DLMT")$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:nobin-best-found
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-VnHilA/figure0er7dA.pdf]]

#+begin_SRC R :results output latex :session *R* :exports none
library(stargazer)

stargazer(select(complete_plot_data, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:

#+begin_export latex
\begin{table}[!htbp] \centering
\scriptsize
  \caption{Parameters of the best points at each run. Rows with the best points for each technique overall are highlighted}
  \label{}
\begin{tabular}{llccccccccc}
\hline \\[-1.8ex]
technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
DLMT & 0.4563346 & 2048 & 8 & 1 & 1 & 2048 & 8 & 13 & 2 & 32 \\
DLMT & 0.4423092 & 128 & 2 & 1 & 21 & 2048 & 1 & 25 & 4 & 32 \\
DLMT & 0.4447055 & 2048 & 256 & 1 & 23 & 2048 & 2048 & 13 & 4 & 8 \\
DLMT & 0.5356327 & 2048 & 64 & 1 & 19 & 2048 & 2048 & 1 & 8 & 16 \\
DLMT & 0.5531261 & 64 & 256 & 1 & 9 & 2048 & 1 & 22 & 8 & 2 \\
DLMT & 0.5218018 & 2048 & 1 & 30 & 1 & 2048 & 1 & 22 & 8 & 4 \\
\rowcolor[HTML]{ACACAC}
DLMT & 0.4351629 & 32 & 256 & 1 & 30 & 2048 & 256 & 22 & 4 & 2 \\
DLMT & 0.4904546 & 1 & 128 & 21 & 1 & 2048 & 128 & 12 & 16 & 2 \\
DLMT & 0.4530676 & 2048 & 512 & 13 & 1 & 2048 & 512 & 8 & 4 & 16 \\
DLMT & 0.4752536 & 2048 & 2048 & 1 & 12 & 2048 & 2048 & 2 & 8 & 1 \\
DLMT & 0.4931927 & 2048 & 1 & 1 & 11 & 2048 & 1 & 1 & 1 & 32 \\
RS & 0.4646119 & 2048 & 64 & 1 & 14 & 2048 & 1 & 20 & 8 & 2 \\
RS & 0.5190496 & 64 & 512 & 1 & 24 & 2048 & 2048 & 6 & 8 & 16 \\
RS & 0.4359155 & 8 & 1 & 29 & 1 & 2048 & 128 & 27 & 8 & 4 \\
RS & 0.4363163 & 512 & 4 & 16 & 1 & 2048 & 128 & 12 & 4 & 2 \\
RS & 0.445589 & 1024 & 16 & 1 & 10 & 2048 & 128 & 16 & 8 & 16 \\
RS & 0.48685 & 8 & 128 & 3 & 1 & 2048 & 1 & 11 & 8 & 2 \\
RS & 0.5267321 & 2048 & 64 & 1 & 6 & 2048 & 1 & 9 & 4 & 16 \\
\rowcolor[HTML]{ACACAC}
RS & 0.4064384 & 256 & 8 & 22 & 1 & 512 & 128 & 15 & 4 & 32 \\
RS & 0.5288379 & 2048 & 8 & 1 & 25 & 2048 & 2048 & 15 & 8 & 2 \\
RS & 0.4439861 & 8 & 32 & 1 & 12 & 2048 & 32 & 25 & 4 & 16 \\
RS & 0.4639212 & 256 & 1 & 1 & 14 & 2048 & 256 & 21 & 2 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
Even after  fixing binary parameters,  or maybe  because of it,  some parameters
were still identified as significant and  fixed. The =T1_I= parameter was only the
fixed at two  iterations on the previous  experiment, but it was  the most fixed
parameter in this one, surpassing =RT_I=,  which was frequently eliminated in both
experiments.   This  suggests   that  fixing   binary  parameters   allowed  the
significance of the other parameters to be detected.

#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-ynhqKR/figure7r6W2z.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

It is  interesting that  only /parasilo-19/ and  /parasilo-9/ eliminated  any factor
other than =OMP=  and =SCR= on the  first step where any factor  was eliminated, and
also that those  runs eliminated the same  factor =RT_I=.  We will  see later that
=OMP= and  =SCR= were fixed to  the same values  in all experiments where  they were
eliminated, and =RT_I=  was only fixed to  a different value on  2 eliminations on
the fourth step.

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Searched Spaces                                        :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.6) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figuregu9cI1.pdf]]

****** Fixed Factors & Values in the Explored Spaces
We see that /parasilo-13/ and /parasilo-23/ did not eliminate any parameters after 4
steps.   We also  see that,  at /parasilo-12/,  /parasilo-20/, and  /parasilo-25/, for
example,  the  search space  seems  to  be restricted  to  a  region with  worse
performance than in the previous steps of the same experiment. This could be due
to the fact that these experiments fixed  the =RT_I= parameter to its fifth level.
A  slight improvement  of the  configurations tested  can be  seen at  the other
experiments, where other factors were fixed.

Identifying when  a restriction of  the search space  to a worse  region happens
would be  useful if we could  revert or re-do  an optimization step. This  is an
interesting  motivation for  keeping a  human on  the loop  of the  optimization
process.

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:nb-ss-ef
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-elHoq9/figure8UQjkW.png]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-fixedbin
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figuremYRSBQ.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "parasilo-21"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "parasilo-21"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{parasilo-21}
#+LABEL: fig:lm-rs-nobin-p14
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureaYZZxh.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-dlmt-fixedbin
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure98HYKr.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "parasilo-23"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "parasilo-23"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, for \texttt{parasilo-23}
#+LABEL: fig:lm-rs-nobin-p54
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurer5tVWU.pdf]]
****** D-Optimality
******* Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:pf-bp-ss
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

****** D_A-Optimality at Each Step                             :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Reuse Data for =aov= and =lm=
Significant  changes were  performed  on the  initial  DLMT implementation.   We
decided  that there  was no  good reason  to not  reuse the  data obtained  from
evaluating designs  at each step,  and the various  samples of the  search space
taken  at different  points. Now,  all  evaluated experiments  compose a  single
growing design used  by =aov= to identify  the best factors, and  all samples from
the  search  space compose  a  single  data set  used  by  =optFederov= to  select
experiments. The data  set is pruned in  both =aov= and =lm=  analyses, to guarantee
only experiments  with the  correct levels  of fixed factors  are used.  This is
crucial for both  analyses, since having different fixed values  of factors that
are not in the model would imply that we would have inexplicable variance in the
data set.

Using all experimental data on =aov= is  interesting because it is always worth it
to  consider additional  information on  the  factors that  are currently  being
studied.  On  one hand, it  might not allow  for enough ``flexibility''  when we
consider regression only on a  small restricted subspace, because points outside
the  subspace  would impact  regression,  and  we  would  be interested  in  the
significance of the factor inside the subspace at the moment. On the other hand,
using all data available makes sense because we are also interested in exploring
any  global structures  of  the  search space,  and  keeping  points from  other
subspaces would increase the chance of ``catching'' the significance of a factor
globally.

Using all sampled space, across all steps,  as a candidate for =optFederov= has no
downsides, provided we prune the search space to account for current constraints
on factor levels fixed on previous steps.  We increase the size of the available
set of configurations  that can compose a  new design each time we  sample a new
subspace. This  would hopefully improve  the quality  of designs produced  as we
progress.

****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/reuse_prune_sample_data_dlmt"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/results"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][5], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

# design_data <- inner_join(designs, formulas)
#
# design_data_plot <- design_data %>%
#   group_by(id, step) %>%
#   do(compute_factor_efficiencies(.)) %>%
#   ungroup()
#
# str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	63 obs. of  3 variables:
 $ removed_variables: Factor w/ 13 levels "","I(RT_I^2)",..: 3 6 5 4 2 1 1 3 5 4 ...
 $ step             : int  1 2 2 2 2 3 4 1 1 2 ...
 $ experiment_id    : chr  "graoully-13" "graoully-13" "graoully-13" "graoully-13" ...
'data.frame':	416 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->512" "T1_J->1" "U_J->1" "U_I->10" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ experiment_id          : chr  "graoully-13" "graoully-13" "graoully-13" "graoully-13" ...
'data.frame':	826 obs. of  31 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  1 1 64 32 128 1 32 1024 32 2048 ...
 $ T2_I                        : int  128 1 2048 32 2048 2048 256 1 2048 128 ...
 $ RT_I                        : int  2 1 4 1 32 1 4 4 4 1 ...
 $ mean_confidence_interval_inf: num  0.876 4.085 4.485 0.685 0.501 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  2048 128 64 32 1 1024 16 64 32 512 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "False" "True" "False" ...
 $ VEC1                        : chr  "True" "False" "True" "True" ...
 $ SCR                         : chr  "False" "False" "False" "True" ...
 $ U1_I                        : int  30 10 3 1 21 29 30 22 12 24 ...
 $ RT_J                        : int  32 8 1 8 2 8 8 8 32 1 ...
 $ T1_I                        : int  64 256 1 32 1 256 1 64 32 64 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.03081 0.00115 0.00054 0.14549 0.22866 ...
 $ cost_mean                   : num  0.895 4.086 4.486 0.775 0.643 ...
 $ U_J                         : int  1 1 1 2 1 1 30 30 1 1 ...
 $ U_I                         : int  19 15 14 1 24 30 1 1 29 1 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "False" "False" "True" ...
 $ mean_confidence_interval_sup: num  0.914 4.086 4.486 0.865 0.785 ...
 $ experiment_id               : chr  "graoully-13" "graoully-13" "graoully-13" "graoully-13" ...
 $ cost_baseline               : num  5.78 5.78 5.78 5.78 5.78 ...
 $ speedup                     : num  6.46 1.41 1.29 7.46 8.99 ...
 $ max_run_speedup             : num  9.5 9.5 9.5 9.5 9.5 ...
 $ min_run_cost                : num  0.608 0.608 0.608 0.608 0.608 ...
 $ best_iteration              : num  20 20 20 20 20 20 20 20 20 20 ...
 $ points                      : int  81 81 81 81 81 81 81 81 81 81 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
tibble [10 × 34] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:10] 20 48 24 34 36 78 39 39 96 58
 $ T2_J                        : int [1:10] 2048 1 1024 2048 1 2048 256 2048 1 2048
 $ T2_I                        : int [1:10] 2048 2048 1 1 2048 2048 2048 2048 1 2048
 $ RT_I                        : int [1:10] 8 2 8 4 2 2 8 4 4 4
 $ mean_confidence_interval_inf: num [1:10] 0.449 0.425 0.431 0.457 0.42 ...
 $ baseline                    : chr [1:10] "False" "False" "False" "False" ...
 $ T1_J                        : int [1:10] 1 16 512 2048 32 2048 32 2048 2 2048
 $ technique                   : chr [1:10] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr [1:10] "False" "True" "False" "True" ...
 $ VEC1                        : chr [1:10] "False" "False" "False" "True" ...
 $ SCR                         : chr [1:10] "True" "True" "True" "True" ...
 $ U1_I                        : int [1:10] 2 1 5 30 8 13 16 1 30 1
 $ RT_J                        : int [1:10] 2 32 8 4 4 4 1 8 4 4
 $ T1_I                        : int [1:10] 512 512 2048 2048 16 1024 2048 64 2048 2048
 $ runs                        : int [1:10] 10 10 10 10 10 10 10 10 10 10
 $ cost_std                    : num [1:10] 0.2572 0.187 0.2233 0.0966 0.2663 ...
 $ cost_mean                   : num [1:10] 0.608 0.541 0.569 0.516 0.585 ...
 $ U_J                         : int [1:10] 1 1 1 1 1 30 1 1 1 1
 $ U_I                         : int [1:10] 10 21 1 28 30 1 3 18 2 11
 $ step                        : int [1:10] 1 2 1 2 2 4 2 2 4 3
 $ correct_result              : chr [1:10] "True" "True" "True" "True" ...
 $ OMP                         : chr [1:10] "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num [1:10] 0.768 0.657 0.708 0.576 0.75 ...
 $ experiment_id               : chr [1:10] "graoully-13" "graoully-15" "graoully-16" "graoully-3" ...
 $ cost_baseline               : num [1:10] 5.78 5.78 5.79 5.78 5.78 ...
 $ speedup                     : num [1:10] 9.5 10.68 10.16 11.19 9.89 ...
 $ max_run_speedup             : num [1:10] 9.5 10.68 10.16 11.19 9.89 ...
 $ min_run_cost                : num [1:10] 0.608 0.541 0.569 0.516 0.585 ...
 $ best_iteration              : num [1:10] 20 48 24 34 36 78 39 39 96 58
 $ points                      : int [1:10] 81 90 81 63 95 90 89 48 97 92
 $ application                 : chr [1:10] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:10] 5.79 5.79 5.79 5.79 5.79 ...
 $ label_center_x              : num [1:10] 1.36 1.36 1.36 1.36 1.36 ...
 $ label_center_y              : num [1:10] 49 49 49 49 49 ...
tibble [20 × 34] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:20] 20 48 24 34 36 78 39 39 96 58 ...
 $ T2_J                        : int [1:20] 2048 1 1024 2048 1 2048 256 2048 1 2048 ...
 $ T2_I                        : int [1:20] 2048 2048 1 1 2048 2048 2048 2048 1 2048 ...
 $ RT_I                        : int [1:20] 8 2 8 4 2 2 8 4 4 4 ...
 $ mean_confidence_interval_inf: num [1:20] 0.449 0.425 0.431 0.457 0.42 ...
 $ baseline                    : chr [1:20] "False" "False" "False" "False" ...
 $ T1_J                        : int [1:20] 1 16 512 2048 32 2048 32 2048 2 2048 ...
 $ technique                   : chr [1:20] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr [1:20] "False" "True" "False" "True" ...
 $ VEC1                        : chr [1:20] "False" "False" "False" "True" ...
 $ SCR                         : chr [1:20] "True" "True" "True" "True" ...
 $ U1_I                        : int [1:20] 2 1 5 30 8 13 16 1 30 1 ...
 $ RT_J                        : int [1:20] 2 32 8 4 4 4 1 8 4 4 ...
 $ T1_I                        : int [1:20] 512 512 2048 2048 16 1024 2048 64 2048 2048 ...
 $ runs                        : int [1:20] 10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num [1:20] 0.2572 0.187 0.2233 0.0966 0.2663 ...
 $ cost_mean                   : num [1:20] 0.608 0.541 0.569 0.516 0.585 ...
 $ U_J                         : int [1:20] 1 1 1 1 1 30 1 1 1 1 ...
 $ U_I                         : int [1:20] 10 21 1 28 30 1 3 18 2 11 ...
 $ step                        : int [1:20] 1 2 1 2 2 4 2 2 4 3 ...
 $ correct_result              : chr [1:20] "True" "True" "True" "True" ...
 $ OMP                         : chr [1:20] "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num [1:20] 0.768 0.657 0.708 0.576 0.75 ...
 $ experiment_id               : chr [1:20] "graoully-13" "graoully-15" "graoully-16" "graoully-3" ...
 $ cost_baseline               : num [1:20] 5.78 5.78 5.79 5.78 5.78 ...
 $ speedup                     : num [1:20] 9.5 10.68 10.16 11.19 9.89 ...
 $ max_run_speedup             : num [1:20] 9.5 10.68 10.16 11.19 9.89 ...
 $ min_run_cost                : num [1:20] 0.608 0.541 0.569 0.516 0.585 ...
 $ best_iteration              : num [1:20] 20 48 24 34 36 78 39 39 96 58 ...
 $ points                      : int [1:20] 81 90 81 63 95 90 89 48 97 92 ...
 $ application                 : chr [1:20] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:20] 5.79 5.79 5.79 5.79 5.79 ...
 $ label_center_x              : num [1:20] 1.36 1.36 1.36 1.36 1.36 ...
 $ label_center_y              : num [1:20] 49 49 49 49 49 ...
'data.frame':	51 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ valid_configurations   : int  62400 62400 62400 62400 62400 62400 62400 62400 62400 62400 ...
 $ D                      : num  0.206 0.205 0.205 0.207 0.207 ...
 $ used_budget            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ model_size             : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best           : num  0.608 0.558 0.558 0.578 0.578 ...
 $ trials                 : int  26 26 26 26 26 26 26 26 26 26 ...
 $ current_best_coordinate: chr  "{'T1_I': 512, 'T1_J': 1, 'U_J': 1, 'U_I': 10, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 2, 'OMP': True, 'VEC2': False"| __truncated__ "{'T1_I': 16, 'T1_J': 64, 'U_J': 1, 'U_I': 14, 'T2_I': 2048, 'T2_J': 1024, 'U1_I': 1, 'OMP': True, 'VEC2': False"| __truncated__ "{'T1_I': 16, 'T1_J': 64, 'U_J': 1, 'U_I': 14, 'T2_I': 2048, 'T2_J': 1024, 'U1_I': 1, 'OMP': True, 'VEC2': False"| __truncated__ "{'T1_I': 2, 'T1_J': 16, 'U_J': 28, 'U_I': 1, 'T2_I': 2048, 'T2_J': 16, 'U1_I': 1, 'OMP': True, 'VEC2': True, 'V"| __truncated__ ...
 $ tested_configurations  : int  2988973 2985943 2985943 2973220 2973220 2973220 2973220 2973220 2973220 3015704 ...
 $ fixed_factors          : chr  "{'OMP': 1}" "{'OMP': 1, 'SCR': 1}" "{'OMP': 1, 'SCR': 1}" "{'T1_I': 11, 'T1_J': 11, 'U_I': 27, 'OMP': 1, 'VEC1': 1, 'SCR': 1}" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ design_best            : num  0.608 0.558 0.558 0.578 0.578 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "OMP" "OMP" "SCR" "SCR" ...
 $ model                  : chr  "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  0.823 0.816 0.816 0.608 0.608 ...
 $ experiment_id          : chr  "graoully-13" "graoully-15" "graoully-15" "graoully-3" ...
'data.frame':	872 obs. of  24 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  1 1 64 32 128 1 32 1024 32 2048 ...
 $ T2_I                        : int  128 1 2048 32 2048 2048 256 1 2048 128 ...
 $ RT_I                        : int  2 1 4 1 32 1 4 4 4 1 ...
 $ mean_confidence_interval_inf: num  0.876 4.085 4.485 0.685 0.501 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  2048 128 64 32 1 1024 16 64 32 512 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "False" "True" "False" ...
 $ VEC1                        : chr  "True" "False" "True" "True" ...
 $ SCR                         : chr  "False" "False" "False" "True" ...
 $ U1_I                        : int  30 10 3 1 21 29 30 22 12 24 ...
 $ RT_J                        : int  32 8 1 8 2 8 8 8 32 1 ...
 $ T1_I                        : int  64 256 1 32 1 256 1 64 32 64 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.03081 0.00115 0.00054 0.14549 0.22866 ...
 $ cost_mean                   : num  0.895 4.086 4.486 0.775 0.643 ...
 $ U_J                         : int  1 1 1 2 1 1 30 30 1 1 ...
 $ U_I                         : int  19 15 14 1 24 30 1 1 29 1 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "False" "False" "True" ...
 $ mean_confidence_interval_sup: num  0.914 4.086 4.486 0.865 0.785 ...
 $ experiment_id               : chr  "graoully-13" "graoully-13" "graoully-13" "graoully-13" ...
There were 39 warnings (use warnings() to see them)
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file "./img/iterations_reuse.pdf"
#+HEADER: :width 12 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 4, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.9) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 30) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          #text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 30) +
                theme(text = element_text(family = "serif"),
                      legend.position = c(0.2, 0.5),
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

mixed_plot_data = bind_rows(mixed_plot_data,
                            it_data %>%
                            mutate(technique = gsub(pattern = "DLMT",
                                                    replacement = "Reusing Designs",
                                                    x = technique, fixed = TRUE)) %>%
                            filter(technique != "RS"))

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-no-cubic
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:./img/iterations_reuse.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 06:38:14 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}} cccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
graoully-13 & DLMT & 0.6084833 & 512 & 1 & 1 & 10 & 2048 & 2048 & 2 & 8 & 2 \\
graoully-15 & DLMT & 0.5412621 & 512 & 16 & 1 & 21 & 2048 & 1 & 1 & 2 & 32 \\
graoully-16 & DLMT & 0.5691611 & 2048 & 512 & 1 & 1 & 1 & 1024 & 5 & 8 & 8 \\
graoully-3 & DLMT & 0.5163602 & 2048 & 2048 & 1 & 28 & 1 & 2048 & 30 & 4 & 4 \\
graoully-4 & DLMT & 0.5845903 & 16 & 32 & 1 & 30 & 2048 & 1 & 8 & 2 & 4 \\
graoully-5 & DLMT & 0.4961376 & 1024 & 2048 & 30 & 1 & 2048 & 2048 & 13 & 2 & 4 \\
graoully-6 & DLMT & 0.5985619 & 2048 & 32 & 1 & 3 & 2048 & 256 & 16 & 8 & 1 \\
graoully-7 & DLMT & 0.5565135 & 64 & 2048 & 1 & 18 & 2048 & 2048 & 1 & 4 & 8 \\
graoully-8 & DLMT & 0.4646318 & 2048 & 2 & 1 & 2 & 1 & 1 & 30 & 4 & 4 \\
graoully-9 & DLMT & 0.5087977 & 2048 & 2048 & 1 & 11 & 2048 & 2048 & 1 & 4 & 4 \\
paravance-50 & RS & 0.5685274 & 512 & 512 & 19 & 1 & 2048 & 1024 & 27 & 4 & 1 \\
paravance-51 & RS & 0.5467725 & 1024 & 32 & 10 & 1 & 2048 & 512 & 9 & 8 & 8 \\
paravance-52 & RS & 0.5417953 & 2048 & 8 & 9 & 1 & 2048 & 128 & 30 & 8 & 16 \\
paravance-53 & RS & 0.5612387 & 2048 & 64 & 16 & 1 & 2048 & 256 & 9 & 16 & 2 \\
paravance-54 & RS & 0.5322531 & 2048 & 8 & 1 & 9 & 1 & 1 & 19 & 1 & 1 \\
paravance-55 & RS & 0.5540684 & 32 & 4 & 1 & 5 & 2048 & 256 & 4 & 16 & 1 \\
paravance-56 & RS & 0.4648199 & 2048 & 1 & 1 & 23 & 1 & 512 & 25 & 8 & 1 \\
paravance-57 & RS & 0.5463944 & 256 & 16 & 1 & 15 & 2048 & 512 & 2 & 2 & 2 \\
paravance-58 & RS & 0.5496127 & 32 & 1 & 1 & 14 & 2048 & 2048 & 24 & 8 & 4 \\
paravance-59 & RS & 0.4758884 & 64 & 16 & 29 & 1 & 2048 & 1 & 27 & 16 & 4 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file "./img/eliminated_terms_reuse.pdf"
#+HEADER: :width 12 :height 10 :exports results
#+begin_SRC R
base_size <- 25

ggplot(subset(eliminated_terms, removed_variables != ""),
       aes(x = removed_variables,
           fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = c(0.8, 0.95),
        legend.background = element_blank(),
        legend.direction = "horizontal",
        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(name = "Step", palette = "Set2")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:./img/eliminated_terms_reuse.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figureUhUeKM.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figureNOlp8P.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figurequjJQK.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file "./img/explored_space_reuse.pdf" :width 13 :height 12 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 2) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.8) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              size = 3, width = 0.1, height = 0, alpha = 0.2) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            angle = 0,
            color = "white",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = c(1, 2, 3, 4),
                   expand = c(0.3, 0.3)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 25) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        strip.background = element_rect(size = 1, fill = "white"),
        strip.text = element_text(size = 15),
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:explored_space_reuse
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:./img/explored_space_reuse.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I, OMP, SCR, VEC1, VEC2) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-new
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figureSHJRg0.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "graoully-16"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "graoully-16"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{graoully-16}
#+LABEL: fig:lm-rs-nobin-g16-new
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figureG7DSgI.pdf]]

#+begin_SRC R :results graphics output :session *R* :file "./img/models_reuse.pdf" :width 19 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
    mutate(RT_I = log2(RT_I)) %>%
    mutate(RT_J = log2(RT_J)) %>%
    mutate(T1_I = log2(T1_I)) %>%
    mutate(T2_I = log2(T2_I)) %>%
    mutate(T1_J = log2(T1_J)) %>%
    mutate(T2_J = log2(T2_J)) %>%
    gather("factor", "level", T2_I, T2_J, RT_I,
           T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
           RT_J, T1_I, SCR) %>%
    mutate(level = str_replace(level, "True", "1")) %>%
    mutate(level = str_replace(level, "False", "0")) %>%
    mutate(level = as.numeric(level)) %>%
    subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
    facet_wrap(factor ~ ., ncol = 5, scale = "free") +
    geom_point(alpha = 0.4,
               stat = "unique") +
    geom_quantile(formula = y ~ poly(x, 2),
                  quantiles = c(0.01, 0.05, 0.15, 0.25),
                  size = 1,
                  alpha = 0.6,
                  color = "darkgreen") +
    geom_smooth(method = "lm", color = "blue") +
    geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
    geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)),
               size = 2, color = "red",
               stat = "unique") +
    ylab("Execution Time (s)") +
    xlab("Factor Levels") +
    theme_bw(base_size = 22) +
    theme(strip.background = element_rect(fill = "white"))
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:./img/models_reuse.pdf]]

#+begin_SRC R :results graphics output :session *R* :file "./img/models_fixed_omp_reuse.pdf" :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
    mutate(RT_I = log2(RT_I)) %>%
    mutate(RT_J = log2(RT_J)) %>%
    mutate(T1_I = log2(T1_I)) %>%
    mutate(T2_I = log2(T2_I)) %>%
    mutate(T1_J = log2(T1_J)) %>%
    mutate(T2_J = log2(T2_J)) %>%
    subset(OMP == "True") %>%
    gather("factor", "level", T2_I, T2_J, RT_I,
           T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
           RT_J, T1_I, SCR) %>%
    mutate(level = str_replace(level, "True", "1")) %>%
    mutate(level = str_replace(level, "False", "0")) %>%
    mutate(level = as.numeric(level)) %>%
    subset(technique == "RS") %>%
    filter(factor != "OMP")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
    facet_wrap(factor ~ ., ncol = 4, scale = "free") +
    geom_point(alpha = 0.4,
               stat = "unique") +
    geom_quantile(formula = y ~ poly(x, 2),
                  quantiles = c(0.01, 0.05, 0.15, 0.25),
                  size = 1,
                  alpha = 0.6,
                  color = "darkgreen") +
    geom_smooth(method = "lm", color = "blue") +
    geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
    geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)),
               size = 2, color = "red",
               stat = "unique") +
    ylab("Execution Time (s)") +
    xlab("Factor Levels") +
    theme_bw(base_size = 20) +
    theme(strip.background = element_rect(fill = "white"))
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, with \texttt{OMP} fixed to \texttt{true}
#+LABEL: fig:lm-rs-nobin
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:./img/models_fixed_omp_reuse.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file "./img/predictions_reuse.pdf" :width 17 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

colors = c("Best step prediction",
           "Best in step design",
           "Best measurement")

point_size = 3.5
line_size = 2

ggplot(summaries) +
    geom_path(aes(x = step,
                  y = predicted_best,
                  color = colors[1]),
              size = line_size) +
    geom_point(aes(x = step,
                   y = predicted_best,
                   color = colors[1]),
               size = point_size) +
    geom_path(aes(x = step,
                  y = design_best,
                  color = colors[2]),
              size = line_size) +
    geom_point(aes(x = step,
                   y = design_best,
                   color = colors[2]),
               size = point_size) +
    geom_path(aes(x = step,
                  y = current_best,
                  color = colors[3]),
              linetype = 2,
              size = line_size) +
    geom_point(aes(x = step,
                   y = current_best,
                   color = colors[3]),
               size = point_size) +
    facet_wrap(experiment_id ~ ., ncol = 4) +
    ylab("Execution Time (s)") +
    xlab("Step") +
    scale_x_discrete(limits = unique(spread_data$step)) +
    theme_bw(base_size = 22) +
    theme(text = element_text(family = "sans"),
          legend.position = c(0.09, 0.95),
          legend.direction = "vertical",
          legend.background = element_blank(),
          legend.title = element_blank(),
          strip.background = element_rect(fill = "white")) +
    scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:./img/predictions_reuse.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-new
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figurekA5QNA.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Reuse Data for =aov= and =lm=: Binary set to =False=
This experiment  uses an initial model  with linear and quadratic  terms for all
factors.  All binary  parameters were  fixed to  its =False=  value.  We  hoped to
determine if the effects of binary factors, which are proportionally much larger
than the  effects of  the other  factors, were preventing  the detection  of the
significance of the other factors.

****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/updated_binfalse_dlmt"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    print(csv_file)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	73 obs. of  3 variables:
 $ removed_variables: Factor w/ 10 levels "","I(RT_I^2)",..: 1 2 2 4 3 1 1 4 2 5 ...
 $ step             : int  1 2 2 2 3 4 1 2 2 3 ...
 $ experiment_id    : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-11" ...
'data.frame':	360 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->512" "T1_J->512" "U_J->1" "U_I->15" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
 $ experiment_id          : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-11" ...
'data.frame':	832 obs. of  27 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1024 1 1 1 32 256 8 1 2048 2048 ...
 $ T1_J                        : int  1 128 16 2048 1 2048 32 1 128 2 ...
 $ cost_mean                   : num  4.58 3.58 6.21 3.68 3.34 ...
 $ U_J                         : int  14 22 15 1 12 1 30 30 1 2 ...
 $ U_I                         : int  1 1 1 29 1 1 1 1 30 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 32 32 2048 2048 256 1 256 2048 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  32 1 2048 1 128 1 128 1 1 512 ...
 $ U1_I                        : int  1 17 30 27 14 10 30 1 3 30 ...
 $ mean_confidence_interval_inf: num  4.58 3.58 6.21 3.66 3.34 ...
 $ mean_confidence_interval_sup: num  4.58 3.58 6.21 3.7 3.34 ...
 $ cost_std                    : num  0.000187 0.000144 0.000764 0.035888 0.000108 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 2 32 2 8 32 16 1 32 1 ...
 $ RT_J                        : int  1 1 4 16 8 1 1 16 2 32 ...
 $ experiment_id               : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-11" ...
 $ cost_baseline               : num  4.96 4.96 4.96 4.96 4.96 ...
 $ speedup                     : num  1.082 1.385 0.799 1.347 1.484 ...
 $ max_run_speedup             : num  1.56 1.56 1.56 1.56 1.56 ...
 $ min_run_cost                : num  3.18 3.18 3.18 3.18 3.18 ...
 $ best_iteration              : num  19 19 19 19 19 19 19 19 19 19 ...
 $ points                      : int  84 84 84 84 84 84 84 84 84 84 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
tibble [10 × 30] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:10] 19 2 11 62 31 25 14 78 65 12
 $ runs                        : int [1:10] 10 10 10 10 10 10 10 10 10 10
 $ baseline                    : chr [1:10] "False" "False" "False" "False" ...
 $ T1_I                        : int [1:10] 512 256 1 1 32 1 1 32 128 32
 $ T1_J                        : int [1:10] 512 1 2 1 2048 1 2048 1 1 64
 $ cost_mean                   : num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ U_J                         : int [1:10] 1 1 1 1 1 1 1 1 1 1
 $ U_I                         : int [1:10] 15 18 15 14 29 30 30 1 1 10
 $ technique                   : chr [1:10] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int [1:10] 512 2048 1 128 2048 256 2048 2048 128 32
 $ correct_result              : chr [1:10] "True" "True" "True" "True" ...
 $ T2_J                        : int [1:10] 1 64 128 2048 2048 2048 2048 1 1 2048
 $ U1_I                        : int [1:10] 30 30 21 30 2 1 30 14 28 1
 $ mean_confidence_interval_inf: num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ mean_confidence_interval_sup: num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ cost_std                    : num [1:10] 1.30e-04 1.79e-04 1.71e-04 1.36e-04 9.59e-05 ...
 $ step                        : int [1:10] 1 1 1 3 2 2 1 4 3 1
 $ RT_I                        : int [1:10] 1 1 4 4 16 16 16 4 4 1
 $ RT_J                        : int [1:10] 4 8 1 2 8 2 4 2 2 2
 $ experiment_id               : chr [1:10] "paravance-11" "paravance-14" "paravance-19" "paravance-25" ...
 $ cost_baseline               : num [1:10] 4.96 4.75 5.06 4.75 4.85 ...
 $ speedup                     : num [1:10] 1.56 1.49 1.66 1.49 1.54 ...
 $ max_run_speedup             : num [1:10] 1.56 1.49 1.66 1.49 1.54 ...
 $ min_run_cost                : num [1:10] 3.18 3.2 3.05 3.18 3.15 ...
 $ best_iteration              : num [1:10] 19 2 11 62 31 25 14 78 65 12
 $ points                      : int [1:10] 84 83 80 86 83 79 84 84 83 86
 $ application                 : chr [1:10] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:10] 4.85 4.85 4.85 4.85 4.85 ...
 $ label_center_x              : num [1:10] 4.16 4.16 4.16 4.16 4.16 ...
 $ label_center_y              : num [1:10] 32.1 32.1 32.1 32.1 32.1 ...
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-16_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-18_1569094827/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-2_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-20_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-21_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-22_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-23_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-24_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-30_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-31_1569094829/search_space.csv"
tibble [20 × 30] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:20] 19 2 11 62 31 25 14 78 65 12 ...
 $ runs                        : int [1:20] 10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr [1:20] "False" "False" "False" "False" ...
 $ T1_I                        : int [1:20] 512 256 1 1 32 1 1 32 128 32 ...
 $ T1_J                        : int [1:20] 512 1 2 1 2048 1 2048 1 1 64 ...
 $ cost_mean                   : num [1:20] 3.18 3.2 3.05 3.18 3.15 ...
 $ U_J                         : int [1:20] 1 1 1 1 1 1 1 1 1 1 ...
 $ U_I                         : int [1:20] 15 18 15 14 29 30 30 1 1 10 ...
 $ technique                   : chr [1:20] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int [1:20] 512 2048 1 128 2048 256 2048 2048 128 32 ...
 $ correct_result              : chr [1:20] "True" "True" "True" "True" ...
 $ T2_J                        : int [1:20] 1 64 128 2048 2048 2048 2048 1 1 2048 ...
 $ U1_I                        : int [1:20] 30 30 21 30 2 1 30 14 28 1 ...
 $ mean_confidence_interval_inf: num [1:20] 3.18 3.2 3.05 3.18 3.15 ...
 $ mean_confidence_interval_sup: num [1:20] 3.18 3.2 3.05 3.18 3.15 ...
 $ cost_std                    : num [1:20] 1.30e-04 1.79e-04 1.71e-04 1.36e-04 9.59e-05 ...
 $ step                        : int [1:20] 1 1 1 3 2 2 1 4 3 1 ...
 $ RT_I                        : int [1:20] 1 1 4 4 16 16 16 4 4 1 ...
 $ RT_J                        : int [1:20] 4 8 1 2 8 2 4 2 2 2 ...
 $ experiment_id               : chr [1:20] "paravance-11" "paravance-14" "paravance-19" "paravance-25" ...
 $ cost_baseline               : num [1:20] 4.96 4.75 5.06 4.75 4.85 ...
 $ speedup                     : num [1:20] 1.56 1.49 1.66 1.49 1.54 ...
 $ max_run_speedup             : num [1:20] 1.56 1.49 1.66 1.49 1.54 ...
 $ min_run_cost                : num [1:20] 3.18 3.2 3.05 3.18 3.15 ...
 $ best_iteration              : num [1:20] 19 2 11 62 31 25 14 78 65 12 ...
 $ points                      : int [1:20] 84 83 80 86 83 79 84 84 83 86 ...
 $ application                 : chr [1:20] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:20] 4.85 4.85 4.85 4.85 4.85 ...
 $ label_center_x              : num [1:20] 4.16 4.16 4.16 4.16 4.16 ...
 $ label_center_y              : num [1:20] 32.1 32.1 32.1 32.1 32.1 ...
'data.frame':	52 obs. of  17 variables:
 $ id                     : int  2 2 2 2 2 2 2 2 2 2 ...
 $ valid_configurations   : int  52800 52800 52800 52800 52800 52800 52800 52800 52800 52800 ...
 $ D                      : num  0.227 0.227 0.227 0.23 0.23 ...
 $ used_budget            : int  22 22 22 22 22 22 22 22 22 22 ...
 $ model_size             : int  18 18 18 18 18 18 18 18 18 18 ...
 $ current_best           : num  3.18 3.18 3.18 3.2 3.2 ...
 $ trials                 : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best_coordinate: chr  "{'T1_I': 512, 'T1_J': 512, 'U_J': 1, 'U_I': 15, 'T2_I': 512, 'T2_J': 1, 'U1_I': 30, 'RT_I': 1, 'RT_J': 4}" "{'T1_I': 512, 'T1_J': 512, 'U_J': 1, 'U_I': 15, 'T2_I': 512, 'T2_J': 1, 'U1_I': 30, 'RT_I': 1, 'RT_J': 4}" "{'T1_I': 512, 'T1_J': 512, 'U_J': 1, 'U_I': 15, 'T2_I': 512, 'T2_J': 1, 'U1_I': 30, 'RT_I': 1, 'RT_J': 4}" "{'T1_I': 256, 'T1_J': 1, 'U_J': 1, 'U_I': 18, 'T2_I': 2048, 'T2_J': 64, 'U1_I': 30, 'RT_I': 1, 'RT_J': 8}" ...
 $ tested_configurations  : int  2523006 2523006 2523006 2529754 2529754 2521004 2521004 2521004 2539995 2539995 ...
 $ fixed_factors          : chr  "{'RT_I': 2}" "{'RT_I': 2}" "{'RT_I': 2}" "{'RT_I': 2}" ...
 $ step                   : int  2 2 2 2 2 2 2 2 2 2 ...
 $ design_best            : num  3.2 3.2 3.2 3.33 3.33 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "I(RT_I^2)" "I(RT_I^2)" "RT_I" "RT_I" ...
 $ model                  : chr  "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  3.94 3.94 3.94 5.55 5.55 ...
 $ experiment_id          : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-14" ...
'data.frame':	842 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1024 1 1 1 32 256 8 1 2048 2048 ...
 $ T1_J                        : int  1 128 16 2048 1 2048 32 1 128 2 ...
 $ cost_mean                   : num  4.58 3.58 6.21 3.68 3.34 ...
 $ U_J                         : int  14 22 15 1 12 1 30 30 1 2 ...
 $ U_I                         : int  1 1 1 29 1 1 1 1 30 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 32 32 2048 2048 256 1 256 2048 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  32 1 2048 1 128 1 128 1 1 512 ...
 $ U1_I                        : int  1 17 30 27 14 10 30 1 3 30 ...
 $ mean_confidence_interval_inf: num  4.58 3.58 6.21 3.66 3.34 ...
 $ mean_confidence_interval_sup: num  4.58 3.58 6.21 3.7 3.34 ...
 $ cost_std                    : num  0.000187 0.000144 0.000764 0.035888 0.000108 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 2 32 2 8 32 16 1 32 1 ...
 $ RT_J                        : int  1 1 4 16 8 1 1 16 2 32 ...
 $ experiment_id               : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-11" ...
There were 40 warnings (use warnings() to see them)
Joining, by = c("id", "step")
tibble [692 × 4] (S3: tbl_df/tbl/data.frame)
 $ metric_value: num [1:692] 0.028 0.101 0.111 0.0949 0.0835 ...
 $ factors     : chr [1:692] "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr [1:692] "paravance-11" "paravance-11" "paravance-11" "paravance-11" ...
 $ step        : num [1:692] 1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-new-bf
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-VnHilA/figurek7MnXw.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 06:39:16 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}} cccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
paravance-11 & DLMT & 3.184848 & 512 & 512 & 1 & 15 & 512 & 1 & 30 & 1 & 4 \\
paravance-14 & DLMT & 3.196773 & 256 & 1 & 1 & 18 & 2048 & 64 & 30 & 1 & 8 \\
paravance-19 & DLMT & 3.04968 & 1 & 2 & 1 & 15 & 1 & 128 & 21 & 4 & 1 \\
paravance-25 & DLMT & 3.183022 & 1 & 1 & 1 & 14 & 128 & 2048 & 30 & 4 & 2 \\
paravance-26 & DLMT & 3.154706 & 32 & 2048 & 1 & 29 & 2048 & 2048 & 2 & 16 & 8 \\
paravance-27 & DLMT & 3.145299 & 1 & 1 & 1 & 30 & 256 & 2048 & 1 & 16 & 2 \\
paravance-28 & DLMT & 3.120673 & 1 & 2048 & 1 & 30 & 2048 & 2048 & 30 & 16 & 4 \\
paravance-29 & DLMT & 3.16354 & 32 & 1 & 1 & 1 & 2048 & 1 & 14 & 4 & 2 \\
paravance-3 & DLMT & 3.158316 & 128 & 1 & 1 & 1 & 128 & 1 & 28 & 4 & 2 \\
paravance-32 & DLMT & 3.197007 & 32 & 64 & 1 & 10 & 32 & 2048 & 1 & 1 & 2 \\
paravance-16 & RS & 3.118132 & 1 & 256 & 25 & 1 & 32 & 512 & 20 & 16 & 4 \\
paravance-18 & RS & 3.042194 & 1 & 2 & 1 & 19 & 1 & 256 & 22 & 4 & 1 \\
paravance-2 & RS & 3.131061 & 1 & 1024 & 1 & 6 & 256 & 2048 & 20 & 16 & 2 \\
paravance-20 & RS & 3.120612 & 256 & 1024 & 13 & 1 & 1 & 1024 & 26 & 16 & 2 \\
paravance-21 & RS & 3.112708 & 32 & 1 & 30 & 1 & 64 & 512 & 20 & 16 & 2 \\
paravance-22 & RS & 3.124333 & 256 & 1 & 1 & 12 & 256 & 1024 & 28 & 8 & 2 \\
paravance-23 & RS & 3.11485 & 512 & 512 & 25 & 1 & 2048 & 2048 & 3 & 16 & 4 \\
paravance-24 & RS & 3.106786 & 128 & 1 & 12 & 1 & 512 & 1 & 23 & 8 & 2 \\
paravance-30 & RS & 3.104083 & 32 & 2048 & 12 & 1 & 1 & 2048 & 8 & 16 & 2 \\
paravance-31 & RS & 3.116196 & 2048 & 256 & 1 & 19 & 2048 & 1 & 24 & 8 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export


****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-new-bf
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeRAoHm.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-new-bf
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure2m33md.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-new-bf
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureLgLJS8.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-29"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.29),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-29"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-29}
#+LABEL: fig:lm-rs-nobin-p29-new-bf
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureAw53CA.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-new-bf
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-new-bf
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure21sY97.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-new-bf
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Updated DLMT with Quantile Regression ($\tau = 0.05$, Binary Parameters)
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_dlmt_nocarry_tau005"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
# data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][5], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	87 obs. of  3 variables:
 $ removed_variables: Factor w/ 21 levels "","OMP","SCR",..: 1 2 6 3 8 12 1 4 2 5 ...
 $ step             : int  1 2 2 2 2 2 3 4 1 1 ...
 $ experiment_id    : chr  "paravance-44" "paravance-44" "paravance-44" "paravance-44" ...
'data.frame':	520 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->16" "T1_J->1" "U_J->1" "U_I->6" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ experiment_id          : chr  "paravance-44" "paravance-44" "paravance-44" "paravance-44" ...
'data.frame':	862 obs. of  31 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 10 11 ...
 $ T2_J                        : int  512 1 64 32 128 128 1 1 256 4 ...
 $ T2_I                        : int  2048 1 1 2048 512 1 2048 2048 64 1 ...
 $ RT_I                        : int  4 8 1 32 8 8 1 1 8 32 ...
 $ mean_confidence_interval_inf: num  0.61 0.658 0.871 0.75 4.646 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  32 2048 8 4 2 128 32 16 64 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "True" "True" "True" "False" ...
 $ VEC1                        : chr  "False" "False" "True" "False" ...
 $ SCR                         : chr  "False" "True" "True" "False" ...
 $ U1_I                        : int  30 4 7 15 14 4 23 2 29 29 ...
 $ RT_J                        : int  1 16 4 1 16 1 1 32 4 4 ...
 $ T1_I                        : int  2048 16 1 1 512 2048 32 512 16 2048 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.195792 0.100415 0.028229 0.172001 0.000452 ...
 $ cost_mean                   : num  0.731 0.72 0.889 0.857 4.646 ...
 $ U_J                         : int  29 30 16 1 30 1 30 1 1 25 ...
 $ U_I                         : int  1 1 1 29 1 30 1 14 16 1 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.852 0.783 0.906 0.964 4.646 ...
 $ experiment_id               : chr  "paravance-44" "paravance-44" "paravance-44" "paravance-44" ...
 $ cost_baseline               : num  4.85 4.85 4.85 4.85 4.85 ...
 $ speedup                     : num  6.63 6.73 5.45 5.66 1.04 ...
 $ max_run_speedup             : num  9.28 9.28 9.28 9.28 9.28 ...
 $ min_run_cost                : num  0.522 0.522 0.522 0.522 0.522 ...
 $ best_iteration              : num  89 89 89 89 89 89 89 89 89 89 ...
 $ points                      : int  87 87 87 87 87 87 87 87 87 87 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
tibble [10 × 34] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:10] 89 31 78 60 56 38 59 32 54 35
 $ T2_J                        : int [1:10] 1 1 2048 2048 2048 512 1 2048 256 2048
 $ T2_I                        : int [1:10] 1 2048 1 2048 2048 2048 2048 2048 2048 1
 $ RT_I                        : int [1:10] 16 4 4 4 4 4 16 16 1 8
 $ mean_confidence_interval_inf: num [1:10] 0.499 0.416 0.438 0.433 0.426 ...
 $ baseline                    : chr [1:10] "False" "False" "False" "False" ...
 $ T1_J                        : int [1:10] 2048 2048 2048 2048 2048 16 2048 1 128 2048
 $ technique                   : chr [1:10] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr [1:10] "False" "False" "False" "False" ...
 $ VEC1                        : chr [1:10] "False" "True" "True" "False" ...
 $ SCR                         : chr [1:10] "True" "True" "True" "True" ...
 $ U1_I                        : int [1:10] 1 29 30 1 20 28 30 8 9 12
 $ RT_J                        : int [1:10] 1 32 1 1 4 1 4 4 4 8
 $ T1_I                        : int [1:10] 2048 2048 2048 1 1 2048 1 2048 1 2048
 $ runs                        : int [1:10] 10 10 10 10 10 10 10 10 10 10
 $ cost_std                    : num [1:10] 0.0381 0.2693 0.0437 0.0642 0.2524 ...
 $ cost_mean                   : num [1:10] 0.522 0.583 0.465 0.473 0.583 ...
 $ U_J                         : int [1:10] 18 3 1 15 17 1 1 1 1 30
 $ U_I                         : int [1:10] 1 1 30 1 1 30 14 7 7 1
 $ step                        : int [1:10] 4 2 4 3 3 2 3 2 2 2
 $ correct_result              : chr [1:10] "True" "True" "True" "True" ...
 $ OMP                         : chr [1:10] "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num [1:10] 0.546 0.75 0.492 0.513 0.739 ...
 $ experiment_id               : chr [1:10] "paravance-44" "paravance-49" "paravance-58" "paravance-61" ...
 $ cost_baseline               : num [1:10] 4.85 4.95 4.75 4.75 4.85 ...
 $ speedup                     : num [1:10] 9.28 8.5 10.22 10.04 8.32 ...
 $ max_run_speedup             : num [1:10] 9.28 8.5 10.22 10.04 8.32 ...
 $ min_run_cost                : num [1:10] 0.522 0.583 0.465 0.473 0.583 ...
 $ best_iteration              : num [1:10] 89 31 78 60 56 38 59 32 54 35
 $ points                      : int [1:10] 87 87 87 85 96 69 90 88 85 88
 $ application                 : chr [1:10] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:10] 4.79 4.79 4.79 4.79 4.79 ...
 $ label_center_x              : num [1:10] 1.44 1.44 1.44 1.44 1.44 ...
 $ label_center_y              : num [1:10] 53.5 53.5 53.5 53.5 53.5 ...
tibble [20 × 34] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:20] 89 31 78 60 56 38 59 32 54 35 ...
 $ T2_J                        : int [1:20] 1 1 2048 2048 2048 512 1 2048 256 2048 ...
 $ T2_I                        : int [1:20] 1 2048 1 2048 2048 2048 2048 2048 2048 1 ...
 $ RT_I                        : int [1:20] 16 4 4 4 4 4 16 16 1 8 ...
 $ mean_confidence_interval_inf: num [1:20] 0.499 0.416 0.438 0.433 0.426 ...
 $ baseline                    : chr [1:20] "False" "False" "False" "False" ...
 $ T1_J                        : int [1:20] 2048 2048 2048 2048 2048 16 2048 1 128 2048 ...
 $ technique                   : chr [1:20] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr [1:20] "False" "False" "False" "False" ...
 $ VEC1                        : chr [1:20] "False" "True" "True" "False" ...
 $ SCR                         : chr [1:20] "True" "True" "True" "True" ...
 $ U1_I                        : int [1:20] 1 29 30 1 20 28 30 8 9 12 ...
 $ RT_J                        : int [1:20] 1 32 1 1 4 1 4 4 4 8 ...
 $ T1_I                        : int [1:20] 2048 2048 2048 1 1 2048 1 2048 1 2048 ...
 $ runs                        : int [1:20] 10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num [1:20] 0.0381 0.2693 0.0437 0.0642 0.2524 ...
 $ cost_mean                   : num [1:20] 0.522 0.583 0.465 0.473 0.583 ...
 $ U_J                         : int [1:20] 18 3 1 15 17 1 1 1 1 30 ...
 $ U_I                         : int [1:20] 1 1 30 1 1 30 14 7 7 1 ...
 $ step                        : int [1:20] 4 2 4 3 3 2 3 2 2 2 ...
 $ correct_result              : chr [1:20] "True" "True" "True" "True" ...
 $ OMP                         : chr [1:20] "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num [1:20] 0.546 0.75 0.492 0.513 0.739 ...
 $ experiment_id               : chr [1:20] "paravance-44" "paravance-49" "paravance-58" "paravance-61" ...
 $ cost_baseline               : num [1:20] 4.85 4.95 4.75 4.75 4.85 ...
 $ speedup                     : num [1:20] 9.28 8.5 10.22 10.04 8.32 ...
 $ max_run_speedup             : num [1:20] 9.28 8.5 10.22 10.04 8.32 ...
 $ min_run_cost                : num [1:20] 0.522 0.583 0.465 0.473 0.583 ...
 $ best_iteration              : num [1:20] 89 31 78 60 56 38 59 32 54 35 ...
 $ points                      : int [1:20] 87 87 87 85 96 69 90 88 85 88 ...
 $ application                 : chr [1:20] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:20] 4.79 4.79 4.79 4.79 4.79 ...
 $ label_center_x              : num [1:20] 1.44 1.44 1.44 1.44 1.44 ...
 $ label_center_y              : num [1:20] 53.5 53.5 53.5 53.5 53.5 ...
'data.frame':	69 obs. of  17 variables:
 $ id                     : int  1 1 1 1 2 2 2 2 2 2 ...
 $ valid_configurations   : int  62400 62400 62400 62400 62400 62400 62400 62400 62400 55200 ...
 $ D                      : num  0.209 0.209 0.209 0.205 0.219 ...
 $ used_budget            : int  0 0 0 0 25 25 25 25 25 26 ...
 $ model_size             : int  22 22 22 22 22 22 22 22 22 19 ...
 $ current_best           : num  0.588 0.588 0.688 0.542 0.631 ...
 $ trials                 : int  26 26 26 26 26 26 26 26 26 23 ...
 $ current_best_coordinate: chr  "{'T1_I': 2048, 'T1_J': 32, 'U_J': 2, 'U_I': 1, 'T2_I': 2048, 'T2_J': 1, 'U1_I': 27, 'OMP': True, 'VEC2': True, "| __truncated__ "{'T1_I': 2048, 'T1_J': 32, 'U_J': 2, 'U_I': 1, 'T2_I': 2048, 'T2_J': 1, 'U1_I': 27, 'OMP': True, 'VEC2': True, "| __truncated__ "{'T1_I': 1, 'T1_J': 4, 'U_J': 1, 'U_I': 11, 'T2_I': 2048, 'T2_J': 1, 'U1_I': 17, 'OMP': True, 'VEC2': True, 'VE"| __truncated__ "{'T1_I': 32, 'T1_J': 32, 'U_J': 1, 'U_I': 1, 'T2_I': 128, 'T2_J': 2048, 'U1_I': 16, 'OMP': True, 'VEC2': True, "| __truncated__ ...
 $ tested_configurations  : int  2987448 2987448 3002977 2984424 3005886 3005886 3005886 3005886 3005886 1642823 ...
 $ fixed_factors          : chr  "{'T2_I': 11, 'OMP': 1}" "{'T2_I': 11, 'OMP': 1}" "{'OMP': 1}" "{'OMP': 1}" ...
 $ step                   : int  1 1 1 1 2 2 2 2 2 2 ...
 $ design_best            : num  0.588 0.588 0.688 0.542 0.662 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "OMP" "I(T2_I^2)" "OMP" "OMP" ...
 $ model                  : chr  "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  0.7 0.7 0.808 0.636 0.838 ...
 $ experiment_id          : chr  "paravance-49" "paravance-49" "paravance-65" "paravance-66" ...
'data.frame':	888 obs. of  24 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  512 1 64 32 128 128 1 1 2048 256 ...
 $ T2_I                        : int  2048 1 1 2048 512 1 2048 2048 1 64 ...
 $ RT_I                        : int  4 8 1 32 8 8 1 1 4 8 ...
 $ mean_confidence_interval_inf: num  0.61 0.658 0.871 0.75 4.646 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  32 2048 8 4 2 128 32 16 1 64 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "True" "True" "True" "False" ...
 $ VEC1                        : chr  "False" "False" "True" "False" ...
 $ SCR                         : chr  "False" "True" "True" "False" ...
 $ U1_I                        : int  30 4 7 15 14 4 23 2 30 29 ...
 $ RT_J                        : int  1 16 4 1 16 1 1 32 32 4 ...
 $ T1_I                        : int  2048 16 1 1 512 2048 32 512 32 16 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 1 10 ...
 $ cost_std                    : num  0.195792 0.100415 0.028229 0.172001 0.000452 ...
 $ cost_mean                   : num  0.731 0.72 0.889 0.857 4.646 ...
 $ U_J                         : int  29 30 16 1 30 1 30 1 1 1 ...
 $ U_I                         : int  1 1 1 29 1 30 1 14 30 16 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.852 0.783 0.906 0.964 4.646 ...
 $ experiment_id               : chr  "paravance-44" "paravance-44" "paravance-44" "paravance-44" ...
There were 40 warnings (use warnings() to see them)
Joining, by = c("id", "step")
tibble [739 × 4] (S3: tbl_df/tbl/data.frame)
 $ metric_value: num [1:739] 0.015 0.073 0.0864 0.0878 0.0646 ...
 $ factors     : chr [1:739] "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr [1:739] "paravance-44" "paravance-44" "paravance-44" "paravance-44" ...
 $ step        : num [1:739] 1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

mixed_plot_data = bind_rows(mixed_plot_data,
                            it_data %>%
                            mutate(technique = gsub(pattern = "DLMT",
                                                    replacement = "Quantile Regression (tau = 0.05)",
                                                    x = technique, fixed = TRUE)) %>%
                            filter(technique != "RS"))

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-q05
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-VnHilA/figureXDXZM0.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J, OMP, SCR, VEC1, VEC2), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "tiny")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Tue, Sep 24, 2019 - 09:47:50 AM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\tiny
\begin{tabular}{@{\extracolsep{0pt}} ccccccccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & step & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J & OMP & SCR & VEC1 & VEC2 \\
\hline \\[-1.8ex]
paravance-44 & DLMT & 4 & 0.5222684 & 2048 & 2048 & 18 & 1 & 1 & 1 & 1 & 16 & 1 & True & True & False & False \\
paravance-49 & DLMT & 2 & 0.5829423 & 2048 & 2048 & 3 & 1 & 2048 & 1 & 29 & 4 & 32 & True & True & True & False \\
paravance-58 & DLMT & 4 & 0.4648992 & 2048 & 2048 & 1 & 30 & 1 & 2048 & 30 & 4 & 1 & True & True & True & False \\
paravance-61 & DLMT & 3 & 0.4732099 & 1 & 2048 & 15 & 1 & 2048 & 2048 & 1 & 4 & 1 & True & True & False & False \\
paravance-62 & DLMT & 3 & 0.582568 & 1 & 2048 & 17 & 1 & 2048 & 2048 & 20 & 4 & 4 & True & True & False & True \\
paravance-63 & DLMT & 2 & 0.5494125 & 2048 & 16 & 1 & 30 & 2048 & 512 & 28 & 4 & 1 & True & True & False & False \\
paravance-64 & DLMT & 3 & 0.4743967 & 1 & 2048 & 1 & 14 & 2048 & 1 & 30 & 16 & 4 & True & True & True & False \\
paravance-65 & DLMT & 2 & 0.6593068 & 2048 & 1 & 1 & 7 & 2048 & 2048 & 8 & 16 & 4 & True & True & False & False \\
paravance-66 & DLMT & 2 & 0.4504963 & 1 & 128 & 1 & 7 & 2048 & 256 & 9 & 1 & 4 & True & True & True & True \\
paravance-71 & DLMT & 2 & 0.5226401 & 2048 & 2048 & 30 & 1 & 1 & 2048 & 12 & 8 & 8 & True & True & False & False \\
paravance-50 & RS & NA & 0.5685274 & 512 & 512 & 19 & 1 & 2048 & 1024 & 27 & 4 & 1 & True & True & True & False \\
paravance-51 & RS & NA & 0.5467725 & 1024 & 32 & 10 & 1 & 2048 & 512 & 9 & 8 & 8 & True & True & True & True \\
paravance-52 & RS & NA & 0.5417953 & 2048 & 8 & 9 & 1 & 2048 & 128 & 30 & 8 & 16 & True & True & True & True \\
paravance-53 & RS & NA & 0.5612387 & 2048 & 64 & 16 & 1 & 2048 & 256 & 9 & 16 & 2 & True & True & True & True \\
paravance-54 & RS & NA & 0.5322531 & 2048 & 8 & 1 & 9 & 1 & 1 & 19 & 1 & 1 & True & True & True & False \\
paravance-55 & RS & NA & 0.5540684 & 32 & 4 & 1 & 5 & 2048 & 256 & 4 & 16 & 1 & True & True & False & False \\
paravance-56 & RS & NA & 0.4648199 & 2048 & 1 & 1 & 23 & 1 & 512 & 25 & 8 & 1 & True & True & False & True \\
paravance-57 & RS & NA & 0.5463944 & 256 & 16 & 1 & 15 & 2048 & 512 & 2 & 2 & 2 & True & True & False & False \\
paravance-58 & RS & NA & 0.5496127 & 32 & 1 & 1 & 14 & 2048 & 2048 & 24 & 8 & 4 & True & True & True & True \\
paravance-59 & RS & NA & 0.4758884 & 64 & 16 & 29 & 1 & 2048 & 1 & 27 & 16 & 4 & True & True & True & True \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-q05
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeRAoHm.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureXncsjg.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I, OMP, SCR, VEC1, VEC2) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figuresjumNZ.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-62"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-62"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-62}
#+LABEL: fig:lm-rs-nobin-p62-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeG8fKl.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I, OMP, SCR, VEC1, VEC2) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureWM6DrI.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Updated DLMT with Quantile Regression ($\tau = 0.05$)       :noexport:
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_binfalse_dlmt_nocarry_tau005"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	54 obs. of  3 variables:
 $ removed_variables: Factor w/ 13 levels "","RT_I","I(RT_I^2)",..: 1 2 3 4 1 11 1 3 2 1 ...
 $ step             : int  1 2 2 2 3 4 1 2 2 3 ...
 $ experiment_id    : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...
'data.frame':	324 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->1" "T1_J->128" "U_J->1" "U_I->30" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
 $ experiment_id          : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...
'data.frame':	705 obs. of  27 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  8 2048 256 32 64 4 2048 1024 32 1 ...
 $ T1_J                        : int  32 4 1 4 2048 64 2 2048 16 2048 ...
 $ cost_mean                   : num  4.58 3.87 6.44 3.49 5.51 ...
 $ U_J                         : int  1 1 1 1 1 30 1 1 30 30 ...
 $ U_I                         : int  30 16 30 10 19 1 2 13 1 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  2048 1 1 64 256 2048 2048 2048 32 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  128 2048 1 1 2048 1 32 1 128 1 ...
 $ U1_I                        : int  28 30 15 1 13 28 10 22 18 26 ...
 $ mean_confidence_interval_inf: num  4.58 3.87 6.44 3.49 5.51 ...
 $ mean_confidence_interval_sup: num  4.58 3.87 6.44 3.49 5.51 ...
 $ cost_std                    : num  0.000141 0.000275 0.000629 0.000141 0.002583 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 2 32 1 32 32 4 4 8 1 ...
 $ RT_J                        : int  8 32 4 1 1 1 1 8 16 2 ...
 $ experiment_id               : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...
 $ cost_baseline               : num  4.76 4.76 4.76 4.76 4.76 ...
 $ speedup                     : num  1.038 1.23 0.738 1.362 0.863 ...
 $ max_run_speedup             : num  1.52 1.52 1.52 1.52 1.52 ...
 $ min_run_cost                : num  3.13 3.13 3.13 3.13 3.13 ...
 $ best_iteration              : num  16 16 16 16 16 16 16 16 16 16 ...
 $ points                      : int  82 82 82 82 82 82 82 82 82 82 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
tibble [9 × 30] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:9] 16 7 5 8 20 62 1 55 85
 $ runs                        : int [1:9] 10 10 10 10 10 10 10 10 10
 $ baseline                    : chr [1:9] "False" "False" "False" "False" ...
 $ T1_I                        : int [1:9] 1 1 4 1 32 16 4 1 64
 $ T1_J                        : int [1:9] 128 16 32 64 2048 1 1 1 2048
 $ cost_mean                   : num [1:9] 3.13 3.3 3.23 3.21 3.21 ...
 $ U_J                         : int [1:9] 1 1 1 1 11 1 8 1 1
 $ U_I                         : int [1:9] 30 21 1 12 1 17 1 27 2
 $ technique                   : chr [1:9] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int [1:9] 128 2048 64 1 2048 64 1 2048 128
 $ correct_result              : chr [1:9] "True" "True" "True" "True" ...
 $ T2_J                        : int [1:9] 1 1 1 256 1 2048 1 1 2048
 $ U1_I                        : int [1:9] 2 1 17 1 1 1 20 2 1
 $ mean_confidence_interval_inf: num [1:9] 3.13 3.3 3.23 3.21 3.21 ...
 $ mean_confidence_interval_sup: num [1:9] 3.13 3.3 3.23 3.22 3.21 ...
 $ cost_std                    : num [1:9] 0.00036 0.000166 0.00015 0.000411 0.000133 ...
 $ step                        : int [1:9] 1 1 1 1 1 3 1 3 4
 $ RT_I                        : int [1:9] 8 1 4 1 16 8 4 4 16
 $ RT_J                        : int [1:9] 2 4 2 2 4 2 2 2 4
 $ experiment_id               : chr [1:9] "paravance-40" "paravance-41" "paravance-54" "paravance-59" ...
 $ cost_baseline               : num [1:9] 4.76 4.75 4.75 4.77 4.75 ...
 $ speedup                     : num [1:9] 1.52 1.44 1.47 1.48 1.48 ...
 $ max_run_speedup             : num [1:9] 1.52 1.44 1.47 1.48 1.48 ...
 $ min_run_cost                : num [1:9] 3.13 3.3 3.23 3.21 3.21 ...
 $ best_iteration              : num [1:9] 16 7 5 8 20 62 1 55 85
 $ points                      : int [1:9] 82 84 77 74 83 86 53 82 84
 $ application                 : chr [1:9] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:9] 4.79 4.79 4.79 4.79 4.79 ...
 $ label_center_x              : num [1:9] 4.26 4.26 4.26 4.26 4.26 ...
 $ label_center_y              : num [1:9] 30.6 30.6 30.6 30.6 30.6 ...
tibble [19 × 30] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:19] 16 7 5 8 20 62 1 55 85 18 ...
 $ runs                        : int [1:19] 10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr [1:19] "False" "False" "False" "False" ...
 $ T1_I                        : int [1:19] 1 1 4 1 32 16 4 1 64 1 ...
 $ T1_J                        : int [1:19] 128 16 32 64 2048 1 1 1 2048 256 ...
 $ cost_mean                   : num [1:19] 3.13 3.3 3.23 3.21 3.21 ...
 $ U_J                         : int [1:19] 1 1 1 1 11 1 8 1 1 25 ...
 $ U_I                         : int [1:19] 30 21 1 12 1 17 1 27 2 1 ...
 $ technique                   : chr [1:19] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int [1:19] 128 2048 64 1 2048 64 1 2048 128 32 ...
 $ correct_result              : chr [1:19] "True" "True" "True" "True" ...
 $ T2_J                        : int [1:19] 1 1 1 256 1 2048 1 1 2048 512 ...
 $ U1_I                        : int [1:19] 2 1 17 1 1 1 20 2 1 20 ...
 $ mean_confidence_interval_inf: num [1:19] 3.13 3.3 3.23 3.21 3.21 ...
 $ mean_confidence_interval_sup: num [1:19] 3.13 3.3 3.23 3.22 3.21 ...
 $ cost_std                    : num [1:19] 0.00036 0.000166 0.00015 0.000411 0.000133 ...
 $ step                        : int [1:19] 1 1 1 1 1 3 1 3 4 1 ...
 $ RT_I                        : int [1:19] 8 1 4 1 16 8 4 4 16 16 ...
 $ RT_J                        : int [1:19] 2 4 2 2 4 2 2 2 4 4 ...
 $ experiment_id               : chr [1:19] "paravance-40" "paravance-41" "paravance-54" "paravance-59" ...
 $ cost_baseline               : num [1:19] 4.76 4.75 4.75 4.77 4.75 ...
 $ speedup                     : num [1:19] 1.52 1.44 1.47 1.48 1.48 ...
 $ max_run_speedup             : num [1:19] 1.52 1.44 1.47 1.48 1.48 ...
 $ min_run_cost                : num [1:19] 3.13 3.3 3.23 3.21 3.21 ...
 $ best_iteration              : num [1:19] 16 7 5 8 20 62 1 55 85 18 ...
 $ points                      : int [1:19] 82 84 77 74 83 86 53 82 84 398 ...
 $ application                 : chr [1:19] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num [1:19] 4.79 4.79 4.79 4.79 4.79 ...
 $ label_center_x              : num [1:19] 4.26 4.26 4.26 4.26 4.26 ...
 $ label_center_y              : num [1:19] 30.6 30.6 30.6 30.6 30.6 ...
'data.frame':	34 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 2 2 2 ...
 $ valid_configurations   : int  52800 52800 52800 52800 52800 52800 52800 52800 52800 52800 ...
 $ D                      : num  0.219 0.218 0.218 0.218 0.218 ...
 $ used_budget            : int  0 0 0 0 0 0 0 22 22 22 ...
 $ model_size             : int  18 18 18 18 18 18 18 18 18 18 ...
 $ current_best           : num  3.23 3.16 3.16 3.16 3.16 ...
 $ trials                 : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best_coordinate: chr  "{'T1_I': 4, 'T1_J': 32, 'U_J': 1, 'U_I': 1, 'T2_I': 64, 'T2_J': 1, 'U1_I': 17, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 4, 'T1_J': 1, 'U_J': 8, 'U_I': 1, 'T2_I': 1, 'T2_J': 1, 'U1_I': 20, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 4, 'T1_J': 1, 'U_J': 8, 'U_I': 1, 'T2_I': 1, 'T2_J': 1, 'U1_I': 20, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 4, 'T1_J': 1, 'U_J': 8, 'U_I': 1, 'T2_I': 1, 'T2_J': 1, 'U1_I': 20, 'RT_I': 4, 'RT_J': 2}" ...
 $ tested_configurations  : int  2543526 2523646 2523646 2523646 2523646 2523646 2523646 2509565 2509565 2509565 ...
 $ fixed_factors          : chr  "{'RT_I': 0}" "{'T2_I': 0, 'U1_I': 29, 'RT_J': 5, 'RT_I': 2, 'T2_J': 0}" "{'T2_I': 0, 'U1_I': 29, 'RT_J': 5, 'RT_I': 2, 'T2_J': 0}" "{'T2_I': 0, 'U1_I': 29, 'RT_J': 5, 'RT_I': 2, 'T2_J': 0}" ...
 $ step                   : int  1 1 1 1 1 1 1 2 2 2 ...
 $ design_best            : num  3.23 3.16 3.16 3.16 3.16 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "RT_I" "RT_I" "I(RT_J^2)" "U1_I" ...
 $ model                  : chr  "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  4.68 4.12 4.12 4.12 4.12 ...
 $ experiment_id          : chr  "paravance-54" "paravance-69" "paravance-69" "paravance-69" ...
'data.frame':	721 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  8 2048 256 32 64 4 2048 1024 32 1 ...
 $ T1_J                        : int  32 4 1 4 2048 64 2 2048 16 2048 ...
 $ cost_mean                   : num  4.58 3.87 6.44 3.49 5.51 ...
 $ U_J                         : int  1 1 1 1 1 30 1 1 30 30 ...
 $ U_I                         : int  30 16 30 10 19 1 2 13 1 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  2048 1 1 64 256 2048 2048 2048 32 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  128 2048 1 1 2048 1 32 1 128 1 ...
 $ U1_I                        : int  28 30 15 1 13 28 10 22 18 26 ...
 $ mean_confidence_interval_inf: num  4.58 3.87 6.44 3.49 5.51 ...
 $ mean_confidence_interval_sup: num  4.58 3.87 6.44 3.49 5.51 ...
 $ cost_std                    : num  0.000141 0.000275 0.000629 0.000141 0.002583 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 2 32 1 32 32 4 4 8 1 ...
 $ RT_J                        : int  8 32 4 1 1 1 1 8 16 2 ...
 $ experiment_id               : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...
There were 36 warnings (use warnings() to see them)
Joining, by = c("id", "step")
tibble [600 × 4] (S3: tbl_df/tbl/data.frame)
 $ metric_value: num [1:600] 0.022 0.0983 0.089 0.1028 0.1068 ...
 $ factors     : chr [1:600] "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr [1:600] "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...
 $ step        : num [1:600] 1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-q05
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-VnHilA/figureCNEwqz.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 06:40:41 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}} cccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
paravance-19 & DLMT & 3.183816 & 64 & 256 & 1 & 11 & 1024 & 1024 & 9 & 16 & 8 \\
paravance-25 & DLMT & 3.111797 & 2048 & 1 & 21 & 1 & 1 & 2048 & 1 & 8 & 2 \\
paravance-26 & DLMT & 3.142036 & 2048 & 512 & 15 & 1 & 1 & 2048 & 10 & 16 & 2 \\
paravance-27 & DLMT & 3.294139 & 1 & 2048 & 1 & 30 & 128 & 1 & 28 & 4 & 4 \\
paravance-28 & DLMT & 3.162506 & 1 & 1 & 30 & 1 & 256 & 1 & 5 & 4 & 2 \\
paravance-29 & DLMT & 3.232323 & 2048 & 32 & 1 & 17 & 2048 & 2048 & 11 & 4 & 2 \\
paravance-3 & DLMT & 3.20722 & 2048 & 64 & 1 & 14 & 1 & 1024 & 16 & 1 & 4 \\
paravance-30 & DLMT & 3.162193 & 8 & 1 & 30 & 1 & 64 & 1 & 8 & 4 & 2 \\
paravance-31 & DLMT & 3.145759 & 1 & 1 & 1 & 16 & 32 & 64 & 1 & 1 & 4 \\
paravance-32 & DLMT & 3.212736 & 512 & 16 & 1 & 30 & 1 & 1 & 30 & 8 & 2 \\
paravance-16 & RS & 3.118132 & 1 & 256 & 25 & 1 & 32 & 512 & 20 & 16 & 4 \\
paravance-18 & RS & 3.042194 & 1 & 2 & 1 & 19 & 1 & 256 & 22 & 4 & 1 \\
paravance-2 & RS & 3.131061 & 1 & 1024 & 1 & 6 & 256 & 2048 & 20 & 16 & 2 \\
paravance-20 & RS & 3.120612 & 256 & 1024 & 13 & 1 & 1 & 1024 & 26 & 16 & 2 \\
paravance-21 & RS & 3.112708 & 32 & 1 & 30 & 1 & 64 & 512 & 20 & 16 & 2 \\
paravance-22 & RS & 3.124333 & 256 & 1 & 1 & 12 & 256 & 1024 & 28 & 8 & 2 \\
paravance-23 & RS & 3.11485 & 512 & 512 & 25 & 1 & 2048 & 2048 & 3 & 16 & 4 \\
paravance-24 & RS & 3.106786 & 128 & 1 & 12 & 1 & 512 & 1 & 23 & 8 & 2 \\
paravance-30 & RS & 3.104083 & 32 & 2048 & 12 & 1 & 1 & 2048 & 8 & 16 & 2 \\
paravance-31 & RS & 3.116196 & 2048 & 256 & 1 & 19 & 2048 & 1 & 24 & 8 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-q05
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeRAoHm.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurenBX52M.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurecPAXZd.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-67"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.67),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-67"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-67}
#+LABEL: fig:lm-rs-nobin-p67-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeG8fKl.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureWM6DrI.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Updated DLMT with Quantile Regression ($\tau = 0.10$)       :noexport:
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

#current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_binfalse_dlmt_carry_tau005"
current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_binfalse_dlmt_nocarry"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	58 obs. of  3 variables:
 $ removed_variables: Factor w/ 15 levels "","I(RT_I^2)",..: 2 4 1 6 3 1 5 2 1 3 ...
 $ step             : int  1 2 3 4 4 1 2 2 3 4 ...
 $ experiment_id    : chr  "paravance-16" "paravance-16" "paravance-16" "paravance-16" ...

'data.frame':	324 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->64" "T1_J->2048" "U_J->18" "U_I->1" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
 $ experiment_id          : chr  "paravance-16" "paravance-16" "paravance-16" "paravance-16" ...

'data.frame':	674 obs. of  27 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  32 1 64 1 2048 4 1 2048 64 64 ...
 $ T1_J                        : int  2048 128 16 1 8 256 2048 32 2048 64 ...
 $ cost_mean                   : num  3.18 3.32 3.45 3.4 3.88 ...
 $ U_J                         : int  1 14 1 1 28 1 1 1 18 30 ...
 $ U_I                         : int  1 1 30 1 1 28 17 17 1 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1024 8 128 256 2048 2048 1024 1 64 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 2048 1 64 1 256 1 256 1 512 ...
 $ U1_I                        : int  1 4 30 18 29 14 8 2 12 8 ...
 $ mean_confidence_interval_inf: num  3.18 3.32 3.45 3.4 3.88 ...
 $ mean_confidence_interval_sup: num  3.18 3.32 3.45 3.4 3.88 ...
 $ cost_std                    : num  0.00016 0.00026 0.000197 0.000153 0.000146 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  4 4 4 2 4 4 32 4 16 32 ...
 $ RT_J                        : int  2 4 8 8 1 32 1 32 4 4 ...
 $ experiment_id               : chr  "paravance-16" "paravance-16" "paravance-16" "paravance-16" ...
 $ cost_baseline               : num  4.76 4.76 4.76 4.76 4.76 ...
 $ speedup                     : num  1.49 1.43 1.38 1.4 1.22 ...
 $ max_run_speedup             : num  1.51 1.51 1.51 1.51 1.51 ...
 $ min_run_cost                : num  3.15 3.15 3.15 3.15 3.15 ...
 $ best_iteration              : num  78 78 78 78 78 78 78 78 78 78 ...
 $ points                      : int  77 77 77 77 77 77 77 77 77 77 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	9 obs. of  30 variables:
 $ id                          : int  78 20 14 40 37 33 42 53 59
 $ runs                        : int  10 10 10 10 10 10 10 10 10
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  32 32 2048 4 8 2048 1 1 2048
 $ T1_J                        : int  1 2048 2048 1 64 64 128 1 1
 $ cost_mean                   : num  3.15 3.11 3.15 3.36 3.19 ...
 $ U_J                         : int  24 1 1 1 1 16 1 1 1
 $ U_I                         : int  1 3 30 2 30 1 16 15 23
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  128 2048 1 1 64 2048 32 128 2048
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  64 1 1 2048 128 1 128 1 2048
 $ U1_I                        : int  14 30 22 2 10 30 17 11 11
 $ mean_confidence_interval_inf: num  3.15 3.11 3.15 3.36 3.19 ...
 $ mean_confidence_interval_sup: num  3.15 3.11 3.15 3.36 3.19 ...
 $ cost_std                    : num  0.000159 0.000104 0.000058 0.000274 0.000314 ...
 $ step                        : int  4 1 1 2 2 2 2 3 4
 $ RT_I                        : int  8 16 8 1 8 16 1 1 4
 $ RT_J                        : int  2 2 2 8 2 4 4 2 4
 $ experiment_id               : chr  "paravance-16" "paravance-18" "paravance-20" "paravance-24" ...
 $ cost_baseline               : num  4.76 4.76 4.86 4.85 4.75 ...
 $ speedup                     : num  1.51 1.53 1.54 1.44 1.49 ...
 $ max_run_speedup             : num  1.51 1.53 1.54 1.44 1.49 ...
 $ min_run_cost                : num  3.15 3.11 3.15 3.36 3.19 ...
 $ best_iteration              : num  78 20 14 40 37 33 42 53 59
 $ points                      : int  77 85 75 74 70 65 82 74 72
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.81 4.81 4.81 4.81 4.81 ...
 $ label_center_x              : num  4.37 4.37 4.37 4.37 4.37 ...
 $ label_center_y              : num  41.6 41.6 41.6 41.6 41.6 ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	19 obs. of  30 variables:
 $ id                          : int  78 20 14 40 37 33 42 53 59 18 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  32 32 2048 4 8 2048 1 1 2048 1 ...
 $ T1_J                        : int  1 2048 2048 1 64 64 128 1 1 256 ...
 $ cost_mean                   : num  3.15 3.11 3.15 3.36 3.19 ...
 $ U_J                         : int  24 1 1 1 1 16 1 1 1 25 ...
 $ U_I                         : int  1 3 30 2 30 1 16 15 23 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  128 2048 1 1 64 2048 32 128 2048 32 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  64 1 1 2048 128 1 128 1 2048 512 ...
 $ U1_I                        : int  14 30 22 2 10 30 17 11 11 20 ...
 $ mean_confidence_interval_inf: num  3.15 3.11 3.15 3.36 3.19 ...
 $ mean_confidence_interval_sup: num  3.15 3.11 3.15 3.36 3.19 ...
 $ cost_std                    : num  0.000159 0.000104 0.000058 0.000274 0.000314 ...
 $ step                        : int  4 1 1 2 2 2 2 3 4 1 ...
 $ RT_I                        : int  8 16 8 1 8 16 1 1 4 16 ...
 $ RT_J                        : int  2 2 2 8 2 4 4 2 4 4 ...
 $ experiment_id               : chr  "paravance-16" "paravance-18" "paravance-20" "paravance-24" ...
 $ cost_baseline               : num  4.76 4.76 4.86 4.85 4.75 ...
 $ speedup                     : num  1.51 1.53 1.54 1.44 1.49 ...
 $ max_run_speedup             : num  1.51 1.53 1.54 1.44 1.49 ...
 $ min_run_cost                : num  3.15 3.11 3.15 3.36 3.19 ...
 $ best_iteration              : num  78 20 14 40 37 33 42 53 59 18 ...
 $ points                      : int  77 85 75 74 70 65 82 74 72 398 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.81 4.81 4.81 4.81 4.81 ...
 $ label_center_x              : num  4.37 4.37 4.37 4.37 4.37 ...
 $ label_center_y              : num  41.6 41.6 41.6 41.6 41.6 ...

'data.frame':	41 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 2 2 2 ...
 $ valid_configurations   : int  52800 52800 52800 52800 52800 52800 52800 45600 52800 52800 ...
 $ D                      : num  0.223 0.217 0.215 0.218 0.215 ...
 $ used_budget            : int  0 0 0 0 0 0 0 22 22 22 ...
 $ model_size             : int  18 18 18 18 18 18 18 16 18 18 ...
 $ current_best           : num  3.17 3.15 3.38 3.33 3.33 ...
 $ trials                 : int  22 22 22 22 22 22 22 19 22 22 ...
 $ current_best_coordinate: chr  "{'T1_I': 64, 'T1_J': 2048, 'U_J': 18, 'U_I': 1, 'T2_I': 64, 'T2_J': 1, 'U1_I': 12, 'RT_I': 16, 'RT_J': 4}" "{'T1_I': 2048, 'T1_J': 2048, 'U_J': 1, 'U_I': 30, 'T2_I': 1, 'T2_J': 1, 'U1_I': 22, 'RT_I': 8, 'RT_J': 2}" "{'T1_I': 128, 'T1_J': 1, 'U_J': 1, 'U_I': 15, 'T2_I': 128, 'T2_J': 32, 'U1_I': 13, 'RT_I': 8, 'RT_J': 4}" "{'T1_I': 2048, 'T1_J': 1, 'U_J': 1, 'U_I': 12, 'T2_I': 1, 'T2_J': 2048, 'U1_I': 30, 'RT_I': 8, 'RT_J': 4}" ...
 $ tested_configurations  : int  2522375 2543909 2532735 2530519 2516111 2516111 2516111 1841548 2506022 2506022 ...
 $ fixed_factors          : chr  "{'RT_I': 0}" "{'RT_I': 0}" "{'RT_I': 0}" "{'RT_I': 0}" ...
 $ step                   : int  1 1 1 1 1 1 1 2 2 2 ...
 $ design_best            : num  3.17 3.15 3.38 3.33 3.33 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "I(RT_I^2)" "I(RT_I^2)" "I(RT_I^2)" "I(RT_I^2)" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  7.79 4.58 4.58 4.68 3.64 ...
 $ experiment_id          : chr  "paravance-16" "paravance-20" "paravance-24" "paravance-71" ...

'data.frame':	685 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  32 1 64 1 2048 4 1 2048 64 64 ...
 $ T1_J                        : int  2048 128 16 1 8 256 2048 32 2048 64 ...
 $ cost_mean                   : num  3.18 3.32 3.45 3.4 3.88 ...
 $ U_J                         : int  1 14 1 1 28 1 1 1 18 30 ...
 $ U_I                         : int  1 1 30 1 1 28 17 17 1 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1024 8 128 256 2048 2048 1024 1 64 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 2048 1 64 1 256 1 256 1 512 ...
 $ U1_I                        : int  1 4 30 18 29 14 8 2 12 8 ...
 $ mean_confidence_interval_inf: num  3.18 3.32 3.45 3.4 3.88 ...
 $ mean_confidence_interval_sup: num  3.18 3.32 3.45 3.4 3.88 ...
 $ cost_std                    : num  0.00016 0.00026 0.000197 0.000153 0.000146 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  4 4 4 2 4 4 32 4 16 32 ...
 $ RT_J                        : int  2 4 8 8 1 32 1 32 4 4 ...
 $ experiment_id               : chr  "paravance-16" "paravance-16" "paravance-16" "paravance-16" ...

There were 36 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	564 obs. of  4 variables:
 $ metric_value: num  0.0327 0.1146 0.0923 0.0994 0.0918 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "paravance-16" "paravance-16" "paravance-16" "paravance-16" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-q10
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure5OqVJK.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 06:39:59 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}} cccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
paravance-16 & DLMT & 3.151937 & 32 & 1 & 24 & 1 & 128 & 64 & 14 & 8 & 2 \\
paravance-18 & DLMT & 3.111585 & 32 & 2048 & 1 & 3 & 2048 & 1 & 30 & 16 & 2 \\
paravance-20 & DLMT & 3.149921 & 2048 & 2048 & 1 & 30 & 1 & 1 & 22 & 8 & 2 \\
paravance-24 & DLMT & 3.361233 & 4 & 1 & 1 & 2 & 1 & 2048 & 2 & 1 & 8 \\
paravance-49 & DLMT & 3.189757 & 8 & 64 & 1 & 30 & 64 & 128 & 10 & 8 & 2 \\
paravance-5 & DLMT & 3.213894 & 2048 & 64 & 16 & 1 & 2048 & 1 & 30 & 16 & 4 \\
paravance-7 & DLMT & 3.136232 & 1 & 128 & 1 & 16 & 32 & 128 & 17 & 1 & 4 \\
paravance-71 & DLMT & 3.320441 & 1 & 1 & 1 & 15 & 128 & 1 & 11 & 1 & 2 \\
paravance-8 & DLMT & 3.294567 & 2048 & 1 & 1 & 23 & 2048 & 2048 & 11 & 4 & 4 \\
paravance-16 & RS & 3.118132 & 1 & 256 & 25 & 1 & 32 & 512 & 20 & 16 & 4 \\
paravance-18 & RS & 3.042194 & 1 & 2 & 1 & 19 & 1 & 256 & 22 & 4 & 1 \\
paravance-2 & RS & 3.131061 & 1 & 1024 & 1 & 6 & 256 & 2048 & 20 & 16 & 2 \\
paravance-20 & RS & 3.120612 & 256 & 1024 & 13 & 1 & 1 & 1024 & 26 & 16 & 2 \\
paravance-21 & RS & 3.112708 & 32 & 1 & 30 & 1 & 64 & 512 & 20 & 16 & 2 \\
paravance-22 & RS & 3.124333 & 256 & 1 & 1 & 12 & 256 & 1024 & 28 & 8 & 2 \\
paravance-23 & RS & 3.11485 & 512 & 512 & 25 & 1 & 2048 & 2048 & 3 & 16 & 4 \\
paravance-24 & RS & 3.106786 & 128 & 1 & 12 & 1 & 512 & 1 & 23 & 8 & 2 \\
paravance-30 & RS & 3.104083 & 32 & 2048 & 12 & 1 & 1 & 2048 & 8 & 16 & 2 \\
paravance-31 & RS & 3.116196 & 2048 & 256 & 1 & 19 & 2048 & 1 & 24 & 8 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-q10
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeRAoHm.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-q10
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureVAQWfX.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-q10
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurehvZUSx.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-20"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.20),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-20"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-20}
#+LABEL: fig:lm-rs-nobin-p28-q10
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurepYRrzf.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-q10
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-q10
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureWM6DrI.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-q10
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Updated DLMT with Quantile Regression ($\tau = 0.05$, ``Carry Terms'') :noexport:
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_binfalse_dlmt_carry_tau005"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	100 obs. of  3 variables:
 $ removed_variables: Factor w/ 13 levels "","I(RT_I^2)",..: 1 2 3 2 3 8 6 4 5 4 ...
 $ step             : int  1 2 2 2 2 2 2 3 3 3 ...
 $ experiment_id    : chr  "graoully-14" "graoully-14" "graoully-14" "graoully-14" ...

'data.frame':	324 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->1" "T1_J->2048" "U_J->1" "U_I->17" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
 $ experiment_id          : chr  "graoully-14" "graoully-14" "graoully-14" "graoully-14" ...

'data.frame':	697 obs. of  27 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1024 2048 64 8 32 32 32 1 1 1 ...
 $ T1_J                        : int  1 8 1 4 1 16 1024 2048 64 1 ...
 $ cost_mean                   : num  5.61 5.15 4.9 4.4 6.41 ...
 $ U_J                         : int  10 12 1 1 17 1 28 1 13 1 ...
 $ U_I                         : int  1 1 30 30 1 19 1 30 1 28 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1024 1 128 2048 2048 1 2048 128 16 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 1 64 2048 32 2048 1 1 1024 16 ...
 $ U1_I                        : int  16 7 29 15 2 1 30 6 30 20 ...
 $ mean_confidence_interval_inf: num  5.61 5.15 4.9 4.4 6.41 ...
 $ mean_confidence_interval_sup: num  5.61 5.15 4.9 4.4 6.41 ...
 $ cost_std                    : num  0.000184 0.000146 0.000203 0.000211 0.000694 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 4 4 2 32 32 1 32 1 1 ...
 $ RT_J                        : int  8 32 32 1 1 1 32 2 1 1 ...
 $ experiment_id               : chr  "graoully-14" "graoully-14" "graoully-14" "graoully-14" ...
 $ cost_baseline               : num  5.79 5.79 5.79 5.79 5.79 ...
 $ speedup                     : num  1.032 1.124 1.18 1.315 0.902 ...
 $ max_run_speedup             : num  1.51 1.51 1.51 1.51 1.51 ...
 $ min_run_cost                : num  3.84 3.84 3.84 3.84 3.84 ...
 $ best_iteration              : num  32 32 32 32 32 32 32 32 32 32 ...
 $ points                      : int  74 74 74 74 74 74 74 74 74 74 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	9 obs. of  30 variables:
 $ id                          : int  32 30 19 76 75 8 39 67 55
 $ runs                        : int  10 10 10 10 10 10 10 10 10
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 1 1 1 32 1024 1 32 2048
 $ T1_J                        : int  2048 2048 2048 1 1 2048 2048 64 2048
 $ cost_mean                   : num  3.84 3.92 3.83 3.91 3.88 ...
 $ U_J                         : int  30 1 1 30 1 1 30 22 1
 $ U_I                         : int  1 24 30 1 15 17 1 1 14
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  32 4 2048 16 1 1024 512 128 2048
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  1 1 1 2048 1 2048 1 512 1
 $ U1_I                        : int  2 30 13 1 13 29 1 16 13
 $ mean_confidence_interval_inf: num  3.84 3.92 3.83 3.91 3.88 ...
 $ mean_confidence_interval_sup: num  3.84 3.92 3.83 3.91 3.88 ...
 $ cost_std                    : num  4.03e-05 2.11e-03 6.28e-05 1.62e-03 1.10e-04 ...
 $ step                        : int  2 2 1 4 4 1 2 3 3
 $ RT_I                        : int  8 4 16 4 4 4 4 16 1
 $ RT_J                        : int  2 2 4 2 2 2 2 2 4
 $ experiment_id               : chr  "graoully-14" "graoully-15" "graoully-16" "graoully-3" ...
 $ cost_baseline               : num  5.79 5.91 6.04 5.78 5.78 ...
 $ speedup                     : num  1.51 1.51 1.58 1.48 1.49 ...
 $ max_run_speedup             : num  1.51 1.51 1.58 1.48 1.49 ...
 $ min_run_cost                : num  3.84 3.92 3.83 3.91 3.88 ...
 $ best_iteration              : num  32 30 19 76 75 8 39 67 55
 $ points                      : int  74 75 76 82 76 82 79 78 75
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  5.84 5.84 5.84 5.84 5.84 ...
 $ label_center_x              : num  5 5 5 5 5 ...
 $ label_center_y              : num  44.6 44.6 44.6 44.6 44.6 ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	19 obs. of  30 variables:
 $ id                          : int  32 30 19 76 75 8 39 67 55 18 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 1 1 1 32 1024 1 32 2048 1 ...
 $ T1_J                        : int  2048 2048 2048 1 1 2048 2048 64 2048 256 ...
 $ cost_mean                   : num  3.84 3.92 3.83 3.91 3.88 ...
 $ U_J                         : int  30 1 1 30 1 1 30 22 1 25 ...
 $ U_I                         : int  1 24 30 1 15 17 1 1 14 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  32 4 2048 16 1 1024 512 128 2048 32 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  1 1 1 2048 1 2048 1 512 1 512 ...
 $ U1_I                        : int  2 30 13 1 13 29 1 16 13 20 ...
 $ mean_confidence_interval_inf: num  3.84 3.92 3.83 3.91 3.88 ...
 $ mean_confidence_interval_sup: num  3.84 3.92 3.83 3.91 3.88 ...
 $ cost_std                    : num  4.03e-05 2.11e-03 6.28e-05 1.62e-03 1.10e-04 ...
 $ step                        : int  2 2 1 4 4 1 2 3 3 1 ...
 $ RT_I                        : int  8 4 16 4 4 4 4 16 1 16 ...
 $ RT_J                        : int  2 2 4 2 2 2 2 2 4 4 ...
 $ experiment_id               : chr  "graoully-14" "graoully-15" "graoully-16" "graoully-3" ...
 $ cost_baseline               : num  5.79 5.91 6.04 5.78 5.78 ...
 $ speedup                     : num  1.51 1.51 1.58 1.48 1.49 ...
 $ max_run_speedup             : num  1.51 1.51 1.58 1.48 1.49 ...
 $ min_run_cost                : num  3.84 3.92 3.83 3.91 3.88 ...
 $ best_iteration              : num  32 30 19 76 75 8 39 67 55 18 ...
 $ points                      : int  74 75 76 82 76 82 79 78 75 398 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  5.84 5.84 5.84 5.84 5.84 ...
 $ label_center_x              : num  5 5 5 5 5 ...
 $ label_center_y              : num  44.6 44.6 44.6 44.6 44.6 ...

'data.frame':	82 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ valid_configurations   : int  52800 52800 52800 52800 52800 52800 52800 52800 52800 52800 ...
 $ D                      : num  0.219 0.219 0.219 0.219 0.219 ...
 $ used_budget            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ model_size             : int  18 18 18 18 18 18 18 18 18 18 ...
 $ current_best           : num  3.98 3.98 3.98 3.98 3.98 ...
 $ trials                 : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best_coordinate: chr  "{'T1_I': 128, 'T1_J': 1, 'U_J': 1, 'U_I': 1, 'T2_I': 128, 'T2_J': 32, 'U1_I': 1, 'RT_I': 16, 'RT_J': 4}" "{'T1_I': 128, 'T1_J': 1, 'U_J': 1, 'U_I': 1, 'T2_I': 128, 'T2_J': 32, 'U1_I': 1, 'RT_I': 16, 'RT_J': 4}" "{'T1_I': 128, 'T1_J': 1, 'U_J': 1, 'U_I': 1, 'T2_I': 128, 'T2_J': 32, 'U1_I': 1, 'RT_I': 16, 'RT_J': 4}" "{'T1_I': 128, 'T1_J': 1, 'U_J': 1, 'U_I': 1, 'T2_I': 128, 'T2_J': 32, 'U1_I': 1, 'RT_I': 16, 'RT_J': 4}" ...
 $ tested_configurations  : int  2540901 2540901 2540901 2540901 2540901 2540901 2522873 2522873 2522873 2522873 ...
 $ fixed_factors          : chr  "{'U_J': 0, 'RT_I': 2}" "{'U_J': 0, 'RT_I': 2}" "{'U_J': 0, 'RT_I': 2}" "{'U_J': 0, 'RT_I': 2}" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ design_best            : num  3.98 3.98 3.98 3.98 3.98 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "RT_I" "I(RT_I^2)" "RT_I" "I(RT_I^2)" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  5.1 5.1 5.1 5.1 5.1 ...
 $ experiment_id          : chr  "graoully-15" "graoully-15" "graoully-15" "graoully-15" ...

'data.frame':	709 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1024 2048 64 8 32 32 32 1 1 1 ...
 $ T1_J                        : int  1 8 1 4 1 16 1024 2048 64 1 ...
 $ cost_mean                   : num  5.61 5.15 4.9 4.4 6.41 ...
 $ U_J                         : int  10 12 1 1 17 1 28 1 13 1 ...
 $ U_I                         : int  1 1 30 30 1 19 1 30 1 28 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1024 1 128 2048 2048 1 2048 128 16 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 1 64 2048 32 2048 1 1 1024 16 ...
 $ U1_I                        : int  16 7 29 15 2 1 30 6 30 20 ...
 $ mean_confidence_interval_inf: num  5.61 5.15 4.9 4.4 6.41 ...
 $ mean_confidence_interval_sup: num  5.61 5.15 4.9 4.4 6.41 ...
 $ cost_std                    : num  0.000184 0.000146 0.000203 0.000211 0.000694 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 4 4 2 32 32 1 32 1 1 ...
 $ RT_J                        : int  8 32 32 1 1 1 32 2 1 1 ...
 $ experiment_id               : chr  "graoully-14" "graoully-14" "graoully-14" "graoully-14" ...

There were 36 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	570 obs. of  4 variables:
 $ metric_value: num  0.0229 0.1316 0.0851 0.0853 0.0988 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "graoully-14" "graoully-14" "graoully-14" "graoully-14" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-q05
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure5OqVJK.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Tue, Sep 24, 2019 - 09:39:24 AM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\scriptsize
\begin{tabular}{@{\extracolsep{0pt}} ccccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & step & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
graoully-14 & DLMT & 2 & 3.839034 & 1 & 2048 & 30 & 1 & 32 & 1 & 2 & 8 & 2 \\
graoully-15 & DLMT & 2 & 3.920172 & 1 & 2048 & 1 & 24 & 4 & 1 & 30 & 4 & 2 \\
graoully-16 & DLMT & 1 & 3.826293 & 1 & 2048 & 1 & 30 & 2048 & 1 & 13 & 16 & 4 \\
graoully-3 & DLMT & 4 & 3.910717 & 1 & 1 & 30 & 1 & 16 & 2048 & 1 & 4 & 2 \\
graoully-4 & DLMT & 4 & 3.881786 & 32 & 1 & 1 & 15 & 1 & 1 & 13 & 4 & 2 \\
graoully-5 & DLMT & 1 & 3.916675 & 1024 & 2048 & 1 & 17 & 1024 & 2048 & 29 & 4 & 2 \\
graoully-7 & DLMT & 2 & 3.908947 & 1 & 2048 & 30 & 1 & 512 & 1 & 1 & 4 & 2 \\
graoully-8 & DLMT & 3 & 3.901402 & 32 & 64 & 22 & 1 & 128 & 512 & 16 & 16 & 2 \\
graoully-9 & DLMT & 3 & 3.934714 & 2048 & 2048 & 1 & 14 & 2048 & 1 & 13 & 1 & 4 \\
paravance-16 & RS & 1 & 3.118132 & 1 & 256 & 25 & 1 & 32 & 512 & 20 & 16 & 4 \\
paravance-18 & RS & 1 & 3.042194 & 1 & 2 & 1 & 19 & 1 & 256 & 22 & 4 & 1 \\
paravance-2 & RS & 1 & 3.131061 & 1 & 1024 & 1 & 6 & 256 & 2048 & 20 & 16 & 2 \\
paravance-20 & RS & 1 & 3.120612 & 256 & 1024 & 13 & 1 & 1 & 1024 & 26 & 16 & 2 \\
paravance-21 & RS & 1 & 3.112708 & 32 & 1 & 30 & 1 & 64 & 512 & 20 & 16 & 2 \\
paravance-22 & RS & 1 & 3.124333 & 256 & 1 & 1 & 12 & 256 & 1024 & 28 & 8 & 2 \\
paravance-23 & RS & 1 & 3.11485 & 512 & 512 & 25 & 1 & 2048 & 2048 & 3 & 16 & 4 \\
paravance-24 & RS & 1 & 3.106786 & 128 & 1 & 12 & 1 & 512 & 1 & 23 & 8 & 2 \\
paravance-30 & RS & 1 & 3.104083 & 32 & 2048 & 12 & 1 & 1 & 2048 & 8 & 16 & 2 \\
paravance-31 & RS & 1 & 3.116196 & 2048 & 256 & 1 & 19 & 2048 & 1 & 24 & 8 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-q05
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeRAoHm.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureVAQWfX.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureUz34uV.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-26"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.26),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-26"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-26}
#+LABEL: fig:lm-rs-nobin-p26-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeG8fKl.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureWM6DrI.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Updated DLMT with Quantile Regression ($\tau = 0.15$, ``Carry Terms'') :noexport:
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_binfalse_dlmt_carry_tau015"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	99 obs. of  3 variables:
 $ removed_variables: Factor w/ 11 levels "","I(RT_I^2)",..: 1 11 10 2 3 2 3 9 8 4 ...
 $ step             : int  1 2 2 2 2 2 2 2 2 3 ...
 $ experiment_id    : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...

'data.frame':	360 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->1" "T1_J->2048" "U_J->1" "U_I->19" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
 $ experiment_id          : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...

'data.frame':	802 obs. of  27 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  2 1 256 32 2048 1 64 4 4 2048 ...
 $ T1_J                        : int  1 2048 16 128 64 16 32 8 1 32 ...
 $ cost_mean                   : num  4.59 3.8 6.92 4.58 4.59 ...
 $ U_J                         : int  1 30 1 30 18 1 1 16 30 1 ...
 $ U_I                         : int  11 1 29 1 1 20 17 1 1 18 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  32 1 1 32 1 2048 1 16 512 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 1 1 512 64 1 128 2048 1 32 ...
 $ U1_I                        : int  11 16 1 26 2 17 30 12 1 18 ...
 $ mean_confidence_interval_inf: num  4.59 3.8 6.92 4.58 4.58 ...
 $ mean_confidence_interval_sup: num  4.59 3.8 6.92 4.58 4.6 ...
 $ cost_std                    : num  0.000377 0.000124 0.001214 0.000178 0.017378 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  32 8 32 1 1 1 8 4 8 8 ...
 $ RT_J                        : int  1 1 4 32 32 32 1 1 4 4 ...
 $ experiment_id               : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...
 $ cost_baseline               : num  4.76 4.76 4.76 4.76 4.76 ...
 $ speedup                     : num  1.037 1.251 0.687 1.038 1.037 ...
 $ max_run_speedup             : num  1.51 1.51 1.51 1.51 1.51 ...
 $ min_run_cost                : num  3.16 3.16 3.16 3.16 3.16 ...
 $ best_iteration              : num  12 12 12 12 12 12 12 12 12 12 ...
 $ points                      : int  71 71 71 71 71 71 71 71 71 71 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	10 obs. of  30 variables:
 $ id                          : int  12 55 58 52 74 27 4 13 87 35
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 2048 32 2048 1 2048 1 2048 8 2048
 $ T1_J                        : int  2048 2048 2048 1 2 2048 2048 2048 64 1
 $ cost_mean                   : num  3.16 3.19 3.18 3.16 3.03 ...
 $ U_J                         : int  1 30 1 1 1 16 1 30 1 29
 $ U_I                         : int  19 1 1 14 30 1 14 1 7 1
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 1 1 1 1 1 1 1 256 2048
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 2048 2048 1 2048 2048 1 1 64 1
 $ U1_I                        : int  27 17 1 1 22 8 6 8 28 30
 $ mean_confidence_interval_inf: num  3.16 3.19 3.18 3.16 3.03 ...
 $ mean_confidence_interval_sup: num  3.16 3.19 3.18 3.16 3.03 ...
 $ cost_std                    : num  4.27e-04 1.09e-04 1.13e-04 1.12e-04 7.22e-05 ...
 $ step                        : int  1 3 3 3 4 2 1 1 4 2
 $ RT_I                        : int  1 4 4 4 4 4 16 16 8 8
 $ RT_J                        : int  8 2 2 2 1 2 8 4 2 2
 $ experiment_id               : chr  "paravance-40" "paravance-44" "paravance-47" "paravance-63" ...
 $ cost_baseline               : num  4.76 4.86 4.96 4.86 4.75 ...
 $ speedup                     : num  1.51 1.52 1.56 1.54 1.57 ...
 $ max_run_speedup             : num  1.51 1.52 1.56 1.54 1.57 ...
 $ min_run_cost                : num  3.16 3.19 3.18 3.16 3.03 ...
 $ best_iteration              : num  12 55 58 52 74 27 4 13 87 35
 $ points                      : int  71 74 78 82 84 75 84 83 86 85
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.76 4.86 4.96 4.86 4.75 ...
 $ label_center_x              : num  4.29 4.2 4.19 3.94 4.18 ...
 $ label_center_y              : num  12 55 58 52 74 27 4 13 87 35

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	20 obs. of  30 variables:
 $ id                          : int  12 55 58 52 74 27 4 13 87 35 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 2048 32 2048 1 2048 1 2048 8 2048 ...
 $ T1_J                        : int  2048 2048 2048 1 2 2048 2048 2048 64 1 ...
 $ cost_mean                   : num  3.16 3.19 3.18 3.16 3.03 ...
 $ U_J                         : int  1 30 1 1 1 16 1 30 1 29 ...
 $ U_I                         : int  19 1 1 14 30 1 14 1 7 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 1 1 1 1 1 1 1 256 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 2048 2048 1 2048 2048 1 1 64 1 ...
 $ U1_I                        : int  27 17 1 1 22 8 6 8 28 30 ...
 $ mean_confidence_interval_inf: num  3.16 3.19 3.18 3.16 3.03 ...
 $ mean_confidence_interval_sup: num  3.16 3.19 3.18 3.16 3.03 ...
 $ cost_std                    : num  4.27e-04 1.09e-04 1.13e-04 1.12e-04 7.22e-05 ...
 $ step                        : int  1 3 3 3 4 2 1 1 4 2 ...
 $ RT_I                        : int  1 4 4 4 4 4 16 16 8 8 ...
 $ RT_J                        : int  8 2 2 2 1 2 8 4 2 2 ...
 $ experiment_id               : chr  "paravance-40" "paravance-44" "paravance-47" "paravance-63" ...
 $ cost_baseline               : num  4.76 4.86 4.96 4.86 4.75 ...
 $ speedup                     : num  1.51 1.52 1.56 1.54 1.57 ...
 $ max_run_speedup             : num  1.51 1.52 1.56 1.54 1.57 ...
 $ min_run_cost                : num  3.16 3.19 3.18 3.16 3.03 ...
 $ best_iteration              : num  12 55 58 52 74 27 4 13 87 35 ...
 $ points                      : int  71 74 78 82 84 75 84 83 86 85 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.76 4.86 4.96 4.86 4.75 ...
 $ label_center_x              : num  4.29 4.2 4.19 3.94 4.18 ...
 $ label_center_y              : num  12 55 58 52 74 27 4 13 87 35 ...

'data.frame':	78 obs. of  17 variables:
 $ id                     : int  1 1 1 1 2 2 2 2 2 2 ...
 $ valid_configurations   : int  52800 52800 52800 52800 52800 52800 52800 52800 52800 52800 ...
 $ D                      : num  0.22 0.22 0.22 0.22 0.229 ...
 $ used_budget            : int  0 0 0 0 22 22 22 22 22 22 ...
 $ model_size             : int  18 18 18 18 18 18 18 18 18 18 ...
 $ current_best           : num  3.25 3.25 3.25 3.25 3.16 ...
 $ trials                 : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best_coordinate: chr  "{'T1_I': 64, 'T1_J': 32, 'U_J': 3, 'U_I': 1, 'T2_I': 128, 'T2_J': 1, 'U1_I': 29, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 64, 'T1_J': 32, 'U_J': 3, 'U_I': 1, 'T2_I': 128, 'T2_J': 1, 'U1_I': 29, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 64, 'T1_J': 32, 'U_J': 3, 'U_I': 1, 'T2_I': 128, 'T2_J': 1, 'U1_I': 29, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 64, 'T1_J': 32, 'U_J': 3, 'U_I': 1, 'T2_I': 128, 'T2_J': 1, 'U1_I': 29, 'RT_I': 4, 'RT_J': 2}" ...
 $ tested_configurations  : int  2530499 2530499 2530499 2530499 2511103 2511103 2511103 2511103 2511103 2511103 ...
 $ fixed_factors          : chr  "{'RT_I': 2}" "{'RT_I': 2}" "{'RT_I': 2}" "{'RT_I': 2}" ...
 $ step                   : int  1 1 1 1 2 2 2 2 2 2 ...
 $ design_best            : num  3.25 3.25 3.25 3.25 3.24 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "I(RT_I^2)" "RT_I" "I(RT_I^2)" "RT_I" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  3.34 3.34 3.34 3.34 3.34 ...
 $ experiment_id          : chr  "paravance-65" "paravance-65" "paravance-65" "paravance-65" ...

'data.frame':	812 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  2 1 256 32 2048 1 64 4 4 2048 ...
 $ T1_J                        : int  1 2048 16 128 64 16 32 8 1 32 ...
 $ cost_mean                   : num  4.59 3.8 6.92 4.58 4.59 ...
 $ U_J                         : int  1 30 1 30 18 1 1 16 30 1 ...
 $ U_I                         : int  11 1 29 1 1 20 17 1 1 18 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  32 1 1 32 1 2048 1 16 512 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 1 1 512 64 1 128 2048 1 32 ...
 $ U1_I                        : int  11 16 1 26 2 17 30 12 1 18 ...
 $ mean_confidence_interval_inf: num  4.59 3.8 6.92 4.58 4.58 ...
 $ mean_confidence_interval_sup: num  4.59 3.8 6.92 4.58 4.6 ...
 $ cost_std                    : num  0.000377 0.000124 0.001214 0.000178 0.017378 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  32 8 32 1 1 1 8 4 8 8 ...
 $ RT_J                        : int  1 1 4 32 32 32 1 1 4 4 ...
 $ experiment_id               : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...

There were 40 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	666 obs. of  4 variables:
 $ metric_value: num  0.0293 0.0904 0.0815 0.0804 0.0781 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 9 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

it_data <- it_data %>%
  subset(application == "bicgkernel")

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 3, pch = 19) +
    stat_ellipse(size = 1, type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-10, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 28) +
    theme(text = element_text(family = "sans"),
          legend.position = c(0.5, 0.5),
          legend.direction = "horizontal",
          legend.title = element_blank(),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 28) +
                theme(text = element_text(family = "sans"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-q015
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figureCHy8C0.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 09:50:23 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\scriptsize
\begin{tabular}{@{\extracolsep{5pt}} ccccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & step & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
paravance-40 & DLMT & 1 & 3.15577 & 1 & 2048 & 1 & 19 & 1 & 2048 & 27 & 1 & 8 \\
paravance-44 & DLMT & 3 & 3.186451 & 2048 & 2048 & 30 & 1 & 1 & 2048 & 17 & 4 & 2 \\
paravance-47 & DLMT & 3 & 3.179384 & 32 & 2048 & 1 & 1 & 1 & 2048 & 1 & 4 & 2 \\
paravance-63 & DLMT & 3 & 3.157642 & 2048 & 1 & 1 & 14 & 1 & 1 & 1 & 4 & 2 \\
paravance-64 & DLMT & 4 & 3.028382 & 1 & 2 & 1 & 30 & 1 & 2048 & 22 & 4 & 1 \\
paravance-65 & DLMT & 2 & 3.180707 & 2048 & 2048 & 16 & 1 & 1 & 2048 & 8 & 4 & 2 \\
paravance-66 & DLMT & 1 & 3.176287 & 1 & 2048 & 1 & 14 & 1 & 1 & 6 & 16 & 8 \\
paravance-67 & DLMT & 1 & 3.174842 & 2048 & 2048 & 30 & 1 & 1 & 1 & 8 & 16 & 4 \\
paravance-68 & DLMT & 4 & 3.202011 & 8 & 64 & 1 & 7 & 256 & 64 & 28 & 8 & 2 \\
paravance-70 & DLMT & 2 & 3.116248 & 2048 & 1 & 29 & 1 & 2048 & 1 & 30 & 8 & 2 \\
paravance-16 & RS & 1 & 3.118132 & 1 & 256 & 25 & 1 & 32 & 512 & 20 & 16 & 4 \\
paravance-18 & RS & 1 & 3.042194 & 1 & 2 & 1 & 19 & 1 & 256 & 22 & 4 & 1 \\
paravance-2 & RS & 1 & 3.131061 & 1 & 1024 & 1 & 6 & 256 & 2048 & 20 & 16 & 2 \\
paravance-20 & RS & 1 & 3.120612 & 256 & 1024 & 13 & 1 & 1 & 1024 & 26 & 16 & 2 \\
paravance-21 & RS & 1 & 3.112708 & 32 & 1 & 30 & 1 & 64 & 512 & 20 & 16 & 2 \\
paravance-22 & RS & 1 & 3.124333 & 256 & 1 & 1 & 12 & 256 & 1024 & 28 & 8 & 2 \\
paravance-23 & RS & 1 & 3.11485 & 512 & 512 & 25 & 1 & 2048 & 2048 & 3 & 16 & 4 \\
paravance-24 & RS & 1 & 3.106786 & 128 & 1 & 12 & 1 & 512 & 1 & 23 & 8 & 2 \\
paravance-30 & RS & 1 & 3.104083 & 32 & 2048 & 12 & 1 & 1 & 2048 & 8 & 16 & 2 \\
paravance-31 & RS & 1 & 3.116196 & 2048 & 256 & 1 & 19 & 2048 & 1 & 24 & 8 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-q015
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figurecCLw1i.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 8 :height 8 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = subset(fixed_steps_data, experiment_id == "paravance-40"), aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True" & experiment_id == "paravance-40"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.6) +
  geom_text(data = subset(fixed_steps_data, experiment_id == "paravance-40"), aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "white",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 18) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-q015
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figureMP49mw.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-q015
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figuresptLPS.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-47"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.47),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-47"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-47}
#+LABEL: fig:lm-rs-nobin-p28-q015
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeG8fKl.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-q015
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Re-running =aov= and =lm= on =paravance-64=                :noexport:
#+begin_SRC R :results output :session *R* :exports none
p64_designs <- subset(design_data, id == "paravance-64")
str(p64_designs)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	80 obs. of  13 variables:
 $ T1_Ie    : num  -0.333 -1 0.667 -0.333 0.833 ...
 $ T1_Je    : num  -0.167 -0.5 -0.333 -1 -1 ...
 $ T2_Ie    : num  0.833 0.167 -1 -1 0.833 ...
 $ T2_Je    : num  -1 0.833 0 0.833 0 ...
 $ U1_Ie    : num  0.733 -0.6 0.667 -1 -0.6 ...
 $ U_Ie     : num  -1 -0.2 0.2 -1 -1 ...
 $ U_Je     : num  -1 -1 -1 0.0667 -1 ...
 $ RT_Ie    : num  0 -0.333 0.667 0.667 -1 ...
 $ RT_Je    : num  -0.333 0.667 -0.333 -1 -1 ...
 $ cost_mean: num  3.37 3.87 6.82 4.58 4.63 ...
 $ id       : chr  "paravance-64" "paravance-64" "paravance-64" "paravance-64" ...
 $ step     : num  1 1 1 1 1 1 1 1 1 1 ...
 $ formula  : chr  "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ ...
#+end_example

******** First Step:
#+begin_SRC R :results output :session *R* :exports none
p64_step1 <- subset(p64_designs, step == 1)
step_formula <- formula(paste("cost_mean", p64_step1$formula, sep = " "))
#+end_SRC

#+RESULTS:

#+begin_SRC R :results output latex :session *R* :exports results
library(xtable)
reg <- aov(step_formula, data = select(p64_step1, -id, -step, -formula))

print(xtable(reg,
             caption = "First step \\texttt{aov}"),
      size = "scriptsize",
      caption.placement = "top")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Mon Sep 23 20:06:23 2019
\begin{table}[ht]
\centering
\caption{First step \texttt{aov}}
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.92 & 0.92 & 1.27 & 0.3419 \\
  I(T1\_Je\verb|^|2) & 1 & 0.03 & 0.03 & 0.04 & 0.8571 \\
  I(T2\_Ie\verb|^|2) & 1 & 0.31 & 0.31 & 0.43 & 0.5605 \\
  I(T2\_Je\verb|^|2) & 1 & 0.70 & 0.70 & 0.96 & 0.3991 \\
  I(U1\_Ie\verb|^|2) & 1 & 0.44 & 0.44 & 0.61 & 0.4916 \\
  I(U\_Ie\verb|^|2) & 1 & 0.35 & 0.35 & 0.49 & 0.5357 \\
  I(U\_Je\verb|^|2) & 1 & 0.31 & 0.31 & 0.43 & 0.5593 \\
  I(RT\_Ie\verb|^|2) & 1 & 1.89 & 1.89 & 2.61 & 0.2048 \\
  I(RT\_Je\verb|^|2) & 1 & 0.34 & 0.34 & 0.47 & 0.5429 \\
  T1\_Ie & 1 & 0.02 & 0.02 & 0.03 & 0.8755 \\
  T1\_Je & 1 & 0.20 & 0.20 & 0.28 & 0.6330 \\
  T2\_Ie & 1 & 0.06 & 0.06 & 0.09 & 0.7865 \\
  T2\_Je & 1 & 0.96 & 0.96 & 1.33 & 0.3326 \\
  U1\_Ie & 1 & 2.25 & 2.25 & 3.10 & 0.1764 \\
  U\_Ie & 1 & 0.03 & 0.03 & 0.04 & 0.8609 \\
  U\_Je & 1 & 0.01 & 0.01 & 0.01 & 0.9339 \\
  RT\_Ie & 1 & 14.37 & 14.37 & 19.81 & 0.0211 \\
  RT\_Je & 1 & 2.65 & 2.65 & 3.65 & 0.1521 \\
  Residuals & 3 & 2.18 & 0.73 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

#+begin_SRC R :results output latex :session *R* :exports results
library(quantreg)
reg <- rq(step_formula, tau = 0.15, data = select(p64_step1, -id, -step, -formula))

summary(reg, se = "boot")
#+end_SRC

#+RESULTS:
#+begin_export latex

Call: rq(formula = step_formula, tau = 0.15, data = select(p64_step1,
    -id, -step, -formula))

tau: [1] 0.15

Coefficients:
            Value    Std. Error t value  Pr(>|t|)
(Intercept)  4.06637  1.92040    2.11746  0.12448
I(T1_Ie^2)   0.91208  1.16160    0.78519  0.48964
I(T1_Je^2)  -0.38465  0.78012   -0.49306  0.65580
I(T2_Ie^2)  -0.01119  0.75750   -0.01477  0.98914
I(T2_Je^2)  -1.04752  0.84398   -1.24117  0.30275
I(U1_Ie^2)  -0.16496  0.99709   -0.16544  0.87912
I(U_Ie^2)    0.34019  0.87486    0.38885  0.72334
I(U_Je^2)   -0.10516  0.83576   -0.12582  0.90783
I(RT_Ie^2)   2.78112  1.45737    1.90831  0.15238
I(RT_Je^2)   0.14053  0.75263    0.18672  0.86379
T1_Ie        0.15882  0.73878    0.21497  0.84357
T1_Je       -0.27075  0.80352   -0.33695  0.75835
T2_Ie       -0.01863  0.66913   -0.02784  0.97953
T2_Je       -0.31682  0.65220   -0.48577  0.66040
U1_Ie        0.28425  0.77005    0.36913  0.73654
U_Ie         0.00779  0.79577    0.00979  0.99280
U_Je         0.05246  0.73293    0.07158  0.94744
RT_Ie        1.93839  1.03642    1.87027  0.15821
RT_Je        0.99117  0.82334    1.20385  0.31497
#+end_export

We see  that no  factors were  within the filter  threshold. If  we run  the =aov=
analysis  again, but  using a  formula  with only  linear terms  for the  binary
factors, we get the following:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:45:42 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 11.76 & 11.76 & 8.57 & 0.0080 \\
  SCRe & 1 & 0.18 & 0.18 & 0.13 & 0.7188 \\
  VEC1e & 1 & 2.35 & 2.35 & 1.71 & 0.2051 \\
  VEC2e & 1 & 9.08 & 9.08 & 6.62 & 0.0177 \\
  Residuals & 21 & 28.80 & 1.37 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We  see that  =OMP= and  =VEC2= appear  to be  significant, but  only =OMP=  is within
filtering threshold.  If we  had done  this analysis,  we would  have eliminated
=OMP=. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:02 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 1.2879 & 2.5429 & 0.51 & 0.6281 \\
  I(T1\_Ie\verb|^|2) & -0.3443 & 1.3733 & -0.25 & 0.8092 \\
  I(T1\_Je\verb|^|2) & 0.4895 & 1.2750 & 0.38 & 0.7124 \\
  I(T2\_Ie\verb|^|2) & 0.7388 & 1.4653 & 0.50 & 0.6296 \\
  I(T2\_Je\verb|^|2) & -0.1231 & 1.7055 & -0.07 & 0.9445 \\
  I(U1\_Ie\verb|^|2) & -0.1326 & 1.3013 & -0.10 & 0.9217 \\
  I(U\_Ie\verb|^|2) & -0.7352 & 1.5086 & -0.49 & 0.6409 \\
  I(U\_Je\verb|^|2) & 1.1241 & 1.6087 & 0.70 & 0.5073 \\
  I(RT\_Ie\verb|^|2) & -1.4597 & 1.5992 & -0.91 & 0.3917 \\
  I(RT\_Je\verb|^|2) & -0.2175 & 1.6104 & -0.14 & 0.8964 \\
  T1\_Ie & -0.5276 & 0.8441 & -0.63 & 0.5518 \\
  T1\_Je & 0.1608 & 0.9158 & 0.18 & 0.8656 \\
  T2\_Ie & -0.3984 & 0.7922 & -0.50 & 0.6305 \\
  T2\_Je & -0.0715 & 0.7149 & -0.10 & 0.9232 \\
  U1\_Ie & 0.3409 & 0.7285 & 0.47 & 0.6540 \\
  U\_Ie & -0.4304 & 0.8801 & -0.49 & 0.6398 \\
  U\_Je & 0.0087 & 0.9420 & 0.01 & 0.9929 \\
  RT\_Ie & -0.7724 & 1.1074 & -0.70 & 0.5080 \\
  RT\_Je & -0.3787 & 1.1563 & -0.33 & 0.7529 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Nothing seems to substantially change for this case.

******** Second Step:                                       :noexport:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 2 &
                                   correct_result == "True")

p14_step2 <- subset(p14_designs, step == 2)
p14_step2 <- p14_step2[-nrow(p14_step2), ] # Remove extra row
p14_step2$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step2$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below is the =aov= summary using the formula from step 1, at =parasilo-14=:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(step_formula, data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:25 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.00 & 0.00 & 0.00 & 0.9929 \\
  I(T1\_Je\verb|^|2) & 1 & 0.28 & 0.28 & 0.03 & 0.8874 \\
  I(T2\_Ie\verb|^|2) & 1 & 4.25 & 4.25 & 0.39 & 0.5947 \\
  I(T2\_Je\verb|^|2) & 1 & 3.15 & 3.15 & 0.29 & 0.6435 \\
  I(U1\_Ie\verb|^|2) & 1 & 3.11 & 3.11 & 0.29 & 0.6455 \\
  I(U\_Ie\verb|^|2) & 1 & 0.15 & 0.15 & 0.01 & 0.9167 \\
  I(U\_Je\verb|^|2) & 1 & 0.03 & 0.03 & 0.00 & 0.9609 \\
  I(RT\_Ie\verb|^|2) & 1 & 2.25 & 2.25 & 0.21 & 0.6934 \\
  I(RT\_Je\verb|^|2) & 1 & 1.67 & 1.67 & 0.15 & 0.7322 \\
  T1\_Ie & 1 & 10.18 & 10.18 & 0.94 & 0.4344 \\
  T1\_Je & 1 & 5.14 & 5.14 & 0.47 & 0.5621 \\
  T2\_Ie & 1 & 0.38 & 0.38 & 0.04 & 0.8684 \\
  T2\_Je & 1 & 5.43 & 5.43 & 0.50 & 0.5523 \\
  U1\_Ie & 1 & 0.04 & 0.04 & 0.00 & 0.9582 \\
  U\_Ie & 1 & 6.10 & 6.10 & 0.56 & 0.5310 \\
  U\_Je & 1 & 7.02 & 7.02 & 0.65 & 0.5052 \\
  RT\_Ie & 1 & 0.03 & 0.03 & 0.00 & 0.9607 \\
  RT\_Je & 1 & 7.53 & 7.53 & 0.70 & 0.4920 \\
  SCRe & 1 & 0.00 & 0.00 & 0.00 & 0.9893 \\
  VEC1e & 1 & 2.15 & 2.15 & 0.20 & 0.6993 \\
  VEC2e & 1 & 3.20 & 3.20 & 0.30 & 0.6413 \\
  OMPe & 1 & 7.91 & 7.91 & 0.73 & 0.4827 \\
  Residuals & 2 & 21.65 & 10.82 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the =lm= summary:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:43 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & -0.1916 & 7.9828 & -0.02 & 0.9830 \\
  I(T1\_Ie\verb|^|2) & 1.4679 & 2.6477 & 0.55 & 0.6350 \\
  I(T1\_Je\verb|^|2) & 0.6987 & 2.1667 & 0.32 & 0.7777 \\
  I(T2\_Ie\verb|^|2) & 0.6289 & 3.3176 & 0.19 & 0.8672 \\
  I(T2\_Je\verb|^|2) & 1.1182 & 2.3876 & 0.47 & 0.6856 \\
  I(U1\_Ie\verb|^|2) & -0.9683 & 2.5026 & -0.39 & 0.7361 \\
  I(U\_Ie\verb|^|2) & -0.2207 & 2.2762 & -0.10 & 0.9316 \\
  I(U\_Je\verb|^|2) & -0.0863 & 3.2873 & -0.03 & 0.9814 \\
  I(RT\_Ie\verb|^|2) & 1.9707 & 3.1592 & 0.62 & 0.5964 \\
  I(RT\_Je\verb|^|2) & 2.5392 & 3.1931 & 0.80 & 0.5099 \\
  T1\_Ie & 1.2481 & 1.3655 & 0.91 & 0.4572 \\
  T1\_Je & -1.1113 & 1.4826 & -0.75 & 0.5317 \\
  T2\_Ie & 0.5828 & 1.8955 & 0.31 & 0.7875 \\
  T2\_Je & -0.1342 & 1.2659 & -0.11 & 0.9253 \\
  U1\_Ie & -0.2203 & 1.2447 & -0.18 & 0.8758 \\
  U\_Ie & 1.1803 & 1.3740 & 0.86 & 0.4808 \\
  U\_Je & 1.5185 & 2.1771 & 0.70 & 0.5577 \\
  RT\_Ie & 0.8978 & 2.1430 & 0.42 & 0.7160 \\
  RT\_Je & 1.1568 & 1.5989 & 0.72 & 0.5446 \\
  SCRe & -0.5007 & 1.7698 & -0.28 & 0.8038 \\
  VEC1e & 0.5100 & 1.8784 & 0.27 & 0.8114 \\
  VEC2e & -0.1665 & 2.5713 & -0.06 & 0.9543 \\
  OMPe & -1.6240 & 1.8997 & -0.85 & 0.4827 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Now, let's run =aov= again, using only binary factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:59 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 17.13 & 17.13 & 4.92 & 0.0383 \\
  SCRe & 1 & 1.13 & 1.13 & 0.32 & 0.5754 \\
  VEC1e & 1 & 3.14 & 3.14 & 0.90 & 0.3533 \\
  VEC2e & 1 & 0.63 & 0.63 & 0.18 & 0.6758 \\
  Residuals & 20 & 69.64 & 3.48 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that =OMP= and  =VEC2= appear to be  significant, but none  within filtering
threshold. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:18 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 0.7130 & 3.3215 & 0.21 & 0.8371 \\
  I(T1\_Ie\verb|^|2) & 1.3356 & 1.6327 & 0.82 & 0.4446 \\
  I(T1\_Je\verb|^|2) & 0.5249 & 1.5495 & 0.34 & 0.7463 \\
  I(T2\_Ie\verb|^|2) & 0.8102 & 1.7446 & 0.46 & 0.6587 \\
  I(T2\_Je\verb|^|2) & 0.9339 & 1.6036 & 0.58 & 0.5815 \\
  I(U1\_Ie\verb|^|2) & -0.8610 & 1.6098 & -0.53 & 0.6120 \\
  I(U\_Ie\verb|^|2) & -0.3170 & 1.6663 & -0.19 & 0.8554 \\
  I(U\_Je\verb|^|2) & -0.2912 & 1.9952 & -0.15 & 0.8887 \\
  I(RT\_Ie\verb|^|2) & 1.7247 & 1.8927 & 0.91 & 0.3973 \\
  I(RT\_Je\verb|^|2) & 2.3937 & 1.9275 & 1.24 & 0.2606 \\
  T1\_Ie & 1.4526 & 0.9706 & 1.50 & 0.1851 \\
  T1\_Je & -1.2926 & 1.0546 & -1.23 & 0.2662 \\
  T2\_Ie & 0.5029 & 0.9618 & 0.52 & 0.6198 \\
  T2\_Je & -0.3537 & 0.8138 & -0.43 & 0.6790 \\
  U1\_Ie & -0.3135 & 0.7890 & -0.40 & 0.7049 \\
  U\_Ie & 0.9988 & 0.9220 & 1.08 & 0.3203 \\
  U\_Je & 1.3131 & 1.1489 & 1.14 & 0.2966 \\
  RT\_Ie & 0.5144 & 1.2978 & 0.40 & 0.7055 \\
  RT\_Je & 1.2674 & 1.1140 & 1.14 & 0.2986 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

******** Third Step:                                        :noexport:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 3 &
                                   correct_result == "True")

p14_step3 <- subset(p14_designs, step == step)
p14_step3$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step3$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below is the =aov= summary using the formula from step 1, at =parasilo-14=:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(step_formula, data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:37 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.44 & 0.44 & 0.16 & 0.6935 \\
  I(T1\_Je\verb|^|2) & 1 & 8.21 & 8.21 & 2.92 & 0.0915 \\
  I(T2\_Ie\verb|^|2) & 1 & 0.27 & 0.27 & 0.09 & 0.7594 \\
  I(T2\_Je\verb|^|2) & 1 & 2.33 & 2.33 & 0.83 & 0.3656 \\
  I(U1\_Ie\verb|^|2) & 1 & 0.08 & 0.08 & 0.03 & 0.8631 \\
  I(U\_Ie\verb|^|2) & 1 & 8.76 & 8.76 & 3.11 & 0.0815 \\
  I(U\_Je\verb|^|2) & 1 & 1.91 & 1.91 & 0.68 & 0.4120 \\
  I(RT\_Ie\verb|^|2) & 1 & 0.76 & 0.76 & 0.27 & 0.6056 \\
  I(RT\_Je\verb|^|2) & 1 & 0.60 & 0.60 & 0.21 & 0.6462 \\
  T1\_Ie & 1 & 0.15 & 0.15 & 0.05 & 0.8201 \\
  T1\_Je & 1 & 2.10 & 2.10 & 0.75 & 0.3900 \\
  T2\_Ie & 1 & 3.09 & 3.09 & 1.10 & 0.2975 \\
  T2\_Je & 1 & 3.37 & 3.37 & 1.20 & 0.2771 \\
  U1\_Ie & 1 & 4.70 & 4.70 & 1.67 & 0.1999 \\
  U\_Ie & 1 & 4.40 & 4.40 & 1.56 & 0.2150 \\
  U\_Je & 1 & 1.34 & 1.34 & 0.47 & 0.4930 \\
  RT\_Ie & 1 & 0.27 & 0.27 & 0.09 & 0.7597 \\
  RT\_Je & 1 & 0.00 & 0.00 & 0.00 & 0.9859 \\
  SCRe & 1 & 4.27 & 4.27 & 1.52 & 0.2217 \\
  VEC1e & 1 & 2.81 & 2.81 & 1.00 & 0.3206 \\
  VEC2e & 1 & 14.00 & 14.00 & 4.97 & 0.0285 \\
  OMPe & 1 & 0.00 & 0.00 & 0.00 & 0.9945 \\
  Residuals & 81 & 228.03 & 2.82 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the =lm= summary:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:49 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 2.0901 & 1.0424 & 2.01 & 0.0483 \\
  I(T1\_Ie\verb|^|2) & 0.2033 & 0.4877 & 0.42 & 0.6779 \\
  I(T1\_Je\verb|^|2) & 0.5684 & 0.4720 & 1.20 & 0.2320 \\
  I(T2\_Ie\verb|^|2) & 0.3079 & 0.5326 & 0.58 & 0.5649 \\
  I(T2\_Je\verb|^|2) & -0.6988 & 0.5206 & -1.34 & 0.1833 \\
  I(U1\_Ie\verb|^|2) & 0.0450 & 0.4556 & 0.10 & 0.9216 \\
  I(U\_Ie\verb|^|2) & 0.1611 & 0.5254 & 0.31 & 0.7599 \\
  I(U\_Je\verb|^|2) & -0.2009 & 0.5551 & -0.36 & 0.7183 \\
  I(RT\_Ie\verb|^|2) & -0.2769 & 0.5636 & -0.49 & 0.6245 \\
  I(RT\_Je\verb|^|2) & -0.0111 & 0.5453 & -0.02 & 0.9838 \\
  T1\_Ie & 0.0966 & 0.2955 & 0.33 & 0.7446 \\
  T1\_Je & -0.1229 & 0.3069 & -0.40 & 0.6900 \\
  T2\_Ie & 0.1918 & 0.2483 & 0.77 & 0.4422 \\
  T2\_Je & -0.2739 & 0.2579 & -1.06 & 0.2913 \\
  U1\_Ie & 0.3403 & 0.2506 & 1.36 & 0.1783 \\
  U\_Ie & -0.3597 & 0.3078 & -1.17 & 0.2460 \\
  U\_Je & 0.2037 & 0.3048 & 0.67 & 0.5059 \\
  RT\_Ie & -0.0513 & 0.3739 & -0.14 & 0.8913 \\
  RT\_Je & 0.1400 & 0.3690 & 0.38 & 0.7053 \\
  SCRe & -0.3981 & 0.3432 & -1.16 & 0.2495 \\
  VEC1e & -0.2706 & 0.3425 & -0.79 & 0.4319 \\
  VEC2e & 0.7631 & 0.3438 & 2.22 & 0.0293 \\
  OMPe & -0.0023 & 0.3377 & -0.01 & 0.9945 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Now, let's run =aov= again, using only binary factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:48:17 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 0.58 & 0.58 & 0.21 & 0.6482 \\
  SCRe & 1 & 3.32 & 3.32 & 1.20 & 0.2758 \\
  VEC1e & 1 & 2.63 & 2.63 & 0.95 & 0.3320 \\
  VEC2e & 1 & 11.25 & 11.25 & 4.06 & 0.0466 \\
  Residuals & 99 & 274.11 & 2.77 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that =VEC2= appear to be  significant, but not  within filtering
threshold. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:48:15 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 1.8998 & 0.9851 & 1.93 & 0.0571 \\
  I(T1\_Ie\verb|^|2) & 0.3154 & 0.4957 & 0.64 & 0.5264 \\
  I(T1\_Je\verb|^|2) & 0.5832 & 0.4810 & 1.21 & 0.2287 \\
  I(T2\_Ie\verb|^|2) & 0.3367 & 0.5397 & 0.62 & 0.5343 \\
  I(T2\_Je\verb|^|2) & -0.5854 & 0.5283 & -1.11 & 0.2709 \\
  I(U1\_Ie\verb|^|2) & 0.1221 & 0.4630 & 0.26 & 0.7926 \\
  I(U\_Ie\verb|^|2) & 0.1803 & 0.5352 & 0.34 & 0.7371 \\
  I(U\_Je\verb|^|2) & -0.1887 & 0.5649 & -0.33 & 0.7392 \\
  I(RT\_Ie\verb|^|2) & -0.3288 & 0.5693 & -0.58 & 0.5650 \\
  I(RT\_Je\verb|^|2) & -0.0976 & 0.5542 & -0.18 & 0.8606 \\
  T1\_Ie & 0.0194 & 0.2963 & 0.07 & 0.9480 \\
  T1\_Je & -0.1595 & 0.3123 & -0.51 & 0.6108 \\
  T2\_Ie & 0.2132 & 0.2504 & 0.85 & 0.3971 \\
  T2\_Je & -0.3121 & 0.2623 & -1.19 & 0.2374 \\
  U1\_Ie & 0.3361 & 0.2550 & 1.32 & 0.1910 \\
  U\_Ie & -0.2641 & 0.3112 & -0.85 & 0.3984 \\
  U\_Je & 0.2105 & 0.3107 & 0.68 & 0.5000 \\
  RT\_Ie & -0.1031 & 0.3808 & -0.27 & 0.7873 \\
  RT\_Je & 0.0064 & 0.3704 & 0.02 & 0.9861 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-q015
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureWM6DrI.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-q015
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Running more Steps on the Original Experiment
****** Loading Data                                           :noexport:
******* Loading Data for Eliminated Factors                  :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

dlmt_steps <- 8
current_experiment <- "dlmt_spapt_experiments/data/tests/cubic_8steps"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)
#+end_SRC

#+RESULTS:
: 'data.frame':	131 obs. of  3 variables:
:  $ removed_variables: Factor w/ 23 levels "","OMP","RT_I",..: 1 1 2 3 4 13 10 12 22 6 ...
:  $ step             : int  1 2 3 3 3 3 3 3 3 4 ...
:  $ experiment_id    : chr  "paravance-38" "paravance-38" "paravance-38" "paravance-38" ...
: 'data.frame':	1144 obs. of  3 variables:
:  $ current_best_coordinate: chr  "T1_I->2048" "T1_J->128" "U_J->30" "U_I->1" ...
:  $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
:  $ experiment_id          : chr  "paravance-38" "paravance-38" "paravance-38" "paravance-38" ...

******* Loading Data for Histograms and Iterations           :noexport:
#+HEADER: :results output :session *R*
#+BEGIN_SRC R
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             distinct(experiment_id, .keep_all = TRUE)

complete_plot_data <- plot_data

str(complete_plot_data)
#+END_SRC

#+RESULTS:
#+begin_example
'data.frame':	2504 obs. of  7 variables:
 $ cost_mean     : num  0.614 2.142 0.811 4.583 4.493 ...
 $ experiment_id : chr  "paravance-38" "paravance-38" "paravance-38" "paravance-38" ...
 $ technique     : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ cost_baseline : num  4.76 4.76 4.76 4.76 4.76 ...
 $ min_run_cost  : num  0.58 0.58 0.58 0.58 0.58 ...
 $ best_iteration: num  27 27 27 27 27 27 27 27 27 27 ...
 $ application   : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
tibble [11 × 10] (S3: tbl_df/tbl/data.frame)
 $ cost_mean         : num [1:11] 0.614 4.586 1.307 0.883 0.918 ...
 $ experiment_id     : chr [1:11] "paravance-38" "paravance-39" "paravance-4" "paravance-41" ...
 $ technique         : chr [1:11] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ cost_baseline     : num [1:11] 4.76 4.86 4.96 4.76 4.86 ...
 $ min_run_cost      : num [1:11] 0.58 0.41 0.526 0.435 0.421 ...
 $ best_iteration    : num [1:11] 27 160 203 143 238 6 45 65 250 223 ...
 $ application       : chr [1:11] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline: num [1:11] 4.83 4.83 4.83 4.83 4.83 ...
 $ label_center_x    : num [1:11] 1.06 1.06 1.06 1.06 1.06 ...
 $ label_center_y    : num [1:11] 139 139 139 139 139 ...
#+end_example

#+HEADER: :results output :session *R*
#+BEGIN_SRC R
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

data_dir <- "dlmt_spapt_experiments/data/results"
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][5], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel")

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  distinct(experiment_id, .keep_all = TRUE)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)


str(complete_plot_data)
#+END_SRC


#+RESULTS:
#+begin_example
tibble [21 × 10] (S3: tbl_df/tbl/data.frame)
 $ cost_mean         : num [1:21] 0.614 4.586 1.307 0.883 0.918 ...
 $ experiment_id     : chr [1:21] "paravance-38" "paravance-39" "paravance-4" "paravance-41" ...
 $ technique         : chr [1:21] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ cost_baseline     : num [1:21] 4.76 4.86 4.96 4.76 4.86 ...
 $ min_run_cost      : num [1:21] 0.58 0.41 0.526 0.435 0.421 ...
 $ best_iteration    : num [1:21] 27 160 203 143 238 6 45 65 250 223 ...
 $ application       : chr [1:21] "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline: num [1:21] 4.83 4.83 4.83 4.83 4.83 ...
 $ label_center_x    : num [1:21] 1.06 1.06 1.06 1.06 1.06 ...
 $ label_center_y    : num [1:21] 139 139 139 139 139 ...
#+end_example
******* Loading Data Step-by-step Plots                      :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	76 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ valid_configurations   : int  88800 88800 88800 88800 88800 88800 88800 88800 88800 88800 ...
 $ D                      : num  0.0965 0.0965 0.0965 0.0965 0.0965 ...
 $ used_budget            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ model_size             : int  31 31 31 31 31 31 31 31 31 31 ...
 $ current_best           : num  0.617 0.617 0.617 0.617 0.617 ...
 $ trials                 : int  37 37 37 37 37 37 37 37 37 37 ...
 $ current_best_coordinate: chr  "{'T1_I': 512, 'T1_J': 1, 'U_J': 1, 'U_I': 26, 'T2_I': 2048, 'T2_J': 16, 'U1_I': 9, 'OMP': True, 'VEC2': False, "| __truncated__ "{'T1_I': 512, 'T1_J': 1, 'U_J': 1, 'U_I': 26, 'T2_I': 2048, 'T2_J': 16, 'U1_I': 9, 'OMP': True, 'VEC2': False, "| __truncated__ "{'T1_I': 512, 'T1_J': 1, 'U_J': 1, 'U_I': 26, 'T2_I': 2048, 'T2_J': 16, 'U1_I': 9, 'OMP': True, 'VEC2': False, "| __truncated__ "{'T1_I': 512, 'T1_J': 1, 'U_J': 1, 'U_I': 26, 'T2_I': 2048, 'T2_J': 16, 'U1_I': 9, 'OMP': True, 'VEC2': False, "| __truncated__ ...
 $ tested_configurations  : int  4248695 4248695 4248695 4248695 4248695 4248695 4248695 4248695 4241922 4241922 ...
 $ fixed_factors          : chr  "{'RT_J': 0, 'RT_I': 3, 'U_J': 12, 'T2_I': 11, 'OMP': 1, 'SCR': 1}" "{'RT_J': 0, 'RT_I': 3, 'U_J': 12, 'T2_I': 11, 'OMP': 1, 'SCR': 1}" "{'RT_J': 0, 'RT_I': 3, 'U_J': 12, 'T2_I': 11, 'OMP': 1, 'SCR': 1}" "{'RT_J': 0, 'RT_I': 3, 'U_J': 12, 'T2_I': 11, 'OMP': 1, 'SCR': 1}" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ design_best            : num  0.617 0.617 0.617 0.617 0.617 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "OMP" "SCR" "I(T2_I^2)" "I(U_J^2)" ...
 $ model                  : chr  "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T2_I ^ 2) + I(T2_J ^ 2) + I(U1_I ^ 2) + I(U_I ^ 2) + I(U_J ^ 2) + I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  0.755 0.755 0.755 0.755 0.755 ...
 $ experiment_id          : chr  "paravance-39" "paravance-39" "paravance-39" "paravance-39" ...
'data.frame':	2558 obs. of  24 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  2048 512 2048 2048 1 1 16 2048 1 2048 ...
 $ T2_I                        : int  2048 128 256 8 2048 1 256 2048 1024 256 ...
 $ RT_I                        : int  4 32 1 32 2 32 4 4 1 32 ...
 $ mean_confidence_interval_inf: num  0.469 2.142 0.782 4.582 4.493 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  1 8 1 2048 8 128 1 2048 2048 128 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "False" "True" "False" ...
 $ VEC1                        : chr  "False" "True" "False" "False" ...
 $ SCR                         : chr  "True" "True" "False" "False" ...
 $ U1_I                        : int  1 18 15 8 30 30 8 19 1 25 ...
 $ RT_J                        : int  2 1 2 2 32 1 32 16 16 2 ...
 $ T1_I                        : int  2048 4 256 8 1 16 64 16 1 1 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.233482 0.001044 0.047989 0.000322 0.000259 ...
 $ cost_mean                   : num  0.614 2.142 0.811 4.583 4.493 ...
 $ U_J                         : int  20 29 1 1 30 1 1 1 10 9 ...
 $ U_I                         : int  1 1 4 30 1 1 30 22 1 1 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "False" "True" "False" ...
 $ mean_confidence_interval_sup: num  0.759 2.143 0.841 4.583 4.493 ...
 $ experiment_id               : chr  "paravance-38" "paravance-38" "paravance-38" "paravance-38" ...
#+end_example

******* Loading Data for D-Optimality and ANOVA              :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
: There were 50 or more warnings (use warnings() to see the first 50)
: Joining, by = c("id", "step")
: tibble [2,129 × 4] (S3: tbl_df/tbl/data.frame)
:  $ metric_value: num [1:2129] 0.0166 0.0468 0.0533 0.0657 0.0551 ...
:  $ factors     : chr [1:2129] "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
:  $ id          : chr [1:2129] "paravance-38" "paravance-38" "paravance-38" "paravance-38" ...
:  $ step        : num [1:2129] 1 1 1 1 1 1 1 1 1 1 ...

****** Iterations that found the Best Configuration
Figure\nbsp[[fig:nobin-best-found]] shows the iterations where the best configuration of
each of the 10 runs was found, for uniform sampling and for our approach.

#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(subset(it_data, technique == "DLMT")$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

mixed_plot_data = bind_rows(mixed_plot_data,
                            it_data %>%
                            mutate(technique = gsub(pattern = "DLMT",
                                                    replacement = "Running 8 Steps",
                                                    x = technique, fixed = TRUE)) %>%
                            filter(technique != "RS"))

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:nobin-best-found
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-VnHilA/figureGK6YEt.pdf]]

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-ynhqKR/figure7r6W2z.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = 1:dlmt_steps) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

It is  interesting that  only /parasilo-19/ and  /parasilo-9/ eliminated  any factor
other than =OMP=  and =SCR= on the  first step where any factor  was eliminated, and
also that those  runs eliminated the same  factor =RT_I=.  We will  see later that
=OMP= and  =SCR= were fixed to  the same values  in all experiments where  they were
eliminated, and =RT_I=  was only fixed to  a different value on  2 eliminations on
the fourth step.

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Searched Spaces                                        :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.6) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figuregu9cI1.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:le-ss-ef
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-elHoq9/figure8UQjkW.png]]
****** D-Optimality
******* Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:pf-bp-ss
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

****** D_A-Optimality at Each Step                             :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 1,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Running =aov=, =lm=, with =-march=native=
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/dlmt_native"
target_path <- paste(current_experiment, "dgemv3", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/tests/rs_native"
#data_dir <- "dlmt_spapt_experiments/data/results"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("dgemv3")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][5], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "dgemv3"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "dgemv3") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "dgemv3", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)
#+end_SRC

#+RESULTS:
#+begin_example

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Warning message:
replacing previous import ‘vctrs::data_frame’ by ‘tibble::data_frame’ when loading ‘dplyr’
'data.frame':	677 obs. of  3 variables:
 $ removed_variables: Factor w/ 87 levels "","I(RT5_J^2)",..: 1 35 49 26 52 28 21 18 81 39 ...
  ..- attr(*, "names")= chr [1:677] "" "['SCR'" "'I(T1_I^2)'" "'I(T1_Ia^2)'" ...
 $ step             : int  1 2 2 2 2 2 2 2 2 2 ...
 $ experiment_id    : chr  "grisou-24" "grisou-24" "grisou-24" "grisou-24" ...
'data.frame':	1764 obs. of  3 variables:
 $ current_best_coordinate: chr  "T5_I->32" "T1_Ja->4" "RT1_J->16" "RT7_I->8" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ experiment_id          : chr  "grisou-24" "grisou-24" "grisou-24" "grisou-24" ...
Keep up to date with changes at https://www.tidyverse.org/blog/
------------------------------------------------------------------------------
You have loaded plyr after dplyr - this is likely to cause problems.
If you need functions from both plyr and dplyr, please load plyr first, then dplyr:
library(plyr); library(dplyr)
------------------------------------------------------------------------------

Attaching package: ‘plyr’

The following objects are masked from ‘package:dplyr’:

    arrange, count, desc, failwith, id, mutate, rename, summarise,
    summarize

Attaching package: ‘reshape2’

The following object is masked from ‘package:tidyr’:

    smiths
Registering fonts with R
'data.frame':	2327 obs. of  67 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T5_I                        : int  2 2 32 128 256 4 1 64 2 128 ...
 $ T1_Ja                       : int  256 1024 2 64 4 1 256 1024 64 4 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ RT1_J                       : int  1 2 8 32 16 2 2 1 32 2 ...
 $ RT7_I                       : int  8 1 4 32 4 4 32 32 32 4 ...
 $ VEC10                       : chr  "True" "True" "False" "False" ...
 $ RT7_J                       : int  16 8 1 2 8 32 4 4 2 16 ...
 $ T5_J                        : int  256 16 2 4 128 16 8 2 2 256 ...
 $ cost_std                    : num  0.00424 0.00312 0.00648 0.61783 0.00309 ...
 $ VEC9                        : chr  "False" "True" "False" "True" ...
 $ T3_J                        : int  2 2048 4 32 2 4 2 4 16 1 ...
 $ T3_I                        : int  64 32 2 1024 8 1 32 128 64 8 ...
 $ RT1_I                       : int  32 4 8 1 8 8 1 16 1 1 ...
 $ VEC6                        : chr  "False" "False" "False" "True" ...
 $ mean_confidence_interval_inf: num  2.6 1.97 2.24 2.17 4.75 ...
 $ T1_I                        : int  8 1 16 1 512 16 2048 8 128 2 ...
 $ T1_J                        : int  128 64 1 64 2 32 256 32 16 4 ...
 $ T5_Ia                       : int  128 16 1024 128 256 2048 128 2048 16 2048 ...
 $ T3_Ja                       : int  8 2048 8 256 1 32 4 128 1 1 ...
 $ VEC7                        : chr  "True" "False" "True" "True" ...
 $ VEC4                        : chr  "False" "True" "False" "False" ...
 $ VEC5                        : chr  "False" "True" "False" "False" ...
 $ T7_J                        : int  1 16 512 8 2 2 1 8 16 16 ...
 $ VEC3                        : chr  "False" "True" "False" "False" ...
 $ T7_I                        : int  4 2 64 4 1 2 32 32 16 256 ...
 $ VEC2                        : chr  "False" "False" "True" "True" ...
 $ T7_Ia                       : int  16 2048 512 32 8 512 64 64 64 256 ...
 $ VEC8                        : chr  "False" "True" "False" "False" ...
 $ U10_I                       : int  12 12 8 1 12 8 4 16 1 8 ...
 $ U6_I                        : int  8 16 1 16 16 1 8 12 8 8 ...
 $ T1_Ia                       : int  2048 8 2048 512 2048 2048 1 128 256 1024 ...
 $ VEC1                        : chr  "False" "False" "False" "True" ...
 $ U5_J                        : int  1 8 16 4 16 1 16 1 8 12 ...
 $ U5_I                        : int  12 1 1 1 1 8 1 8 1 1 ...
 $ U1_J                        : int  16 1 8 8 1 1 1 16 8 1 ...
 $ U1_I                        : int  1 1 1 1 4 1 1 1 1 12 ...
 $ U8_I                        : int  1 4 1 4 12 12 12 8 4 4 ...
 $ U7_I                        : int  8 12 1 8 1 8 1 1 12 1 ...
 $ U7_J                        : int  1 1 8 1 4 1 12 16 1 1 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ mean_confidence_interval_sup: num  2.6 1.97 2.24 2.93 4.75 ...
 $ U2_I                        : int  4 1 16 4 1 8 1 16 1 1 ...
 $ cost_mean                   : num  2.6 1.97 2.24 2.55 4.75 ...
 $ U9_I                        : int  8 4 16 8 8 12 12 12 12 1 ...
 $ RT3_I                       : int  8 4 1 8 8 1 2 8 1 16 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT3_J                       : int  4 1 8 16 8 4 8 16 8 8 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T7_Ja                       : int  16 512 512 16 512 2 1 128 2048 16 ...
 $ T5_Ja                       : int  1 16 2048 128 512 1 16 4 8 2048 ...
 $ U4_I                        : int  8 16 4 8 1 1 16 12 12 16 ...
 $ T3_Ia                       : int  1024 2048 1024 2048 16 512 32 2048 2048 256 ...
 $ SCR                         : chr  "False" "True" "True" "True" ...
 $ U3_I                        : int  16 1 12 16 1 1 1 1 1 12 ...
 $ RT5_J                       : int  32 2 16 1 8 16 2 1 8 2 ...
 $ RT5_I                       : int  1 1 4 32 1 8 8 4 2 8 ...
 $ U3_J                        : int  1 4 1 1 12 12 1 8 8 1 ...
 $ experiment_id               : chr  "grisou-24" "grisou-24" "grisou-24" "grisou-24" ...
 $ cost_baseline               : num  2.42 2.42 2.42 2.42 2.42 ...
 $ speedup                     : num  0.93 1.23 1.08 0.948 0.509 ...
 $ max_run_speedup             : num  1.98 1.98 1.98 1.98 1.98 ...
 $ min_run_cost                : num  1.22 1.22 1.22 1.22 1.22 ...
 $ best_iteration              : num  206 206 206 206 206 206 206 206 206 206 ...
 $ points                      : int  234 234 234 234 234 234 234 234 234 234 ...
 $ application                 : chr  "dgemv3" "dgemv3" "dgemv3" "dgemv3" ...
tibble [9 × 70] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:9] 206 182 83 22 121 48 56 252 49
 $ T5_I                        : int [1:9] 32 1 16 2 32 4 4 128 32
 $ T1_Ja                       : int [1:9] 2048 16 128 512 1 2048 16 1 512
 $ technique                   : chr [1:9] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ RT1_J                       : int [1:9] 8 8 2 2 8 2 1 4 8
 $ RT7_I                       : int [1:9] 4 8 4 4 8 8 8 4 8
 $ VEC10                       : chr [1:9] "True" "False" "False" "True" ...
 $ RT7_J                       : int [1:9] 4 8 32 4 4 1 2 4 2
 $ T5_J                        : int [1:9] 256 32 4 1 1 16 512 32 1
 $ cost_std                    : num [1:9] 0.00372 0.00718 0.00465 0.00391 0.00387 ...
 $ VEC9                        : chr [1:9] "True" "True" "False" "True" ...
 $ T3_J                        : int [1:9] 8 64 4 8 16 64 256 128 16
 $ T3_I                        : int [1:9] 1 8 1024 512 1 64 128 1024 1024
 $ RT1_I                       : int [1:9] 8 4 8 4 4 1 32 32 2
 $ VEC6                        : chr [1:9] "True" "True" "True" "False" ...
 $ mean_confidence_interval_inf: num [1:9] 1.22 1.23 1.39 1.34 1.35 ...
 $ T1_I                        : int [1:9] 1024 64 8 128 16 64 8 8 1
 $ T1_J                        : int [1:9] 1024 1 16 8 2048 512 1 16 32
 $ T5_Ia                       : int [1:9] 128 32 1024 16 512 512 32 256 128
 $ T3_Ja                       : int [1:9] 1 1024 64 1 128 1 1 2048 128
 $ VEC7                        : chr [1:9] "True" "True" "True" "False" ...
 $ VEC4                        : chr [1:9] "True" "True" "True" "False" ...
 $ VEC5                        : chr [1:9] "True" "False" "True" "False" ...
 $ T7_J                        : int [1:9] 16 128 16 1 256 16 32 256 16
 $ VEC3                        : chr [1:9] "False" "True" "False" "False" ...
 $ T7_I                        : int [1:9] 8 32 32 1 1 64 32 2048 32
 $ VEC2                        : chr [1:9] "False" "True" "True" "False" ...
 $ T7_Ia                       : int [1:9] 32 64 1024 8 16 1024 512 1 1
 $ VEC8                        : chr [1:9] "False" "True" "True" "True" ...
 $ U10_I                       : int [1:9] 16 1 8 8 12 1 1 16 12
 $ U6_I                        : int [1:9] 8 16 1 1 4 12 1 1 4
 $ T1_Ia                       : int [1:9] 1024 2048 1 256 2048 2048 1024 1024 8
 $ VEC1                        : chr [1:9] "False" "True" "False" "False" ...
 $ U5_J                        : int [1:9] 1 1 1 1 1 8 1 1 1
 $ U5_I                        : int [1:9] 16 4 16 8 12 1 4 4 4
 $ U1_J                        : int [1:9] 4 1 1 1 4 1 1 1 1
 $ U1_I                        : int [1:9] 1 12 16 1 1 4 8 8 16
 $ U8_I                        : int [1:9] 16 12 4 8 4 12 12 12 1
 $ U7_I                        : int [1:9] 1 8 8 1 16 1 8 1 4
 $ U7_J                        : int [1:9] 8 1 1 4 1 12 1 1 1
 $ baseline                    : chr [1:9] "False" "False" "False" "False" ...
 $ runs                        : int [1:9] 10 10 10 10 10 10 10 10 10
 $ mean_confidence_interval_sup: num [1:9] 1.22 1.24 1.39 1.34 1.35 ...
 $ U2_I                        : int [1:9] 1 4 8 1 1 16 4 12 12
 $ cost_mean                   : num [1:9] 1.22 1.23 1.39 1.34 1.35 ...
 $ U9_I                        : int [1:9] 8 12 1 4 1 4 12 1 12
 $ RT3_I                       : int [1:9] 4 8 4 4 4 4 1 2 4
 $ step                        : int [1:9] 4 3 1 1 2 1 1 4 1
 $ RT3_J                       : int [1:9] 8 8 1 16 32 16 4 2 4
 $ correct_result              : chr [1:9] "True" "True" "True" "True" ...
 $ T7_Ja                       : int [1:9] 64 128 1 1 2048 1 512 1 1024
 $ T5_Ja                       : int [1:9] 512 256 256 64 32 32 2048 128 1024
 $ U4_I                        : int [1:9] 8 4 16 12 1 8 8 16 8
 $ T3_Ia                       : int [1:9] 512 512 1 1024 512 1024 1 1024 1
 $ SCR                         : chr [1:9] "True" "True" "True" "True" ...
 $ U3_I                        : int [1:9] 1 12 8 1 1 1 12 1 1
 $ RT5_J                       : int [1:9] 32 2 32 2 2 8 32 2 16
 $ RT5_I                       : int [1:9] 4 8 2 4 16 4 4 8 1
 $ U3_J                        : int [1:9] 16 1 1 16 16 1 1 1 8
 $ experiment_id               : chr [1:9] "grisou-24" "grisou-25" "grisou-27" "grisou-3" ...
 $ cost_baseline               : num [1:9] 2.42 2.42 2.42 2.42 2.41 ...
 $ speedup                     : num [1:9] 1.98 1.96 1.75 1.8 1.78 ...
 $ max_run_speedup             : num [1:9] 1.98 1.96 1.75 1.8 1.78 ...
 $ min_run_cost                : num [1:9] 1.22 1.23 1.39 1.34 1.35 ...
 $ best_iteration              : num [1:9] 206 182 83 22 121 48 56 252 49
 $ points                      : int [1:9] 234 246 264 266 243 258 277 284 255
 $ application                 : chr [1:9] "dgemv3" "dgemv3" "dgemv3" "dgemv3" ...
 $ mean_cost_baseline          : num [1:9] 2.42 2.42 2.42 2.42 2.42 ...
 $ label_center_x              : num [1:9] 2.28 2.28 2.28 2.28 2.28 ...
 $ label_center_y              : num [1:9] 113 113 113 113 113 ...
tibble [19 × 70] (S3: tbl_df/tbl/data.frame)
 $ id                          : int [1:19] 206 182 83 22 121 48 56 252 49 274 ...
 $ T5_I                        : int [1:19] 32 1 16 2 32 4 4 128 32 512 ...
 $ T1_Ja                       : int [1:19] 2048 16 128 512 1 2048 16 1 512 256 ...
 $ technique                   : chr [1:19] "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ RT1_J                       : int [1:19] 8 8 2 2 8 2 1 4 8 4 ...
 $ RT7_I                       : int [1:19] 4 8 4 4 8 8 8 4 8 4 ...
 $ VEC10                       : chr [1:19] "True" "False" "False" "True" ...
 $ RT7_J                       : int [1:19] 4 8 32 4 4 1 2 4 2 4 ...
 $ T5_J                        : int [1:19] 256 32 4 1 1 16 512 32 1 8 ...
 $ cost_std                    : num [1:19] 0.00372 0.00718 0.00465 0.00391 0.00387 ...
 $ VEC9                        : chr [1:19] "True" "True" "False" "True" ...
 $ T3_J                        : int [1:19] 8 64 4 8 16 64 256 128 16 4 ...
 $ T3_I                        : int [1:19] 1 8 1024 512 1 64 128 1024 1024 16 ...
 $ RT1_I                       : int [1:19] 8 4 8 4 4 1 32 32 2 2 ...
 $ VEC6                        : chr [1:19] "True" "True" "True" "False" ...
 $ mean_confidence_interval_inf: num [1:19] 1.22 1.23 1.39 1.34 1.35 ...
 $ T1_I                        : int [1:19] 1024 64 8 128 16 64 8 8 1 4 ...
 $ T1_J                        : int [1:19] 1024 1 16 8 2048 512 1 16 32 16 ...
 $ T5_Ia                       : int [1:19] 128 32 1024 16 512 512 32 256 128 1 ...
 $ T3_Ja                       : int [1:19] 1 1024 64 1 128 1 1 2048 128 1 ...
 $ VEC7                        : chr [1:19] "True" "True" "True" "False" ...
 $ VEC4                        : chr [1:19] "True" "True" "True" "False" ...
 $ VEC5                        : chr [1:19] "True" "False" "True" "False" ...
 $ T7_J                        : int [1:19] 16 128 16 1 256 16 32 256 16 32 ...
 $ VEC3                        : chr [1:19] "False" "True" "False" "False" ...
 $ T7_I                        : int [1:19] 8 32 32 1 1 64 32 2048 32 1 ...
 $ VEC2                        : chr [1:19] "False" "True" "True" "False" ...
 $ T7_Ia                       : int [1:19] 32 64 1024 8 16 1024 512 1 1 512 ...
 $ VEC8                        : chr [1:19] "False" "True" "True" "True" ...
 $ U10_I                       : int [1:19] 16 1 8 8 12 1 1 16 12 8 ...
 $ U6_I                        : int [1:19] 8 16 1 1 4 12 1 1 4 12 ...
 $ T1_Ia                       : int [1:19] 1024 2048 1 256 2048 2048 1024 1024 8 1024 ...
 $ VEC1                        : chr [1:19] "False" "True" "False" "False" ...
 $ U5_J                        : int [1:19] 1 1 1 1 1 8 1 1 1 4 ...
 $ U5_I                        : int [1:19] 16 4 16 8 12 1 4 4 4 1 ...
 $ U1_J                        : int [1:19] 4 1 1 1 4 1 1 1 1 16 ...
 $ U1_I                        : int [1:19] 1 12 16 1 1 4 8 8 16 1 ...
 $ U8_I                        : int [1:19] 16 12 4 8 4 12 12 12 1 8 ...
 $ U7_I                        : int [1:19] 1 8 8 1 16 1 8 1 4 16 ...
 $ U7_J                        : int [1:19] 8 1 1 4 1 12 1 1 1 1 ...
 $ baseline                    : chr [1:19] "False" "False" "False" "False" ...
 $ runs                        : int [1:19] 10 10 10 10 10 10 10 10 10 10 ...
 $ mean_confidence_interval_sup: num [1:19] 1.22 1.24 1.39 1.34 1.35 ...
 $ U2_I                        : int [1:19] 1 4 8 1 1 16 4 12 12 4 ...
 $ cost_mean                   : num [1:19] 1.22 1.23 1.39 1.34 1.35 ...
 $ U9_I                        : int [1:19] 8 12 1 4 1 4 12 1 12 1 ...
 $ RT3_I                       : int [1:19] 4 8 4 4 4 4 1 2 4 4 ...
 $ step                        : int [1:19] 4 3 1 1 2 1 1 4 1 1 ...
 $ RT3_J                       : int [1:19] 8 8 1 16 32 16 4 2 4 32 ...
 $ correct_result              : chr [1:19] "True" "True" "True" "True" ...
 $ T7_Ja                       : int [1:19] 64 128 1 1 2048 1 512 1 1024 2048 ...
 $ T5_Ja                       : int [1:19] 512 256 256 64 32 32 2048 128 1024 16 ...
 $ U4_I                        : int [1:19] 8 4 16 12 1 8 8 16 8 1 ...
 $ T3_Ia                       : int [1:19] 512 512 1 1024 512 1024 1 1024 1 2048 ...
 $ SCR                         : chr [1:19] "True" "True" "True" "True" ...
 $ U3_I                        : int [1:19] 1 12 8 1 1 1 12 1 1 8 ...
 $ RT5_J                       : int [1:19] 32 2 32 2 2 8 32 2 16 2 ...
 $ RT5_I                       : int [1:19] 4 8 2 4 16 4 4 8 1 4 ...
 $ U3_J                        : int [1:19] 16 1 1 16 16 1 1 1 8 1 ...
 $ experiment_id               : chr [1:19] "grisou-24" "grisou-25" "grisou-27" "grisou-3" ...
 $ cost_baseline               : num [1:19] 2.42 2.42 2.42 2.42 2.41 ...
 $ speedup                     : num [1:19] 1.98 1.96 1.75 1.8 1.78 ...
 $ max_run_speedup             : num [1:19] 1.98 1.96 1.75 1.8 1.78 ...
 $ min_run_cost                : num [1:19] 1.22 1.23 1.39 1.34 1.35 ...
 $ best_iteration              : num [1:19] 206 182 83 22 121 48 56 252 49 274 ...
 $ points                      : int [1:19] 234 246 264 266 243 258 277 284 255 400 ...
 $ application                 : chr [1:19] "dgemv3" "dgemv3" "dgemv3" "dgemv3" ...
 $ mean_cost_baseline          : num [1:19] 2.42 2.42 2.42 2.42 2.42 ...
 $ label_center_x              : num [1:19] 2.28 2.28 2.28 2.28 2.28 ...
 $ label_center_y              : num [1:19] 113 113 113 113 113 ...
'data.frame':	660 obs. of  17 variables:
 $ id                     : int  2 2 2 2 2 2 2 2 2 2 ...
 $ valid_configurations   : int  792 792 792 792 792 792 792 792 792 792 ...
 $ D                      : num  0.153 0.153 0.153 0.153 0.153 ...
 $ used_budget            : int  88 88 88 88 88 88 88 88 88 88 ...
 $ model_size             : int  87 87 87 87 87 87 87 87 87 87 ...
 $ current_best           : num  1.3 1.3 1.3 1.3 1.3 ...
 $ trials                 : int  88 88 88 88 88 88 88 88 88 88 ...
 $ current_best_coordinate: chr  "{'T5_I': 8, 'T1_Ja': 1024, 'RT1_J': 8, 'RT7_I': 8, 'VEC10': False, 'RT7_J': 4, 'T5_J': 32, 'VEC9': True, 'T3_J'"| __truncated__ "{'T5_I': 8, 'T1_Ja': 1024, 'RT1_J': 8, 'RT7_I': 8, 'VEC10': False, 'RT7_J': 4, 'T5_J': 32, 'VEC9': True, 'T3_J'"| __truncated__ "{'T5_I': 8, 'T1_Ja': 1024, 'RT1_J': 8, 'RT7_I': 8, 'VEC10': False, 'RT7_J': 4, 'T5_J': 32, 'VEC9': True, 'T3_J'"| __truncated__ "{'T5_I': 8, 'T1_Ja': 1024, 'RT1_J': 8, 'RT7_I': 8, 'VEC10': False, 'RT7_J': 4, 'T5_J': 32, 'VEC9': True, 'T3_J'"| __truncated__ ...
 $ tested_configurations  : int  4776703 4776703 4776703 4776703 4776703 4776703 4776703 4776703 4776703 4776703 ...
 $ step                   : int  2 2 2 2 2 2 2 2 2 2 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ model                  : chr  "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T1_Ia ^ 2) + I(T1_Ja ^ 2) + I(T3_I ^ 2) + I(T3_J ^ 2) + I(T3_Ia ^ 2) + I(T3_Ja "| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T1_Ia ^ 2) + I(T1_Ja ^ 2) + I(T3_I ^ 2) + I(T3_J ^ 2) + I(T3_Ia ^ 2) + I(T3_Ja "| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T1_Ia ^ 2) + I(T1_Ja ^ 2) + I(T3_I ^ 2) + I(T3_J ^ 2) + I(T3_Ia ^ 2) + I(T3_Ja "| __truncated__ "~ I(T1_I ^ 2) + I(T1_J ^ 2) + I(T1_Ia ^ 2) + I(T1_Ja ^ 2) + I(T3_I ^ 2) + I(T3_J ^ 2) + I(T3_Ia ^ 2) + I(T3_Ja "| __truncated__ ...
 $ fixed_factors          : chr  "{'RT1_J': 3, 'T5_J': 8, 'T5_I': 5, 'VEC10': 1, 'RT7_J': 2, 'T1_Ja': 11, 'T3_I': 0, 'T1_I': 10, 'T1_J': 10, 'T3_"| __truncated__ "{'RT1_J': 3, 'T5_J': 8, 'T5_I': 5, 'VEC10': 1, 'RT7_J': 2, 'T1_Ja': 11, 'T3_I': 0, 'T1_I': 10, 'T1_J': 10, 'T3_"| __truncated__ "{'RT1_J': 3, 'T5_J': 8, 'T5_I': 5, 'VEC10': 1, 'RT7_J': 2, 'T1_Ja': 11, 'T3_I': 0, 'T1_I': 10, 'T1_J': 10, 'T3_"| __truncated__ "{'RT1_J': 3, 'T5_J': 8, 'T5_I': 5, 'VEC10': 1, 'RT7_J': 2, 'T1_Ja': 11, 'T3_I': 0, 'T1_I': 10, 'T1_J': 10, 'T3_"| __truncated__ ...
 $ design_best            : num  1.3 1.3 1.3 1.3 1.3 ...
 $ removed_variables      : chr  "SCR" "I(T1_I^2)" "I(T1_Ia^2)" "T1_I" ...
 $ predicted_best         : num  1.7 1.7 1.7 1.7 1.7 ...
 $ experiment_id          : chr  "grisou-24" "grisou-24" "grisou-24" "grisou-24" ...
'data.frame':	2336 obs. of  60 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T5_I                        : int  2 2 32 128 256 4 1 64 2 128 ...
 $ T1_Ja                       : int  256 1024 2 64 4 1 256 1024 64 4 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ RT1_J                       : int  1 2 8 32 16 2 2 1 32 2 ...
 $ RT7_I                       : int  8 1 4 32 4 4 32 32 32 4 ...
 $ VEC10                       : chr  "True" "True" "False" "False" ...
 $ RT7_J                       : int  16 8 1 2 8 32 4 4 2 16 ...
 $ T5_J                        : int  256 16 2 4 128 16 8 2 2 256 ...
 $ cost_std                    : num  0.00424 0.00312 0.00648 0.61783 0.00309 ...
 $ VEC9                        : chr  "False" "True" "False" "True" ...
 $ T3_J                        : int  2 2048 4 32 2 4 2 4 16 1 ...
 $ T3_I                        : int  64 32 2 1024 8 1 32 128 64 8 ...
 $ RT1_I                       : int  32 4 8 1 8 8 1 16 1 1 ...
 $ VEC6                        : chr  "False" "False" "False" "True" ...
 $ mean_confidence_interval_inf: num  2.6 1.97 2.24 2.17 4.75 ...
 $ T1_I                        : int  8 1 16 1 512 16 2048 8 128 2 ...
 $ T1_J                        : int  128 64 1 64 2 32 256 32 16 4 ...
 $ T5_Ia                       : int  128 16 1024 128 256 2048 128 2048 16 2048 ...
 $ T3_Ja                       : int  8 2048 8 256 1 32 4 128 1 1 ...
 $ VEC7                        : chr  "True" "False" "True" "True" ...
 $ VEC4                        : chr  "False" "True" "False" "False" ...
 $ VEC5                        : chr  "False" "True" "False" "False" ...
 $ T7_J                        : int  1 16 512 8 2 2 1 8 16 16 ...
 $ VEC3                        : chr  "False" "True" "False" "False" ...
 $ T7_I                        : int  4 2 64 4 1 2 32 32 16 256 ...
 $ VEC2                        : chr  "False" "False" "True" "True" ...
 $ T7_Ia                       : int  16 2048 512 32 8 512 64 64 64 256 ...
 $ VEC8                        : chr  "False" "True" "False" "False" ...
 $ U10_I                       : int  12 12 8 1 12 8 4 16 1 8 ...
 $ U6_I                        : int  8 16 1 16 16 1 8 12 8 8 ...
 $ T1_Ia                       : int  2048 8 2048 512 2048 2048 1 128 256 1024 ...
 $ VEC1                        : chr  "False" "False" "False" "True" ...
 $ U5_J                        : int  1 8 16 4 16 1 16 1 8 12 ...
 $ U5_I                        : int  12 1 1 1 1 8 1 8 1 1 ...
 $ U1_J                        : int  16 1 8 8 1 1 1 16 8 1 ...
 $ U1_I                        : int  1 1 1 1 4 1 1 1 1 12 ...
 $ U8_I                        : int  1 4 1 4 12 12 12 8 4 4 ...
 $ U7_I                        : int  8 12 1 8 1 8 1 1 12 1 ...
 $ U7_J                        : int  1 1 8 1 4 1 12 16 1 1 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ mean_confidence_interval_sup: num  2.6 1.97 2.24 2.93 4.75 ...
 $ U2_I                        : int  4 1 16 4 1 8 1 16 1 1 ...
 $ cost_mean                   : num  2.6 1.97 2.24 2.55 4.75 ...
 $ U9_I                        : int  8 4 16 8 8 12 12 12 12 1 ...
 $ RT3_I                       : int  8 4 1 8 8 1 2 8 1 16 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT3_J                       : int  4 1 8 16 8 4 8 16 8 8 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T7_Ja                       : int  16 512 512 16 512 2 1 128 2048 16 ...
 $ T5_Ja                       : int  1 16 2048 128 512 1 16 4 8 2048 ...
 $ U4_I                        : int  8 16 4 8 1 1 16 12 12 16 ...
 $ T3_Ia                       : int  1024 2048 1024 2048 16 512 32 2048 2048 256 ...
 $ SCR                         : chr  "False" "True" "True" "True" ...
 $ U3_I                        : int  16 1 12 16 1 1 1 1 1 12 ...
 $ RT5_J                       : int  32 2 16 1 8 16 2 1 8 2 ...
 $ RT5_I                       : int  1 1 4 32 1 8 8 4 2 8 ...
 $ U3_J                        : int  1 4 1 1 12 12 1 8 8 1 ...
 $ experiment_id               : chr  "grisou-24" "grisou-24" "grisou-24" "grisou-24" ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file "./img/dlmt_dgemv_native.pdf"
#+HEADER: :width 12 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor",
                                                 "gesummv", "dgemv3", "lu", "mvt", "seidel",
                                                 "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor",
                                                        "gesummv", "dgemv3", "lu", "mvt",
                                                        "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm",
                             "tensor", "gesummv", "dgemv3", "lu", "mvt",
                             "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "dgemv", "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 4, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline,
                   size = "-O3"),
               linetype = 8,
               stat = "unique",
               color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400),
                       breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_x_continuous(limits = c(0, 2.5),
                       breaks = seq(0, 2.5, length.out = 5)) +
    scale_size_manual("", values = 0.9) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 30) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          #text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    scale_color_brewer(palette = "Set1")
    #scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 30) +
                theme(text = element_text(family = "serif"),
                      legend.position = c(0.2, 0.5),
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

# mixed_plot_data = bind_rows(mixed_plot_data,
#                             it_data %>%
#                             mutate(technique = gsub(pattern = "DLMT",
#                                                     replacement = "Reusing Designs",
#                                                     x = technique, fixed = TRUE)) %>%
#                             filter(technique != "RS"))

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-no-cubic
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:./img/dlmt_dgemv_native.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 06:38:14 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}} cccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
graoully-13 & DLMT & 0.6084833 & 512 & 1 & 1 & 10 & 2048 & 2048 & 2 & 8 & 2 \\
graoully-15 & DLMT & 0.5412621 & 512 & 16 & 1 & 21 & 2048 & 1 & 1 & 2 & 32 \\
graoully-16 & DLMT & 0.5691611 & 2048 & 512 & 1 & 1 & 1 & 1024 & 5 & 8 & 8 \\
graoully-3 & DLMT & 0.5163602 & 2048 & 2048 & 1 & 28 & 1 & 2048 & 30 & 4 & 4 \\
graoully-4 & DLMT & 0.5845903 & 16 & 32 & 1 & 30 & 2048 & 1 & 8 & 2 & 4 \\
graoully-5 & DLMT & 0.4961376 & 1024 & 2048 & 30 & 1 & 2048 & 2048 & 13 & 2 & 4 \\
graoully-6 & DLMT & 0.5985619 & 2048 & 32 & 1 & 3 & 2048 & 256 & 16 & 8 & 1 \\
graoully-7 & DLMT & 0.5565135 & 64 & 2048 & 1 & 18 & 2048 & 2048 & 1 & 4 & 8 \\
graoully-8 & DLMT & 0.4646318 & 2048 & 2 & 1 & 2 & 1 & 1 & 30 & 4 & 4 \\
graoully-9 & DLMT & 0.5087977 & 2048 & 2048 & 1 & 11 & 2048 & 2048 & 1 & 4 & 4 \\
paravance-50 & RS & 0.5685274 & 512 & 512 & 19 & 1 & 2048 & 1024 & 27 & 4 & 1 \\
paravance-51 & RS & 0.5467725 & 1024 & 32 & 10 & 1 & 2048 & 512 & 9 & 8 & 8 \\
paravance-52 & RS & 0.5417953 & 2048 & 8 & 9 & 1 & 2048 & 128 & 30 & 8 & 16 \\
paravance-53 & RS & 0.5612387 & 2048 & 64 & 16 & 1 & 2048 & 256 & 9 & 16 & 2 \\
paravance-54 & RS & 0.5322531 & 2048 & 8 & 1 & 9 & 1 & 1 & 19 & 1 & 1 \\
paravance-55 & RS & 0.5540684 & 32 & 4 & 1 & 5 & 2048 & 256 & 4 & 16 & 1 \\
paravance-56 & RS & 0.4648199 & 2048 & 1 & 1 & 23 & 1 & 512 & 25 & 8 & 1 \\
paravance-57 & RS & 0.5463944 & 256 & 16 & 1 & 15 & 2048 & 512 & 2 & 2 & 2 \\
paravance-58 & RS & 0.5496127 & 32 & 1 & 1 & 14 & 2048 & 2048 & 24 & 8 & 4 \\
paravance-59 & RS & 0.4758884 & 64 & 16 & 29 & 1 & 2048 & 1 & 27 & 16 & 4 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file "./img/eliminated_terms_reuse.pdf"
#+HEADER: :width 12 :height 10 :exports results
#+begin_SRC R
base_size <- 25

ggplot(subset(eliminated_terms, removed_variables != ""),
       aes(x = removed_variables,
           fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = c(0.8, 0.95),
        legend.background = element_blank(),
        legend.direction = "horizontal",
        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(name = "Step", palette = "Set2")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:./img/eliminated_terms_reuse.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figureUhUeKM.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figureNOlp8P.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figurequjJQK.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file "./img/explored_space_reuse.pdf" :width 13 :height 12 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 2) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.8) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              size = 3, width = 0.1, height = 0, alpha = 0.2) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            angle = 0,
            color = "white",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = c(1, 2, 3, 4),
                   expand = c(0.3, 0.3)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 25) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        strip.background = element_rect(size = 1, fill = "white"),
        strip.text = element_text(size = 15),
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:explored_space_reuse
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:./img/explored_space_reuse.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I, OMP, SCR, VEC1, VEC2) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-new
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figureSHJRg0.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "graoully-16"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "graoully-16"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{graoully-16}
#+LABEL: fig:lm-rs-nobin-g16-new
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figureG7DSgI.pdf]]

#+begin_SRC R :results graphics output :session *R* :file "./img/models_reuse.pdf" :width 19 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
    mutate(RT_I = log2(RT_I)) %>%
    mutate(RT_J = log2(RT_J)) %>%
    mutate(T1_I = log2(T1_I)) %>%
    mutate(T2_I = log2(T2_I)) %>%
    mutate(T1_J = log2(T1_J)) %>%
    mutate(T2_J = log2(T2_J)) %>%
    gather("factor", "level", T2_I, T2_J, RT_I,
           T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
           RT_J, T1_I, SCR) %>%
    mutate(level = str_replace(level, "True", "1")) %>%
    mutate(level = str_replace(level, "False", "0")) %>%
    mutate(level = as.numeric(level)) %>%
    subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
    facet_wrap(factor ~ ., ncol = 5, scale = "free") +
    geom_point(alpha = 0.4,
               stat = "unique") +
    geom_quantile(formula = y ~ poly(x, 2),
                  quantiles = c(0.01, 0.05, 0.15, 0.25),
                  size = 1,
                  alpha = 0.6,
                  color = "darkgreen") +
    geom_smooth(method = "lm", color = "blue") +
    geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
    geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)),
               size = 2, color = "red",
               stat = "unique") +
    ylab("Execution Time (s)") +
    xlab("Factor Levels") +
    theme_bw(base_size = 22) +
    theme(strip.background = element_rect(fill = "white"))
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:./img/models_reuse.pdf]]

#+begin_SRC R :results graphics output :session *R* :file "./img/models_fixed_omp_reuse.pdf" :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
    mutate(RT_I = log2(RT_I)) %>%
    mutate(RT_J = log2(RT_J)) %>%
    mutate(T1_I = log2(T1_I)) %>%
    mutate(T2_I = log2(T2_I)) %>%
    mutate(T1_J = log2(T1_J)) %>%
    mutate(T2_J = log2(T2_J)) %>%
    subset(OMP == "True") %>%
    gather("factor", "level", T2_I, T2_J, RT_I,
           T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
           RT_J, T1_I, SCR) %>%
    mutate(level = str_replace(level, "True", "1")) %>%
    mutate(level = str_replace(level, "False", "0")) %>%
    mutate(level = as.numeric(level)) %>%
    subset(technique == "RS") %>%
    filter(factor != "OMP")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
    facet_wrap(factor ~ ., ncol = 4, scale = "free") +
    geom_point(alpha = 0.4,
               stat = "unique") +
    geom_quantile(formula = y ~ poly(x, 2),
                  quantiles = c(0.01, 0.05, 0.15, 0.25),
                  size = 1,
                  alpha = 0.6,
                  color = "darkgreen") +
    geom_smooth(method = "lm", color = "blue") +
    geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
    geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)),
               size = 2, color = "red",
               stat = "unique") +
    ylab("Execution Time (s)") +
    xlab("Factor Levels") +
    theme_bw(base_size = 20) +
    theme(strip.background = element_rect(fill = "white"))
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, with \texttt{OMP} fixed to \texttt{true}
#+LABEL: fig:lm-rs-nobin
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:./img/models_fixed_omp_reuse.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file "./img/predictions_reuse.pdf" :width 17 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

colors = c("Best step prediction",
           "Best in step design",
           "Best measurement")

point_size = 3.5
line_size = 2

ggplot(summaries) +
    geom_path(aes(x = step,
                  y = predicted_best,
                  color = colors[1]),
              size = line_size) +
    geom_point(aes(x = step,
                   y = predicted_best,
                   color = colors[1]),
               size = point_size) +
    geom_path(aes(x = step,
                  y = design_best,
                  color = colors[2]),
              size = line_size) +
    geom_point(aes(x = step,
                   y = design_best,
                   color = colors[2]),
               size = point_size) +
    geom_path(aes(x = step,
                  y = current_best,
                  color = colors[3]),
              linetype = 2,
              size = line_size) +
    geom_point(aes(x = step,
                   y = current_best,
                   color = colors[3]),
               size = point_size) +
    facet_wrap(experiment_id ~ ., ncol = 4) +
    ylab("Execution Time (s)") +
    xlab("Step") +
    scale_x_discrete(limits = unique(spread_data$step)) +
    theme_bw(base_size = 22) +
    theme(text = element_text(family = "sans"),
          legend.position = c(0.09, 0.95),
          legend.direction = "vertical",
          legend.background = element_blank(),
          legend.title = element_blank(),
          strip.background = element_rect(fill = "white")) +
    scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:./img/predictions_reuse.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-new
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-X0G35y/figurekA5QNA.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Plotting Mixed Experiments
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file "./img/iterations_all.pdf"
#+HEADER: :width 15 :height 15
#+BEGIN_SRC R
library(ggplot2)
library(dplyr)
library(latex2exp)
library(patchwork)
library(paletteer)

plot_df =  read.csv("data/complete_bicgkernel_data.csv") %>%
    mutate(technique = factor(technique,
                              levels = c("RS",
                                         "Original",
                                         "No Cubic Terms",
                                         "Reusing Designs",
                                         "Running 8 Steps",
                                         "Quantile Regression (tau = 0.05)"),
                              labels = c("RS",
                                         "Original",
                                         "No Cubic",
                                         "Reuse Data",
                                         "Extra Steps",
                                         "QR (5%)")))

p1 = ggplot() +
    geom_jitter(data = plot_df,
                aes(y = min_run_cost,
                    x = technique,
                    color = best_iteration),
                stat = "unique",
                width = 0.2,
                height = 0.0,
                size = 4) +
    geom_hline(data = plot_df,
               aes(yintercept = min(mean_cost_baseline)),
               stat = "unique",
               size = 1.1,
               linetype = 2,
               color = "black") +
    geom_text(data = plot_df,
              aes(x = 0.5,
                  y = min(mean_cost_baseline) - 0.14),
              size = 10,
              stat = "unique",
              label = "Baseline (-O3)",
              hjust = 0,
              color = "black") +
    ylab("Execution Time (s)") +
    scale_color_paletteer_c(name = "Iteration Found",
                            n.breaks = 6,
                            direction = -1,
                            palette = "oompaBase::greenscale") +
    theme_bw(base_size = 33) +
    theme(legend.position = c(0.7, 0.86),
          legend.direction = "horizontal",
          legend.title = element_text(size = 25),
          legend.key.width = unit(2, "cm"),
          axis.title.x = element_blank(),
          legend.background = element_blank())

p2 = ggplot() +
    geom_jitter(data = plot_df,
                aes(y = best_iteration,
                    x = technique,
                    color = min_run_cost),
                stat = "unique",
                width = 0.2,
                height = 0.0,
                size = 4) +
    ylab("Iteration Finding the Best Point") +
    scale_color_paletteer_c(name = "Execution Time",
                            n.breaks = 6,
                            direction = -1,
                            palette = "oompaBase::greenscale") +
    theme_bw(base_size = 33) +
    theme(legend.position = c(0.7, 0.9),
          legend.direction = "horizontal",
          legend.title = element_text(size = 25),
          legend.key.width = unit(2, "cm"),
          axis.title.x = element_blank(),
          legend.background = element_blank())

p1 / p2
#+END_SRC

#+CAPTION: Iteration where best was found
#+RESULTS:
[[file:./img/iterations_all.pdf]]
** September
*** [2019-09-24 Tue]
**** Performance Modeling and Optimization of the =seidel= SPAPT kernel :ExportableReports:
:PROPERTIES:
:EXPORT_FILE_NAME: report.pdf
:END:
#+LATEX: \tableofcontents
***** Initial Setup                                            :noexport:
****** Cloning/Pulling the Repository                         :noexport:
#+HEADER: :results output :eval no-export :exports none
#+BEGIN_SRC shell
git clone https://github.com/phrb/dlmt_spapt_experiments.git || (cd dlmt_spapt_experiments && git pull)
#+END_SRC

#+RESULTS:
: Already up to date.
***** Introduction
****** CCGRID Experiments
******* Loading Data                                         :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_carry_tau005"
target_path <- paste(current_experiment, "seidel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

data_dir <- "dlmt_spapt_experiments/data/results"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("seidel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][5], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "seidel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "seidel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "seidel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(formula)
}

target_path <- paste(current_experiment, "seidel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	53 obs. of  3 variables:
 $ removed_variables: Factor w/ 18 levels "","I(T1_Ta^2)",..: 1 6 9 5 2 4 3 7 8 5 ...
 $ step             : int  1 2 2 2 2 2 2 2 2 2 ...
 $ experiment_id    : chr  "paravance-38" "paravance-38" "paravance-38" "paravance-38" ...

'data.frame':	240 obs. of  3 variables:
 $ current_best_coordinate: chr  "RT1_J->1" "T1_Ja->2048" "T1_I->2" "T1_J->2048" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ experiment_id          : chr  "paravance-38" "paravance-38" "paravance-38" "paravance-38" ...

'data.frame':	452 obs. of  33 variables:
 $ id                          : int  1 2 3 4 5 6 7 9 10 11 ...
 $ RT1_J                       : int  32 1 2 32 16 2 8 8 4 1 ...
 $ T1_Ja                       : int  512 512 8 1 256 2048 2048 128 64 128 ...
 $ RT1_I                       : int  1 1 2 1 4 8 1 1 16 1 ...
 $ RT1_T                       : int  2 32 32 1 1 8 1 8 2 8 ...
 $ mean_confidence_interval_inf: num  3.56 1.585 0.38 1.246 0.269 ...
 $ T1_I                        : int  64 2 2048 16 1 2048 64 2 2 32 ...
 $ T1_J                        : int  16 64 2 128 1 2048 128 16 1 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T1_T                        : int  16 16 1 16 4 32 1 1 1024 2048 ...
 $ SCR                         : chr  "True" "False" "True" "True" ...
 $ T1_Ia                       : int  1 1 1 32 2048 1 1 64 2 1 ...
 $ U1_T                        : int  1 1 25 30 1 1 1 8 1 1 ...
 $ T1_Ta                       : int  64 1 1 32 16 2048 1024 1024 1024 1 ...
 $ U1_J                        : int  30 20 29 14 9 14 9 1 22 3 ...
 $ U1_I                        : int  10 15 1 1 12 22 30 12 30 4 ...
 $ VEC                         : chr  "False" "True" "False" "True" ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.000173 0.000221 0.024153 0.000514 0.015456 ...
 $ cost_mean                   : num  3.56 1.585 0.395 1.246 0.279 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "False" "False" "True" "False" ...
 $ mean_confidence_interval_sup: num  3.56 1.585 0.41 1.246 0.288 ...
 $ experiment_id               : chr  "paravance-38" "paravance-38" "paravance-38" "paravance-38" ...
 $ cost_baseline               : num  2.35 2.35 2.35 2.35 2.35 ...
 $ speedup                     : num  0.661 1.485 5.962 1.889 8.441 ...
 $ max_run_speedup             : num  42.3 42.3 42.3 42.3 42.3 ...
 $ min_run_cost                : num  0.0557 0.0557 0.0557 0.0557 0.0557 ...
 $ best_iteration              : num  104 104 104 104 104 104 104 104 104 104 ...
 $ points                      : int  109 109 109 109 109 109 109 109 109 109 ...
 $ application                 : chr  "seidel" "seidel" "seidel" "seidel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	4 obs. of  36 variables:
 $ id                          : int  104 116 78 32
 $ RT1_J                       : int  8 1 1 1
 $ T1_Ja                       : int  1 1 2048 2048
 $ RT1_I                       : int  8 8 32 8
 $ RT1_T                       : int  1 1 2 1
 $ mean_confidence_interval_inf: num  0.0462 0.0845 0.0462 0.0645
 $ T1_I                        : int  2048 16 16 512
 $ T1_J                        : int  2048 2048 1 128
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT"
 $ T1_T                        : int  1 32 1 1
 $ SCR                         : chr  "True" "True" "True" "True"
 $ T1_Ia                       : int  2048 128 1 1
 $ U1_T                        : int  5 15 30 1
 $ T1_Ta                       : int  1 32 2 1
 $ U1_J                        : int  30 1 30 27
 $ U1_I                        : int  1 10 1 16
 $ VEC                         : chr  "True" "True" "False" "False"
 $ baseline                    : chr  "False" "False" "False" "False"
 $ runs                        : int  10 10 10 10
 $ cost_std                    : num  0.01524 0.00754 0.00828 0.00717
 $ cost_mean                   : num  0.0557 0.0892 0.0513 0.069
 $ step                        : int  4 4 3 1
 $ correct_result              : chr  "True" "True" "True" "True"
 $ OMP                         : chr  "True" "True" "True" "True"
 $ mean_confidence_interval_sup: num  0.0651 0.0939 0.0564 0.0734
 $ experiment_id               : chr  "paravance-38" "paravance-40" "paravance-69" "paravance-70"
 $ cost_baseline               : num  2.35 2.35 2.35 2.35
 $ speedup                     : num  42.3 26.4 45.9 34.1
 $ max_run_speedup             : num  42.3 26.4 45.9 34.1
 $ min_run_cost                : num  0.0557 0.0892 0.0513 0.069
 $ best_iteration              : num  104 116 78 32
 $ points                      : int  109 121 103 119
 $ application                 : chr  "seidel" "seidel" "seidel" "seidel"
 $ mean_cost_baseline          : num  2.35 2.35 2.35 2.35
 $ label_center_x              : num  1.08 1.08 1.08 1.08
 $ label_center_y              : num  82.3 82.3 82.3 82.3

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	15 obs. of  36 variables:
 $ id                          : int  104 116 78 32 214 263 275 86 223 185 ...
 $ RT1_J                       : int  8 1 1 1 1 2 2 2 2 2 ...
 $ T1_Ja                       : int  1 1 2048 2048 2048 1 1 2048 32 32 ...
 $ RT1_I                       : int  8 8 32 8 4 2 2 1 1 2 ...
 $ RT1_T                       : int  1 1 2 1 1 32 1 1 32 32 ...
 $ mean_confidence_interval_inf: num  0.0462 0.0845 0.0462 0.0645 0.0808 ...
 $ T1_I                        : int  2048 16 16 512 256 256 128 128 2 8 ...
 $ T1_J                        : int  2048 2048 1 128 128 256 1 16 8 4 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T1_T                        : int  1 32 1 1 16 16 1 1 1 16 ...
 $ SCR                         : chr  "True" "True" "True" "True" ...
 $ T1_Ia                       : int  2048 128 1 1 256 512 1 512 512 128 ...
 $ U1_T                        : int  5 15 30 1 9 8 19 2 2 15 ...
 $ T1_Ta                       : int  1 32 2 1 1 16 2 4 4 1 ...
 $ U1_J                        : int  30 1 30 27 4 1 15 18 20 1 ...
 $ U1_I                        : int  1 10 1 16 1 9 1 1 1 25 ...
 $ VEC                         : chr  "True" "True" "False" "False" ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.01524 0.00754 0.00828 0.00717 0.00799 ...
 $ cost_mean                   : num  0.0557 0.0892 0.0513 0.069 0.0857 ...
 $ step                        : int  4 4 3 1 NA NA NA NA NA NA ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.0651 0.0939 0.0564 0.0734 0.0907 ...
 $ experiment_id               : chr  "paravance-38" "paravance-40" "paravance-69" "paravance-70" ...
 $ cost_baseline               : num  2.35 2.35 2.35 2.35 2.9 ...
 $ speedup                     : num  42.3 26.4 45.9 34.1 33.8 ...
 $ max_run_speedup             : num  42.3 26.4 45.9 34.1 33.8 ...
 $ min_run_cost                : num  0.0557 0.0892 0.0513 0.069 0.0857 ...
 $ best_iteration              : num  104 116 78 32 214 263 275 86 223 185 ...
 $ points                      : int  109 121 103 119 276 274 268 274 267 268 ...
 $ application                 : chr  "seidel" "seidel" "seidel" "seidel" ...
 $ mean_cost_baseline          : num  2.35 2.35 2.35 2.35 2.9 ...
 $ label_center_x              : num  1.08 1.08 1.08 1.08 1.82 ...
 $ label_center_y              : num  82.3 82.3 82.3 82.3 196 ...

'data.frame':	47 obs. of  17 variables:
 $ id                     : int  2 2 2 2 2 2 2 2 2 2 ...
 $ valid_configurations   : int  79200 79200 79200 79200 79200 79200 79200 79200 79200 79200 ...
 $ D                      : num  0.206 0.206 0.206 0.206 0.206 ...
 $ used_budget            : int  30 30 30 30 30 30 30 30 30 30 ...
 $ model_size             : int  27 27 27 27 27 27 27 27 27 27 ...
 $ current_best           : num  0.0998 0.0998 0.0998 0.0998 0.0998 ...
 $ trials                 : int  33 33 33 33 33 33 33 33 33 33 ...
 $ current_best_coordinate: chr  "{'RT1_J': 1, 'T1_Ja': 2048, 'T1_I': 2, 'T1_J': 2048, 'T1_Ia': 2048, 'RT1_I': 1, 'U1_T': 12, 'T1_Ta': 32, 'U1_J'"| __truncated__ "{'RT1_J': 1, 'T1_Ja': 2048, 'T1_I': 2, 'T1_J': 2048, 'T1_Ia': 2048, 'RT1_I': 1, 'U1_T': 12, 'T1_Ta': 32, 'U1_J'"| __truncated__ "{'RT1_J': 1, 'T1_Ja': 2048, 'T1_I': 2, 'T1_J': 2048, 'T1_Ia': 2048, 'RT1_I': 1, 'U1_T': 12, 'T1_Ta': 32, 'U1_J'"| __truncated__ "{'RT1_J': 1, 'T1_Ja': 2048, 'T1_I': 2, 'T1_J': 2048, 'T1_Ia': 2048, 'RT1_I': 1, 'U1_T': 12, 'T1_Ta': 32, 'U1_J'"| __truncated__ ...
 $ tested_configurations  : int  7355120 7355120 7355120 7355120 7355120 7355120 7355120 7355120 7355120 7355120 ...
 $ fixed_factors          : chr  "{'T1_T': 0, 'OMP': 1, 'RT1_T': 0, 'VEC': 1, 'SCR': 1}" "{'T1_T': 0, 'OMP': 1, 'RT1_T': 0, 'VEC': 1, 'SCR': 1}" "{'T1_T': 0, 'OMP': 1, 'RT1_T': 0, 'VEC': 1, 'SCR': 1}" "{'T1_T': 0, 'OMP': 1, 'RT1_T': 0, 'VEC': 1, 'SCR': 1}" ...
 $ step                   : int  2 2 2 2 2 2 2 2 2 2 ...
 $ design_best            : num  0.132 0.132 0.132 0.132 0.132 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "OMP" "T1_T" "RT1_T" "I(T1_Ta^2)" ...
 $ model                  : chr  "~ I(T1_T ^ 2)
I(T1_I ^ 2)
I(T1_J ^ 2)
I(T1_Ta ^ 2)
I(T1_Ia ^ 2)
I(T1_Ja ^ 2)
I(U1_T ^ 2)
I(U1_I ^"| __truncated__ "~ I(T1_T ^ 2)
I(T1_I ^ 2)
I(T1_J ^ 2)
I(T1_Ta ^ 2)
I(T1_Ia ^ 2)
I(T1_Ja ^ 2)
I(U1_T ^ 2)
I(U1_I ^"| __truncated__ "~ I(T1_T ^ 2)
I(T1_I ^ 2)
I(T1_J ^ 2)
I(T1_Ta ^ 2)
I(T1_Ia ^ 2)
I(T1_Ja ^ 2)
I(U1_T ^ 2)
I(U1_I ^"| __truncated__ "~ I(T1_T ^ 2)
I(T1_I ^ 2)
I(T1_J ^ 2)
I(T1_Ta ^ 2)
I(T1_Ia ^ 2)
I(T1_Ja ^ 2)
I(U1_T ^ 2)
I(U1_I ^"| __truncated__ ...
 $ predicted_best         : num  0.298 0.298 0.298 0.298 0.298 ...
 $ experiment_id          : chr  "paravance-38" "paravance-38" "paravance-38" "paravance-38" ...

'data.frame':	499 obs. of  26 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ RT1_J                       : int  32 1 2 32 16 2 8 2 8 4 ...
 $ T1_Ja                       : int  512 512 8 1 256 2048 2048 1 128 64 ...
 $ RT1_I                       : int  1 1 2 1 4 8 1 32 1 16 ...
 $ RT1_T                       : int  2 32 32 1 1 8 1 1 8 2 ...
 $ mean_confidence_interval_inf: num  3.56 1.585 0.38 1.246 0.269 ...
 $ T1_I                        : int  64 2 2048 16 1 2048 64 2048 2 2 ...
 $ T1_J                        : int  16 64 2 128 1 2048 128 8 16 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T1_T                        : int  16 16 1 16 4 32 1 4 1 1024 ...
 $ SCR                         : chr  "True" "False" "True" "True" ...
 $ T1_Ia                       : int  1 1 1 32 2048 1 1 1 64 2 ...
 $ U1_T                        : int  1 1 25 30 1 1 1 4 8 1 ...
 $ T1_Ta                       : int  64 1 1 32 16 2048 1024 64 1024 1024 ...
 $ U1_J                        : int  30 20 29 14 9 14 9 7 1 22 ...
 $ U1_I                        : int  10 15 1 1 12 22 30 1 12 30 ...
 $ VEC                         : chr  "False" "True" "False" "True" ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ runs                        : int  10 10 10 10 10 10 10 1 10 10 ...
 $ cost_std                    : num  0.000173 0.000221 0.024153 0.000514 0.015456 ...
 $ cost_mean                   : num  3.56 1.585 0.395 1.246 0.279 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "False" "False" "True" "False" ...
 $ mean_confidence_interval_sup: num  3.56 1.585 0.41 1.246 0.288 ...
 $ experiment_id               : chr  "paravance-38" "paravance-38" "paravance-38" "paravance-38" ...

There were 16 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Error in solve.default((t(X) %*% X)/nrow(X)) :
  system is computationally singular: reciprocal condition number = 8.36443e-19

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	2129 obs. of  4 variables:
 $ metric_value: num  0.0166 0.0468 0.0533 0.0657 0.0551 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "paravance-38" "paravance-38" "paravance-38" "paravance-38" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

******* Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure6ahKjx.pdf]]

The results are very similar from the  ones in the paper, but our approach found
slightly better  configurations slightly  faster. Random  sampling also  found a
much better configuration much faster than before in one experiment.

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J, OMP, SCR, VEC1, VEC2), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "tiny")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 06:09:05 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}} cccccccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J & OMP & SCR & VEC1 & VEC2 \\
\hline \\[-1.8ex]
parasilo-1 & DLMT & 0.5244322 & 2048 & 64 & 1 & 30 & 1 & 1 & 25 & 1 & 1 & True & True & False & True \\
parasilo-10 & DLMT & 0.55769 & 8 & 2 & 1 & 9 & 2048 & 2048 & 2 & 4 & 32 & True & True & False & True \\
parasilo-11 & DLMT & 0.4753558 & 2048 & 1024 & 30 & 1 & 1 & 1024 & 16 & 4 & 4 & True & True & False & False \\
parasilo-13 & DLMT & 0.5016148 & 1 & 256 & 21 & 1 & 2048 & 256 & 1 & 8 & 4 & True & False & False & False \\
parasilo-14 & DLMT & 0.5404449 & 2048 & 1 & 1 & 13 & 2048 & 2048 & 4 & 8 & 4 & True & True & False & True \\
parasilo-17 & DLMT & 0.5371861 & 2048 & 1 & 29 & 1 & 2048 & 1024 & 7 & 4 & 8 & True & True & True & False \\
parasilo-19 & DLMT & 0.5507874 & 2048 & 2 & 1 & 13 & 2048 & 128 & 15 & 1 & 1 & True & True & True & True \\
parasilo-2 & DLMT & 0.5229024 & 1024 & 1 & 1 & 1 & 2048 & 1024 & 2 & 8 & 1 & True & True & True & False \\
parasilo-20 & DLMT & 0.5643309 & 1 & 2048 & 1 & 12 & 2048 & 2048 & 4 & 1 & 8 & True & True & False & True \\
parasilo-9 & DLMT & 0.4685077 & 2048 & 128 & 1 & 16 & 1 & 256 & 19 & 1 & 1 & True & True & True & True \\
paravance-50 & RS & 0.5685274 & 512 & 512 & 19 & 1 & 2048 & 1024 & 27 & 4 & 1 & True & True & True & False \\
paravance-51 & RS & 0.5467725 & 1024 & 32 & 10 & 1 & 2048 & 512 & 9 & 8 & 8 & True & True & True & True \\
paravance-52 & RS & 0.5417953 & 2048 & 8 & 9 & 1 & 2048 & 128 & 30 & 8 & 16 & True & True & True & True \\
paravance-53 & RS & 0.5612387 & 2048 & 64 & 16 & 1 & 2048 & 256 & 9 & 16 & 2 & True & True & True & True \\
paravance-54 & RS & 0.5322531 & 2048 & 8 & 1 & 9 & 1 & 1 & 19 & 1 & 1 & True & True & True & False \\
paravance-55 & RS & 0.5540684 & 32 & 4 & 1 & 5 & 2048 & 256 & 4 & 16 & 1 & True & True & False & False \\
paravance-56 & RS & 0.4648199 & 2048 & 1 & 1 & 23 & 1 & 512 & 25 & 8 & 1 & True & True & False & True \\
paravance-57 & RS & 0.5463944 & 256 & 16 & 1 & 15 & 2048 & 512 & 2 & 2 & 2 & True & True & False & False \\
paravance-58 & RS & 0.5496127 & 32 & 1 & 1 & 14 & 2048 & 2048 & 24 & 8 & 4 & True & True & True & True \\
paravance-59 & RS & 0.4758884 & 64 & 16 & 29 & 1 & 2048 & 1 & 27 & 16 & 4 & True & True & True & True \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

******* Eliminated Factors and Fixed Values
Figure\nbsp{}[[fig:eliminated-terms]] shows the /count of  model terms/ that were eliminated
at each color-coded DLMT step.  As before, we see that =OMP= and =SCR= were the most
eliminated factors, especially on the first step.

#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-ynhqKR/figure7r6W2z.pdf]]

******* Fixed Model Terms                                    :noexport:
******** Combined Experiments                               :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******** Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

******* Fixed Factors & Values                               :noexport:
******** Combined Experiments                               :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******** Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

******* Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureH9Y6En.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
         RT_J, T1_I, SCR) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureCf51rF.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
         RT_J, T1_I, SCR) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-elHoq9/figure3xnWMZ.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  subset(OMP == "True") %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
         RT_J, T1_I, SCR) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, with \texttt{OMP} fixed to \texttt{true}
#+LABEL: fig:lm-rs-nobin
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqNvfdJ.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  subset(OMP == "False") %>%
  subset(SCR == "True") %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
         RT_J, T1_I, SCR) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  ylim(c(NA, 2.0)) +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, with \texttt{OMP} fixed to \texttt{false}
#+LABEL: fig:lm-rs-nobin-false
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureczY2cs.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-58"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-58"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, with \texttt{OMP} fixed to \texttt{true}, for \texttt{paravance-58}
#+LABEL: fig:lm-rs-nobin-p58
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureva5tXz.pdf]]

******** Re-running =aov= and =lm= on =parasilo-14=         :noexport:
We are interested in  what would happen with =aov= and =lm=  analyses if we selected
only binary or  numeric factors, respectively, in the problems  where no factors
were identified as significant.

#+begin_SRC R :results output :session *R* :exports none
p14_designs <- subset(design_data, id == "parasilo-14")
str(p14_designs)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	104 obs. of  16 variables:
 $ T1_Ie  : num  -0.167 -0.333 -1 0.833 0.833 ...
 $ T1_Je  : num  0.833 -0.167 -0.5 0.833 -0.167 ...
 $ T2_Ie  : num  0 -1 -1 -1 -1 ...
 $ T2_Je  : num  0.833 0.833 0.833 0.833 -0.167 ...
 $ U1_Ie  : num  0.267 0.867 0.867 -0.733 -1 ...
 $ U_Ie   : num  -0.333 -1 0.133 0.333 -1 ...
 $ U_Je   : num  -1 0.9333 -1 -1 -0.0667 ...
 $ RT_Ie  : num  -0.333 0.667 -1 0.667 -0.333 ...
 $ RT_Je  : num  -1 -0.333 -0.333 -0.333 0.667 ...
 $ SCRe   : int  -1 -1 0 0 0 -1 0 0 0 -1 ...
 $ VEC1e  : int  0 0 0 -1 0 0 0 0 0 -1 ...
 $ VEC2e  : int  -1 -1 0 0 -1 0 0 -1 -1 0 ...
 $ OMPe   : int  -1 -1 0 0 -1 0 -1 0 0 0 ...
 $ id     : chr  "parasilo-14" "parasilo-14" "parasilo-14" "parasilo-14" ...
 $ step   : num  1 1 1 1 1 1 1 1 1 1 ...
 $ formula: chr  "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ ...
#+end_example

********* First Step:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 1 &
                                   correct_result == "True")

p14_step1 <- subset(p14_designs, step == 1)
p14_step1$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step1$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below  is  listed the  =aov=  summary  using the  formula  from  step 1,  for  the
 =parasilo-14= experiment:

#+begin_SRC R :results output latex :session *R* :exports results
library(xtable)
reg <- aov(step_formula, data = select(p14_step1, -id, -step, -formula))

print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:44:42 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.07 & 0.07 & 0.02 & 0.9006 \\
  I(T1\_Je\verb|^|2) & 1 & 0.12 & 0.12 & 0.03 & 0.8671 \\
  I(T2\_Ie\verb|^|2) & 1 & 1.13 & 1.13 & 0.30 & 0.6196 \\
  I(T2\_Je\verb|^|2) & 1 & 0.16 & 0.16 & 0.04 & 0.8470 \\
  I(U1\_Ie\verb|^|2) & 1 & 0.20 & 0.20 & 0.05 & 0.8306 \\
  I(U\_Ie\verb|^|2) & 1 & 3.03 & 3.03 & 0.82 & 0.4321 \\
  I(U\_Je\verb|^|2) & 1 & 1.82 & 1.82 & 0.49 & 0.5338 \\
  I(RT\_Ie\verb|^|2) & 1 & 1.67 & 1.67 & 0.45 & 0.5503 \\
  I(RT\_Je\verb|^|2) & 1 & 0.18 & 0.18 & 0.05 & 0.8406 \\
  T1\_Ie & 1 & 4.16 & 4.16 & 1.12 & 0.3669 \\
  T1\_Je & 1 & 0.08 & 0.08 & 0.02 & 0.8914 \\
  T2\_Ie & 1 & 0.62 & 0.62 & 0.17 & 0.7088 \\
  T2\_Je & 1 & 0.00 & 0.00 & 0.00 & 0.9814 \\
  U1\_Ie & 1 & 1.44 & 1.44 & 0.39 & 0.5765 \\
  U\_Ie & 1 & 1.78 & 1.78 & 0.48 & 0.5384 \\
  U\_Je & 1 & 0.20 & 0.20 & 0.05 & 0.8320 \\
  RT\_Ie & 1 & 1.86 & 1.86 & 0.50 & 0.5299 \\
  RT\_Je & 1 & 0.51 & 0.51 & 0.14 & 0.7357 \\
  SCRe & 1 & 0.11 & 0.11 & 0.03 & 0.8756 \\
  VEC1e & 1 & 0.38 & 0.38 & 0.10 & 0.7703 \\
  VEC2e & 1 & 11.14 & 11.14 & 3.01 & 0.1811 \\
  OMPe & 1 & 10.41 & 10.41 & 2.81 & 0.1922 \\
  Residuals & 3 & 11.11 & 3.70 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the corresponding =lm= summary, using all factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:45:14 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & -0.5839 & 2.4374 & -0.24 & 0.8261 \\
  I(T1\_Ie\verb|^|2) & -0.2431 & 1.3278 & -0.18 & 0.8664 \\
  I(T1\_Je\verb|^|2) & 0.4758 & 1.1416 & 0.42 & 0.7049 \\
  I(T2\_Ie\verb|^|2) & 0.0730 & 1.3430 & 0.05 & 0.9600 \\
  I(T2\_Je\verb|^|2) & 0.0590 & 1.5563 & 0.04 & 0.9721 \\
  I(U1\_Ie\verb|^|2) & -0.5001 & 1.2198 & -0.41 & 0.7093 \\
  I(U\_Ie\verb|^|2) & 0.1348 & 1.4173 & 0.10 & 0.9302 \\
  I(U\_Je\verb|^|2) & 0.9153 & 1.4447 & 0.63 & 0.5714 \\
  I(RT\_Ie\verb|^|2) & -1.0011 & 1.4857 & -0.67 & 0.5487 \\
  I(RT\_Je\verb|^|2) & -0.6684 & 1.4761 & -0.45 & 0.6814 \\
  T1\_Ie & -0.4607 & 0.7685 & -0.60 & 0.5911 \\
  T1\_Je & 0.1903 & 0.8235 & 0.23 & 0.8321 \\
  T2\_Ie & -0.6126 & 0.7159 & -0.86 & 0.4551 \\
  T2\_Je & 0.0893 & 0.6485 & 0.14 & 0.8992 \\
  U1\_Ie & 0.1033 & 0.6584 & 0.16 & 0.8852 \\
  U\_Ie & -0.4396 & 0.7991 & -0.55 & 0.6206 \\
  U\_Je & -0.4164 & 0.8970 & -0.46 & 0.6741 \\
  RT\_Ie & -0.5819 & 1.0100 & -0.58 & 0.6049 \\
  RT\_Je & -0.7700 & 1.0608 & -0.73 & 0.5204 \\
  SCRe & -0.1850 & 0.9460 & -0.20 & 0.8574 \\
  VEC1e & -0.5071 & 0.8662 & -0.59 & 0.5994 \\
  VEC2e & -1.5946 & 0.9118 & -1.75 & 0.1786 \\
  OMPe & -1.4164 & 0.8447 & -1.68 & 0.1922 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that no  factors were  within the filter  threshold. If  we run  the =aov=
analysis  again, but  using a  formula  with only  linear terms  for the  binary
factors, we get the following:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:45:42 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 11.76 & 11.76 & 8.57 & 0.0080 \\
  SCRe & 1 & 0.18 & 0.18 & 0.13 & 0.7188 \\
  VEC1e & 1 & 2.35 & 2.35 & 1.71 & 0.2051 \\
  VEC2e & 1 & 9.08 & 9.08 & 6.62 & 0.0177 \\
  Residuals & 21 & 28.80 & 1.37 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We  see that  =OMP= and  =VEC2= appear  to be  significant, but  only =OMP=  is within
filtering threshold.  If we  had done  this analysis,  we would  have eliminated
=OMP=. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:02 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 1.2879 & 2.5429 & 0.51 & 0.6281 \\
  I(T1\_Ie\verb|^|2) & -0.3443 & 1.3733 & -0.25 & 0.8092 \\
  I(T1\_Je\verb|^|2) & 0.4895 & 1.2750 & 0.38 & 0.7124 \\
  I(T2\_Ie\verb|^|2) & 0.7388 & 1.4653 & 0.50 & 0.6296 \\
  I(T2\_Je\verb|^|2) & -0.1231 & 1.7055 & -0.07 & 0.9445 \\
  I(U1\_Ie\verb|^|2) & -0.1326 & 1.3013 & -0.10 & 0.9217 \\
  I(U\_Ie\verb|^|2) & -0.7352 & 1.5086 & -0.49 & 0.6409 \\
  I(U\_Je\verb|^|2) & 1.1241 & 1.6087 & 0.70 & 0.5073 \\
  I(RT\_Ie\verb|^|2) & -1.4597 & 1.5992 & -0.91 & 0.3917 \\
  I(RT\_Je\verb|^|2) & -0.2175 & 1.6104 & -0.14 & 0.8964 \\
  T1\_Ie & -0.5276 & 0.8441 & -0.63 & 0.5518 \\
  T1\_Je & 0.1608 & 0.9158 & 0.18 & 0.8656 \\
  T2\_Ie & -0.3984 & 0.7922 & -0.50 & 0.6305 \\
  T2\_Je & -0.0715 & 0.7149 & -0.10 & 0.9232 \\
  U1\_Ie & 0.3409 & 0.7285 & 0.47 & 0.6540 \\
  U\_Ie & -0.4304 & 0.8801 & -0.49 & 0.6398 \\
  U\_Je & 0.0087 & 0.9420 & 0.01 & 0.9929 \\
  RT\_Ie & -0.7724 & 1.1074 & -0.70 & 0.5080 \\
  RT\_Je & -0.3787 & 1.1563 & -0.33 & 0.7529 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Nothing seems to substantially change for this case.

********* Second Step:                                     :noexport:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 2 &
                                   correct_result == "True")

p14_step2 <- subset(p14_designs, step == 2)
p14_step2 <- p14_step2[-nrow(p14_step2), ] # Remove extra row
p14_step2$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step2$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below is the =aov= summary using the formula from step 1, at =parasilo-14=:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(step_formula, data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:25 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.00 & 0.00 & 0.00 & 0.9929 \\
  I(T1\_Je\verb|^|2) & 1 & 0.28 & 0.28 & 0.03 & 0.8874 \\
  I(T2\_Ie\verb|^|2) & 1 & 4.25 & 4.25 & 0.39 & 0.5947 \\
  I(T2\_Je\verb|^|2) & 1 & 3.15 & 3.15 & 0.29 & 0.6435 \\
  I(U1\_Ie\verb|^|2) & 1 & 3.11 & 3.11 & 0.29 & 0.6455 \\
  I(U\_Ie\verb|^|2) & 1 & 0.15 & 0.15 & 0.01 & 0.9167 \\
  I(U\_Je\verb|^|2) & 1 & 0.03 & 0.03 & 0.00 & 0.9609 \\
  I(RT\_Ie\verb|^|2) & 1 & 2.25 & 2.25 & 0.21 & 0.6934 \\
  I(RT\_Je\verb|^|2) & 1 & 1.67 & 1.67 & 0.15 & 0.7322 \\
  T1\_Ie & 1 & 10.18 & 10.18 & 0.94 & 0.4344 \\
  T1\_Je & 1 & 5.14 & 5.14 & 0.47 & 0.5621 \\
  T2\_Ie & 1 & 0.38 & 0.38 & 0.04 & 0.8684 \\
  T2\_Je & 1 & 5.43 & 5.43 & 0.50 & 0.5523 \\
  U1\_Ie & 1 & 0.04 & 0.04 & 0.00 & 0.9582 \\
  U\_Ie & 1 & 6.10 & 6.10 & 0.56 & 0.5310 \\
  U\_Je & 1 & 7.02 & 7.02 & 0.65 & 0.5052 \\
  RT\_Ie & 1 & 0.03 & 0.03 & 0.00 & 0.9607 \\
  RT\_Je & 1 & 7.53 & 7.53 & 0.70 & 0.4920 \\
  SCRe & 1 & 0.00 & 0.00 & 0.00 & 0.9893 \\
  VEC1e & 1 & 2.15 & 2.15 & 0.20 & 0.6993 \\
  VEC2e & 1 & 3.20 & 3.20 & 0.30 & 0.6413 \\
  OMPe & 1 & 7.91 & 7.91 & 0.73 & 0.4827 \\
  Residuals & 2 & 21.65 & 10.82 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the =lm= summary:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:43 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & -0.1916 & 7.9828 & -0.02 & 0.9830 \\
  I(T1\_Ie\verb|^|2) & 1.4679 & 2.6477 & 0.55 & 0.6350 \\
  I(T1\_Je\verb|^|2) & 0.6987 & 2.1667 & 0.32 & 0.7777 \\
  I(T2\_Ie\verb|^|2) & 0.6289 & 3.3176 & 0.19 & 0.8672 \\
  I(T2\_Je\verb|^|2) & 1.1182 & 2.3876 & 0.47 & 0.6856 \\
  I(U1\_Ie\verb|^|2) & -0.9683 & 2.5026 & -0.39 & 0.7361 \\
  I(U\_Ie\verb|^|2) & -0.2207 & 2.2762 & -0.10 & 0.9316 \\
  I(U\_Je\verb|^|2) & -0.0863 & 3.2873 & -0.03 & 0.9814 \\
  I(RT\_Ie\verb|^|2) & 1.9707 & 3.1592 & 0.62 & 0.5964 \\
  I(RT\_Je\verb|^|2) & 2.5392 & 3.1931 & 0.80 & 0.5099 \\
  T1\_Ie & 1.2481 & 1.3655 & 0.91 & 0.4572 \\
  T1\_Je & -1.1113 & 1.4826 & -0.75 & 0.5317 \\
  T2\_Ie & 0.5828 & 1.8955 & 0.31 & 0.7875 \\
  T2\_Je & -0.1342 & 1.2659 & -0.11 & 0.9253 \\
  U1\_Ie & -0.2203 & 1.2447 & -0.18 & 0.8758 \\
  U\_Ie & 1.1803 & 1.3740 & 0.86 & 0.4808 \\
  U\_Je & 1.5185 & 2.1771 & 0.70 & 0.5577 \\
  RT\_Ie & 0.8978 & 2.1430 & 0.42 & 0.7160 \\
  RT\_Je & 1.1568 & 1.5989 & 0.72 & 0.5446 \\
  SCRe & -0.5007 & 1.7698 & -0.28 & 0.8038 \\
  VEC1e & 0.5100 & 1.8784 & 0.27 & 0.8114 \\
  VEC2e & -0.1665 & 2.5713 & -0.06 & 0.9543 \\
  OMPe & -1.6240 & 1.8997 & -0.85 & 0.4827 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Now, let's run =aov= again, using only binary factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:59 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 17.13 & 17.13 & 4.92 & 0.0383 \\
  SCRe & 1 & 1.13 & 1.13 & 0.32 & 0.5754 \\
  VEC1e & 1 & 3.14 & 3.14 & 0.90 & 0.3533 \\
  VEC2e & 1 & 0.63 & 0.63 & 0.18 & 0.6758 \\
  Residuals & 20 & 69.64 & 3.48 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that =OMP= and  =VEC2= appear to be  significant, but none  within filtering
threshold. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:18 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 0.7130 & 3.3215 & 0.21 & 0.8371 \\
  I(T1\_Ie\verb|^|2) & 1.3356 & 1.6327 & 0.82 & 0.4446 \\
  I(T1\_Je\verb|^|2) & 0.5249 & 1.5495 & 0.34 & 0.7463 \\
  I(T2\_Ie\verb|^|2) & 0.8102 & 1.7446 & 0.46 & 0.6587 \\
  I(T2\_Je\verb|^|2) & 0.9339 & 1.6036 & 0.58 & 0.5815 \\
  I(U1\_Ie\verb|^|2) & -0.8610 & 1.6098 & -0.53 & 0.6120 \\
  I(U\_Ie\verb|^|2) & -0.3170 & 1.6663 & -0.19 & 0.8554 \\
  I(U\_Je\verb|^|2) & -0.2912 & 1.9952 & -0.15 & 0.8887 \\
  I(RT\_Ie\verb|^|2) & 1.7247 & 1.8927 & 0.91 & 0.3973 \\
  I(RT\_Je\verb|^|2) & 2.3937 & 1.9275 & 1.24 & 0.2606 \\
  T1\_Ie & 1.4526 & 0.9706 & 1.50 & 0.1851 \\
  T1\_Je & -1.2926 & 1.0546 & -1.23 & 0.2662 \\
  T2\_Ie & 0.5029 & 0.9618 & 0.52 & 0.6198 \\
  T2\_Je & -0.3537 & 0.8138 & -0.43 & 0.6790 \\
  U1\_Ie & -0.3135 & 0.7890 & -0.40 & 0.7049 \\
  U\_Ie & 0.9988 & 0.9220 & 1.08 & 0.3203 \\
  U\_Je & 1.3131 & 1.1489 & 1.14 & 0.2966 \\
  RT\_Ie & 0.5144 & 1.2978 & 0.40 & 0.7055 \\
  RT\_Je & 1.2674 & 1.1140 & 1.14 & 0.2986 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

********* Third Step:                                      :noexport:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 3 &
                                   correct_result == "True")

p14_step3 <- subset(p14_designs, step == step)
p14_step3$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step3$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below is the =aov= summary using the formula from step 1, at =parasilo-14=:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(step_formula, data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:37 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.44 & 0.44 & 0.16 & 0.6935 \\
  I(T1\_Je\verb|^|2) & 1 & 8.21 & 8.21 & 2.92 & 0.0915 \\
  I(T2\_Ie\verb|^|2) & 1 & 0.27 & 0.27 & 0.09 & 0.7594 \\
  I(T2\_Je\verb|^|2) & 1 & 2.33 & 2.33 & 0.83 & 0.3656 \\
  I(U1\_Ie\verb|^|2) & 1 & 0.08 & 0.08 & 0.03 & 0.8631 \\
  I(U\_Ie\verb|^|2) & 1 & 8.76 & 8.76 & 3.11 & 0.0815 \\
  I(U\_Je\verb|^|2) & 1 & 1.91 & 1.91 & 0.68 & 0.4120 \\
  I(RT\_Ie\verb|^|2) & 1 & 0.76 & 0.76 & 0.27 & 0.6056 \\
  I(RT\_Je\verb|^|2) & 1 & 0.60 & 0.60 & 0.21 & 0.6462 \\
  T1\_Ie & 1 & 0.15 & 0.15 & 0.05 & 0.8201 \\
  T1\_Je & 1 & 2.10 & 2.10 & 0.75 & 0.3900 \\
  T2\_Ie & 1 & 3.09 & 3.09 & 1.10 & 0.2975 \\
  T2\_Je & 1 & 3.37 & 3.37 & 1.20 & 0.2771 \\
  U1\_Ie & 1 & 4.70 & 4.70 & 1.67 & 0.1999 \\
  U\_Ie & 1 & 4.40 & 4.40 & 1.56 & 0.2150 \\
  U\_Je & 1 & 1.34 & 1.34 & 0.47 & 0.4930 \\
  RT\_Ie & 1 & 0.27 & 0.27 & 0.09 & 0.7597 \\
  RT\_Je & 1 & 0.00 & 0.00 & 0.00 & 0.9859 \\
  SCRe & 1 & 4.27 & 4.27 & 1.52 & 0.2217 \\
  VEC1e & 1 & 2.81 & 2.81 & 1.00 & 0.3206 \\
  VEC2e & 1 & 14.00 & 14.00 & 4.97 & 0.0285 \\
  OMPe & 1 & 0.00 & 0.00 & 0.00 & 0.9945 \\
  Residuals & 81 & 228.03 & 2.82 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the =lm= summary:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:49 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 2.0901 & 1.0424 & 2.01 & 0.0483 \\
  I(T1\_Ie\verb|^|2) & 0.2033 & 0.4877 & 0.42 & 0.6779 \\
  I(T1\_Je\verb|^|2) & 0.5684 & 0.4720 & 1.20 & 0.2320 \\
  I(T2\_Ie\verb|^|2) & 0.3079 & 0.5326 & 0.58 & 0.5649 \\
  I(T2\_Je\verb|^|2) & -0.6988 & 0.5206 & -1.34 & 0.1833 \\
  I(U1\_Ie\verb|^|2) & 0.0450 & 0.4556 & 0.10 & 0.9216 \\
  I(U\_Ie\verb|^|2) & 0.1611 & 0.5254 & 0.31 & 0.7599 \\
  I(U\_Je\verb|^|2) & -0.2009 & 0.5551 & -0.36 & 0.7183 \\
  I(RT\_Ie\verb|^|2) & -0.2769 & 0.5636 & -0.49 & 0.6245 \\
  I(RT\_Je\verb|^|2) & -0.0111 & 0.5453 & -0.02 & 0.9838 \\
  T1\_Ie & 0.0966 & 0.2955 & 0.33 & 0.7446 \\
  T1\_Je & -0.1229 & 0.3069 & -0.40 & 0.6900 \\
  T2\_Ie & 0.1918 & 0.2483 & 0.77 & 0.4422 \\
  T2\_Je & -0.2739 & 0.2579 & -1.06 & 0.2913 \\
  U1\_Ie & 0.3403 & 0.2506 & 1.36 & 0.1783 \\
  U\_Ie & -0.3597 & 0.3078 & -1.17 & 0.2460 \\
  U\_Je & 0.2037 & 0.3048 & 0.67 & 0.5059 \\
  RT\_Ie & -0.0513 & 0.3739 & -0.14 & 0.8913 \\
  RT\_Je & 0.1400 & 0.3690 & 0.38 & 0.7053 \\
  SCRe & -0.3981 & 0.3432 & -1.16 & 0.2495 \\
  VEC1e & -0.2706 & 0.3425 & -0.79 & 0.4319 \\
  VEC2e & 0.7631 & 0.3438 & 2.22 & 0.0293 \\
  OMPe & -0.0023 & 0.3377 & -0.01 & 0.9945 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Now, let's run =aov= again, using only binary factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:48:17 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 0.58 & 0.58 & 0.21 & 0.6482 \\
  SCRe & 1 & 3.32 & 3.32 & 1.20 & 0.2758 \\
  VEC1e & 1 & 2.63 & 2.63 & 0.95 & 0.3320 \\
  VEC2e & 1 & 11.25 & 11.25 & 4.06 & 0.0466 \\
  Residuals & 99 & 274.11 & 2.77 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that =VEC2= appear to be  significant, but not  within filtering
threshold. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:48:15 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 1.8998 & 0.9851 & 1.93 & 0.0571 \\
  I(T1\_Ie\verb|^|2) & 0.3154 & 0.4957 & 0.64 & 0.5264 \\
  I(T1\_Je\verb|^|2) & 0.5832 & 0.4810 & 1.21 & 0.2287 \\
  I(T2\_Ie\verb|^|2) & 0.3367 & 0.5397 & 0.62 & 0.5343 \\
  I(T2\_Je\verb|^|2) & -0.5854 & 0.5283 & -1.11 & 0.2709 \\
  I(U1\_Ie\verb|^|2) & 0.1221 & 0.4630 & 0.26 & 0.7926 \\
  I(U\_Ie\verb|^|2) & 0.1803 & 0.5352 & 0.34 & 0.7371 \\
  I(U\_Je\verb|^|2) & -0.1887 & 0.5649 & -0.33 & 0.7392 \\
  I(RT\_Ie\verb|^|2) & -0.3288 & 0.5693 & -0.58 & 0.5650 \\
  I(RT\_Je\verb|^|2) & -0.0976 & 0.5542 & -0.18 & 0.8606 \\
  T1\_Ie & 0.0194 & 0.2963 & 0.07 & 0.9480 \\
  T1\_Je & -0.1595 & 0.3123 & -0.51 & 0.6108 \\
  T2\_Ie & 0.2132 & 0.2504 & 0.85 & 0.3971 \\
  T2\_Je & -0.3121 & 0.2623 & -1.19 & 0.2374 \\
  U1\_Ie & 0.3361 & 0.2550 & 1.32 & 0.1910 \\
  U\_Ie & -0.2641 & 0.3112 & -0.85 & 0.3984 \\
  U\_Je & 0.2105 & 0.3107 & 0.68 & 0.5000 \\
  RT\_Ie & -0.1031 & 0.3808 & -0.27 & 0.7873 \\
  RT\_Je & 0.0064 & 0.3704 & 0.02 & 0.9861 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

******** Combined Experiments                               :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

******* Predicted Performance at Each Step
Figure\nbsp{}[[fig:nc-predicted-best]] compares  the performance  /predicted by  the fitted
model/, represented  by the green  line, with the  performance of /the  best point
found at each design/, represented by the  blue line. The red line marks the best
point found so far.

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

It  is only  at the  fourth step  of /parasilo-17/  that the  point with  the best
predicted performance  was better  than the  best point on  the design  for that
step, while also being better than the best point found so far. Although we seem
to be  effectively restricting the search  space with our exploration,  which is
evidenced  by the  improvement that  occurs as  steps progress  and by  the best
points being found inside designs, the  models fit using experiment data are not
able to improve the current best on the majority of cases.

******* D-Optimality
******** D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

******** D_A-Optimality at Each Step                        :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Removing Cubic Terms                                     :noexport:
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/formula_log_encoded"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

data_dir <- "dlmt_spapt_experiments/data/results"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][5], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	61 obs. of  3 variables:
 $ removed_variables: Factor w/ 12 levels "","OMP","SCR",..: 2 3 1 1 1 1 1 2 7 4 ...
 $ step             : int  1 1 2 3 4 1 2 3 4 4 ...
 $ experiment_id    : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...

'data.frame':	520 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->64" "T1_J->32" "U_J->18" "U_I->1" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ experiment_id          : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...

'data.frame':	999 obs. of  31 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  2048 1024 1024 512 1 1 1 2048 1 32 ...
 $ T2_I                        : int  512 128 512 2048 32 2048 16 1 256 2048 ...
 $ RT_I                        : int  8 32 1 32 1 32 1 2 1 4 ...
 $ mean_confidence_interval_inf: num  0.873 4.582 0.831 0.834 4.575 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  2 1024 128 128 64 2048 1024 1024 1 4 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "False" "True" "True" ...
 $ VEC1                        : chr  "True" "False" "True" "False" ...
 $ SCR                         : chr  "True" "False" "True" "False" ...
 $ U1_I                        : int  30 1 9 17 29 6 14 12 9 12 ...
 $ RT_J                        : int  2 2 8 1 1 2 32 1 32 32 ...
 $ T1_I                        : int  2 4 1 1 1 1 16 16 32 1 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.065226 0.000207 0.058666 0.118338 0.000682 ...
 $ cost_mean                   : num  0.913 4.582 0.868 0.907 4.576 ...
 $ U_J                         : int  1 18 1 29 6 1 1 1 30 1 ...
 $ U_I                         : int  20 1 30 1 1 2 11 11 1 21 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "False" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.954 4.582 0.904 0.981 4.576 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
 $ cost_baseline               : num  4.86 4.86 4.86 4.86 4.86 ...
 $ speedup                     : num  5.32 1.06 5.6 5.35 1.06 ...
 $ max_run_speedup             : num  9.26 9.26 9.26 9.26 9.26 ...
 $ min_run_cost                : num  0.524 0.524 0.524 0.524 0.524 ...
 $ best_iteration              : num  86 86 86 86 86 86 86 86 86 86 ...
 $ points                      : int  101 101 101 101 101 101 101 101 101 101 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	10 obs. of  34 variables:
 $ id                          : int  86 104 64 78 57 109 93 69 73 43
 $ T2_J                        : int  1 2048 1024 256 2048 1024 128 1024 2048 256
 $ T2_I                        : int  1 2048 1 2048 2048 2048 2048 2048 2048 1
 $ RT_I                        : int  1 4 4 8 8 4 1 8 1 1
 $ mean_confidence_interval_inf: num  0.493 0.409 0.437 0.477 0.45 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  64 2 1024 256 1 1 2 1 2048 128
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "True" "True" "False" "False" ...
 $ VEC1                        : chr  "False" "False" "False" "False" ...
 $ SCR                         : chr  "True" "True" "True" "False" ...
 $ U1_I                        : int  25 2 16 1 4 7 15 2 4 19
 $ RT_J                        : int  1 32 4 4 4 8 1 1 8 1
 $ T1_I                        : int  2048 8 2048 1 2048 2048 2048 1024 1 2048
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10
 $ cost_std                    : num  0.0505 0.24 0.0625 0.0394 0.1464 ...
 $ cost_mean                   : num  0.524 0.558 0.475 0.502 0.54 ...
 $ U_J                         : int  1 1 30 21 1 29 1 1 1 1
 $ U_I                         : int  30 9 1 1 13 1 13 1 12 16
 $ step                        : int  4 4 3 3 3 4 4 3 3 2
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.556 0.706 0.514 0.526 0.631 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-10" "parasilo-11" "parasilo-13" ...
 $ cost_baseline               : num  4.86 4.85 4.75 4.75 4.86 ...
 $ speedup                     : num  9.26 8.7 10 9.48 8.99 ...
 $ max_run_speedup             : num  9.26 8.7 10 9.48 8.99 ...
 $ min_run_cost                : num  0.524 0.558 0.475 0.502 0.54 ...
 $ best_iteration              : num  86 104 64 78 57 109 93 69 73 43
 $ points                      : int  101 106 94 102 103 106 91 103 98 95
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.8 4.8 4.8 4.8 4.8 ...
 $ label_center_x              : num  1.47 1.47 1.47 1.47 1.47 ...
 $ label_center_y              : num  78 78 78 78 78 ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	20 obs. of  34 variables:
 $ id                          : int  86 104 64 78 57 109 93 69 73 43 ...
 $ T2_J                        : int  1 2048 1024 256 2048 1024 128 1024 2048 256 ...
 $ T2_I                        : int  1 2048 1 2048 2048 2048 2048 2048 2048 1 ...
 $ RT_I                        : int  1 4 4 8 8 4 1 8 1 1 ...
 $ mean_confidence_interval_inf: num  0.493 0.409 0.437 0.477 0.45 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  64 2 1024 256 1 1 2 1 2048 128 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "True" "True" "False" "False" ...
 $ VEC1                        : chr  "False" "False" "False" "False" ...
 $ SCR                         : chr  "True" "True" "True" "False" ...
 $ U1_I                        : int  25 2 16 1 4 7 15 2 4 19 ...
 $ RT_J                        : int  1 32 4 4 4 8 1 1 8 1 ...
 $ T1_I                        : int  2048 8 2048 1 2048 2048 2048 1024 1 2048 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.0505 0.24 0.0625 0.0394 0.1464 ...
 $ cost_mean                   : num  0.524 0.558 0.475 0.502 0.54 ...
 $ U_J                         : int  1 1 30 21 1 29 1 1 1 1 ...
 $ U_I                         : int  30 9 1 1 13 1 13 1 12 16 ...
 $ step                        : int  4 4 3 3 3 4 4 3 3 2 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.556 0.706 0.514 0.526 0.631 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-10" "parasilo-11" "parasilo-13" ...
 $ cost_baseline               : num  4.86 4.85 4.75 4.75 4.86 ...
 $ speedup                     : num  9.26 8.7 10 9.48 8.99 ...
 $ max_run_speedup             : num  9.26 8.7 10 9.48 8.99 ...
 $ min_run_cost                : num  0.524 0.558 0.475 0.502 0.54 ...
 $ best_iteration              : num  86 104 64 78 57 109 93 69 73 43 ...
 $ points                      : int  101 106 94 102 103 106 91 103 98 95 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.8 4.8 4.8 4.8 4.8 ...
 $ label_center_x              : num  1.47 1.47 1.47 1.47 1.47 ...
 $ label_center_y              : num  78 78 78 78 78 ...

'data.frame':	36 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ valid_configurations   : int  37440 37440 37440 37440 37440 37440 37440 37440 37440 37440 ...
 $ D                      : num  0.203 0.203 0.205 0.205 0.205 ...
 $ used_budget            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ model_size             : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best           : num  0.53 0.53 0.659 0.659 0.636 ...
 $ trials                 : int  26 26 26 26 26 26 26 26 26 26 ...
 $ current_best_coordinate: chr  "{'T1_I': 64, 'T1_J': 32, 'U_J': 18, 'U_I': 1, 'T2_I': 2048, 'T2_J': 1, 'U1_I': 28, 'OMP': True, 'VEC2': True, '"| __truncated__ "{'T1_I': 64, 'T1_J': 32, 'U_J': 18, 'U_I': 1, 'T2_I': 2048, 'T2_J': 1, 'U1_I': 28, 'OMP': True, 'VEC2': True, '"| __truncated__ "{'T1_I': 32, 'T1_J': 64, 'U_J': 1, 'U_I': 17, 'T2_I': 2048, 'T2_J': 64, 'U1_I': 29, 'OMP': True, 'VEC2': False,"| __truncated__ "{'T1_I': 32, 'T1_J': 64, 'U_J': 1, 'U_I': 17, 'T2_I': 2048, 'T2_J': 64, 'U1_I': 29, 'OMP': True, 'VEC2': False,"| __truncated__ ...
 $ tested_configurations  : int  1789293 1789293 1796907 1796907 1793026 1788535 1790630 1790630 1796726 1796726 ...
 $ fixed_factors          : chr  "{'OMP': 1, 'SCR': 1}" "{'OMP': 1, 'SCR': 1}" "{'OMP': 1, 'SCR': 1}" "{'OMP': 1, 'SCR': 1}" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ design_best            : num  0.53 0.53 0.659 0.659 0.636 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "OMP" "SCR" "OMP" "SCR" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  0.74 0.74 0.742 0.742 0.727 ...
 $ experiment_id          : chr  "parasilo-1" "parasilo-1" "parasilo-11" "parasilo-11" ...

'data.frame':	1028 obs. of  24 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  2048 1024 1024 512 1 1 1 2048 1 32 ...
 $ T2_I                        : int  512 128 512 2048 32 2048 16 1 256 2048 ...
 $ RT_I                        : int  8 32 1 32 1 32 1 2 1 4 ...
 $ mean_confidence_interval_inf: num  0.873 4.582 0.831 0.834 4.575 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  2 1024 128 128 64 2048 1024 1024 1 4 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "False" "True" "True" ...
 $ VEC1                        : chr  "True" "False" "True" "False" ...
 $ SCR                         : chr  "True" "False" "True" "False" ...
 $ U1_I                        : int  30 1 9 17 29 6 14 12 9 12 ...
 $ RT_J                        : int  2 2 8 1 1 2 32 1 32 32 ...
 $ T1_I                        : int  2 4 1 1 1 1 16 16 32 1 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.065226 0.000207 0.058666 0.118338 0.000682 ...
 $ cost_mean                   : num  0.913 4.582 0.868 0.907 4.576 ...
 $ U_J                         : int  1 18 1 29 6 1 1 1 30 1 ...
 $ U_I                         : int  20 1 30 1 1 2 11 11 1 21 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "False" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.954 4.582 0.904 0.981 4.576 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...

There were 40 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	860 obs. of  4 variables:
 $ metric_value: num  0.019 0.0906 0.0788 0.0683 0.071 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
Figure\nbsp[[fig:best-found]] shows the iterations where  the best configuration of each
of the 10 runs was found, for uniform sampling and for our approach.

The results are  the same as the ones  presented in the paper, but  the data are
not the same.  The data for the figures  in this report were obtained with a new
set of  10 repetitions the same  experiment, but using a  performance model with
only linear  and quadratic terms, removing  the cubic terms used  in the paper's
experiments.

#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureZgRZWM.pdf]]

The results are very similar from the  ones in the paper, but our approach found
slightly better  configurations slightly  faster. Random  sampling also  found a
much better configuration much faster than before in one experiment.

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J, OMP, SCR, VEC1, VEC2), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "tiny")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 06:09:05 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}} cccccccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J & OMP & SCR & VEC1 & VEC2 \\
\hline \\[-1.8ex]
parasilo-1 & DLMT & 0.5244322 & 2048 & 64 & 1 & 30 & 1 & 1 & 25 & 1 & 1 & True & True & False & True \\
parasilo-10 & DLMT & 0.55769 & 8 & 2 & 1 & 9 & 2048 & 2048 & 2 & 4 & 32 & True & True & False & True \\
parasilo-11 & DLMT & 0.4753558 & 2048 & 1024 & 30 & 1 & 1 & 1024 & 16 & 4 & 4 & True & True & False & False \\
parasilo-13 & DLMT & 0.5016148 & 1 & 256 & 21 & 1 & 2048 & 256 & 1 & 8 & 4 & True & False & False & False \\
parasilo-14 & DLMT & 0.5404449 & 2048 & 1 & 1 & 13 & 2048 & 2048 & 4 & 8 & 4 & True & True & False & True \\
parasilo-17 & DLMT & 0.5371861 & 2048 & 1 & 29 & 1 & 2048 & 1024 & 7 & 4 & 8 & True & True & True & False \\
parasilo-19 & DLMT & 0.5507874 & 2048 & 2 & 1 & 13 & 2048 & 128 & 15 & 1 & 1 & True & True & True & True \\
parasilo-2 & DLMT & 0.5229024 & 1024 & 1 & 1 & 1 & 2048 & 1024 & 2 & 8 & 1 & True & True & True & False \\
parasilo-20 & DLMT & 0.5643309 & 1 & 2048 & 1 & 12 & 2048 & 2048 & 4 & 1 & 8 & True & True & False & True \\
parasilo-9 & DLMT & 0.4685077 & 2048 & 128 & 1 & 16 & 1 & 256 & 19 & 1 & 1 & True & True & True & True \\
paravance-50 & RS & 0.5685274 & 512 & 512 & 19 & 1 & 2048 & 1024 & 27 & 4 & 1 & True & True & True & False \\
paravance-51 & RS & 0.5467725 & 1024 & 32 & 10 & 1 & 2048 & 512 & 9 & 8 & 8 & True & True & True & True \\
paravance-52 & RS & 0.5417953 & 2048 & 8 & 9 & 1 & 2048 & 128 & 30 & 8 & 16 & True & True & True & True \\
paravance-53 & RS & 0.5612387 & 2048 & 64 & 16 & 1 & 2048 & 256 & 9 & 16 & 2 & True & True & True & True \\
paravance-54 & RS & 0.5322531 & 2048 & 8 & 1 & 9 & 1 & 1 & 19 & 1 & 1 & True & True & True & False \\
paravance-55 & RS & 0.5540684 & 32 & 4 & 1 & 5 & 2048 & 256 & 4 & 16 & 1 & True & True & False & False \\
paravance-56 & RS & 0.4648199 & 2048 & 1 & 1 & 23 & 1 & 512 & 25 & 8 & 1 & True & True & False & True \\
paravance-57 & RS & 0.5463944 & 256 & 16 & 1 & 15 & 2048 & 512 & 2 & 2 & 2 & True & True & False & False \\
paravance-58 & RS & 0.5496127 & 32 & 1 & 1 & 14 & 2048 & 2048 & 24 & 8 & 4 & True & True & True & True \\
paravance-59 & RS & 0.4758884 & 64 & 16 & 29 & 1 & 2048 & 1 & 27 & 16 & 4 & True & True & True & True \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
Figure\nbsp{}[[fig:eliminated-terms]] shows the /count of  model terms/ that were eliminated
at each color-coded DLMT step.  As before, we see that =OMP= and =SCR= were the most
eliminated factors, especially on the first step.

#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-ynhqKR/figure7r6W2z.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
Figure\nbsp{}[[fig:encpnc-ff-ss-be]]  shows  the  factors   that  were  identified  as
significant by ANOVA, with significance threshold  of $0.01$, at each DLMT step.
Identifying  a  factor  removes  the corresponding  parameter  from  the  model,
regardless of the  model term that was identified.  Figures  are grouped by each
of the 10 experiments.  Figure headers  identify each run, and correspond to the
names of the Grid5000 machines where experiments were run.

It is interesting that only  /parasilo-19/, /parasilo-20/, and /parasilo-9/ eliminated
any  factor other  than =OMP=  and =SCR=  on  the first  step where  any factor  was
eliminated, and also  that those runs fixed  the factor =RT_I= to  the same value.

We can  also see  that =OMP=  seems to be  the parameter  behind the  most extreme
changes in the execution time of  tested configurations. This is specially clear
at  /parasilo-13/   and  /parasilo-10/,  where  the   explored  configurations  have
relatively high execution time until after step 3, where =OMP= is fixed.

A very slight worsening of execution times, an increase, that is, can be seen at
the fourth step at /parasilo-11/, after =RT_I= was fixed. The minimum execution time
seems to be higher than in the third step.

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figuretV900e.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
         RT_J, T1_I, SCR) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurepGi7gO.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
         RT_J, T1_I, SCR) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-elHoq9/figure3xnWMZ.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  subset(OMP == "True") %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
         RT_J, T1_I, SCR) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, with \texttt{OMP} fixed to \texttt{true}
#+LABEL: fig:lm-rs-nobin
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqNvfdJ.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  subset(OMP == "False") %>%
  subset(SCR == "True") %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, VEC2, VEC1, OMP, U_J, U_I, U1_I,
         RT_J, T1_I, SCR) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  ylim(c(NA, 2.0)) +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, with \texttt{OMP} fixed to \texttt{false}
#+LABEL: fig:lm-rs-nobin-false
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureczY2cs.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-58"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-58"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, with \texttt{OMP} fixed to \texttt{true}, for \texttt{paravance-58}
#+LABEL: fig:lm-rs-nobin-p58
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureva5tXz.pdf]]

******* Re-running =aov= and =lm= on =parasilo-14=                 :noexport:
We are interested in  what would happen with =aov= and =lm=  analyses if we selected
only binary or  numeric factors, respectively, in the problems  where no factors
were identified as significant.

#+begin_SRC R :results output :session *R* :exports none
p14_designs <- subset(design_data, id == "parasilo-14")
str(p14_designs)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	104 obs. of  16 variables:
 $ T1_Ie  : num  -0.167 -0.333 -1 0.833 0.833 ...
 $ T1_Je  : num  0.833 -0.167 -0.5 0.833 -0.167 ...
 $ T2_Ie  : num  0 -1 -1 -1 -1 ...
 $ T2_Je  : num  0.833 0.833 0.833 0.833 -0.167 ...
 $ U1_Ie  : num  0.267 0.867 0.867 -0.733 -1 ...
 $ U_Ie   : num  -0.333 -1 0.133 0.333 -1 ...
 $ U_Je   : num  -1 0.9333 -1 -1 -0.0667 ...
 $ RT_Ie  : num  -0.333 0.667 -1 0.667 -0.333 ...
 $ RT_Je  : num  -1 -0.333 -0.333 -0.333 0.667 ...
 $ SCRe   : int  -1 -1 0 0 0 -1 0 0 0 -1 ...
 $ VEC1e  : int  0 0 0 -1 0 0 0 0 0 -1 ...
 $ VEC2e  : int  -1 -1 0 0 -1 0 0 -1 -1 0 ...
 $ OMPe   : int  -1 -1 0 0 -1 0 -1 0 0 0 ...
 $ id     : chr  "parasilo-14" "parasilo-14" "parasilo-14" "parasilo-14" ...
 $ step   : num  1 1 1 1 1 1 1 1 1 1 ...
 $ formula: chr  "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ ...
#+end_example

******** First Step:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 1 &
                                   correct_result == "True")

p14_step1 <- subset(p14_designs, step == 1)
p14_step1$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step1$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below  is  listed the  =aov=  summary  using the  formula  from  step 1,  for  the
 =parasilo-14= experiment:

#+begin_SRC R :results output latex :session *R* :exports results
library(xtable)
reg <- aov(step_formula, data = select(p14_step1, -id, -step, -formula))

print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:44:42 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.07 & 0.07 & 0.02 & 0.9006 \\
  I(T1\_Je\verb|^|2) & 1 & 0.12 & 0.12 & 0.03 & 0.8671 \\
  I(T2\_Ie\verb|^|2) & 1 & 1.13 & 1.13 & 0.30 & 0.6196 \\
  I(T2\_Je\verb|^|2) & 1 & 0.16 & 0.16 & 0.04 & 0.8470 \\
  I(U1\_Ie\verb|^|2) & 1 & 0.20 & 0.20 & 0.05 & 0.8306 \\
  I(U\_Ie\verb|^|2) & 1 & 3.03 & 3.03 & 0.82 & 0.4321 \\
  I(U\_Je\verb|^|2) & 1 & 1.82 & 1.82 & 0.49 & 0.5338 \\
  I(RT\_Ie\verb|^|2) & 1 & 1.67 & 1.67 & 0.45 & 0.5503 \\
  I(RT\_Je\verb|^|2) & 1 & 0.18 & 0.18 & 0.05 & 0.8406 \\
  T1\_Ie & 1 & 4.16 & 4.16 & 1.12 & 0.3669 \\
  T1\_Je & 1 & 0.08 & 0.08 & 0.02 & 0.8914 \\
  T2\_Ie & 1 & 0.62 & 0.62 & 0.17 & 0.7088 \\
  T2\_Je & 1 & 0.00 & 0.00 & 0.00 & 0.9814 \\
  U1\_Ie & 1 & 1.44 & 1.44 & 0.39 & 0.5765 \\
  U\_Ie & 1 & 1.78 & 1.78 & 0.48 & 0.5384 \\
  U\_Je & 1 & 0.20 & 0.20 & 0.05 & 0.8320 \\
  RT\_Ie & 1 & 1.86 & 1.86 & 0.50 & 0.5299 \\
  RT\_Je & 1 & 0.51 & 0.51 & 0.14 & 0.7357 \\
  SCRe & 1 & 0.11 & 0.11 & 0.03 & 0.8756 \\
  VEC1e & 1 & 0.38 & 0.38 & 0.10 & 0.7703 \\
  VEC2e & 1 & 11.14 & 11.14 & 3.01 & 0.1811 \\
  OMPe & 1 & 10.41 & 10.41 & 2.81 & 0.1922 \\
  Residuals & 3 & 11.11 & 3.70 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the corresponding =lm= summary, using all factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:45:14 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & -0.5839 & 2.4374 & -0.24 & 0.8261 \\
  I(T1\_Ie\verb|^|2) & -0.2431 & 1.3278 & -0.18 & 0.8664 \\
  I(T1\_Je\verb|^|2) & 0.4758 & 1.1416 & 0.42 & 0.7049 \\
  I(T2\_Ie\verb|^|2) & 0.0730 & 1.3430 & 0.05 & 0.9600 \\
  I(T2\_Je\verb|^|2) & 0.0590 & 1.5563 & 0.04 & 0.9721 \\
  I(U1\_Ie\verb|^|2) & -0.5001 & 1.2198 & -0.41 & 0.7093 \\
  I(U\_Ie\verb|^|2) & 0.1348 & 1.4173 & 0.10 & 0.9302 \\
  I(U\_Je\verb|^|2) & 0.9153 & 1.4447 & 0.63 & 0.5714 \\
  I(RT\_Ie\verb|^|2) & -1.0011 & 1.4857 & -0.67 & 0.5487 \\
  I(RT\_Je\verb|^|2) & -0.6684 & 1.4761 & -0.45 & 0.6814 \\
  T1\_Ie & -0.4607 & 0.7685 & -0.60 & 0.5911 \\
  T1\_Je & 0.1903 & 0.8235 & 0.23 & 0.8321 \\
  T2\_Ie & -0.6126 & 0.7159 & -0.86 & 0.4551 \\
  T2\_Je & 0.0893 & 0.6485 & 0.14 & 0.8992 \\
  U1\_Ie & 0.1033 & 0.6584 & 0.16 & 0.8852 \\
  U\_Ie & -0.4396 & 0.7991 & -0.55 & 0.6206 \\
  U\_Je & -0.4164 & 0.8970 & -0.46 & 0.6741 \\
  RT\_Ie & -0.5819 & 1.0100 & -0.58 & 0.6049 \\
  RT\_Je & -0.7700 & 1.0608 & -0.73 & 0.5204 \\
  SCRe & -0.1850 & 0.9460 & -0.20 & 0.8574 \\
  VEC1e & -0.5071 & 0.8662 & -0.59 & 0.5994 \\
  VEC2e & -1.5946 & 0.9118 & -1.75 & 0.1786 \\
  OMPe & -1.4164 & 0.8447 & -1.68 & 0.1922 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that no  factors were  within the filter  threshold. If  we run  the =aov=
analysis  again, but  using a  formula  with only  linear terms  for the  binary
factors, we get the following:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:45:42 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 11.76 & 11.76 & 8.57 & 0.0080 \\
  SCRe & 1 & 0.18 & 0.18 & 0.13 & 0.7188 \\
  VEC1e & 1 & 2.35 & 2.35 & 1.71 & 0.2051 \\
  VEC2e & 1 & 9.08 & 9.08 & 6.62 & 0.0177 \\
  Residuals & 21 & 28.80 & 1.37 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We  see that  =OMP= and  =VEC2= appear  to be  significant, but  only =OMP=  is within
filtering threshold.  If we  had done  this analysis,  we would  have eliminated
=OMP=. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:02 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 1.2879 & 2.5429 & 0.51 & 0.6281 \\
  I(T1\_Ie\verb|^|2) & -0.3443 & 1.3733 & -0.25 & 0.8092 \\
  I(T1\_Je\verb|^|2) & 0.4895 & 1.2750 & 0.38 & 0.7124 \\
  I(T2\_Ie\verb|^|2) & 0.7388 & 1.4653 & 0.50 & 0.6296 \\
  I(T2\_Je\verb|^|2) & -0.1231 & 1.7055 & -0.07 & 0.9445 \\
  I(U1\_Ie\verb|^|2) & -0.1326 & 1.3013 & -0.10 & 0.9217 \\
  I(U\_Ie\verb|^|2) & -0.7352 & 1.5086 & -0.49 & 0.6409 \\
  I(U\_Je\verb|^|2) & 1.1241 & 1.6087 & 0.70 & 0.5073 \\
  I(RT\_Ie\verb|^|2) & -1.4597 & 1.5992 & -0.91 & 0.3917 \\
  I(RT\_Je\verb|^|2) & -0.2175 & 1.6104 & -0.14 & 0.8964 \\
  T1\_Ie & -0.5276 & 0.8441 & -0.63 & 0.5518 \\
  T1\_Je & 0.1608 & 0.9158 & 0.18 & 0.8656 \\
  T2\_Ie & -0.3984 & 0.7922 & -0.50 & 0.6305 \\
  T2\_Je & -0.0715 & 0.7149 & -0.10 & 0.9232 \\
  U1\_Ie & 0.3409 & 0.7285 & 0.47 & 0.6540 \\
  U\_Ie & -0.4304 & 0.8801 & -0.49 & 0.6398 \\
  U\_Je & 0.0087 & 0.9420 & 0.01 & 0.9929 \\
  RT\_Ie & -0.7724 & 1.1074 & -0.70 & 0.5080 \\
  RT\_Je & -0.3787 & 1.1563 & -0.33 & 0.7529 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Nothing seems to substantially change for this case.

******** Second Step:                                       :noexport:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 2 &
                                   correct_result == "True")

p14_step2 <- subset(p14_designs, step == 2)
p14_step2 <- p14_step2[-nrow(p14_step2), ] # Remove extra row
p14_step2$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step2$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below is the =aov= summary using the formula from step 1, at =parasilo-14=:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(step_formula, data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:25 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.00 & 0.00 & 0.00 & 0.9929 \\
  I(T1\_Je\verb|^|2) & 1 & 0.28 & 0.28 & 0.03 & 0.8874 \\
  I(T2\_Ie\verb|^|2) & 1 & 4.25 & 4.25 & 0.39 & 0.5947 \\
  I(T2\_Je\verb|^|2) & 1 & 3.15 & 3.15 & 0.29 & 0.6435 \\
  I(U1\_Ie\verb|^|2) & 1 & 3.11 & 3.11 & 0.29 & 0.6455 \\
  I(U\_Ie\verb|^|2) & 1 & 0.15 & 0.15 & 0.01 & 0.9167 \\
  I(U\_Je\verb|^|2) & 1 & 0.03 & 0.03 & 0.00 & 0.9609 \\
  I(RT\_Ie\verb|^|2) & 1 & 2.25 & 2.25 & 0.21 & 0.6934 \\
  I(RT\_Je\verb|^|2) & 1 & 1.67 & 1.67 & 0.15 & 0.7322 \\
  T1\_Ie & 1 & 10.18 & 10.18 & 0.94 & 0.4344 \\
  T1\_Je & 1 & 5.14 & 5.14 & 0.47 & 0.5621 \\
  T2\_Ie & 1 & 0.38 & 0.38 & 0.04 & 0.8684 \\
  T2\_Je & 1 & 5.43 & 5.43 & 0.50 & 0.5523 \\
  U1\_Ie & 1 & 0.04 & 0.04 & 0.00 & 0.9582 \\
  U\_Ie & 1 & 6.10 & 6.10 & 0.56 & 0.5310 \\
  U\_Je & 1 & 7.02 & 7.02 & 0.65 & 0.5052 \\
  RT\_Ie & 1 & 0.03 & 0.03 & 0.00 & 0.9607 \\
  RT\_Je & 1 & 7.53 & 7.53 & 0.70 & 0.4920 \\
  SCRe & 1 & 0.00 & 0.00 & 0.00 & 0.9893 \\
  VEC1e & 1 & 2.15 & 2.15 & 0.20 & 0.6993 \\
  VEC2e & 1 & 3.20 & 3.20 & 0.30 & 0.6413 \\
  OMPe & 1 & 7.91 & 7.91 & 0.73 & 0.4827 \\
  Residuals & 2 & 21.65 & 10.82 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the =lm= summary:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:43 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & -0.1916 & 7.9828 & -0.02 & 0.9830 \\
  I(T1\_Ie\verb|^|2) & 1.4679 & 2.6477 & 0.55 & 0.6350 \\
  I(T1\_Je\verb|^|2) & 0.6987 & 2.1667 & 0.32 & 0.7777 \\
  I(T2\_Ie\verb|^|2) & 0.6289 & 3.3176 & 0.19 & 0.8672 \\
  I(T2\_Je\verb|^|2) & 1.1182 & 2.3876 & 0.47 & 0.6856 \\
  I(U1\_Ie\verb|^|2) & -0.9683 & 2.5026 & -0.39 & 0.7361 \\
  I(U\_Ie\verb|^|2) & -0.2207 & 2.2762 & -0.10 & 0.9316 \\
  I(U\_Je\verb|^|2) & -0.0863 & 3.2873 & -0.03 & 0.9814 \\
  I(RT\_Ie\verb|^|2) & 1.9707 & 3.1592 & 0.62 & 0.5964 \\
  I(RT\_Je\verb|^|2) & 2.5392 & 3.1931 & 0.80 & 0.5099 \\
  T1\_Ie & 1.2481 & 1.3655 & 0.91 & 0.4572 \\
  T1\_Je & -1.1113 & 1.4826 & -0.75 & 0.5317 \\
  T2\_Ie & 0.5828 & 1.8955 & 0.31 & 0.7875 \\
  T2\_Je & -0.1342 & 1.2659 & -0.11 & 0.9253 \\
  U1\_Ie & -0.2203 & 1.2447 & -0.18 & 0.8758 \\
  U\_Ie & 1.1803 & 1.3740 & 0.86 & 0.4808 \\
  U\_Je & 1.5185 & 2.1771 & 0.70 & 0.5577 \\
  RT\_Ie & 0.8978 & 2.1430 & 0.42 & 0.7160 \\
  RT\_Je & 1.1568 & 1.5989 & 0.72 & 0.5446 \\
  SCRe & -0.5007 & 1.7698 & -0.28 & 0.8038 \\
  VEC1e & 0.5100 & 1.8784 & 0.27 & 0.8114 \\
  VEC2e & -0.1665 & 2.5713 & -0.06 & 0.9543 \\
  OMPe & -1.6240 & 1.8997 & -0.85 & 0.4827 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Now, let's run =aov= again, using only binary factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:59 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 17.13 & 17.13 & 4.92 & 0.0383 \\
  SCRe & 1 & 1.13 & 1.13 & 0.32 & 0.5754 \\
  VEC1e & 1 & 3.14 & 3.14 & 0.90 & 0.3533 \\
  VEC2e & 1 & 0.63 & 0.63 & 0.18 & 0.6758 \\
  Residuals & 20 & 69.64 & 3.48 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that =OMP= and  =VEC2= appear to be  significant, but none  within filtering
threshold. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:18 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 0.7130 & 3.3215 & 0.21 & 0.8371 \\
  I(T1\_Ie\verb|^|2) & 1.3356 & 1.6327 & 0.82 & 0.4446 \\
  I(T1\_Je\verb|^|2) & 0.5249 & 1.5495 & 0.34 & 0.7463 \\
  I(T2\_Ie\verb|^|2) & 0.8102 & 1.7446 & 0.46 & 0.6587 \\
  I(T2\_Je\verb|^|2) & 0.9339 & 1.6036 & 0.58 & 0.5815 \\
  I(U1\_Ie\verb|^|2) & -0.8610 & 1.6098 & -0.53 & 0.6120 \\
  I(U\_Ie\verb|^|2) & -0.3170 & 1.6663 & -0.19 & 0.8554 \\
  I(U\_Je\verb|^|2) & -0.2912 & 1.9952 & -0.15 & 0.8887 \\
  I(RT\_Ie\verb|^|2) & 1.7247 & 1.8927 & 0.91 & 0.3973 \\
  I(RT\_Je\verb|^|2) & 2.3937 & 1.9275 & 1.24 & 0.2606 \\
  T1\_Ie & 1.4526 & 0.9706 & 1.50 & 0.1851 \\
  T1\_Je & -1.2926 & 1.0546 & -1.23 & 0.2662 \\
  T2\_Ie & 0.5029 & 0.9618 & 0.52 & 0.6198 \\
  T2\_Je & -0.3537 & 0.8138 & -0.43 & 0.6790 \\
  U1\_Ie & -0.3135 & 0.7890 & -0.40 & 0.7049 \\
  U\_Ie & 0.9988 & 0.9220 & 1.08 & 0.3203 \\
  U\_Je & 1.3131 & 1.1489 & 1.14 & 0.2966 \\
  RT\_Ie & 0.5144 & 1.2978 & 0.40 & 0.7055 \\
  RT\_Je & 1.2674 & 1.1140 & 1.14 & 0.2986 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

******** Third Step:                                        :noexport:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 3 &
                                   correct_result == "True")

p14_step3 <- subset(p14_designs, step == step)
p14_step3$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step3$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below is the =aov= summary using the formula from step 1, at =parasilo-14=:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(step_formula, data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:37 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.44 & 0.44 & 0.16 & 0.6935 \\
  I(T1\_Je\verb|^|2) & 1 & 8.21 & 8.21 & 2.92 & 0.0915 \\
  I(T2\_Ie\verb|^|2) & 1 & 0.27 & 0.27 & 0.09 & 0.7594 \\
  I(T2\_Je\verb|^|2) & 1 & 2.33 & 2.33 & 0.83 & 0.3656 \\
  I(U1\_Ie\verb|^|2) & 1 & 0.08 & 0.08 & 0.03 & 0.8631 \\
  I(U\_Ie\verb|^|2) & 1 & 8.76 & 8.76 & 3.11 & 0.0815 \\
  I(U\_Je\verb|^|2) & 1 & 1.91 & 1.91 & 0.68 & 0.4120 \\
  I(RT\_Ie\verb|^|2) & 1 & 0.76 & 0.76 & 0.27 & 0.6056 \\
  I(RT\_Je\verb|^|2) & 1 & 0.60 & 0.60 & 0.21 & 0.6462 \\
  T1\_Ie & 1 & 0.15 & 0.15 & 0.05 & 0.8201 \\
  T1\_Je & 1 & 2.10 & 2.10 & 0.75 & 0.3900 \\
  T2\_Ie & 1 & 3.09 & 3.09 & 1.10 & 0.2975 \\
  T2\_Je & 1 & 3.37 & 3.37 & 1.20 & 0.2771 \\
  U1\_Ie & 1 & 4.70 & 4.70 & 1.67 & 0.1999 \\
  U\_Ie & 1 & 4.40 & 4.40 & 1.56 & 0.2150 \\
  U\_Je & 1 & 1.34 & 1.34 & 0.47 & 0.4930 \\
  RT\_Ie & 1 & 0.27 & 0.27 & 0.09 & 0.7597 \\
  RT\_Je & 1 & 0.00 & 0.00 & 0.00 & 0.9859 \\
  SCRe & 1 & 4.27 & 4.27 & 1.52 & 0.2217 \\
  VEC1e & 1 & 2.81 & 2.81 & 1.00 & 0.3206 \\
  VEC2e & 1 & 14.00 & 14.00 & 4.97 & 0.0285 \\
  OMPe & 1 & 0.00 & 0.00 & 0.00 & 0.9945 \\
  Residuals & 81 & 228.03 & 2.82 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the =lm= summary:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:49 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 2.0901 & 1.0424 & 2.01 & 0.0483 \\
  I(T1\_Ie\verb|^|2) & 0.2033 & 0.4877 & 0.42 & 0.6779 \\
  I(T1\_Je\verb|^|2) & 0.5684 & 0.4720 & 1.20 & 0.2320 \\
  I(T2\_Ie\verb|^|2) & 0.3079 & 0.5326 & 0.58 & 0.5649 \\
  I(T2\_Je\verb|^|2) & -0.6988 & 0.5206 & -1.34 & 0.1833 \\
  I(U1\_Ie\verb|^|2) & 0.0450 & 0.4556 & 0.10 & 0.9216 \\
  I(U\_Ie\verb|^|2) & 0.1611 & 0.5254 & 0.31 & 0.7599 \\
  I(U\_Je\verb|^|2) & -0.2009 & 0.5551 & -0.36 & 0.7183 \\
  I(RT\_Ie\verb|^|2) & -0.2769 & 0.5636 & -0.49 & 0.6245 \\
  I(RT\_Je\verb|^|2) & -0.0111 & 0.5453 & -0.02 & 0.9838 \\
  T1\_Ie & 0.0966 & 0.2955 & 0.33 & 0.7446 \\
  T1\_Je & -0.1229 & 0.3069 & -0.40 & 0.6900 \\
  T2\_Ie & 0.1918 & 0.2483 & 0.77 & 0.4422 \\
  T2\_Je & -0.2739 & 0.2579 & -1.06 & 0.2913 \\
  U1\_Ie & 0.3403 & 0.2506 & 1.36 & 0.1783 \\
  U\_Ie & -0.3597 & 0.3078 & -1.17 & 0.2460 \\
  U\_Je & 0.2037 & 0.3048 & 0.67 & 0.5059 \\
  RT\_Ie & -0.0513 & 0.3739 & -0.14 & 0.8913 \\
  RT\_Je & 0.1400 & 0.3690 & 0.38 & 0.7053 \\
  SCRe & -0.3981 & 0.3432 & -1.16 & 0.2495 \\
  VEC1e & -0.2706 & 0.3425 & -0.79 & 0.4319 \\
  VEC2e & 0.7631 & 0.3438 & 2.22 & 0.0293 \\
  OMPe & -0.0023 & 0.3377 & -0.01 & 0.9945 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Now, let's run =aov= again, using only binary factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:48:17 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 0.58 & 0.58 & 0.21 & 0.6482 \\
  SCRe & 1 & 3.32 & 3.32 & 1.20 & 0.2758 \\
  VEC1e & 1 & 2.63 & 2.63 & 0.95 & 0.3320 \\
  VEC2e & 1 & 11.25 & 11.25 & 4.06 & 0.0466 \\
  Residuals & 99 & 274.11 & 2.77 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that =VEC2= appear to be  significant, but not  within filtering
threshold. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:48:15 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 1.8998 & 0.9851 & 1.93 & 0.0571 \\
  I(T1\_Ie\verb|^|2) & 0.3154 & 0.4957 & 0.64 & 0.5264 \\
  I(T1\_Je\verb|^|2) & 0.5832 & 0.4810 & 1.21 & 0.2287 \\
  I(T2\_Ie\verb|^|2) & 0.3367 & 0.5397 & 0.62 & 0.5343 \\
  I(T2\_Je\verb|^|2) & -0.5854 & 0.5283 & -1.11 & 0.2709 \\
  I(U1\_Ie\verb|^|2) & 0.1221 & 0.4630 & 0.26 & 0.7926 \\
  I(U\_Ie\verb|^|2) & 0.1803 & 0.5352 & 0.34 & 0.7371 \\
  I(U\_Je\verb|^|2) & -0.1887 & 0.5649 & -0.33 & 0.7392 \\
  I(RT\_Ie\verb|^|2) & -0.3288 & 0.5693 & -0.58 & 0.5650 \\
  I(RT\_Je\verb|^|2) & -0.0976 & 0.5542 & -0.18 & 0.8606 \\
  T1\_Ie & 0.0194 & 0.2963 & 0.07 & 0.9480 \\
  T1\_Je & -0.1595 & 0.3123 & -0.51 & 0.6108 \\
  T2\_Ie & 0.2132 & 0.2504 & 0.85 & 0.3971 \\
  T2\_Je & -0.3121 & 0.2623 & -1.19 & 0.2374 \\
  U1\_Ie & 0.3361 & 0.2550 & 1.32 & 0.1910 \\
  U\_Ie & -0.2641 & 0.3112 & -0.85 & 0.3984 \\
  U\_Je & 0.2105 & 0.3107 & 0.68 & 0.5000 \\
  RT\_Ie & -0.1031 & 0.3808 & -0.27 & 0.7873 \\
  RT\_Je & 0.0064 & 0.3704 & 0.02 & 0.9861 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
Figure\nbsp{}[[fig:nc-predicted-best]] compares  the performance  /predicted by  the fitted
model/, represented  by the green  line, with the  performance of /the  best point
found at each design/, represented by the  blue line. The red line marks the best
point found so far.

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

It  is only  at the  fourth step  of /parasilo-17/  that the  point with  the best
predicted performance  was better  than the  best point on  the design  for that
step, while also being better than the best point found so far. Although we seem
to be  effectively restricting the search  space with our exploration,  which is
evidenced  by the  improvement that  occurs as  steps progress  and by  the best
points being found inside designs, the  models fit using experiment data are not
able to improve the current best on the majority of cases.

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Fixing Binary Factors                                    :noexport:
****** Loading Data                                           :noexport:
******* Loading Data for Eliminated Factors                  :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/no_binary"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	54 obs. of  3 variables:
 $ removed_variables: Factor w/ 7 levels "","I(T1_I^2)",..: 1 4 2 1 3 1 1 2 3 7 ...
 $ step             : int  1 2 2 3 4 1 2 3 4 4 ...
 $ experiment_id    : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...

'data.frame':	396 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->2048" "T1_J->1024" "U_J->1" "U_I->8" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
 $ experiment_id          : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
#+end_example

******* Loading Data for Histograms and Iterations           :noexport:
#+HEADER: :results output :session *R*
#+BEGIN_SRC R
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)
#+END_SRC

#+RESULTS:
#+begin_example

'data.frame':	1286 obs. of  27 variables:
 $ id                          : int  2 3 4 5 6 7 8 9 10 11 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  2048 8 8 2048 1024 1 1 1 2048 2 ...
 $ T1_J                        : int  4 512 1 128 1 2048 16 1 16 1 ...
 $ cost_mean                   : num  0.747 0.916 0.83 0.642 0.68 ...
 $ U_J                         : int  27 10 1 1 1 18 30 20 8 1 ...
 $ U_I                         : int  1 1 20 27 2 1 1 1 1 30 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 8 128 2048 2048 2048 16 16 1 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 1 8 256 256 1 1 256 16 2048 ...
 $ U1_I                        : int  29 5 12 10 12 8 19 24 21 2 ...
 $ mean_confidence_interval_inf: num  0.607 0.904 0.774 0.492 0.525 ...
 $ mean_confidence_interval_sup: num  0.886 0.928 0.885 0.793 0.834 ...
 $ cost_std                    : num  0.2251 0.0194 0.089 0.2431 0.2487 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 1 32 16 2 8 32 32 16 1 ...
 $ RT_J                        : int  4 32 4 2 32 16 2 1 1 32 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
 $ cost_baseline               : num  0.869 0.869 0.869 0.869 0.869 ...
 $ speedup                     : num  1.163 0.948 1.047 1.353 1.278 ...
 $ max_run_speedup             : num  1.9 1.9 1.9 1.9 1.9 ...
 $ min_run_cost                : num  0.456 0.456 0.456 0.456 0.456 ...
 $ best_iteration              : num  90 90 90 90 90 90 90 90 90 90 ...
 $ points                      : int  115 115 115 115 115 115 115 115 115 115 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	11 obs. of  30 variables:
 $ id                          : int  90 29 94 40 37 46 65 22 109 49 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  2048 128 2048 2048 64 2048 32 1 2048 2048 ...
 $ T1_J                        : int  8 2 256 64 256 1 256 128 512 2048 ...
 $ cost_mean                   : num  0.456 0.442 0.445 0.536 0.553 ...
 $ U_J                         : int  1 1 1 1 1 30 1 21 13 1 ...
 $ U_I                         : int  1 21 23 19 9 1 30 1 1 12 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  2048 2048 2048 2048 2048 2048 2048 2048 2048 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  8 1 2048 2048 1 1 256 128 512 2048 ...
 $ U1_I                        : int  13 25 13 1 22 22 22 12 8 2 ...
 $ mean_confidence_interval_inf: num  0.437 0.436 0.425 0.401 0.43 ...
 $ mean_confidence_interval_sup: num  0.476 0.448 0.464 0.67 0.676 ...
 $ cost_std                    : num  0.03137 0.00994 0.03109 0.21718 0.19865 ...
 $ step                        : int  3 1 3 2 2 2 2 1 4 2 ...
 $ RT_I                        : int  2 4 4 8 8 8 4 16 4 8 ...
 $ RT_J                        : int  32 32 8 16 2 4 2 2 16 1 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-10" "parasilo-12" "parasilo-13" ...
 $ cost_baseline               : num  0.869 0.872 0.871 0.871 0.879 ...
 $ speedup                     : num  1.9 1.97 1.96 1.63 1.59 ...
 $ max_run_speedup             : num  1.9 1.97 1.96 1.63 1.59 ...
 $ min_run_cost                : num  0.456 0.442 0.445 0.536 0.553 ...
 $ best_iteration              : num  90 29 94 40 37 46 65 22 109 49 ...
 $ points                      : int  115 126 120 125 115 110 116 129 126 103 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  0.874 0.874 0.874 0.874 0.874 ...
 $ label_center_x              : num  0.729 0.729 0.729 0.729 0.729 ...
 $ label_center_y              : num  59.3 59.3 59.3 59.3 59.3 ...
#+end_example

#+HEADER: :results output :session *R*
#+BEGIN_SRC R
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

str(complete_plot_data)

data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        #target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  mutate(technique = "RS_no_bin") %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)
#+END_SRC

#+RESULTS:
#+begin_example

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	11 obs. of  30 variables:
 $ id                          : int  90 29 94 40 37 46 65 22 109 49 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  2048 128 2048 2048 64 2048 32 1 2048 2048 ...
 $ T1_J                        : int  8 2 256 64 256 1 256 128 512 2048 ...
 $ cost_mean                   : num  0.456 0.442 0.445 0.536 0.553 ...
 $ U_J                         : int  1 1 1 1 1 30 1 21 13 1 ...
 $ U_I                         : int  1 21 23 19 9 1 30 1 1 12 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  2048 2048 2048 2048 2048 2048 2048 2048 2048 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  8 1 2048 2048 1 1 256 128 512 2048 ...
 $ U1_I                        : int  13 25 13 1 22 22 22 12 8 2 ...
 $ mean_confidence_interval_inf: num  0.437 0.436 0.425 0.401 0.43 ...
 $ mean_confidence_interval_sup: num  0.476 0.448 0.464 0.67 0.676 ...
 $ cost_std                    : num  0.03137 0.00994 0.03109 0.21718 0.19865 ...
 $ step                        : int  3 1 3 2 2 2 2 1 4 2 ...
 $ RT_I                        : int  2 4 4 8 8 8 4 16 4 8 ...
 $ RT_J                        : int  32 32 8 16 2 4 2 2 16 1 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-10" "parasilo-12" "parasilo-13" ...
 $ cost_baseline               : num  0.869 0.872 0.871 0.871 0.879 ...
 $ speedup                     : num  1.9 1.97 1.96 1.63 1.59 ...
 $ max_run_speedup             : num  1.9 1.97 1.96 1.63 1.59 ...
 $ min_run_cost                : num  0.456 0.442 0.445 0.536 0.553 ...
 $ best_iteration              : num  90 29 94 40 37 46 65 22 109 49 ...
 $ points                      : int  115 126 120 125 115 110 116 129 126 103 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  0.874 0.874 0.874 0.874 0.874 ...
 $ label_center_x              : num  0.729 0.729 0.729 0.729 0.729 ...
 $ label_center_y              : num  59.3 59.3 59.3 59.3 59.3 ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	22 obs. of  30 variables:
 $ id                          : int  90 29 94 40 37 46 65 22 109 49 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  2048 128 2048 2048 64 2048 32 1 2048 2048 ...
 $ T1_J                        : int  8 2 256 64 256 1 256 128 512 2048 ...
 $ cost_mean                   : num  0.456 0.442 0.445 0.536 0.553 ...
 $ U_J                         : int  1 1 1 1 1 30 1 21 13 1 ...
 $ U_I                         : int  1 21 23 19 9 1 30 1 1 12 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  2048 2048 2048 2048 2048 2048 2048 2048 2048 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  8 1 2048 2048 1 1 256 128 512 2048 ...
 $ U1_I                        : int  13 25 13 1 22 22 22 12 8 2 ...
 $ mean_confidence_interval_inf: num  0.437 0.436 0.425 0.401 0.43 ...
 $ mean_confidence_interval_sup: num  0.476 0.448 0.464 0.67 0.676 ...
 $ cost_std                    : num  0.03137 0.00994 0.03109 0.21718 0.19865 ...
 $ step                        : int  3 1 3 2 2 2 2 1 4 2 ...
 $ RT_I                        : int  2 4 4 8 8 8 4 16 4 8 ...
 $ RT_J                        : int  32 32 8 16 2 4 2 2 16 1 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-10" "parasilo-12" "parasilo-13" ...
 $ cost_baseline               : num  0.869 0.872 0.871 0.871 0.879 ...
 $ speedup                     : num  1.9 1.97 1.96 1.63 1.59 ...
 $ max_run_speedup             : num  1.9 1.97 1.96 1.63 1.59 ...
 $ min_run_cost                : num  0.456 0.442 0.445 0.536 0.553 ...
 $ best_iteration              : num  90 29 94 40 37 46 65 22 109 49 ...
 $ points                      : int  115 126 120 125 115 110 116 129 126 103 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  0.874 0.874 0.874 0.874 0.874 ...
 $ label_center_x              : num  0.729 0.729 0.729 0.729 0.729 ...
 $ label_center_y              : num  59.3 59.3 59.3 59.3 59.3 ...
#+end_example
******* Loading Data Step-by-step Plots                      :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	25 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 2 2 2 ...
 $ valid_configurations   : int  46080 46080 46080 46080 46080 46080 46080 46080 46080 46080 ...
 $ D                      : num  0.0862 0.0862 0.0866 0.0866 0.087 ...
 $ used_budget            : int  0 0 0 0 0 0 0 31 31 29 ...
 $ model_size             : int  27 27 27 27 27 27 27 27 27 27 ...
 $ current_best           : num  0.541 0.541 0.585 0.585 0.537 ...
 $ trials                 : int  32 32 32 32 32 32 32 32 32 32 ...
 $ current_best_coordinate: chr  "{'T1_I': 2048, 'T1_J': 64, 'U_J': 1, 'U_I': 2, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 24, 'RT_I': 8, 'RT_J': 1}" "{'T1_I': 2048, 'T1_J': 64, 'U_J': 1, 'U_I': 2, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 24, 'RT_I': 8, 'RT_J': 1}" "{'T1_I': 64, 'T1_J': 1, 'U_J': 1, 'U_I': 6, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 19, 'RT_I': 1, 'RT_J': 32}" "{'T1_I': 64, 'T1_J': 1, 'U_J': 1, 'U_I': 6, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 19, 'RT_I': 1, 'RT_J': 32}" ...
 $ tested_configurations  : int  2211505 2211505 2217801 2217801 2203665 2203665 2203665 2222185 2222185 2207980 ...
 $ fixed_factors          : chr  "{'T2_I': 11, 'T1_I': 11}" "{'T2_I': 11, 'T1_I': 11}" "{'T2_I': 11, 'T1_I': 11}" "{'T2_I': 11, 'T1_I': 11}" ...
 $ step                   : int  1 1 1 1 1 1 1 2 2 2 ...
 $ design_best            : num  0.541 0.541 0.585 0.585 0.537 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "I(T1_I^2)" "I(T2_I^2)" "I(T2_I^2)" "I(T1_I^2)" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  0.709 0.709 0.597 0.597 0.552 ...
 $ experiment_id          : chr  "parasilo-21" "parasilo-21" "parasilo-25" "parasilo-25" ...

'data.frame':	1328 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  1 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 2048 8 8 2048 1024 1 1 1 2048 ...
 $ T1_J                        : int  256 4 512 1 128 1 2048 16 1 16 ...
 $ cost_mean                   : num  Inf 0.747 0.916 0.83 0.642 ...
 $ U_J                         : int  1 27 10 1 1 1 18 30 20 8 ...
 $ U_I                         : int  17 1 1 20 27 2 1 1 1 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 1 8 128 2048 2048 2048 16 16 1 ...
 $ correct_result              : chr  "False" "True" "True" "True" ...
 $ T2_J                        : int  2048 2048 1 8 256 256 1 1 256 16 ...
 $ U1_I                        : int  21 29 5 12 10 12 8 19 24 21 ...
 $ mean_confidence_interval_inf: num  Inf 0.607 0.904 0.774 0.492 ...
 $ mean_confidence_interval_sup: num  Inf 0.886 0.928 0.885 0.793 ...
 $ cost_std                    : num  Inf 0.2251 0.0194 0.089 0.2431 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  4 1 1 32 16 2 8 32 32 16 ...
 $ RT_J                        : int  32 4 32 4 2 32 16 2 1 1 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
#+end_example

******* Loading Data for D-Optimality and ANOVA              :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

There were 44 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	1103 obs. of  4 variables:
 $ metric_value: num  0.0141 0.046 0.0596 0.0544 0.0651 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
Since =OMP= was  quickly fixed at most iterations of  the previous experiment, and
had the largest  impact on performance we  could observe, we decided  to fix it,
along with  all other  binary parameters.

In the experiments shown on this section, all binary parameters are turned on by
default,     including      on     the     random      sampling     experiments.
Figure\nbsp[[fig:nobin-best-found]] shows the iterations where the best configuration of
each of the 10 runs was found, for uniform sampling and for our approach. We see
that random  sampling found an extremely  fast point right at  the second tested
configuration.

#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(subset(it_data, technique == "DLMT")$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:nobin-best-found
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-H9uPID/figureAG21QL.pdf]]

#+begin_SRC R :results output latex :session *R* :exports none
library(stargazer)

stargazer(select(complete_plot_data, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:

#+begin_export latex
\begin{table}[!htbp] \centering
\scriptsize
  \caption{Parameters of the best points at each run. Rows with the best points for each technique overall are highlighted}
  \label{}
\begin{tabular}{llccccccccc}
\hline \\[-1.8ex]
technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
DLMT & 0.4563346 & 2048 & 8 & 1 & 1 & 2048 & 8 & 13 & 2 & 32 \\
DLMT & 0.4423092 & 128 & 2 & 1 & 21 & 2048 & 1 & 25 & 4 & 32 \\
DLMT & 0.4447055 & 2048 & 256 & 1 & 23 & 2048 & 2048 & 13 & 4 & 8 \\
DLMT & 0.5356327 & 2048 & 64 & 1 & 19 & 2048 & 2048 & 1 & 8 & 16 \\
DLMT & 0.5531261 & 64 & 256 & 1 & 9 & 2048 & 1 & 22 & 8 & 2 \\
DLMT & 0.5218018 & 2048 & 1 & 30 & 1 & 2048 & 1 & 22 & 8 & 4 \\
\rowcolor[HTML]{ACACAC}
DLMT & 0.4351629 & 32 & 256 & 1 & 30 & 2048 & 256 & 22 & 4 & 2 \\
DLMT & 0.4904546 & 1 & 128 & 21 & 1 & 2048 & 128 & 12 & 16 & 2 \\
DLMT & 0.4530676 & 2048 & 512 & 13 & 1 & 2048 & 512 & 8 & 4 & 16 \\
DLMT & 0.4752536 & 2048 & 2048 & 1 & 12 & 2048 & 2048 & 2 & 8 & 1 \\
DLMT & 0.4931927 & 2048 & 1 & 1 & 11 & 2048 & 1 & 1 & 1 & 32 \\
RS & 0.4646119 & 2048 & 64 & 1 & 14 & 2048 & 1 & 20 & 8 & 2 \\
RS & 0.5190496 & 64 & 512 & 1 & 24 & 2048 & 2048 & 6 & 8 & 16 \\
RS & 0.4359155 & 8 & 1 & 29 & 1 & 2048 & 128 & 27 & 8 & 4 \\
RS & 0.4363163 & 512 & 4 & 16 & 1 & 2048 & 128 & 12 & 4 & 2 \\
RS & 0.445589 & 1024 & 16 & 1 & 10 & 2048 & 128 & 16 & 8 & 16 \\
RS & 0.48685 & 8 & 128 & 3 & 1 & 2048 & 1 & 11 & 8 & 2 \\
RS & 0.5267321 & 2048 & 64 & 1 & 6 & 2048 & 1 & 9 & 4 & 16 \\
\rowcolor[HTML]{ACACAC}
RS & 0.4064384 & 256 & 8 & 22 & 1 & 512 & 128 & 15 & 4 & 32 \\
RS & 0.5288379 & 2048 & 8 & 1 & 25 & 2048 & 2048 & 15 & 8 & 2 \\
RS & 0.4439861 & 8 & 32 & 1 & 12 & 2048 & 32 & 25 & 4 & 16 \\
RS & 0.4639212 & 256 & 1 & 1 & 14 & 2048 & 256 & 21 & 2 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
Even after  fixing binary parameters,  or maybe  because of it,  some parameters
were still identified as significant and  fixed. The =T1_I= parameter was only the
fixed at two  iterations on the previous  experiment, but it was  the most fixed
parameter in this one, surpassing =RT_I=,  which was frequently eliminated in both
experiments.   This  suggests   that  fixing   binary  parameters   allowed  the
significance of the other parameters to be detected.

#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-ynhqKR/figure7r6W2z.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

It is  interesting that  only /parasilo-19/ and  /parasilo-9/ eliminated  any factor
other than =OMP=  and =SCR= on the  first step where any factor  was eliminated, and
also that those  runs eliminated the same  factor =RT_I=.  We will  see later that
=OMP= and  =SCR= were fixed to  the same values  in all experiments where  they were
eliminated, and =RT_I=  was only fixed to  a different value on  2 eliminations on
the fourth step.

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Searched Spaces                                        :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.6) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figuregu9cI1.pdf]]

****** Fixed Factors & Values in the Explored Spaces
We see that /parasilo-13/ and /parasilo-23/ did not eliminate any parameters after 4
steps.   We also  see that,  at /parasilo-12/,  /parasilo-20/, and  /parasilo-25/, for
example,  the  search space  seems  to  be restricted  to  a  region with  worse
performance than in the previous steps of the same experiment. This could be due
to the fact that these experiments fixed  the =RT_I= parameter to its fifth level.
A  slight improvement  of the  configurations tested  can be  seen at  the other
experiments, where other factors were fixed.

Identifying when  a restriction of  the search space  to a worse  region happens
would be  useful if we could  revert or re-do  an optimization step. This  is an
interesting  motivation for  keeping a  human on  the loop  of the  optimization
process.

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:nb-ss-ef
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-elHoq9/figure8UQjkW.png]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-fixedbin
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figuremYRSBQ.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "parasilo-21"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "parasilo-21"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{parasilo-21}
#+LABEL: fig:lm-rs-nobin-p14
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureaYZZxh.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-dlmt-fixedbin
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure98HYKr.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "parasilo-23"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "parasilo-23"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs, for \texttt{parasilo-23}
#+LABEL: fig:lm-rs-nobin-p54
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurer5tVWU.pdf]]
****** D-Optimality
******* Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:pf-bp-ss
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

****** D_A-Optimality at Each Step                             :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Reuse Data for =aov= and =lm=                                :noexport:
Significant  changes were  performed  on the  initial  DLMT implementation.   We
decided  that there  was no  good reason  to not  reuse the  data obtained  from
evaluating designs  at each step,  and the various  samples of the  search space
taken  at different  points. Now,  all  evaluated experiments  compose a  single
growing design used  by =aov= to identify  the best factors, and  all samples from
the  search  space compose  a  single  data set  used  by  =optFederov= to  select
experiments. The data  set is pruned in  both =aov= and =lm=  analyses, to guarantee
only experiments  with the  correct levels  of fixed factors  are used.  This is
crucial for both  analyses, since having different fixed values  of factors that
are not in the model would imply that we would have inexplicable variance in the
data set.

Using all experimental data on =aov= is  interesting because it is always worth it
to  consider additional  information on  the  factors that  are currently  being
studied.  On  one hand, it  might not allow  for enough ``flexibility''  when we
consider regression only on a  small restricted subspace, because points outside
the  subspace  would impact  regression,  and  we  would  be interested  in  the
significance of the factor inside the subspace at the moment. On the other hand,
using all data available makes sense because we are also interested in exploring
any  global structures  of  the  search space,  and  keeping  points from  other
subspaces would increase the chance of ``catching'' the significance of a factor
globally.

Using all sampled space, across all steps,  as a candidate for =optFederov= has no
downsides, provided we prune the search space to account for current constraints
on factor levels fixed on previous steps.  We increase the size of the available
set of configurations  that can compose a  new design each time we  sample a new
subspace. This  would hopefully improve  the quality  of designs produced  as we
progress.

****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/reuse_prune_sample_data_dlmt"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/results"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][5], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	63 obs. of  3 variables:
 $ removed_variables: Factor w/ 13 levels "","I(RT_I^2)",..: 3 6 5 4 2 1 1 3 5 4 ...
 $ step             : int  1 2 2 2 2 3 4 1 1 2 ...
 $ experiment_id    : chr  "graoully-13" "graoully-13" "graoully-13" "graoully-13" ...

'data.frame':	416 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->512" "T1_J->1" "U_J->1" "U_I->10" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ experiment_id          : chr  "graoully-13" "graoully-13" "graoully-13" "graoully-13" ...

'data.frame':	826 obs. of  31 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  1 1 64 32 128 1 32 1024 32 2048 ...
 $ T2_I                        : int  128 1 2048 32 2048 2048 256 1 2048 128 ...
 $ RT_I                        : int  2 1 4 1 32 1 4 4 4 1 ...
 $ mean_confidence_interval_inf: num  0.876 4.085 4.485 0.685 0.501 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  2048 128 64 32 1 1024 16 64 32 512 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "False" "True" "False" ...
 $ VEC1                        : chr  "True" "False" "True" "True" ...
 $ SCR                         : chr  "False" "False" "False" "True" ...
 $ U1_I                        : int  30 10 3 1 21 29 30 22 12 24 ...
 $ RT_J                        : int  32 8 1 8 2 8 8 8 32 1 ...
 $ T1_I                        : int  64 256 1 32 1 256 1 64 32 64 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.03081 0.00115 0.00054 0.14549 0.22866 ...
 $ cost_mean                   : num  0.895 4.086 4.486 0.775 0.643 ...
 $ U_J                         : int  1 1 1 2 1 1 30 30 1 1 ...
 $ U_I                         : int  19 15 14 1 24 30 1 1 29 1 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "False" "False" "True" ...
 $ mean_confidence_interval_sup: num  0.914 4.086 4.486 0.865 0.785 ...
 $ experiment_id               : chr  "graoully-13" "graoully-13" "graoully-13" "graoully-13" ...
 $ cost_baseline               : num  5.78 5.78 5.78 5.78 5.78 ...
 $ speedup                     : num  6.46 1.41 1.29 7.46 8.99 ...
 $ max_run_speedup             : num  9.5 9.5 9.5 9.5 9.5 ...
 $ min_run_cost                : num  0.608 0.608 0.608 0.608 0.608 ...
 $ best_iteration              : num  20 20 20 20 20 20 20 20 20 20 ...
 $ points                      : int  81 81 81 81 81 81 81 81 81 81 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	10 obs. of  34 variables:
 $ id                          : int  20 48 24 34 36 78 39 39 96 58
 $ T2_J                        : int  2048 1 1024 2048 1 2048 256 2048 1 2048
 $ T2_I                        : int  2048 2048 1 1 2048 2048 2048 2048 1 2048
 $ RT_I                        : int  8 2 8 4 2 2 8 4 4 4
 $ mean_confidence_interval_inf: num  0.449 0.425 0.431 0.457 0.42 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  1 16 512 2048 32 2048 32 2048 2 2048
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "True" "False" "True" ...
 $ VEC1                        : chr  "False" "False" "False" "True" ...
 $ SCR                         : chr  "True" "True" "True" "True" ...
 $ U1_I                        : int  2 1 5 30 8 13 16 1 30 1
 $ RT_J                        : int  2 32 8 4 4 4 1 8 4 4
 $ T1_I                        : int  512 512 2048 2048 16 1024 2048 64 2048 2048
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10
 $ cost_std                    : num  0.2572 0.187 0.2233 0.0966 0.2663 ...
 $ cost_mean                   : num  0.608 0.541 0.569 0.516 0.585 ...
 $ U_J                         : int  1 1 1 1 1 30 1 1 1 1
 $ U_I                         : int  10 21 1 28 30 1 3 18 2 11
 $ step                        : int  1 2 1 2 2 4 2 2 4 3
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.768 0.657 0.708 0.576 0.75 ...
 $ experiment_id               : chr  "graoully-13" "graoully-15" "graoully-16" "graoully-3" ...
 $ cost_baseline               : num  5.78 5.78 5.79 5.78 5.78 ...
 $ speedup                     : num  9.5 10.68 10.16 11.19 9.89 ...
 $ max_run_speedup             : num  9.5 10.68 10.16 11.19 9.89 ...
 $ min_run_cost                : num  0.608 0.541 0.569 0.516 0.585 ...
 $ best_iteration              : num  20 48 24 34 36 78 39 39 96 58
 $ points                      : int  81 90 81 63 95 90 89 48 97 92
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  5.79 5.79 5.79 5.79 5.79 ...
 $ label_center_x              : num  1.36 1.36 1.36 1.36 1.36 ...
 $ label_center_y              : num  49 49 49 49 49 ...

[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-50_1537463780/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-50_1537466671/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-51_1537463771/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-51_1537466499/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-52_1537463781/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-52_1537466679/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-53_1537463765/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-53_1537466910/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-54_1537463776/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-54_1537467091/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-55_1537463780/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-55_1537466511/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-56_1537463776/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-56_1537467164/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-57_1537463776/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-57_1537466531/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-58_1537463762/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-58_1537467080/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-59_1537463775/search_space.csv"
[1] "dlmt_spapt_experiments/data/results/bicgkernel/xeon_e5_2630_v3_paravance-59_1537466644/search_space.csv"

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	20 obs. of  34 variables:
 $ id                          : int  20 48 24 34 36 78 39 39 96 58 ...
 $ T2_J                        : int  2048 1 1024 2048 1 2048 256 2048 1 2048 ...
 $ T2_I                        : int  2048 2048 1 1 2048 2048 2048 2048 1 2048 ...
 $ RT_I                        : int  8 2 8 4 2 2 8 4 4 4 ...
 $ mean_confidence_interval_inf: num  0.449 0.425 0.431 0.457 0.42 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  1 16 512 2048 32 2048 32 2048 2 2048 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "True" "False" "True" ...
 $ VEC1                        : chr  "False" "False" "False" "True" ...
 $ SCR                         : chr  "True" "True" "True" "True" ...
 $ U1_I                        : int  2 1 5 30 8 13 16 1 30 1 ...
 $ RT_J                        : int  2 32 8 4 4 4 1 8 4 4 ...
 $ T1_I                        : int  512 512 2048 2048 16 1024 2048 64 2048 2048 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.2572 0.187 0.2233 0.0966 0.2663 ...
 $ cost_mean                   : num  0.608 0.541 0.569 0.516 0.585 ...
 $ U_J                         : int  1 1 1 1 1 30 1 1 1 1 ...
 $ U_I                         : int  10 21 1 28 30 1 3 18 2 11 ...
 $ step                        : int  1 2 1 2 2 4 2 2 4 3 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.768 0.657 0.708 0.576 0.75 ...
 $ experiment_id               : chr  "graoully-13" "graoully-15" "graoully-16" "graoully-3" ...
 $ cost_baseline               : num  5.78 5.78 5.79 5.78 5.78 ...
 $ speedup                     : num  9.5 10.68 10.16 11.19 9.89 ...
 $ max_run_speedup             : num  9.5 10.68 10.16 11.19 9.89 ...
 $ min_run_cost                : num  0.608 0.541 0.569 0.516 0.585 ...
 $ best_iteration              : num  20 48 24 34 36 78 39 39 96 58 ...
 $ points                      : int  81 90 81 63 95 90 89 48 97 92 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  5.79 5.79 5.79 5.79 5.79 ...
 $ label_center_x              : num  1.36 1.36 1.36 1.36 1.36 ...
 $ label_center_y              : num  49 49 49 49 49 ...

'data.frame':	51 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ valid_configurations   : int  62400 62400 62400 62400 62400 62400 62400 62400 62400 62400 ...
 $ D                      : num  0.206 0.205 0.205 0.207 0.207 ...
 $ used_budget            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ model_size             : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best           : num  0.608 0.558 0.558 0.578 0.578 ...
 $ trials                 : int  26 26 26 26 26 26 26 26 26 26 ...
 $ current_best_coordinate: chr  "{'T1_I': 512, 'T1_J': 1, 'U_J': 1, 'U_I': 10, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 2, 'OMP': True, 'VEC2': False"| __truncated__ "{'T1_I': 16, 'T1_J': 64, 'U_J': 1, 'U_I': 14, 'T2_I': 2048, 'T2_J': 1024, 'U1_I': 1, 'OMP': True, 'VEC2': False"| __truncated__ "{'T1_I': 16, 'T1_J': 64, 'U_J': 1, 'U_I': 14, 'T2_I': 2048, 'T2_J': 1024, 'U1_I': 1, 'OMP': True, 'VEC2': False"| __truncated__ "{'T1_I': 2, 'T1_J': 16, 'U_J': 28, 'U_I': 1, 'T2_I': 2048, 'T2_J': 16, 'U1_I': 1, 'OMP': True, 'VEC2': True, 'V"| __truncated__ ...
 $ tested_configurations  : int  2988973 2985943 2985943 2973220 2973220 2973220 2973220 2973220 2973220 3015704 ...
 $ fixed_factors          : chr  "{'OMP': 1}" "{'OMP': 1, 'SCR': 1}" "{'OMP': 1, 'SCR': 1}" "{'T1_I': 11, 'T1_J': 11, 'U_I': 27, 'OMP': 1, 'VEC1': 1, 'SCR': 1}" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ design_best            : num  0.608 0.558 0.558 0.578 0.578 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "OMP" "OMP" "SCR" "SCR" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  0.823 0.816 0.816 0.608 0.608 ...
 $ experiment_id          : chr  "graoully-13" "graoully-15" "graoully-15" "graoully-3" ...

'data.frame':	872 obs. of  24 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  1 1 64 32 128 1 32 1024 32 2048 ...
 $ T2_I                        : int  128 1 2048 32 2048 2048 256 1 2048 128 ...
 $ RT_I                        : int  2 1 4 1 32 1 4 4 4 1 ...
 $ mean_confidence_interval_inf: num  0.876 4.085 4.485 0.685 0.501 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  2048 128 64 32 1 1024 16 64 32 512 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "False" "True" "False" ...
 $ VEC1                        : chr  "True" "False" "True" "True" ...
 $ SCR                         : chr  "False" "False" "False" "True" ...
 $ U1_I                        : int  30 10 3 1 21 29 30 22 12 24 ...
 $ RT_J                        : int  32 8 1 8 2 8 8 8 32 1 ...
 $ T1_I                        : int  64 256 1 32 1 256 1 64 32 64 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.03081 0.00115 0.00054 0.14549 0.22866 ...
 $ cost_mean                   : num  0.895 4.086 4.486 0.775 0.643 ...
 $ U_J                         : int  1 1 1 2 1 1 30 30 1 1 ...
 $ U_I                         : int  19 15 14 1 24 30 1 1 29 1 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "False" "False" "True" ...
 $ mean_confidence_interval_sup: num  0.914 4.086 4.486 0.865 0.785 ...
 $ experiment_id               : chr  "graoully-13" "graoully-13" "graoully-13" "graoully-13" ...

There were 39 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Error in solve.default((t(X) %*% X)/nrow(X)) :
  system is computationally singular: reciprocal condition number = 2.03271e-18

Error in str(design_data_plot) : object 'design_data_plot' not found
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-new
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureazAWUy.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 06:38:14 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}} cccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
graoully-13 & DLMT & 0.6084833 & 512 & 1 & 1 & 10 & 2048 & 2048 & 2 & 8 & 2 \\
graoully-15 & DLMT & 0.5412621 & 512 & 16 & 1 & 21 & 2048 & 1 & 1 & 2 & 32 \\
graoully-16 & DLMT & 0.5691611 & 2048 & 512 & 1 & 1 & 1 & 1024 & 5 & 8 & 8 \\
graoully-3 & DLMT & 0.5163602 & 2048 & 2048 & 1 & 28 & 1 & 2048 & 30 & 4 & 4 \\
graoully-4 & DLMT & 0.5845903 & 16 & 32 & 1 & 30 & 2048 & 1 & 8 & 2 & 4 \\
graoully-5 & DLMT & 0.4961376 & 1024 & 2048 & 30 & 1 & 2048 & 2048 & 13 & 2 & 4 \\
graoully-6 & DLMT & 0.5985619 & 2048 & 32 & 1 & 3 & 2048 & 256 & 16 & 8 & 1 \\
graoully-7 & DLMT & 0.5565135 & 64 & 2048 & 1 & 18 & 2048 & 2048 & 1 & 4 & 8 \\
graoully-8 & DLMT & 0.4646318 & 2048 & 2 & 1 & 2 & 1 & 1 & 30 & 4 & 4 \\
graoully-9 & DLMT & 0.5087977 & 2048 & 2048 & 1 & 11 & 2048 & 2048 & 1 & 4 & 4 \\
paravance-50 & RS & 0.5685274 & 512 & 512 & 19 & 1 & 2048 & 1024 & 27 & 4 & 1 \\
paravance-51 & RS & 0.5467725 & 1024 & 32 & 10 & 1 & 2048 & 512 & 9 & 8 & 8 \\
paravance-52 & RS & 0.5417953 & 2048 & 8 & 9 & 1 & 2048 & 128 & 30 & 8 & 16 \\
paravance-53 & RS & 0.5612387 & 2048 & 64 & 16 & 1 & 2048 & 256 & 9 & 16 & 2 \\
paravance-54 & RS & 0.5322531 & 2048 & 8 & 1 & 9 & 1 & 1 & 19 & 1 & 1 \\
paravance-55 & RS & 0.5540684 & 32 & 4 & 1 & 5 & 2048 & 256 & 4 & 16 & 1 \\
paravance-56 & RS & 0.4648199 & 2048 & 1 & 1 & 23 & 1 & 512 & 25 & 8 & 1 \\
paravance-57 & RS & 0.5463944 & 256 & 16 & 1 & 15 & 2048 & 512 & 2 & 2 & 2 \\
paravance-58 & RS & 0.5496127 & 32 & 1 & 1 & 14 & 2048 & 2048 & 24 & 8 & 4 \\
paravance-59 & RS & 0.4758884 & 64 & 16 & 29 & 1 & 2048 & 1 & 27 & 16 & 4 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-new
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figuresZzq4T.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-new
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figuregBzTsF.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I, OMP, SCR, VEC1, VEC2) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-new
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurezeShpG.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "graoully-16"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "graoully-16"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{graoully-16}
#+LABEL: fig:lm-rs-nobin-g16-new
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurev2Hjmx.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I, OMP, SCR, VEC1, VEC2) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-new
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure25V7aE.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-new
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurelZvmet.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-new
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureIgO4Cw.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Reuse Data for =aov= and =lm=: Binary set to =False=           :noexport:
This experiment  uses an initial model  with linear and quadratic  terms for all
factors.  All binary  parameters were  fixed to  its =False=  value.  We  hoped to
determine if the effects of binary factors, which are proportionally much larger
than the  effects of  the other  factors, were preventing  the detection  of the
significance of the other factors.

****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/updated_binfalse_dlmt"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    print(csv_file)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	73 obs. of  3 variables:
 $ removed_variables: Factor w/ 10 levels "","I(RT_I^2)",..: 1 2 2 4 3 1 1 4 2 5 ...
 $ step             : int  1 2 2 2 3 4 1 2 2 3 ...
 $ experiment_id    : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-11" ...

'data.frame':	360 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->512" "T1_J->512" "U_J->1" "U_I->15" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
 $ experiment_id          : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-11" ...

'data.frame':	832 obs. of  27 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1024 1 1 1 32 256 8 1 2048 2048 ...
 $ T1_J                        : int  1 128 16 2048 1 2048 32 1 128 2 ...
 $ cost_mean                   : num  4.58 3.58 6.21 3.68 3.34 ...
 $ U_J                         : int  14 22 15 1 12 1 30 30 1 2 ...
 $ U_I                         : int  1 1 1 29 1 1 1 1 30 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 32 32 2048 2048 256 1 256 2048 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  32 1 2048 1 128 1 128 1 1 512 ...
 $ U1_I                        : int  1 17 30 27 14 10 30 1 3 30 ...
 $ mean_confidence_interval_inf: num  4.58 3.58 6.21 3.66 3.34 ...
 $ mean_confidence_interval_sup: num  4.58 3.58 6.21 3.7 3.34 ...
 $ cost_std                    : num  0.000187 0.000144 0.000764 0.035888 0.000108 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 2 32 2 8 32 16 1 32 1 ...
 $ RT_J                        : int  1 1 4 16 8 1 1 16 2 32 ...
 $ experiment_id               : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-11" ...
 $ cost_baseline               : num  4.96 4.96 4.96 4.96 4.96 ...
 $ speedup                     : num  1.082 1.385 0.799 1.347 1.484 ...
 $ max_run_speedup             : num  1.56 1.56 1.56 1.56 1.56 ...
 $ min_run_cost                : num  3.18 3.18 3.18 3.18 3.18 ...
 $ best_iteration              : num  19 19 19 19 19 19 19 19 19 19 ...
 $ points                      : int  84 84 84 84 84 84 84 84 84 84 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	10 obs. of  30 variables:
 $ id                          : int  19 2 11 62 31 25 14 78 65 12
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  512 256 1 1 32 1 1 32 128 32
 $ T1_J                        : int  512 1 2 1 2048 1 2048 1 1 64
 $ cost_mean                   : num  3.18 3.2 3.05 3.18 3.15 ...
 $ U_J                         : int  1 1 1 1 1 1 1 1 1 1
 $ U_I                         : int  15 18 15 14 29 30 30 1 1 10
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  512 2048 1 128 2048 256 2048 2048 128 32
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  1 64 128 2048 2048 2048 2048 1 1 2048
 $ U1_I                        : int  30 30 21 30 2 1 30 14 28 1
 $ mean_confidence_interval_inf: num  3.18 3.2 3.05 3.18 3.15 ...
 $ mean_confidence_interval_sup: num  3.18 3.2 3.05 3.18 3.15 ...
 $ cost_std                    : num  1.30e-04 1.79e-04 1.71e-04 1.36e-04 9.59e-05 ...
 $ step                        : int  1 1 1 3 2 2 1 4 3 1
 $ RT_I                        : int  1 1 4 4 16 16 16 4 4 1
 $ RT_J                        : int  4 8 1 2 8 2 4 2 2 2
 $ experiment_id               : chr  "paravance-11" "paravance-14" "paravance-19" "paravance-25" ...
 $ cost_baseline               : num  4.96 4.75 5.06 4.75 4.85 ...
 $ speedup                     : num  1.56 1.49 1.66 1.49 1.54 ...
 $ max_run_speedup             : num  1.56 1.49 1.66 1.49 1.54 ...
 $ min_run_cost                : num  3.18 3.2 3.05 3.18 3.15 ...
 $ best_iteration              : num  19 2 11 62 31 25 14 78 65 12
 $ points                      : int  84 83 80 86 83 79 84 84 83 86
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.85 4.85 4.85 4.85 4.85 ...
 $ label_center_x              : num  4.16 4.16 4.16 4.16 4.16 ...
 $ label_center_y              : num  32.1 32.1 32.1 32.1 32.1 ...

[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-16_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-18_1569094827/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-2_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-20_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-21_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-22_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-23_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-24_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-30_1569094829/search_space.csv"
[1] "dlmt_spapt_experiments/data/tests/updated_binfalse_random/bicgkernel/xeon_e5_2630_v3_paravance-31_1569094829/search_space.csv"

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	20 obs. of  30 variables:
 $ id                          : int  19 2 11 62 31 25 14 78 65 12 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  512 256 1 1 32 1 1 32 128 32 ...
 $ T1_J                        : int  512 1 2 1 2048 1 2048 1 1 64 ...
 $ cost_mean                   : num  3.18 3.2 3.05 3.18 3.15 ...
 $ U_J                         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ U_I                         : int  15 18 15 14 29 30 30 1 1 10 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  512 2048 1 128 2048 256 2048 2048 128 32 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  1 64 128 2048 2048 2048 2048 1 1 2048 ...
 $ U1_I                        : int  30 30 21 30 2 1 30 14 28 1 ...
 $ mean_confidence_interval_inf: num  3.18 3.2 3.05 3.18 3.15 ...
 $ mean_confidence_interval_sup: num  3.18 3.2 3.05 3.18 3.15 ...
 $ cost_std                    : num  1.30e-04 1.79e-04 1.71e-04 1.36e-04 9.59e-05 ...
 $ step                        : int  1 1 1 3 2 2 1 4 3 1 ...
 $ RT_I                        : int  1 1 4 4 16 16 16 4 4 1 ...
 $ RT_J                        : int  4 8 1 2 8 2 4 2 2 2 ...
 $ experiment_id               : chr  "paravance-11" "paravance-14" "paravance-19" "paravance-25" ...
 $ cost_baseline               : num  4.96 4.75 5.06 4.75 4.85 ...
 $ speedup                     : num  1.56 1.49 1.66 1.49 1.54 ...
 $ max_run_speedup             : num  1.56 1.49 1.66 1.49 1.54 ...
 $ min_run_cost                : num  3.18 3.2 3.05 3.18 3.15 ...
 $ best_iteration              : num  19 2 11 62 31 25 14 78 65 12 ...
 $ points                      : int  84 83 80 86 83 79 84 84 83 86 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.85 4.85 4.85 4.85 4.85 ...
 $ label_center_x              : num  4.16 4.16 4.16 4.16 4.16 ...
 $ label_center_y              : num  32.1 32.1 32.1 32.1 32.1 ...

'data.frame':	52 obs. of  17 variables:
 $ id                     : int  2 2 2 2 2 2 2 2 2 2 ...
 $ valid_configurations   : int  52800 52800 52800 52800 52800 52800 52800 52800 52800 52800 ...
 $ D                      : num  0.227 0.227 0.227 0.23 0.23 ...
 $ used_budget            : int  22 22 22 22 22 22 22 22 22 22 ...
 $ model_size             : int  18 18 18 18 18 18 18 18 18 18 ...
 $ current_best           : num  3.18 3.18 3.18 3.2 3.2 ...
 $ trials                 : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best_coordinate: chr  "{'T1_I': 512, 'T1_J': 512, 'U_J': 1, 'U_I': 15, 'T2_I': 512, 'T2_J': 1, 'U1_I': 30, 'RT_I': 1, 'RT_J': 4}" "{'T1_I': 512, 'T1_J': 512, 'U_J': 1, 'U_I': 15, 'T2_I': 512, 'T2_J': 1, 'U1_I': 30, 'RT_I': 1, 'RT_J': 4}" "{'T1_I': 512, 'T1_J': 512, 'U_J': 1, 'U_I': 15, 'T2_I': 512, 'T2_J': 1, 'U1_I': 30, 'RT_I': 1, 'RT_J': 4}" "{'T1_I': 256, 'T1_J': 1, 'U_J': 1, 'U_I': 18, 'T2_I': 2048, 'T2_J': 64, 'U1_I': 30, 'RT_I': 1, 'RT_J': 8}" ...
 $ tested_configurations  : int  2523006 2523006 2523006 2529754 2529754 2521004 2521004 2521004 2539995 2539995 ...
 $ fixed_factors          : chr  "{'RT_I': 2}" "{'RT_I': 2}" "{'RT_I': 2}" "{'RT_I': 2}" ...
 $ step                   : int  2 2 2 2 2 2 2 2 2 2 ...
 $ design_best            : num  3.2 3.2 3.2 3.33 3.33 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "I(RT_I^2)" "I(RT_I^2)" "RT_I" "RT_I" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  3.94 3.94 3.94 5.55 5.55 ...
 $ experiment_id          : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-14" ...

'data.frame':	842 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1024 1 1 1 32 256 8 1 2048 2048 ...
 $ T1_J                        : int  1 128 16 2048 1 2048 32 1 128 2 ...
 $ cost_mean                   : num  4.58 3.58 6.21 3.68 3.34 ...
 $ U_J                         : int  14 22 15 1 12 1 30 30 1 2 ...
 $ U_I                         : int  1 1 1 29 1 1 1 1 30 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 32 32 2048 2048 256 1 256 2048 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  32 1 2048 1 128 1 128 1 1 512 ...
 $ U1_I                        : int  1 17 30 27 14 10 30 1 3 30 ...
 $ mean_confidence_interval_inf: num  4.58 3.58 6.21 3.66 3.34 ...
 $ mean_confidence_interval_sup: num  4.58 3.58 6.21 3.7 3.34 ...
 $ cost_std                    : num  0.000187 0.000144 0.000764 0.035888 0.000108 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 2 32 2 8 32 16 1 32 1 ...
 $ RT_J                        : int  1 1 4 16 8 1 1 16 2 32 ...
 $ experiment_id               : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-11" ...

There were 40 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	692 obs. of  4 variables:
 $ metric_value: num  0.028 0.101 0.111 0.0949 0.0835 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "paravance-11" "paravance-11" "paravance-11" "paravance-11" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-new-bf
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurejY01Tp.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 06:39:16 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}} cccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
paravance-11 & DLMT & 3.184848 & 512 & 512 & 1 & 15 & 512 & 1 & 30 & 1 & 4 \\
paravance-14 & DLMT & 3.196773 & 256 & 1 & 1 & 18 & 2048 & 64 & 30 & 1 & 8 \\
paravance-19 & DLMT & 3.04968 & 1 & 2 & 1 & 15 & 1 & 128 & 21 & 4 & 1 \\
paravance-25 & DLMT & 3.183022 & 1 & 1 & 1 & 14 & 128 & 2048 & 30 & 4 & 2 \\
paravance-26 & DLMT & 3.154706 & 32 & 2048 & 1 & 29 & 2048 & 2048 & 2 & 16 & 8 \\
paravance-27 & DLMT & 3.145299 & 1 & 1 & 1 & 30 & 256 & 2048 & 1 & 16 & 2 \\
paravance-28 & DLMT & 3.120673 & 1 & 2048 & 1 & 30 & 2048 & 2048 & 30 & 16 & 4 \\
paravance-29 & DLMT & 3.16354 & 32 & 1 & 1 & 1 & 2048 & 1 & 14 & 4 & 2 \\
paravance-3 & DLMT & 3.158316 & 128 & 1 & 1 & 1 & 128 & 1 & 28 & 4 & 2 \\
paravance-32 & DLMT & 3.197007 & 32 & 64 & 1 & 10 & 32 & 2048 & 1 & 1 & 2 \\
paravance-16 & RS & 3.118132 & 1 & 256 & 25 & 1 & 32 & 512 & 20 & 16 & 4 \\
paravance-18 & RS & 3.042194 & 1 & 2 & 1 & 19 & 1 & 256 & 22 & 4 & 1 \\
paravance-2 & RS & 3.131061 & 1 & 1024 & 1 & 6 & 256 & 2048 & 20 & 16 & 2 \\
paravance-20 & RS & 3.120612 & 256 & 1024 & 13 & 1 & 1 & 1024 & 26 & 16 & 2 \\
paravance-21 & RS & 3.112708 & 32 & 1 & 30 & 1 & 64 & 512 & 20 & 16 & 2 \\
paravance-22 & RS & 3.124333 & 256 & 1 & 1 & 12 & 256 & 1024 & 28 & 8 & 2 \\
paravance-23 & RS & 3.11485 & 512 & 512 & 25 & 1 & 2048 & 2048 & 3 & 16 & 4 \\
paravance-24 & RS & 3.106786 & 128 & 1 & 12 & 1 & 512 & 1 & 23 & 8 & 2 \\
paravance-30 & RS & 3.104083 & 32 & 2048 & 12 & 1 & 1 & 2048 & 8 & 16 & 2 \\
paravance-31 & RS & 3.116196 & 2048 & 256 & 1 & 19 & 2048 & 1 & 24 & 8 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export


****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-new-bf
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeRAoHm.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-new-bf
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure2m33md.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-new-bf
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureLgLJS8.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-29"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.29),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-29"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-29}
#+LABEL: fig:lm-rs-nobin-p29-new-bf
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureAw53CA.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-new-bf
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-new-bf
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure21sY97.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-new-bf
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Updated DLMT with Quantile Regression ($\tau = 0.05$, Binary Parameters) :noexport:
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_dlmt_nocarry_tau005"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
# data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][5], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	87 obs. of  3 variables:
 $ removed_variables: Factor w/ 21 levels "","OMP","SCR",..: 1 2 6 3 8 12 1 4 2 5 ...
 $ step             : int  1 2 2 2 2 2 3 4 1 1 ...
 $ experiment_id    : chr  "paravance-44" "paravance-44" "paravance-44" "paravance-44" ...

'data.frame':	520 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->16" "T1_J->1" "U_J->1" "U_I->6" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ experiment_id          : chr  "paravance-44" "paravance-44" "paravance-44" "paravance-44" ...

'data.frame':	862 obs. of  31 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 10 11 ...
 $ T2_J                        : int  512 1 64 32 128 128 1 1 256 4 ...
 $ T2_I                        : int  2048 1 1 2048 512 1 2048 2048 64 1 ...
 $ RT_I                        : int  4 8 1 32 8 8 1 1 8 32 ...
 $ mean_confidence_interval_inf: num  0.61 0.658 0.871 0.75 4.646 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  32 2048 8 4 2 128 32 16 64 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "True" "True" "True" "False" ...
 $ VEC1                        : chr  "False" "False" "True" "False" ...
 $ SCR                         : chr  "False" "True" "True" "False" ...
 $ U1_I                        : int  30 4 7 15 14 4 23 2 29 29 ...
 $ RT_J                        : int  1 16 4 1 16 1 1 32 4 4 ...
 $ T1_I                        : int  2048 16 1 1 512 2048 32 512 16 2048 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.195792 0.100415 0.028229 0.172001 0.000452 ...
 $ cost_mean                   : num  0.731 0.72 0.889 0.857 4.646 ...
 $ U_J                         : int  29 30 16 1 30 1 30 1 1 25 ...
 $ U_I                         : int  1 1 1 29 1 30 1 14 16 1 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.852 0.783 0.906 0.964 4.646 ...
 $ experiment_id               : chr  "paravance-44" "paravance-44" "paravance-44" "paravance-44" ...
 $ cost_baseline               : num  4.85 4.85 4.85 4.85 4.85 ...
 $ speedup                     : num  6.63 6.73 5.45 5.66 1.04 ...
 $ max_run_speedup             : num  9.28 9.28 9.28 9.28 9.28 ...
 $ min_run_cost                : num  0.522 0.522 0.522 0.522 0.522 ...
 $ best_iteration              : num  89 89 89 89 89 89 89 89 89 89 ...
 $ points                      : int  87 87 87 87 87 87 87 87 87 87 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	10 obs. of  34 variables:
 $ id                          : int  89 31 78 60 56 38 59 32 54 35
 $ T2_J                        : int  1 1 2048 2048 2048 512 1 2048 256 2048
 $ T2_I                        : int  1 2048 1 2048 2048 2048 2048 2048 2048 1
 $ RT_I                        : int  16 4 4 4 4 4 16 16 1 8
 $ mean_confidence_interval_inf: num  0.499 0.416 0.438 0.433 0.426 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  2048 2048 2048 2048 2048 16 2048 1 128 2048
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "False" "False" "False" ...
 $ VEC1                        : chr  "False" "True" "True" "False" ...
 $ SCR                         : chr  "True" "True" "True" "True" ...
 $ U1_I                        : int  1 29 30 1 20 28 30 8 9 12
 $ RT_J                        : int  1 32 1 1 4 1 4 4 4 8
 $ T1_I                        : int  2048 2048 2048 1 1 2048 1 2048 1 2048
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10
 $ cost_std                    : num  0.0381 0.2693 0.0437 0.0642 0.2524 ...
 $ cost_mean                   : num  0.522 0.583 0.465 0.473 0.583 ...
 $ U_J                         : int  18 3 1 15 17 1 1 1 1 30
 $ U_I                         : int  1 1 30 1 1 30 14 7 7 1
 $ step                        : int  4 2 4 3 3 2 3 2 2 2
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.546 0.75 0.492 0.513 0.739 ...
 $ experiment_id               : chr  "paravance-44" "paravance-49" "paravance-58" "paravance-61" ...
 $ cost_baseline               : num  4.85 4.95 4.75 4.75 4.85 ...
 $ speedup                     : num  9.28 8.5 10.22 10.04 8.32 ...
 $ max_run_speedup             : num  9.28 8.5 10.22 10.04 8.32 ...
 $ min_run_cost                : num  0.522 0.583 0.465 0.473 0.583 ...
 $ best_iteration              : num  89 31 78 60 56 38 59 32 54 35
 $ points                      : int  87 87 87 85 96 69 90 88 85 88
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.79 4.79 4.79 4.79 4.79 ...
 $ label_center_x              : num  1.44 1.44 1.44 1.44 1.44 ...
 $ label_center_y              : num  53.5 53.5 53.5 53.5 53.5 ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	20 obs. of  34 variables:
 $ id                          : int  89 31 78 60 56 38 59 32 54 35 ...
 $ T2_J                        : int  1 1 2048 2048 2048 512 1 2048 256 2048 ...
 $ T2_I                        : int  1 2048 1 2048 2048 2048 2048 2048 2048 1 ...
 $ RT_I                        : int  16 4 4 4 4 4 16 16 1 8 ...
 $ mean_confidence_interval_inf: num  0.499 0.416 0.438 0.433 0.426 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  2048 2048 2048 2048 2048 16 2048 1 128 2048 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "False" "False" "False" ...
 $ VEC1                        : chr  "False" "True" "True" "False" ...
 $ SCR                         : chr  "True" "True" "True" "True" ...
 $ U1_I                        : int  1 29 30 1 20 28 30 8 9 12 ...
 $ RT_J                        : int  1 32 1 1 4 1 4 4 4 8 ...
 $ T1_I                        : int  2048 2048 2048 1 1 2048 1 2048 1 2048 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.0381 0.2693 0.0437 0.0642 0.2524 ...
 $ cost_mean                   : num  0.522 0.583 0.465 0.473 0.583 ...
 $ U_J                         : int  18 3 1 15 17 1 1 1 1 30 ...
 $ U_I                         : int  1 1 30 1 1 30 14 7 7 1 ...
 $ step                        : int  4 2 4 3 3 2 3 2 2 2 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.546 0.75 0.492 0.513 0.739 ...
 $ experiment_id               : chr  "paravance-44" "paravance-49" "paravance-58" "paravance-61" ...
 $ cost_baseline               : num  4.85 4.95 4.75 4.75 4.85 ...
 $ speedup                     : num  9.28 8.5 10.22 10.04 8.32 ...
 $ max_run_speedup             : num  9.28 8.5 10.22 10.04 8.32 ...
 $ min_run_cost                : num  0.522 0.583 0.465 0.473 0.583 ...
 $ best_iteration              : num  89 31 78 60 56 38 59 32 54 35 ...
 $ points                      : int  87 87 87 85 96 69 90 88 85 88 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.79 4.79 4.79 4.79 4.79 ...
 $ label_center_x              : num  1.44 1.44 1.44 1.44 1.44 ...
 $ label_center_y              : num  53.5 53.5 53.5 53.5 53.5 ...

'data.frame':	69 obs. of  17 variables:
 $ id                     : int  1 1 1 1 2 2 2 2 2 2 ...
 $ valid_configurations   : int  62400 62400 62400 62400 62400 62400 62400 62400 62400 55200 ...
 $ D                      : num  0.209 0.209 0.209 0.205 0.219 ...
 $ used_budget            : int  0 0 0 0 25 25 25 25 25 26 ...
 $ model_size             : int  22 22 22 22 22 22 22 22 22 19 ...
 $ current_best           : num  0.588 0.588 0.688 0.542 0.631 ...
 $ trials                 : int  26 26 26 26 26 26 26 26 26 23 ...
 $ current_best_coordinate: chr  "{'T1_I': 2048, 'T1_J': 32, 'U_J': 2, 'U_I': 1, 'T2_I': 2048, 'T2_J': 1, 'U1_I': 27, 'OMP': True, 'VEC2': True, "| __truncated__ "{'T1_I': 2048, 'T1_J': 32, 'U_J': 2, 'U_I': 1, 'T2_I': 2048, 'T2_J': 1, 'U1_I': 27, 'OMP': True, 'VEC2': True, "| __truncated__ "{'T1_I': 1, 'T1_J': 4, 'U_J': 1, 'U_I': 11, 'T2_I': 2048, 'T2_J': 1, 'U1_I': 17, 'OMP': True, 'VEC2': True, 'VE"| __truncated__ "{'T1_I': 32, 'T1_J': 32, 'U_J': 1, 'U_I': 1, 'T2_I': 128, 'T2_J': 2048, 'U1_I': 16, 'OMP': True, 'VEC2': True, "| __truncated__ ...
 $ tested_configurations  : int  2987448 2987448 3002977 2984424 3005886 3005886 3005886 3005886 3005886 1642823 ...
 $ fixed_factors          : chr  "{'T2_I': 11, 'OMP': 1}" "{'T2_I': 11, 'OMP': 1}" "{'OMP': 1}" "{'OMP': 1}" ...
 $ step                   : int  1 1 1 1 2 2 2 2 2 2 ...
 $ design_best            : num  0.588 0.588 0.688 0.542 0.662 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "OMP" "I(T2_I^2)" "OMP" "OMP" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  0.7 0.7 0.808 0.636 0.838 ...
 $ experiment_id          : chr  "paravance-49" "paravance-49" "paravance-65" "paravance-66" ...

'data.frame':	888 obs. of  24 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  512 1 64 32 128 128 1 1 2048 256 ...
 $ T2_I                        : int  2048 1 1 2048 512 1 2048 2048 1 64 ...
 $ RT_I                        : int  4 8 1 32 8 8 1 1 4 8 ...
 $ mean_confidence_interval_inf: num  0.61 0.658 0.871 0.75 4.646 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  32 2048 8 4 2 128 32 16 1 64 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "True" "True" "True" "False" ...
 $ VEC1                        : chr  "False" "False" "True" "False" ...
 $ SCR                         : chr  "False" "True" "True" "False" ...
 $ U1_I                        : int  30 4 7 15 14 4 23 2 30 29 ...
 $ RT_J                        : int  1 16 4 1 16 1 1 32 32 4 ...
 $ T1_I                        : int  2048 16 1 1 512 2048 32 512 32 16 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 1 10 ...
 $ cost_std                    : num  0.195792 0.100415 0.028229 0.172001 0.000452 ...
 $ cost_mean                   : num  0.731 0.72 0.889 0.857 4.646 ...
 $ U_J                         : int  29 30 16 1 30 1 30 1 1 1 ...
 $ U_I                         : int  1 1 1 29 1 30 1 14 30 16 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  0.852 0.783 0.906 0.964 4.646 ...
 $ experiment_id               : chr  "paravance-44" "paravance-44" "paravance-44" "paravance-44" ...

There were 40 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	739 obs. of  4 variables:
 $ metric_value: num  0.015 0.073 0.0864 0.0878 0.0646 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "paravance-44" "paravance-44" "paravance-44" "paravance-44" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-q05
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure6pzgmk.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J, OMP, SCR, VEC1, VEC2), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "tiny")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Tue, Sep 24, 2019 - 09:47:50 AM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\tiny
\begin{tabular}{@{\extracolsep{0pt}} ccccccccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & step & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J & OMP & SCR & VEC1 & VEC2 \\
\hline \\[-1.8ex]
paravance-44 & DLMT & 4 & 0.5222684 & 2048 & 2048 & 18 & 1 & 1 & 1 & 1 & 16 & 1 & True & True & False & False \\
paravance-49 & DLMT & 2 & 0.5829423 & 2048 & 2048 & 3 & 1 & 2048 & 1 & 29 & 4 & 32 & True & True & True & False \\
paravance-58 & DLMT & 4 & 0.4648992 & 2048 & 2048 & 1 & 30 & 1 & 2048 & 30 & 4 & 1 & True & True & True & False \\
paravance-61 & DLMT & 3 & 0.4732099 & 1 & 2048 & 15 & 1 & 2048 & 2048 & 1 & 4 & 1 & True & True & False & False \\
paravance-62 & DLMT & 3 & 0.582568 & 1 & 2048 & 17 & 1 & 2048 & 2048 & 20 & 4 & 4 & True & True & False & True \\
paravance-63 & DLMT & 2 & 0.5494125 & 2048 & 16 & 1 & 30 & 2048 & 512 & 28 & 4 & 1 & True & True & False & False \\
paravance-64 & DLMT & 3 & 0.4743967 & 1 & 2048 & 1 & 14 & 2048 & 1 & 30 & 16 & 4 & True & True & True & False \\
paravance-65 & DLMT & 2 & 0.6593068 & 2048 & 1 & 1 & 7 & 2048 & 2048 & 8 & 16 & 4 & True & True & False & False \\
paravance-66 & DLMT & 2 & 0.4504963 & 1 & 128 & 1 & 7 & 2048 & 256 & 9 & 1 & 4 & True & True & True & True \\
paravance-71 & DLMT & 2 & 0.5226401 & 2048 & 2048 & 30 & 1 & 1 & 2048 & 12 & 8 & 8 & True & True & False & False \\
paravance-50 & RS & NA & 0.5685274 & 512 & 512 & 19 & 1 & 2048 & 1024 & 27 & 4 & 1 & True & True & True & False \\
paravance-51 & RS & NA & 0.5467725 & 1024 & 32 & 10 & 1 & 2048 & 512 & 9 & 8 & 8 & True & True & True & True \\
paravance-52 & RS & NA & 0.5417953 & 2048 & 8 & 9 & 1 & 2048 & 128 & 30 & 8 & 16 & True & True & True & True \\
paravance-53 & RS & NA & 0.5612387 & 2048 & 64 & 16 & 1 & 2048 & 256 & 9 & 16 & 2 & True & True & True & True \\
paravance-54 & RS & NA & 0.5322531 & 2048 & 8 & 1 & 9 & 1 & 1 & 19 & 1 & 1 & True & True & True & False \\
paravance-55 & RS & NA & 0.5540684 & 32 & 4 & 1 & 5 & 2048 & 256 & 4 & 16 & 1 & True & True & False & False \\
paravance-56 & RS & NA & 0.4648199 & 2048 & 1 & 1 & 23 & 1 & 512 & 25 & 8 & 1 & True & True & False & True \\
paravance-57 & RS & NA & 0.5463944 & 256 & 16 & 1 & 15 & 2048 & 512 & 2 & 2 & 2 & True & True & False & False \\
paravance-58 & RS & NA & 0.5496127 & 32 & 1 & 1 & 14 & 2048 & 2048 & 24 & 8 & 4 & True & True & True & True \\
paravance-59 & RS & NA & 0.4758884 & 64 & 16 & 29 & 1 & 2048 & 1 & 27 & 16 & 4 & True & True & True & True \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-q05
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeRAoHm.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureXncsjg.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I, OMP, SCR, VEC1, VEC2) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figuresjumNZ.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-62"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-62"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-62}
#+LABEL: fig:lm-rs-nobin-p62-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeG8fKl.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I, OMP, SCR, VEC1, VEC2) %>%
  mutate(level = str_replace(level, "True", "1")) %>%
  mutate(level = str_replace(level, "False", "0")) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureWM6DrI.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Updated DLMT with Quantile Regression ($\tau = 0.05$)       :noexport:
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_binfalse_dlmt_nocarry_tau005"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	54 obs. of  3 variables:
 $ removed_variables: Factor w/ 13 levels "","RT_I","I(RT_I^2)",..: 1 2 3 4 1 11 1 3 2 1 ...
 $ step             : int  1 2 2 2 3 4 1 2 2 3 ...
 $ experiment_id    : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...

'data.frame':	324 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->1" "T1_J->128" "U_J->1" "U_I->30" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
 $ experiment_id          : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...

'data.frame':	705 obs. of  27 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  8 2048 256 32 64 4 2048 1024 32 1 ...
 $ T1_J                        : int  32 4 1 4 2048 64 2 2048 16 2048 ...
 $ cost_mean                   : num  4.58 3.87 6.44 3.49 5.51 ...
 $ U_J                         : int  1 1 1 1 1 30 1 1 30 30 ...
 $ U_I                         : int  30 16 30 10 19 1 2 13 1 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  2048 1 1 64 256 2048 2048 2048 32 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  128 2048 1 1 2048 1 32 1 128 1 ...
 $ U1_I                        : int  28 30 15 1 13 28 10 22 18 26 ...
 $ mean_confidence_interval_inf: num  4.58 3.87 6.44 3.49 5.51 ...
 $ mean_confidence_interval_sup: num  4.58 3.87 6.44 3.49 5.51 ...
 $ cost_std                    : num  0.000141 0.000275 0.000629 0.000141 0.002583 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 2 32 1 32 32 4 4 8 1 ...
 $ RT_J                        : int  8 32 4 1 1 1 1 8 16 2 ...
 $ experiment_id               : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...
 $ cost_baseline               : num  4.76 4.76 4.76 4.76 4.76 ...
 $ speedup                     : num  1.038 1.23 0.738 1.362 0.863 ...
 $ max_run_speedup             : num  1.52 1.52 1.52 1.52 1.52 ...
 $ min_run_cost                : num  3.13 3.13 3.13 3.13 3.13 ...
 $ best_iteration              : num  16 16 16 16 16 16 16 16 16 16 ...
 $ points                      : int  82 82 82 82 82 82 82 82 82 82 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	9 obs. of  30 variables:
 $ id                          : int  16 7 5 8 20 62 1 55 85
 $ runs                        : int  10 10 10 10 10 10 10 10 10
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 1 4 1 32 16 4 1 64
 $ T1_J                        : int  128 16 32 64 2048 1 1 1 2048
 $ cost_mean                   : num  3.13 3.3 3.23 3.21 3.21 ...
 $ U_J                         : int  1 1 1 1 11 1 8 1 1
 $ U_I                         : int  30 21 1 12 1 17 1 27 2
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  128 2048 64 1 2048 64 1 2048 128
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  1 1 1 256 1 2048 1 1 2048
 $ U1_I                        : int  2 1 17 1 1 1 20 2 1
 $ mean_confidence_interval_inf: num  3.13 3.3 3.23 3.21 3.21 ...
 $ mean_confidence_interval_sup: num  3.13 3.3 3.23 3.22 3.21 ...
 $ cost_std                    : num  0.00036 0.000166 0.00015 0.000411 0.000133 ...
 $ step                        : int  1 1 1 1 1 3 1 3 4
 $ RT_I                        : int  8 1 4 1 16 8 4 4 16
 $ RT_J                        : int  2 4 2 2 4 2 2 2 4
 $ experiment_id               : chr  "paravance-40" "paravance-41" "paravance-54" "paravance-59" ...
 $ cost_baseline               : num  4.76 4.75 4.75 4.77 4.75 ...
 $ speedup                     : num  1.52 1.44 1.47 1.48 1.48 ...
 $ max_run_speedup             : num  1.52 1.44 1.47 1.48 1.48 ...
 $ min_run_cost                : num  3.13 3.3 3.23 3.21 3.21 ...
 $ best_iteration              : num  16 7 5 8 20 62 1 55 85
 $ points                      : int  82 84 77 74 83 86 53 82 84
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.79 4.79 4.79 4.79 4.79 ...
 $ label_center_x              : num  4.26 4.26 4.26 4.26 4.26 ...
 $ label_center_y              : num  30.6 30.6 30.6 30.6 30.6 ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	19 obs. of  30 variables:
 $ id                          : int  16 7 5 8 20 62 1 55 85 18 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 1 4 1 32 16 4 1 64 1 ...
 $ T1_J                        : int  128 16 32 64 2048 1 1 1 2048 256 ...
 $ cost_mean                   : num  3.13 3.3 3.23 3.21 3.21 ...
 $ U_J                         : int  1 1 1 1 11 1 8 1 1 25 ...
 $ U_I                         : int  30 21 1 12 1 17 1 27 2 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  128 2048 64 1 2048 64 1 2048 128 32 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  1 1 1 256 1 2048 1 1 2048 512 ...
 $ U1_I                        : int  2 1 17 1 1 1 20 2 1 20 ...
 $ mean_confidence_interval_inf: num  3.13 3.3 3.23 3.21 3.21 ...
 $ mean_confidence_interval_sup: num  3.13 3.3 3.23 3.22 3.21 ...
 $ cost_std                    : num  0.00036 0.000166 0.00015 0.000411 0.000133 ...
 $ step                        : int  1 1 1 1 1 3 1 3 4 1 ...
 $ RT_I                        : int  8 1 4 1 16 8 4 4 16 16 ...
 $ RT_J                        : int  2 4 2 2 4 2 2 2 4 4 ...
 $ experiment_id               : chr  "paravance-40" "paravance-41" "paravance-54" "paravance-59" ...
 $ cost_baseline               : num  4.76 4.75 4.75 4.77 4.75 ...
 $ speedup                     : num  1.52 1.44 1.47 1.48 1.48 ...
 $ max_run_speedup             : num  1.52 1.44 1.47 1.48 1.48 ...
 $ min_run_cost                : num  3.13 3.3 3.23 3.21 3.21 ...
 $ best_iteration              : num  16 7 5 8 20 62 1 55 85 18 ...
 $ points                      : int  82 84 77 74 83 86 53 82 84 398 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.79 4.79 4.79 4.79 4.79 ...
 $ label_center_x              : num  4.26 4.26 4.26 4.26 4.26 ...
 $ label_center_y              : num  30.6 30.6 30.6 30.6 30.6 ...

'data.frame':	34 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 2 2 2 ...
 $ valid_configurations   : int  52800 52800 52800 52800 52800 52800 52800 52800 52800 52800 ...
 $ D                      : num  0.219 0.218 0.218 0.218 0.218 ...
 $ used_budget            : int  0 0 0 0 0 0 0 22 22 22 ...
 $ model_size             : int  18 18 18 18 18 18 18 18 18 18 ...
 $ current_best           : num  3.23 3.16 3.16 3.16 3.16 ...
 $ trials                 : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best_coordinate: chr  "{'T1_I': 4, 'T1_J': 32, 'U_J': 1, 'U_I': 1, 'T2_I': 64, 'T2_J': 1, 'U1_I': 17, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 4, 'T1_J': 1, 'U_J': 8, 'U_I': 1, 'T2_I': 1, 'T2_J': 1, 'U1_I': 20, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 4, 'T1_J': 1, 'U_J': 8, 'U_I': 1, 'T2_I': 1, 'T2_J': 1, 'U1_I': 20, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 4, 'T1_J': 1, 'U_J': 8, 'U_I': 1, 'T2_I': 1, 'T2_J': 1, 'U1_I': 20, 'RT_I': 4, 'RT_J': 2}" ...
 $ tested_configurations  : int  2543526 2523646 2523646 2523646 2523646 2523646 2523646 2509565 2509565 2509565 ...
 $ fixed_factors          : chr  "{'RT_I': 0}" "{'T2_I': 0, 'U1_I': 29, 'RT_J': 5, 'RT_I': 2, 'T2_J': 0}" "{'T2_I': 0, 'U1_I': 29, 'RT_J': 5, 'RT_I': 2, 'T2_J': 0}" "{'T2_I': 0, 'U1_I': 29, 'RT_J': 5, 'RT_I': 2, 'T2_J': 0}" ...
 $ step                   : int  1 1 1 1 1 1 1 2 2 2 ...
 $ design_best            : num  3.23 3.16 3.16 3.16 3.16 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "RT_I" "RT_I" "I(RT_J^2)" "U1_I" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  4.68 4.12 4.12 4.12 4.12 ...
 $ experiment_id          : chr  "paravance-54" "paravance-69" "paravance-69" "paravance-69" ...

'data.frame':	721 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  8 2048 256 32 64 4 2048 1024 32 1 ...
 $ T1_J                        : int  32 4 1 4 2048 64 2 2048 16 2048 ...
 $ cost_mean                   : num  4.58 3.87 6.44 3.49 5.51 ...
 $ U_J                         : int  1 1 1 1 1 30 1 1 30 30 ...
 $ U_I                         : int  30 16 30 10 19 1 2 13 1 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  2048 1 1 64 256 2048 2048 2048 32 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  128 2048 1 1 2048 1 32 1 128 1 ...
 $ U1_I                        : int  28 30 15 1 13 28 10 22 18 26 ...
 $ mean_confidence_interval_inf: num  4.58 3.87 6.44 3.49 5.51 ...
 $ mean_confidence_interval_sup: num  4.58 3.87 6.44 3.49 5.51 ...
 $ cost_std                    : num  0.000141 0.000275 0.000629 0.000141 0.002583 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 2 32 1 32 32 4 4 8 1 ...
 $ RT_J                        : int  8 32 4 1 1 1 1 8 16 2 ...
 $ experiment_id               : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...

There were 36 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	600 obs. of  4 variables:
 $ metric_value: num  0.022 0.0983 0.089 0.1028 0.1068 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-q05
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurezlrFF4.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 06:40:41 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}} cccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
paravance-19 & DLMT & 3.183816 & 64 & 256 & 1 & 11 & 1024 & 1024 & 9 & 16 & 8 \\
paravance-25 & DLMT & 3.111797 & 2048 & 1 & 21 & 1 & 1 & 2048 & 1 & 8 & 2 \\
paravance-26 & DLMT & 3.142036 & 2048 & 512 & 15 & 1 & 1 & 2048 & 10 & 16 & 2 \\
paravance-27 & DLMT & 3.294139 & 1 & 2048 & 1 & 30 & 128 & 1 & 28 & 4 & 4 \\
paravance-28 & DLMT & 3.162506 & 1 & 1 & 30 & 1 & 256 & 1 & 5 & 4 & 2 \\
paravance-29 & DLMT & 3.232323 & 2048 & 32 & 1 & 17 & 2048 & 2048 & 11 & 4 & 2 \\
paravance-3 & DLMT & 3.20722 & 2048 & 64 & 1 & 14 & 1 & 1024 & 16 & 1 & 4 \\
paravance-30 & DLMT & 3.162193 & 8 & 1 & 30 & 1 & 64 & 1 & 8 & 4 & 2 \\
paravance-31 & DLMT & 3.145759 & 1 & 1 & 1 & 16 & 32 & 64 & 1 & 1 & 4 \\
paravance-32 & DLMT & 3.212736 & 512 & 16 & 1 & 30 & 1 & 1 & 30 & 8 & 2 \\
paravance-16 & RS & 3.118132 & 1 & 256 & 25 & 1 & 32 & 512 & 20 & 16 & 4 \\
paravance-18 & RS & 3.042194 & 1 & 2 & 1 & 19 & 1 & 256 & 22 & 4 & 1 \\
paravance-2 & RS & 3.131061 & 1 & 1024 & 1 & 6 & 256 & 2048 & 20 & 16 & 2 \\
paravance-20 & RS & 3.120612 & 256 & 1024 & 13 & 1 & 1 & 1024 & 26 & 16 & 2 \\
paravance-21 & RS & 3.112708 & 32 & 1 & 30 & 1 & 64 & 512 & 20 & 16 & 2 \\
paravance-22 & RS & 3.124333 & 256 & 1 & 1 & 12 & 256 & 1024 & 28 & 8 & 2 \\
paravance-23 & RS & 3.11485 & 512 & 512 & 25 & 1 & 2048 & 2048 & 3 & 16 & 4 \\
paravance-24 & RS & 3.106786 & 128 & 1 & 12 & 1 & 512 & 1 & 23 & 8 & 2 \\
paravance-30 & RS & 3.104083 & 32 & 2048 & 12 & 1 & 1 & 2048 & 8 & 16 & 2 \\
paravance-31 & RS & 3.116196 & 2048 & 256 & 1 & 19 & 2048 & 1 & 24 & 8 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-q05
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeRAoHm.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureXncsjg.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureUz34uV.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-67"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.67),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-67"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-67}
#+LABEL: fig:lm-rs-nobin-p67-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeG8fKl.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureWM6DrI.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Updated DLMT with Quantile Regression ($\tau = 0.10$)       :noexport:
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

#current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_binfalse_dlmt_carry_tau005"
current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_binfalse_dlmt_nocarry"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	58 obs. of  3 variables:
 $ removed_variables: Factor w/ 15 levels "","I(RT_I^2)",..: 2 4 1 6 3 1 5 2 1 3 ...
 $ step             : int  1 2 3 4 4 1 2 2 3 4 ...
 $ experiment_id    : chr  "paravance-16" "paravance-16" "paravance-16" "paravance-16" ...

'data.frame':	324 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->64" "T1_J->2048" "U_J->18" "U_I->1" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
 $ experiment_id          : chr  "paravance-16" "paravance-16" "paravance-16" "paravance-16" ...

'data.frame':	674 obs. of  27 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  32 1 64 1 2048 4 1 2048 64 64 ...
 $ T1_J                        : int  2048 128 16 1 8 256 2048 32 2048 64 ...
 $ cost_mean                   : num  3.18 3.32 3.45 3.4 3.88 ...
 $ U_J                         : int  1 14 1 1 28 1 1 1 18 30 ...
 $ U_I                         : int  1 1 30 1 1 28 17 17 1 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1024 8 128 256 2048 2048 1024 1 64 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 2048 1 64 1 256 1 256 1 512 ...
 $ U1_I                        : int  1 4 30 18 29 14 8 2 12 8 ...
 $ mean_confidence_interval_inf: num  3.18 3.32 3.45 3.4 3.88 ...
 $ mean_confidence_interval_sup: num  3.18 3.32 3.45 3.4 3.88 ...
 $ cost_std                    : num  0.00016 0.00026 0.000197 0.000153 0.000146 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  4 4 4 2 4 4 32 4 16 32 ...
 $ RT_J                        : int  2 4 8 8 1 32 1 32 4 4 ...
 $ experiment_id               : chr  "paravance-16" "paravance-16" "paravance-16" "paravance-16" ...
 $ cost_baseline               : num  4.76 4.76 4.76 4.76 4.76 ...
 $ speedup                     : num  1.49 1.43 1.38 1.4 1.22 ...
 $ max_run_speedup             : num  1.51 1.51 1.51 1.51 1.51 ...
 $ min_run_cost                : num  3.15 3.15 3.15 3.15 3.15 ...
 $ best_iteration              : num  78 78 78 78 78 78 78 78 78 78 ...
 $ points                      : int  77 77 77 77 77 77 77 77 77 77 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	9 obs. of  30 variables:
 $ id                          : int  78 20 14 40 37 33 42 53 59
 $ runs                        : int  10 10 10 10 10 10 10 10 10
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  32 32 2048 4 8 2048 1 1 2048
 $ T1_J                        : int  1 2048 2048 1 64 64 128 1 1
 $ cost_mean                   : num  3.15 3.11 3.15 3.36 3.19 ...
 $ U_J                         : int  24 1 1 1 1 16 1 1 1
 $ U_I                         : int  1 3 30 2 30 1 16 15 23
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  128 2048 1 1 64 2048 32 128 2048
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  64 1 1 2048 128 1 128 1 2048
 $ U1_I                        : int  14 30 22 2 10 30 17 11 11
 $ mean_confidence_interval_inf: num  3.15 3.11 3.15 3.36 3.19 ...
 $ mean_confidence_interval_sup: num  3.15 3.11 3.15 3.36 3.19 ...
 $ cost_std                    : num  0.000159 0.000104 0.000058 0.000274 0.000314 ...
 $ step                        : int  4 1 1 2 2 2 2 3 4
 $ RT_I                        : int  8 16 8 1 8 16 1 1 4
 $ RT_J                        : int  2 2 2 8 2 4 4 2 4
 $ experiment_id               : chr  "paravance-16" "paravance-18" "paravance-20" "paravance-24" ...
 $ cost_baseline               : num  4.76 4.76 4.86 4.85 4.75 ...
 $ speedup                     : num  1.51 1.53 1.54 1.44 1.49 ...
 $ max_run_speedup             : num  1.51 1.53 1.54 1.44 1.49 ...
 $ min_run_cost                : num  3.15 3.11 3.15 3.36 3.19 ...
 $ best_iteration              : num  78 20 14 40 37 33 42 53 59
 $ points                      : int  77 85 75 74 70 65 82 74 72
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.81 4.81 4.81 4.81 4.81 ...
 $ label_center_x              : num  4.37 4.37 4.37 4.37 4.37 ...
 $ label_center_y              : num  41.6 41.6 41.6 41.6 41.6 ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	19 obs. of  30 variables:
 $ id                          : int  78 20 14 40 37 33 42 53 59 18 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  32 32 2048 4 8 2048 1 1 2048 1 ...
 $ T1_J                        : int  1 2048 2048 1 64 64 128 1 1 256 ...
 $ cost_mean                   : num  3.15 3.11 3.15 3.36 3.19 ...
 $ U_J                         : int  24 1 1 1 1 16 1 1 1 25 ...
 $ U_I                         : int  1 3 30 2 30 1 16 15 23 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  128 2048 1 1 64 2048 32 128 2048 32 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  64 1 1 2048 128 1 128 1 2048 512 ...
 $ U1_I                        : int  14 30 22 2 10 30 17 11 11 20 ...
 $ mean_confidence_interval_inf: num  3.15 3.11 3.15 3.36 3.19 ...
 $ mean_confidence_interval_sup: num  3.15 3.11 3.15 3.36 3.19 ...
 $ cost_std                    : num  0.000159 0.000104 0.000058 0.000274 0.000314 ...
 $ step                        : int  4 1 1 2 2 2 2 3 4 1 ...
 $ RT_I                        : int  8 16 8 1 8 16 1 1 4 16 ...
 $ RT_J                        : int  2 2 2 8 2 4 4 2 4 4 ...
 $ experiment_id               : chr  "paravance-16" "paravance-18" "paravance-20" "paravance-24" ...
 $ cost_baseline               : num  4.76 4.76 4.86 4.85 4.75 ...
 $ speedup                     : num  1.51 1.53 1.54 1.44 1.49 ...
 $ max_run_speedup             : num  1.51 1.53 1.54 1.44 1.49 ...
 $ min_run_cost                : num  3.15 3.11 3.15 3.36 3.19 ...
 $ best_iteration              : num  78 20 14 40 37 33 42 53 59 18 ...
 $ points                      : int  77 85 75 74 70 65 82 74 72 398 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.81 4.81 4.81 4.81 4.81 ...
 $ label_center_x              : num  4.37 4.37 4.37 4.37 4.37 ...
 $ label_center_y              : num  41.6 41.6 41.6 41.6 41.6 ...

'data.frame':	41 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 2 2 2 ...
 $ valid_configurations   : int  52800 52800 52800 52800 52800 52800 52800 45600 52800 52800 ...
 $ D                      : num  0.223 0.217 0.215 0.218 0.215 ...
 $ used_budget            : int  0 0 0 0 0 0 0 22 22 22 ...
 $ model_size             : int  18 18 18 18 18 18 18 16 18 18 ...
 $ current_best           : num  3.17 3.15 3.38 3.33 3.33 ...
 $ trials                 : int  22 22 22 22 22 22 22 19 22 22 ...
 $ current_best_coordinate: chr  "{'T1_I': 64, 'T1_J': 2048, 'U_J': 18, 'U_I': 1, 'T2_I': 64, 'T2_J': 1, 'U1_I': 12, 'RT_I': 16, 'RT_J': 4}" "{'T1_I': 2048, 'T1_J': 2048, 'U_J': 1, 'U_I': 30, 'T2_I': 1, 'T2_J': 1, 'U1_I': 22, 'RT_I': 8, 'RT_J': 2}" "{'T1_I': 128, 'T1_J': 1, 'U_J': 1, 'U_I': 15, 'T2_I': 128, 'T2_J': 32, 'U1_I': 13, 'RT_I': 8, 'RT_J': 4}" "{'T1_I': 2048, 'T1_J': 1, 'U_J': 1, 'U_I': 12, 'T2_I': 1, 'T2_J': 2048, 'U1_I': 30, 'RT_I': 8, 'RT_J': 4}" ...
 $ tested_configurations  : int  2522375 2543909 2532735 2530519 2516111 2516111 2516111 1841548 2506022 2506022 ...
 $ fixed_factors          : chr  "{'RT_I': 0}" "{'RT_I': 0}" "{'RT_I': 0}" "{'RT_I': 0}" ...
 $ step                   : int  1 1 1 1 1 1 1 2 2 2 ...
 $ design_best            : num  3.17 3.15 3.38 3.33 3.33 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "I(RT_I^2)" "I(RT_I^2)" "I(RT_I^2)" "I(RT_I^2)" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  7.79 4.58 4.58 4.68 3.64 ...
 $ experiment_id          : chr  "paravance-16" "paravance-20" "paravance-24" "paravance-71" ...

'data.frame':	685 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  32 1 64 1 2048 4 1 2048 64 64 ...
 $ T1_J                        : int  2048 128 16 1 8 256 2048 32 2048 64 ...
 $ cost_mean                   : num  3.18 3.32 3.45 3.4 3.88 ...
 $ U_J                         : int  1 14 1 1 28 1 1 1 18 30 ...
 $ U_I                         : int  1 1 30 1 1 28 17 17 1 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1024 8 128 256 2048 2048 1024 1 64 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 2048 1 64 1 256 1 256 1 512 ...
 $ U1_I                        : int  1 4 30 18 29 14 8 2 12 8 ...
 $ mean_confidence_interval_inf: num  3.18 3.32 3.45 3.4 3.88 ...
 $ mean_confidence_interval_sup: num  3.18 3.32 3.45 3.4 3.88 ...
 $ cost_std                    : num  0.00016 0.00026 0.000197 0.000153 0.000146 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  4 4 4 2 4 4 32 4 16 32 ...
 $ RT_J                        : int  2 4 8 8 1 32 1 32 4 4 ...
 $ experiment_id               : chr  "paravance-16" "paravance-16" "paravance-16" "paravance-16" ...

There were 36 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	564 obs. of  4 variables:
 $ metric_value: num  0.0327 0.1146 0.0923 0.0994 0.0918 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "paravance-16" "paravance-16" "paravance-16" "paravance-16" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-q10
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure5OqVJK.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 06:39:59 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\begin{tabular}{@{\extracolsep{5pt}} cccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
paravance-16 & DLMT & 3.151937 & 32 & 1 & 24 & 1 & 128 & 64 & 14 & 8 & 2 \\
paravance-18 & DLMT & 3.111585 & 32 & 2048 & 1 & 3 & 2048 & 1 & 30 & 16 & 2 \\
paravance-20 & DLMT & 3.149921 & 2048 & 2048 & 1 & 30 & 1 & 1 & 22 & 8 & 2 \\
paravance-24 & DLMT & 3.361233 & 4 & 1 & 1 & 2 & 1 & 2048 & 2 & 1 & 8 \\
paravance-49 & DLMT & 3.189757 & 8 & 64 & 1 & 30 & 64 & 128 & 10 & 8 & 2 \\
paravance-5 & DLMT & 3.213894 & 2048 & 64 & 16 & 1 & 2048 & 1 & 30 & 16 & 4 \\
paravance-7 & DLMT & 3.136232 & 1 & 128 & 1 & 16 & 32 & 128 & 17 & 1 & 4 \\
paravance-71 & DLMT & 3.320441 & 1 & 1 & 1 & 15 & 128 & 1 & 11 & 1 & 2 \\
paravance-8 & DLMT & 3.294567 & 2048 & 1 & 1 & 23 & 2048 & 2048 & 11 & 4 & 4 \\
paravance-16 & RS & 3.118132 & 1 & 256 & 25 & 1 & 32 & 512 & 20 & 16 & 4 \\
paravance-18 & RS & 3.042194 & 1 & 2 & 1 & 19 & 1 & 256 & 22 & 4 & 1 \\
paravance-2 & RS & 3.131061 & 1 & 1024 & 1 & 6 & 256 & 2048 & 20 & 16 & 2 \\
paravance-20 & RS & 3.120612 & 256 & 1024 & 13 & 1 & 1 & 1024 & 26 & 16 & 2 \\
paravance-21 & RS & 3.112708 & 32 & 1 & 30 & 1 & 64 & 512 & 20 & 16 & 2 \\
paravance-22 & RS & 3.124333 & 256 & 1 & 1 & 12 & 256 & 1024 & 28 & 8 & 2 \\
paravance-23 & RS & 3.11485 & 512 & 512 & 25 & 1 & 2048 & 2048 & 3 & 16 & 4 \\
paravance-24 & RS & 3.106786 & 128 & 1 & 12 & 1 & 512 & 1 & 23 & 8 & 2 \\
paravance-30 & RS & 3.104083 & 32 & 2048 & 12 & 1 & 1 & 2048 & 8 & 16 & 2 \\
paravance-31 & RS & 3.116196 & 2048 & 256 & 1 & 19 & 2048 & 1 & 24 & 8 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-q10
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeRAoHm.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-q10
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureVAQWfX.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-q10
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurehvZUSx.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-20"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.20),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-20"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-20}
#+LABEL: fig:lm-rs-nobin-p28-q10
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figurepYRrzf.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-q10
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-q10
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureWM6DrI.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-q10
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Updated DLMT with Quantile Regression ($\tau = 0.05$, ``Carry Terms'') :noexport:
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_binfalse_dlmt_carry_tau005"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	100 obs. of  3 variables:
 $ removed_variables: Factor w/ 13 levels "","I(RT_I^2)",..: 1 2 3 2 3 8 6 4 5 4 ...
 $ step             : int  1 2 2 2 2 2 2 3 3 3 ...
 $ experiment_id    : chr  "graoully-14" "graoully-14" "graoully-14" "graoully-14" ...

'data.frame':	324 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->1" "T1_J->2048" "U_J->1" "U_I->17" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
 $ experiment_id          : chr  "graoully-14" "graoully-14" "graoully-14" "graoully-14" ...

'data.frame':	697 obs. of  27 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1024 2048 64 8 32 32 32 1 1 1 ...
 $ T1_J                        : int  1 8 1 4 1 16 1024 2048 64 1 ...
 $ cost_mean                   : num  5.61 5.15 4.9 4.4 6.41 ...
 $ U_J                         : int  10 12 1 1 17 1 28 1 13 1 ...
 $ U_I                         : int  1 1 30 30 1 19 1 30 1 28 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1024 1 128 2048 2048 1 2048 128 16 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 1 64 2048 32 2048 1 1 1024 16 ...
 $ U1_I                        : int  16 7 29 15 2 1 30 6 30 20 ...
 $ mean_confidence_interval_inf: num  5.61 5.15 4.9 4.4 6.41 ...
 $ mean_confidence_interval_sup: num  5.61 5.15 4.9 4.4 6.41 ...
 $ cost_std                    : num  0.000184 0.000146 0.000203 0.000211 0.000694 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 4 4 2 32 32 1 32 1 1 ...
 $ RT_J                        : int  8 32 32 1 1 1 32 2 1 1 ...
 $ experiment_id               : chr  "graoully-14" "graoully-14" "graoully-14" "graoully-14" ...
 $ cost_baseline               : num  5.79 5.79 5.79 5.79 5.79 ...
 $ speedup                     : num  1.032 1.124 1.18 1.315 0.902 ...
 $ max_run_speedup             : num  1.51 1.51 1.51 1.51 1.51 ...
 $ min_run_cost                : num  3.84 3.84 3.84 3.84 3.84 ...
 $ best_iteration              : num  32 32 32 32 32 32 32 32 32 32 ...
 $ points                      : int  74 74 74 74 74 74 74 74 74 74 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	9 obs. of  30 variables:
 $ id                          : int  32 30 19 76 75 8 39 67 55
 $ runs                        : int  10 10 10 10 10 10 10 10 10
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 1 1 1 32 1024 1 32 2048
 $ T1_J                        : int  2048 2048 2048 1 1 2048 2048 64 2048
 $ cost_mean                   : num  3.84 3.92 3.83 3.91 3.88 ...
 $ U_J                         : int  30 1 1 30 1 1 30 22 1
 $ U_I                         : int  1 24 30 1 15 17 1 1 14
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  32 4 2048 16 1 1024 512 128 2048
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  1 1 1 2048 1 2048 1 512 1
 $ U1_I                        : int  2 30 13 1 13 29 1 16 13
 $ mean_confidence_interval_inf: num  3.84 3.92 3.83 3.91 3.88 ...
 $ mean_confidence_interval_sup: num  3.84 3.92 3.83 3.91 3.88 ...
 $ cost_std                    : num  4.03e-05 2.11e-03 6.28e-05 1.62e-03 1.10e-04 ...
 $ step                        : int  2 2 1 4 4 1 2 3 3
 $ RT_I                        : int  8 4 16 4 4 4 4 16 1
 $ RT_J                        : int  2 2 4 2 2 2 2 2 4
 $ experiment_id               : chr  "graoully-14" "graoully-15" "graoully-16" "graoully-3" ...
 $ cost_baseline               : num  5.79 5.91 6.04 5.78 5.78 ...
 $ speedup                     : num  1.51 1.51 1.58 1.48 1.49 ...
 $ max_run_speedup             : num  1.51 1.51 1.58 1.48 1.49 ...
 $ min_run_cost                : num  3.84 3.92 3.83 3.91 3.88 ...
 $ best_iteration              : num  32 30 19 76 75 8 39 67 55
 $ points                      : int  74 75 76 82 76 82 79 78 75
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  5.84 5.84 5.84 5.84 5.84 ...
 $ label_center_x              : num  5 5 5 5 5 ...
 $ label_center_y              : num  44.6 44.6 44.6 44.6 44.6 ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	19 obs. of  30 variables:
 $ id                          : int  32 30 19 76 75 8 39 67 55 18 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 1 1 1 32 1024 1 32 2048 1 ...
 $ T1_J                        : int  2048 2048 2048 1 1 2048 2048 64 2048 256 ...
 $ cost_mean                   : num  3.84 3.92 3.83 3.91 3.88 ...
 $ U_J                         : int  30 1 1 30 1 1 30 22 1 25 ...
 $ U_I                         : int  1 24 30 1 15 17 1 1 14 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  32 4 2048 16 1 1024 512 128 2048 32 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  1 1 1 2048 1 2048 1 512 1 512 ...
 $ U1_I                        : int  2 30 13 1 13 29 1 16 13 20 ...
 $ mean_confidence_interval_inf: num  3.84 3.92 3.83 3.91 3.88 ...
 $ mean_confidence_interval_sup: num  3.84 3.92 3.83 3.91 3.88 ...
 $ cost_std                    : num  4.03e-05 2.11e-03 6.28e-05 1.62e-03 1.10e-04 ...
 $ step                        : int  2 2 1 4 4 1 2 3 3 1 ...
 $ RT_I                        : int  8 4 16 4 4 4 4 16 1 16 ...
 $ RT_J                        : int  2 2 4 2 2 2 2 2 4 4 ...
 $ experiment_id               : chr  "graoully-14" "graoully-15" "graoully-16" "graoully-3" ...
 $ cost_baseline               : num  5.79 5.91 6.04 5.78 5.78 ...
 $ speedup                     : num  1.51 1.51 1.58 1.48 1.49 ...
 $ max_run_speedup             : num  1.51 1.51 1.58 1.48 1.49 ...
 $ min_run_cost                : num  3.84 3.92 3.83 3.91 3.88 ...
 $ best_iteration              : num  32 30 19 76 75 8 39 67 55 18 ...
 $ points                      : int  74 75 76 82 76 82 79 78 75 398 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  5.84 5.84 5.84 5.84 5.84 ...
 $ label_center_x              : num  5 5 5 5 5 ...
 $ label_center_y              : num  44.6 44.6 44.6 44.6 44.6 ...

'data.frame':	82 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ valid_configurations   : int  52800 52800 52800 52800 52800 52800 52800 52800 52800 52800 ...
 $ D                      : num  0.219 0.219 0.219 0.219 0.219 ...
 $ used_budget            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ model_size             : int  18 18 18 18 18 18 18 18 18 18 ...
 $ current_best           : num  3.98 3.98 3.98 3.98 3.98 ...
 $ trials                 : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best_coordinate: chr  "{'T1_I': 128, 'T1_J': 1, 'U_J': 1, 'U_I': 1, 'T2_I': 128, 'T2_J': 32, 'U1_I': 1, 'RT_I': 16, 'RT_J': 4}" "{'T1_I': 128, 'T1_J': 1, 'U_J': 1, 'U_I': 1, 'T2_I': 128, 'T2_J': 32, 'U1_I': 1, 'RT_I': 16, 'RT_J': 4}" "{'T1_I': 128, 'T1_J': 1, 'U_J': 1, 'U_I': 1, 'T2_I': 128, 'T2_J': 32, 'U1_I': 1, 'RT_I': 16, 'RT_J': 4}" "{'T1_I': 128, 'T1_J': 1, 'U_J': 1, 'U_I': 1, 'T2_I': 128, 'T2_J': 32, 'U1_I': 1, 'RT_I': 16, 'RT_J': 4}" ...
 $ tested_configurations  : int  2540901 2540901 2540901 2540901 2540901 2540901 2522873 2522873 2522873 2522873 ...
 $ fixed_factors          : chr  "{'U_J': 0, 'RT_I': 2}" "{'U_J': 0, 'RT_I': 2}" "{'U_J': 0, 'RT_I': 2}" "{'U_J': 0, 'RT_I': 2}" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ design_best            : num  3.98 3.98 3.98 3.98 3.98 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "RT_I" "I(RT_I^2)" "RT_I" "I(RT_I^2)" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  5.1 5.1 5.1 5.1 5.1 ...
 $ experiment_id          : chr  "graoully-15" "graoully-15" "graoully-15" "graoully-15" ...

'data.frame':	709 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1024 2048 64 8 32 32 32 1 1 1 ...
 $ T1_J                        : int  1 8 1 4 1 16 1024 2048 64 1 ...
 $ cost_mean                   : num  5.61 5.15 4.9 4.4 6.41 ...
 $ U_J                         : int  10 12 1 1 17 1 28 1 13 1 ...
 $ U_I                         : int  1 1 30 30 1 19 1 30 1 28 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1024 1 128 2048 2048 1 2048 128 16 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 1 64 2048 32 2048 1 1 1024 16 ...
 $ U1_I                        : int  16 7 29 15 2 1 30 6 30 20 ...
 $ mean_confidence_interval_inf: num  5.61 5.15 4.9 4.4 6.41 ...
 $ mean_confidence_interval_sup: num  5.61 5.15 4.9 4.4 6.41 ...
 $ cost_std                    : num  0.000184 0.000146 0.000203 0.000211 0.000694 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  1 4 4 2 32 32 1 32 1 1 ...
 $ RT_J                        : int  8 32 32 1 1 1 32 2 1 1 ...
 $ experiment_id               : chr  "graoully-14" "graoully-14" "graoully-14" "graoully-14" ...

There were 36 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	570 obs. of  4 variables:
 $ metric_value: num  0.0229 0.1316 0.0851 0.0853 0.0988 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "graoully-14" "graoully-14" "graoully-14" "graoully-14" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-q05
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure5OqVJK.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Tue, Sep 24, 2019 - 09:39:24 AM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\scriptsize
\begin{tabular}{@{\extracolsep{0pt}} ccccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & step & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
graoully-14 & DLMT & 2 & 3.839034 & 1 & 2048 & 30 & 1 & 32 & 1 & 2 & 8 & 2 \\
graoully-15 & DLMT & 2 & 3.920172 & 1 & 2048 & 1 & 24 & 4 & 1 & 30 & 4 & 2 \\
graoully-16 & DLMT & 1 & 3.826293 & 1 & 2048 & 1 & 30 & 2048 & 1 & 13 & 16 & 4 \\
graoully-3 & DLMT & 4 & 3.910717 & 1 & 1 & 30 & 1 & 16 & 2048 & 1 & 4 & 2 \\
graoully-4 & DLMT & 4 & 3.881786 & 32 & 1 & 1 & 15 & 1 & 1 & 13 & 4 & 2 \\
graoully-5 & DLMT & 1 & 3.916675 & 1024 & 2048 & 1 & 17 & 1024 & 2048 & 29 & 4 & 2 \\
graoully-7 & DLMT & 2 & 3.908947 & 1 & 2048 & 30 & 1 & 512 & 1 & 1 & 4 & 2 \\
graoully-8 & DLMT & 3 & 3.901402 & 32 & 64 & 22 & 1 & 128 & 512 & 16 & 16 & 2 \\
graoully-9 & DLMT & 3 & 3.934714 & 2048 & 2048 & 1 & 14 & 2048 & 1 & 13 & 1 & 4 \\
paravance-16 & RS & 1 & 3.118132 & 1 & 256 & 25 & 1 & 32 & 512 & 20 & 16 & 4 \\
paravance-18 & RS & 1 & 3.042194 & 1 & 2 & 1 & 19 & 1 & 256 & 22 & 4 & 1 \\
paravance-2 & RS & 1 & 3.131061 & 1 & 1024 & 1 & 6 & 256 & 2048 & 20 & 16 & 2 \\
paravance-20 & RS & 1 & 3.120612 & 256 & 1024 & 13 & 1 & 1 & 1024 & 26 & 16 & 2 \\
paravance-21 & RS & 1 & 3.112708 & 32 & 1 & 30 & 1 & 64 & 512 & 20 & 16 & 2 \\
paravance-22 & RS & 1 & 3.124333 & 256 & 1 & 1 & 12 & 256 & 1024 & 28 & 8 & 2 \\
paravance-23 & RS & 1 & 3.11485 & 512 & 512 & 25 & 1 & 2048 & 2048 & 3 & 16 & 4 \\
paravance-24 & RS & 1 & 3.106786 & 128 & 1 & 12 & 1 & 512 & 1 & 23 & 8 & 2 \\
paravance-30 & RS & 1 & 3.104083 & 32 & 2048 & 12 & 1 & 1 & 2048 & 8 & 16 & 2 \\
paravance-31 & RS & 1 & 3.116196 & 2048 & 256 & 1 & 19 & 2048 & 1 & 24 & 8 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-q05
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeRAoHm.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureVAQWfX.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureUz34uV.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-26"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.26),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-26"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-26}
#+LABEL: fig:lm-rs-nobin-p26-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeG8fKl.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-q05
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureWM6DrI.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-q005
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Updated DLMT with Quantile Regression ($\tau = 0.15$, ``Carry Terms'') :noexport:
****** Loading Data                                           :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

# Eliminated Factors

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

current_experiment <- "dlmt_spapt_experiments/data/tests/quantreg_binfalse_dlmt_carry_tau015"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# Loading Data for Histograms and Iterations

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

full_data <- data

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             subset(cost_mean == min_run_cost)

complete_plot_data <- plot_data

str(complete_plot_data)

library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
data_dir <- "dlmt_spapt_experiments/data/tests/updated_binfalse_random"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- bind_rows(filter(full_data, technique == "DLMT"),
                       filter(rs_data, technique == "RS", application == "bicgkernel"))

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  subset(cost_mean == min_run_cost)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)

str(complete_plot_data)

library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

# Loading Data Step-by-step Plots

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)

library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

# Loading Data for D-Optimality and ANOVA

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  new_formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  names(new_formula) <- c("formula")

  # Uncomment for encoded variables (also change elsewhere!):
  # new_formula$formula <- str_replace_all(new_formula$formula[1], "e", "")
  #

  new_formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  new_formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(new_formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	99 obs. of  3 variables:
 $ removed_variables: Factor w/ 11 levels "","I(RT_I^2)",..: 1 11 10 2 3 2 3 9 8 4 ...
 $ step             : int  1 2 2 2 2 2 2 2 2 3 ...
 $ experiment_id    : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...

'data.frame':	360 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->1" "T1_J->2048" "U_J->1" "U_I->19" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 2 ...
 $ experiment_id          : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...

'data.frame':	802 obs. of  27 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  2 1 256 32 2048 1 64 4 4 2048 ...
 $ T1_J                        : int  1 2048 16 128 64 16 32 8 1 32 ...
 $ cost_mean                   : num  4.59 3.8 6.92 4.58 4.59 ...
 $ U_J                         : int  1 30 1 30 18 1 1 16 30 1 ...
 $ U_I                         : int  11 1 29 1 1 20 17 1 1 18 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  32 1 1 32 1 2048 1 16 512 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 1 1 512 64 1 128 2048 1 32 ...
 $ U1_I                        : int  11 16 1 26 2 17 30 12 1 18 ...
 $ mean_confidence_interval_inf: num  4.59 3.8 6.92 4.58 4.58 ...
 $ mean_confidence_interval_sup: num  4.59 3.8 6.92 4.58 4.6 ...
 $ cost_std                    : num  0.000377 0.000124 0.001214 0.000178 0.017378 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  32 8 32 1 1 1 8 4 8 8 ...
 $ RT_J                        : int  1 1 4 32 32 32 1 1 4 4 ...
 $ experiment_id               : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...
 $ cost_baseline               : num  4.76 4.76 4.76 4.76 4.76 ...
 $ speedup                     : num  1.037 1.251 0.687 1.038 1.037 ...
 $ max_run_speedup             : num  1.51 1.51 1.51 1.51 1.51 ...
 $ min_run_cost                : num  3.16 3.16 3.16 3.16 3.16 ...
 $ best_iteration              : num  12 12 12 12 12 12 12 12 12 12 ...
 $ points                      : int  71 71 71 71 71 71 71 71 71 71 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	10 obs. of  30 variables:
 $ id                          : int  12 55 58 52 74 27 4 13 87 35
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 2048 32 2048 1 2048 1 2048 8 2048
 $ T1_J                        : int  2048 2048 2048 1 2 2048 2048 2048 64 1
 $ cost_mean                   : num  3.16 3.19 3.18 3.16 3.03 ...
 $ U_J                         : int  1 30 1 1 1 16 1 30 1 29
 $ U_I                         : int  19 1 1 14 30 1 14 1 7 1
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 1 1 1 1 1 1 1 256 2048
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 2048 2048 1 2048 2048 1 1 64 1
 $ U1_I                        : int  27 17 1 1 22 8 6 8 28 30
 $ mean_confidence_interval_inf: num  3.16 3.19 3.18 3.16 3.03 ...
 $ mean_confidence_interval_sup: num  3.16 3.19 3.18 3.16 3.03 ...
 $ cost_std                    : num  4.27e-04 1.09e-04 1.13e-04 1.12e-04 7.22e-05 ...
 $ step                        : int  1 3 3 3 4 2 1 1 4 2
 $ RT_I                        : int  1 4 4 4 4 4 16 16 8 8
 $ RT_J                        : int  8 2 2 2 1 2 8 4 2 2
 $ experiment_id               : chr  "paravance-40" "paravance-44" "paravance-47" "paravance-63" ...
 $ cost_baseline               : num  4.76 4.86 4.96 4.86 4.75 ...
 $ speedup                     : num  1.51 1.52 1.56 1.54 1.57 ...
 $ max_run_speedup             : num  1.51 1.52 1.56 1.54 1.57 ...
 $ min_run_cost                : num  3.16 3.19 3.18 3.16 3.03 ...
 $ best_iteration              : num  12 55 58 52 74 27 4 13 87 35
 $ points                      : int  71 74 78 82 84 75 84 83 86 85
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.79 4.79 4.79 4.79 4.79 ...
 $ label_center_x              : num  4.14 4.14 4.14 4.14 4.14 ...
 $ label_center_y              : num  42.2 42.2 42.2 42.2 42.2 ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	20 obs. of  30 variables:
 $ id                          : int  12 55 58 52 74 27 4 13 87 35 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  1 2048 32 2048 1 2048 1 2048 8 2048 ...
 $ T1_J                        : int  2048 2048 2048 1 2 2048 2048 2048 64 1 ...
 $ cost_mean                   : num  3.16 3.19 3.18 3.16 3.03 ...
 $ U_J                         : int  1 30 1 1 1 16 1 30 1 29 ...
 $ U_I                         : int  19 1 1 14 30 1 14 1 7 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  1 1 1 1 1 1 1 1 256 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 2048 2048 1 2048 2048 1 1 64 1 ...
 $ U1_I                        : int  27 17 1 1 22 8 6 8 28 30 ...
 $ mean_confidence_interval_inf: num  3.16 3.19 3.18 3.16 3.03 ...
 $ mean_confidence_interval_sup: num  3.16 3.19 3.18 3.16 3.03 ...
 $ cost_std                    : num  4.27e-04 1.09e-04 1.13e-04 1.12e-04 7.22e-05 ...
 $ step                        : int  1 3 3 3 4 2 1 1 4 2 ...
 $ RT_I                        : int  1 4 4 4 4 4 16 16 8 8 ...
 $ RT_J                        : int  8 2 2 2 1 2 8 4 2 2 ...
 $ experiment_id               : chr  "paravance-40" "paravance-44" "paravance-47" "paravance-63" ...
 $ cost_baseline               : num  4.76 4.86 4.96 4.86 4.75 ...
 $ speedup                     : num  1.51 1.52 1.56 1.54 1.57 ...
 $ max_run_speedup             : num  1.51 1.52 1.56 1.54 1.57 ...
 $ min_run_cost                : num  3.16 3.19 3.18 3.16 3.03 ...
 $ best_iteration              : num  12 55 58 52 74 27 4 13 87 35 ...
 $ points                      : int  71 74 78 82 84 75 84 83 86 85 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.79 4.79 4.79 4.79 4.79 ...
 $ label_center_x              : num  4.14 4.14 4.14 4.14 4.14 ...
 $ label_center_y              : num  42.2 42.2 42.2 42.2 42.2 ...

'data.frame':	78 obs. of  17 variables:
 $ id                     : int  1 1 1 1 2 2 2 2 2 2 ...
 $ valid_configurations   : int  52800 52800 52800 52800 52800 52800 52800 52800 52800 52800 ...
 $ D                      : num  0.22 0.22 0.22 0.22 0.229 ...
 $ used_budget            : int  0 0 0 0 22 22 22 22 22 22 ...
 $ model_size             : int  18 18 18 18 18 18 18 18 18 18 ...
 $ current_best           : num  3.25 3.25 3.25 3.25 3.16 ...
 $ trials                 : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best_coordinate: chr  "{'T1_I': 64, 'T1_J': 32, 'U_J': 3, 'U_I': 1, 'T2_I': 128, 'T2_J': 1, 'U1_I': 29, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 64, 'T1_J': 32, 'U_J': 3, 'U_I': 1, 'T2_I': 128, 'T2_J': 1, 'U1_I': 29, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 64, 'T1_J': 32, 'U_J': 3, 'U_I': 1, 'T2_I': 128, 'T2_J': 1, 'U1_I': 29, 'RT_I': 4, 'RT_J': 2}" "{'T1_I': 64, 'T1_J': 32, 'U_J': 3, 'U_I': 1, 'T2_I': 128, 'T2_J': 1, 'U1_I': 29, 'RT_I': 4, 'RT_J': 2}" ...
 $ tested_configurations  : int  2530499 2530499 2530499 2530499 2511103 2511103 2511103 2511103 2511103 2511103 ...
 $ fixed_factors          : chr  "{'RT_I': 2}" "{'RT_I': 2}" "{'RT_I': 2}" "{'RT_I': 2}" ...
 $ step                   : int  1 1 1 1 2 2 2 2 2 2 ...
 $ design_best            : num  3.25 3.25 3.25 3.25 3.24 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "I(RT_I^2)" "RT_I" "I(RT_I^2)" "RT_I" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  3.34 3.34 3.34 3.34 3.34 ...
 $ experiment_id          : chr  "paravance-65" "paravance-65" "paravance-65" "paravance-65" ...

'data.frame':	812 obs. of  20 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_I                        : int  2 1 256 32 2048 1 64 4 4 2048 ...
 $ T1_J                        : int  1 2048 16 128 64 16 32 8 1 32 ...
 $ cost_mean                   : num  4.59 3.8 6.92 4.58 4.59 ...
 $ U_J                         : int  1 30 1 30 18 1 1 16 30 1 ...
 $ U_I                         : int  11 1 29 1 1 20 17 1 1 18 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ T2_I                        : int  32 1 1 32 1 2048 1 16 512 2048 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ T2_J                        : int  2048 1 1 512 64 1 128 2048 1 32 ...
 $ U1_I                        : int  11 16 1 26 2 17 30 12 1 18 ...
 $ mean_confidence_interval_inf: num  4.59 3.8 6.92 4.58 4.58 ...
 $ mean_confidence_interval_sup: num  4.59 3.8 6.92 4.58 4.6 ...
 $ cost_std                    : num  0.000377 0.000124 0.001214 0.000178 0.017378 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ RT_I                        : int  32 8 32 1 1 1 8 4 8 8 ...
 $ RT_J                        : int  1 1 4 32 32 32 1 1 4 4 ...
 $ experiment_id               : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...

There were 40 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	666 obs. of  4 variables:
 $ metric_value: num  0.0293 0.0904 0.0815 0.0804 0.0781 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "paravance-40" "paravance-40" "paravance-40" "paravance-40" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(it_data$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    #geom_label_repel(data = . %>% group_by(application) %>%
    #                              filter(technique == "RS") %>%
    #                              filter(best_iteration == min(best_iteration)),
    #                 aes(label = technique, x = label_center_x, y = label_center_y), show.legend = FALSE) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    #scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    #annotation_logticks(sides = "b") +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    #scale_color_brewer(palette = "Set1")
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:best-found-q015
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figure5OqVJK.pdf]]

#+begin_SRC R :results output latex :session *R* :exports results
library(stargazer)

stargazer(select(complete_plot_data, experiment_id, technique, step, step, cost_mean,
                 T1_I, T1_J, U_J, U_I, T2_I, T2_J, U1_I,
                 RT_I, RT_J), rownames = FALSE, summary = FALSE, column.sep.width = "0pt", font.size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex


% Table created by stargazer v.5.2.2 by Marek Hlavac, Harvard University. E-mail: hlavac at fas.harvard.edu
% Date and time: Mon, Sep 23, 2019 - 09:50:23 PM
\begin{table}[!htbp] \centering
  \caption{}
  \label{}
\scriptsize
\begin{tabular}{@{\extracolsep{5pt}} ccccccccccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
experiment\_id & technique & step & cost\_mean & T1\_I & T1\_J & U\_J & U\_I & T2\_I & T2\_J & U1\_I & RT\_I & RT\_J \\
\hline \\[-1.8ex]
paravance-40 & DLMT & 1 & 3.15577 & 1 & 2048 & 1 & 19 & 1 & 2048 & 27 & 1 & 8 \\
paravance-44 & DLMT & 3 & 3.186451 & 2048 & 2048 & 30 & 1 & 1 & 2048 & 17 & 4 & 2 \\
paravance-47 & DLMT & 3 & 3.179384 & 32 & 2048 & 1 & 1 & 1 & 2048 & 1 & 4 & 2 \\
paravance-63 & DLMT & 3 & 3.157642 & 2048 & 1 & 1 & 14 & 1 & 1 & 1 & 4 & 2 \\
paravance-64 & DLMT & 4 & 3.028382 & 1 & 2 & 1 & 30 & 1 & 2048 & 22 & 4 & 1 \\
paravance-65 & DLMT & 2 & 3.180707 & 2048 & 2048 & 16 & 1 & 1 & 2048 & 8 & 4 & 2 \\
paravance-66 & DLMT & 1 & 3.176287 & 1 & 2048 & 1 & 14 & 1 & 1 & 6 & 16 & 8 \\
paravance-67 & DLMT & 1 & 3.174842 & 2048 & 2048 & 30 & 1 & 1 & 1 & 8 & 16 & 4 \\
paravance-68 & DLMT & 4 & 3.202011 & 8 & 64 & 1 & 7 & 256 & 64 & 28 & 8 & 2 \\
paravance-70 & DLMT & 2 & 3.116248 & 2048 & 1 & 29 & 1 & 2048 & 1 & 30 & 8 & 2 \\
paravance-16 & RS & 1 & 3.118132 & 1 & 256 & 25 & 1 & 32 & 512 & 20 & 16 & 4 \\
paravance-18 & RS & 1 & 3.042194 & 1 & 2 & 1 & 19 & 1 & 256 & 22 & 4 & 1 \\
paravance-2 & RS & 1 & 3.131061 & 1 & 1024 & 1 & 6 & 256 & 2048 & 20 & 16 & 2 \\
paravance-20 & RS & 1 & 3.120612 & 256 & 1024 & 13 & 1 & 1 & 1024 & 26 & 16 & 2 \\
paravance-21 & RS & 1 & 3.112708 & 32 & 1 & 30 & 1 & 64 & 512 & 20 & 16 & 2 \\
paravance-22 & RS & 1 & 3.124333 & 256 & 1 & 1 & 12 & 256 & 1024 & 28 & 8 & 2 \\
paravance-23 & RS & 1 & 3.11485 & 512 & 512 & 25 & 1 & 2048 & 2048 & 3 & 16 & 4 \\
paravance-24 & RS & 1 & 3.106786 & 128 & 1 & 12 & 1 & 512 & 1 & 23 & 8 & 2 \\
paravance-30 & RS & 1 & 3.104083 & 32 & 2048 & 12 & 1 & 1 & 2048 & 8 & 16 & 2 \\
paravance-31 & RS & 1 & 3.116196 & 2048 & 256 & 1 & 19 & 2048 & 1 & 24 & 8 & 2 \\
\hline \\[-1.8ex]
\end{tabular}
\end{table}
#+end_export

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms-q015
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeRAoHm.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be-q015
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureVAQWfX.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "DLMT")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs
#+LABEL: fig:lm-dlmt-all-q015
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figuresptLPS.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
ggplot(subset(all_parameters_plot_data, experiment_id == "paravance-47"), aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.47),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(subset(all_parameters_plot_data, experiment_id == "paravance-47"), cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+END_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the DLMT runs, for \texttt{paravance-47}
#+LABEL: fig:lm-rs-nobin-p28-q015
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureeG8fKl.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
all_parameters_plot_data <- full_data %>%
  mutate(RT_I = log2(RT_I)) %>%
  mutate(RT_J = log2(RT_J)) %>%
  mutate(T1_I = log2(T1_I)) %>%
  mutate(T2_I = log2(T2_I)) %>%
  mutate(T1_J = log2(T1_J)) %>%
  mutate(T2_J = log2(T2_J)) %>%
  gather("factor", "level", T2_I, T2_J, RT_I,
         T1_J, U_J, U_I, U1_I,
         RT_J, T1_I) %>%
  mutate(level = as.numeric(level)) %>%
  subset(technique == "RS")

ggplot(all_parameters_plot_data, aes(x = level, y = cost_mean)) +
  facet_wrap(factor ~ ., ncol = 4, scale = "free") +
  geom_point(alpha = 0.4) +
  # geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red", alpha = 0.5) +
  geom_quantile(formula = y ~ poly(x, 2),
                quantiles = c(0.01, 0.05, 0.15, 0.25),
                size = 1,
                alpha = 0.6,
                color = "darkgreen") +
  geom_smooth(method = "lm", color = "blue") +
  geom_smooth(method = "lm", color = "purple", formula = y ~ poly(x, 2), alpha = 0.6) +
  geom_point(data = subset(all_parameters_plot_data, cost_mean == min(cost_mean)), size = 2, color = "red") +
  theme_bw(base_size = 17)
#+end_SRC

#+CAPTION: Fitting \texttt{lm} linear and cubic models to separate factors for the RS runs
#+LABEL: fig:lm-rs-all-q015
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureDkdM8P.pdf]]

******* Re-running =aov= and =lm= on =paravance-64=                :noexport:
#+begin_SRC R :results output :session *R* :exports none
p64_designs <- subset(design_data, id == "paravance-64")
str(p64_designs)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	80 obs. of  13 variables:
 $ T1_Ie    : num  -0.333 -1 0.667 -0.333 0.833 ...
 $ T1_Je    : num  -0.167 -0.5 -0.333 -1 -1 ...
 $ T2_Ie    : num  0.833 0.167 -1 -1 0.833 ...
 $ T2_Je    : num  -1 0.833 0 0.833 0 ...
 $ U1_Ie    : num  0.733 -0.6 0.667 -1 -0.6 ...
 $ U_Ie     : num  -1 -0.2 0.2 -1 -1 ...
 $ U_Je     : num  -1 -1 -1 0.0667 -1 ...
 $ RT_Ie    : num  0 -0.333 0.667 0.667 -1 ...
 $ RT_Je    : num  -0.333 0.667 -0.333 -1 -1 ...
 $ cost_mean: num  3.37 3.87 6.82 4.58 4.63 ...
 $ id       : chr  "paravance-64" "paravance-64" "paravance-64" "paravance-64" ...
 $ step     : num  1 1 1 1 1 1 1 1 1 1 ...
 $ formula  : chr  "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ "~ I(T1_Ie ^ 2)
I(T1_Je ^ 2)
I(T2_Ie ^ 2)
I(T2_Je ^ 2)
I(U1_Ie ^ 2)
I(U_Ie ^ 2)
I(U_Je ^ 2)
I(RT_I"| __truncated__ ...
#+end_example

******** First Step:
#+begin_SRC R :results output :session *R* :exports none
p64_step1 <- subset(p64_designs, step == 1)
step_formula <- formula(paste("cost_mean", p64_step1$formula, sep = " "))
#+end_SRC

#+RESULTS:

#+begin_SRC R :results output latex :session *R* :exports results
library(xtable)
reg <- aov(step_formula, data = select(p64_step1, -id, -step, -formula))

print(xtable(reg,
             caption = "First step \\texttt{aov}"),
      size = "scriptsize",
      caption.placement = "top")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Mon Sep 23 20:06:23 2019
\begin{table}[ht]
\centering
\caption{First step \texttt{aov}}
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.92 & 0.92 & 1.27 & 0.3419 \\
  I(T1\_Je\verb|^|2) & 1 & 0.03 & 0.03 & 0.04 & 0.8571 \\
  I(T2\_Ie\verb|^|2) & 1 & 0.31 & 0.31 & 0.43 & 0.5605 \\
  I(T2\_Je\verb|^|2) & 1 & 0.70 & 0.70 & 0.96 & 0.3991 \\
  I(U1\_Ie\verb|^|2) & 1 & 0.44 & 0.44 & 0.61 & 0.4916 \\
  I(U\_Ie\verb|^|2) & 1 & 0.35 & 0.35 & 0.49 & 0.5357 \\
  I(U\_Je\verb|^|2) & 1 & 0.31 & 0.31 & 0.43 & 0.5593 \\
  I(RT\_Ie\verb|^|2) & 1 & 1.89 & 1.89 & 2.61 & 0.2048 \\
  I(RT\_Je\verb|^|2) & 1 & 0.34 & 0.34 & 0.47 & 0.5429 \\
  T1\_Ie & 1 & 0.02 & 0.02 & 0.03 & 0.8755 \\
  T1\_Je & 1 & 0.20 & 0.20 & 0.28 & 0.6330 \\
  T2\_Ie & 1 & 0.06 & 0.06 & 0.09 & 0.7865 \\
  T2\_Je & 1 & 0.96 & 0.96 & 1.33 & 0.3326 \\
  U1\_Ie & 1 & 2.25 & 2.25 & 3.10 & 0.1764 \\
  U\_Ie & 1 & 0.03 & 0.03 & 0.04 & 0.8609 \\
  U\_Je & 1 & 0.01 & 0.01 & 0.01 & 0.9339 \\
  RT\_Ie & 1 & 14.37 & 14.37 & 19.81 & 0.0211 \\
  RT\_Je & 1 & 2.65 & 2.65 & 3.65 & 0.1521 \\
  Residuals & 3 & 2.18 & 0.73 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

#+begin_SRC R :results output latex :session *R* :exports results
library(quantreg)
reg <- rq(step_formula, tau = 0.15, data = select(p64_step1, -id, -step, -formula))

summary(reg, se = "boot")
#+end_SRC

#+RESULTS:
#+begin_export latex

Call: rq(formula = step_formula, tau = 0.15, data = select(p64_step1,
    -id, -step, -formula))

tau: [1] 0.15

Coefficients:
            Value    Std. Error t value  Pr(>|t|)
(Intercept)  4.06637  1.92040    2.11746  0.12448
I(T1_Ie^2)   0.91208  1.16160    0.78519  0.48964
I(T1_Je^2)  -0.38465  0.78012   -0.49306  0.65580
I(T2_Ie^2)  -0.01119  0.75750   -0.01477  0.98914
I(T2_Je^2)  -1.04752  0.84398   -1.24117  0.30275
I(U1_Ie^2)  -0.16496  0.99709   -0.16544  0.87912
I(U_Ie^2)    0.34019  0.87486    0.38885  0.72334
I(U_Je^2)   -0.10516  0.83576   -0.12582  0.90783
I(RT_Ie^2)   2.78112  1.45737    1.90831  0.15238
I(RT_Je^2)   0.14053  0.75263    0.18672  0.86379
T1_Ie        0.15882  0.73878    0.21497  0.84357
T1_Je       -0.27075  0.80352   -0.33695  0.75835
T2_Ie       -0.01863  0.66913   -0.02784  0.97953
T2_Je       -0.31682  0.65220   -0.48577  0.66040
U1_Ie        0.28425  0.77005    0.36913  0.73654
U_Ie         0.00779  0.79577    0.00979  0.99280
U_Je         0.05246  0.73293    0.07158  0.94744
RT_Ie        1.93839  1.03642    1.87027  0.15821
RT_Je        0.99117  0.82334    1.20385  0.31497
#+end_export

We see  that no  factors were  within the filter  threshold. If  we run  the =aov=
analysis  again, but  using a  formula  with only  linear terms  for the  binary
factors, we get the following:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:45:42 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 11.76 & 11.76 & 8.57 & 0.0080 \\
  SCRe & 1 & 0.18 & 0.18 & 0.13 & 0.7188 \\
  VEC1e & 1 & 2.35 & 2.35 & 1.71 & 0.2051 \\
  VEC2e & 1 & 9.08 & 9.08 & 6.62 & 0.0177 \\
  Residuals & 21 & 28.80 & 1.37 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We  see that  =OMP= and  =VEC2= appear  to be  significant, but  only =OMP=  is within
filtering threshold.  If we  had done  this analysis,  we would  have eliminated
=OMP=. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step1, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:02 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 1.2879 & 2.5429 & 0.51 & 0.6281 \\
  I(T1\_Ie\verb|^|2) & -0.3443 & 1.3733 & -0.25 & 0.8092 \\
  I(T1\_Je\verb|^|2) & 0.4895 & 1.2750 & 0.38 & 0.7124 \\
  I(T2\_Ie\verb|^|2) & 0.7388 & 1.4653 & 0.50 & 0.6296 \\
  I(T2\_Je\verb|^|2) & -0.1231 & 1.7055 & -0.07 & 0.9445 \\
  I(U1\_Ie\verb|^|2) & -0.1326 & 1.3013 & -0.10 & 0.9217 \\
  I(U\_Ie\verb|^|2) & -0.7352 & 1.5086 & -0.49 & 0.6409 \\
  I(U\_Je\verb|^|2) & 1.1241 & 1.6087 & 0.70 & 0.5073 \\
  I(RT\_Ie\verb|^|2) & -1.4597 & 1.5992 & -0.91 & 0.3917 \\
  I(RT\_Je\verb|^|2) & -0.2175 & 1.6104 & -0.14 & 0.8964 \\
  T1\_Ie & -0.5276 & 0.8441 & -0.63 & 0.5518 \\
  T1\_Je & 0.1608 & 0.9158 & 0.18 & 0.8656 \\
  T2\_Ie & -0.3984 & 0.7922 & -0.50 & 0.6305 \\
  T2\_Je & -0.0715 & 0.7149 & -0.10 & 0.9232 \\
  U1\_Ie & 0.3409 & 0.7285 & 0.47 & 0.6540 \\
  U\_Ie & -0.4304 & 0.8801 & -0.49 & 0.6398 \\
  U\_Je & 0.0087 & 0.9420 & 0.01 & 0.9929 \\
  RT\_Ie & -0.7724 & 1.1074 & -0.70 & 0.5080 \\
  RT\_Je & -0.3787 & 1.1563 & -0.33 & 0.7529 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Nothing seems to substantially change for this case.

******** Second Step:                                       :noexport:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 2 &
                                   correct_result == "True")

p14_step2 <- subset(p14_designs, step == 2)
p14_step2 <- p14_step2[-nrow(p14_step2), ] # Remove extra row
p14_step2$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step2$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below is the =aov= summary using the formula from step 1, at =parasilo-14=:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(step_formula, data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:25 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.00 & 0.00 & 0.00 & 0.9929 \\
  I(T1\_Je\verb|^|2) & 1 & 0.28 & 0.28 & 0.03 & 0.8874 \\
  I(T2\_Ie\verb|^|2) & 1 & 4.25 & 4.25 & 0.39 & 0.5947 \\
  I(T2\_Je\verb|^|2) & 1 & 3.15 & 3.15 & 0.29 & 0.6435 \\
  I(U1\_Ie\verb|^|2) & 1 & 3.11 & 3.11 & 0.29 & 0.6455 \\
  I(U\_Ie\verb|^|2) & 1 & 0.15 & 0.15 & 0.01 & 0.9167 \\
  I(U\_Je\verb|^|2) & 1 & 0.03 & 0.03 & 0.00 & 0.9609 \\
  I(RT\_Ie\verb|^|2) & 1 & 2.25 & 2.25 & 0.21 & 0.6934 \\
  I(RT\_Je\verb|^|2) & 1 & 1.67 & 1.67 & 0.15 & 0.7322 \\
  T1\_Ie & 1 & 10.18 & 10.18 & 0.94 & 0.4344 \\
  T1\_Je & 1 & 5.14 & 5.14 & 0.47 & 0.5621 \\
  T2\_Ie & 1 & 0.38 & 0.38 & 0.04 & 0.8684 \\
  T2\_Je & 1 & 5.43 & 5.43 & 0.50 & 0.5523 \\
  U1\_Ie & 1 & 0.04 & 0.04 & 0.00 & 0.9582 \\
  U\_Ie & 1 & 6.10 & 6.10 & 0.56 & 0.5310 \\
  U\_Je & 1 & 7.02 & 7.02 & 0.65 & 0.5052 \\
  RT\_Ie & 1 & 0.03 & 0.03 & 0.00 & 0.9607 \\
  RT\_Je & 1 & 7.53 & 7.53 & 0.70 & 0.4920 \\
  SCRe & 1 & 0.00 & 0.00 & 0.00 & 0.9893 \\
  VEC1e & 1 & 2.15 & 2.15 & 0.20 & 0.6993 \\
  VEC2e & 1 & 3.20 & 3.20 & 0.30 & 0.6413 \\
  OMPe & 1 & 7.91 & 7.91 & 0.73 & 0.4827 \\
  Residuals & 2 & 21.65 & 10.82 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the =lm= summary:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:43 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & -0.1916 & 7.9828 & -0.02 & 0.9830 \\
  I(T1\_Ie\verb|^|2) & 1.4679 & 2.6477 & 0.55 & 0.6350 \\
  I(T1\_Je\verb|^|2) & 0.6987 & 2.1667 & 0.32 & 0.7777 \\
  I(T2\_Ie\verb|^|2) & 0.6289 & 3.3176 & 0.19 & 0.8672 \\
  I(T2\_Je\verb|^|2) & 1.1182 & 2.3876 & 0.47 & 0.6856 \\
  I(U1\_Ie\verb|^|2) & -0.9683 & 2.5026 & -0.39 & 0.7361 \\
  I(U\_Ie\verb|^|2) & -0.2207 & 2.2762 & -0.10 & 0.9316 \\
  I(U\_Je\verb|^|2) & -0.0863 & 3.2873 & -0.03 & 0.9814 \\
  I(RT\_Ie\verb|^|2) & 1.9707 & 3.1592 & 0.62 & 0.5964 \\
  I(RT\_Je\verb|^|2) & 2.5392 & 3.1931 & 0.80 & 0.5099 \\
  T1\_Ie & 1.2481 & 1.3655 & 0.91 & 0.4572 \\
  T1\_Je & -1.1113 & 1.4826 & -0.75 & 0.5317 \\
  T2\_Ie & 0.5828 & 1.8955 & 0.31 & 0.7875 \\
  T2\_Je & -0.1342 & 1.2659 & -0.11 & 0.9253 \\
  U1\_Ie & -0.2203 & 1.2447 & -0.18 & 0.8758 \\
  U\_Ie & 1.1803 & 1.3740 & 0.86 & 0.4808 \\
  U\_Je & 1.5185 & 2.1771 & 0.70 & 0.5577 \\
  RT\_Ie & 0.8978 & 2.1430 & 0.42 & 0.7160 \\
  RT\_Je & 1.1568 & 1.5989 & 0.72 & 0.5446 \\
  SCRe & -0.5007 & 1.7698 & -0.28 & 0.8038 \\
  VEC1e & 0.5100 & 1.8784 & 0.27 & 0.8114 \\
  VEC2e & -0.1665 & 2.5713 & -0.06 & 0.9543 \\
  OMPe & -1.6240 & 1.8997 & -0.85 & 0.4827 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Now, let's run =aov= again, using only binary factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:46:59 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 17.13 & 17.13 & 4.92 & 0.0383 \\
  SCRe & 1 & 1.13 & 1.13 & 0.32 & 0.5754 \\
  VEC1e & 1 & 3.14 & 3.14 & 0.90 & 0.3533 \\
  VEC2e & 1 & 0.63 & 0.63 & 0.18 & 0.6758 \\
  Residuals & 20 & 69.64 & 3.48 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that =OMP= and  =VEC2= appear to be  significant, but none  within filtering
threshold. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step2, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:18 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 0.7130 & 3.3215 & 0.21 & 0.8371 \\
  I(T1\_Ie\verb|^|2) & 1.3356 & 1.6327 & 0.82 & 0.4446 \\
  I(T1\_Je\verb|^|2) & 0.5249 & 1.5495 & 0.34 & 0.7463 \\
  I(T2\_Ie\verb|^|2) & 0.8102 & 1.7446 & 0.46 & 0.6587 \\
  I(T2\_Je\verb|^|2) & 0.9339 & 1.6036 & 0.58 & 0.5815 \\
  I(U1\_Ie\verb|^|2) & -0.8610 & 1.6098 & -0.53 & 0.6120 \\
  I(U\_Ie\verb|^|2) & -0.3170 & 1.6663 & -0.19 & 0.8554 \\
  I(U\_Je\verb|^|2) & -0.2912 & 1.9952 & -0.15 & 0.8887 \\
  I(RT\_Ie\verb|^|2) & 1.7247 & 1.8927 & 0.91 & 0.3973 \\
  I(RT\_Je\verb|^|2) & 2.3937 & 1.9275 & 1.24 & 0.2606 \\
  T1\_Ie & 1.4526 & 0.9706 & 1.50 & 0.1851 \\
  T1\_Je & -1.2926 & 1.0546 & -1.23 & 0.2662 \\
  T2\_Ie & 0.5029 & 0.9618 & 0.52 & 0.6198 \\
  T2\_Je & -0.3537 & 0.8138 & -0.43 & 0.6790 \\
  U1\_Ie & -0.3135 & 0.7890 & -0.40 & 0.7049 \\
  U\_Ie & 0.9988 & 0.9220 & 1.08 & 0.3203 \\
  U\_Je & 1.3131 & 1.1489 & 1.14 & 0.2966 \\
  RT\_Ie & 0.5144 & 1.2978 & 0.40 & 0.7055 \\
  RT\_Je & 1.2674 & 1.1140 & 1.14 & 0.2986 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

******** Third Step:                                        :noexport:
#+begin_SRC R :results output :session *R* :exports none
responses <- subset(search_spaces, experiment_id == "parasilo-14" &
                                   step == 3 &
                                   correct_result == "True")

p14_step3 <- subset(p14_designs, step == step)
p14_step3$response <- responses$cost_mean
step_formula <- formula(paste("response", p14_step3$formula, sep = ""))
#+end_SRC

#+RESULTS:

Below is the =aov= summary using the formula from step 1, at =parasilo-14=:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(step_formula, data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:37 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
I(T1\_Ie\verb|^|2) & 1 & 0.44 & 0.44 & 0.16 & 0.6935 \\
  I(T1\_Je\verb|^|2) & 1 & 8.21 & 8.21 & 2.92 & 0.0915 \\
  I(T2\_Ie\verb|^|2) & 1 & 0.27 & 0.27 & 0.09 & 0.7594 \\
  I(T2\_Je\verb|^|2) & 1 & 2.33 & 2.33 & 0.83 & 0.3656 \\
  I(U1\_Ie\verb|^|2) & 1 & 0.08 & 0.08 & 0.03 & 0.8631 \\
  I(U\_Ie\verb|^|2) & 1 & 8.76 & 8.76 & 3.11 & 0.0815 \\
  I(U\_Je\verb|^|2) & 1 & 1.91 & 1.91 & 0.68 & 0.4120 \\
  I(RT\_Ie\verb|^|2) & 1 & 0.76 & 0.76 & 0.27 & 0.6056 \\
  I(RT\_Je\verb|^|2) & 1 & 0.60 & 0.60 & 0.21 & 0.6462 \\
  T1\_Ie & 1 & 0.15 & 0.15 & 0.05 & 0.8201 \\
  T1\_Je & 1 & 2.10 & 2.10 & 0.75 & 0.3900 \\
  T2\_Ie & 1 & 3.09 & 3.09 & 1.10 & 0.2975 \\
  T2\_Je & 1 & 3.37 & 3.37 & 1.20 & 0.2771 \\
  U1\_Ie & 1 & 4.70 & 4.70 & 1.67 & 0.1999 \\
  U\_Ie & 1 & 4.40 & 4.40 & 1.56 & 0.2150 \\
  U\_Je & 1 & 1.34 & 1.34 & 0.47 & 0.4930 \\
  RT\_Ie & 1 & 0.27 & 0.27 & 0.09 & 0.7597 \\
  RT\_Je & 1 & 0.00 & 0.00 & 0.00 & 0.9859 \\
  SCRe & 1 & 4.27 & 4.27 & 1.52 & 0.2217 \\
  VEC1e & 1 & 2.81 & 2.81 & 1.00 & 0.3206 \\
  VEC2e & 1 & 14.00 & 14.00 & 4.97 & 0.0285 \\
  OMPe & 1 & 0.00 & 0.00 & 0.00 & 0.9945 \\
  Residuals & 81 & 228.03 & 2.82 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

And the =lm= summary:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(step_formula, data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:47:49 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 2.0901 & 1.0424 & 2.01 & 0.0483 \\
  I(T1\_Ie\verb|^|2) & 0.2033 & 0.4877 & 0.42 & 0.6779 \\
  I(T1\_Je\verb|^|2) & 0.5684 & 0.4720 & 1.20 & 0.2320 \\
  I(T2\_Ie\verb|^|2) & 0.3079 & 0.5326 & 0.58 & 0.5649 \\
  I(T2\_Je\verb|^|2) & -0.6988 & 0.5206 & -1.34 & 0.1833 \\
  I(U1\_Ie\verb|^|2) & 0.0450 & 0.4556 & 0.10 & 0.9216 \\
  I(U\_Ie\verb|^|2) & 0.1611 & 0.5254 & 0.31 & 0.7599 \\
  I(U\_Je\verb|^|2) & -0.2009 & 0.5551 & -0.36 & 0.7183 \\
  I(RT\_Ie\verb|^|2) & -0.2769 & 0.5636 & -0.49 & 0.6245 \\
  I(RT\_Je\verb|^|2) & -0.0111 & 0.5453 & -0.02 & 0.9838 \\
  T1\_Ie & 0.0966 & 0.2955 & 0.33 & 0.7446 \\
  T1\_Je & -0.1229 & 0.3069 & -0.40 & 0.6900 \\
  T2\_Ie & 0.1918 & 0.2483 & 0.77 & 0.4422 \\
  T2\_Je & -0.2739 & 0.2579 & -1.06 & 0.2913 \\
  U1\_Ie & 0.3403 & 0.2506 & 1.36 & 0.1783 \\
  U\_Ie & -0.3597 & 0.3078 & -1.17 & 0.2460 \\
  U\_Je & 0.2037 & 0.3048 & 0.67 & 0.5059 \\
  RT\_Ie & -0.0513 & 0.3739 & -0.14 & 0.8913 \\
  RT\_Je & 0.1400 & 0.3690 & 0.38 & 0.7053 \\
  SCRe & -0.3981 & 0.3432 & -1.16 & 0.2495 \\
  VEC1e & -0.2706 & 0.3425 & -0.79 & 0.4319 \\
  VEC2e & 0.7631 & 0.3438 & 2.22 & 0.0293 \\
  OMPe & -0.0023 & 0.3377 & -0.01 & 0.9945 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

Now, let's run =aov= again, using only binary factors:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- aov(formula(response ~ OMPe + SCRe + VEC1e + VEC2e),
           data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:48:17 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{lrrrrr}
  \hline
 & Df & Sum Sq & Mean Sq & F value & Pr($>$F) \\
  \hline
OMPe & 1 & 0.58 & 0.58 & 0.21 & 0.6482 \\
  SCRe & 1 & 3.32 & 3.32 & 1.20 & 0.2758 \\
  VEC1e & 1 & 2.63 & 2.63 & 0.95 & 0.3320 \\
  VEC2e & 1 & 11.25 & 11.25 & 4.06 & 0.0466 \\
  Residuals & 99 & 274.11 & 2.77 &  &  \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

We see  that =VEC2= appear to be  significant, but not  within filtering
threshold. If we redo the =lm= analysis without binary factors, we get:

#+begin_SRC R :results output latex :session *R* :exports results
reg <- lm(update.formula(step_formula, . ~ . -OMPe -SCRe -VEC1e -VEC2e),
           data = select(p14_step3, -id, -step, -formula))

library(xtable)
print(xtable(reg), size = "scriptsize")
#+end_SRC

#+RESULTS:
#+begin_export latex

% latex table generated in R 3.6.1 by xtable 1.8-4 package
% Tue Sep 10 17:48:15 2019
\begin{table}[ht]
\centering
\begingroup\scriptsize
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
  \hline
(Intercept) & 1.8998 & 0.9851 & 1.93 & 0.0571 \\
  I(T1\_Ie\verb|^|2) & 0.3154 & 0.4957 & 0.64 & 0.5264 \\
  I(T1\_Je\verb|^|2) & 0.5832 & 0.4810 & 1.21 & 0.2287 \\
  I(T2\_Ie\verb|^|2) & 0.3367 & 0.5397 & 0.62 & 0.5343 \\
  I(T2\_Je\verb|^|2) & -0.5854 & 0.5283 & -1.11 & 0.2709 \\
  I(U1\_Ie\verb|^|2) & 0.1221 & 0.4630 & 0.26 & 0.7926 \\
  I(U\_Ie\verb|^|2) & 0.1803 & 0.5352 & 0.34 & 0.7371 \\
  I(U\_Je\verb|^|2) & -0.1887 & 0.5649 & -0.33 & 0.7392 \\
  I(RT\_Ie\verb|^|2) & -0.3288 & 0.5693 & -0.58 & 0.5650 \\
  I(RT\_Je\verb|^|2) & -0.0976 & 0.5542 & -0.18 & 0.8606 \\
  T1\_Ie & 0.0194 & 0.2963 & 0.07 & 0.9480 \\
  T1\_Je & -0.1595 & 0.3123 & -0.51 & 0.6108 \\
  T2\_Ie & 0.2132 & 0.2504 & 0.85 & 0.3971 \\
  T2\_Je & -0.3121 & 0.2623 & -1.19 & 0.2374 \\
  U1\_Ie & 0.3361 & 0.2550 & 1.32 & 0.1910 \\
  U\_Ie & -0.2641 & 0.3112 & -0.85 & 0.3984 \\
  U\_Je & 0.2105 & 0.3107 & 0.68 & 0.5000 \\
  RT\_Ie & -0.1031 & 0.3808 & -0.27 & 0.7873 \\
  RT\_Je & 0.0064 & 0.3704 & 0.02 & 0.9861 \\
   \hline
\end{tabular}
\endgroup
\end{table}
#+end_export

******* Combined Experiments                                 :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

****** Predicted Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:nc-predicted-best-q015
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureWM6DrI.pdf]]

****** D-Optimality
******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = unique(summaries$step)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss-q015
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-Bco3bb/figureqMGCjQ.pdf]]

******* D_A-Optimality at Each Step                           :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 3,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]

***** Running more Steps on the Original Experiment            :noexport:
****** Loading Data                                           :noexport:
******* Loading Data for Eliminated Factors                  :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

dlmt_steps <- 8
current_experiment <- "dlmt_spapt_experiments/data/tests/cubic_8steps"
target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

eliminated_terms <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  select(removed_variables, step, experiment_id) %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = ""))))) %>%
  mutate(removed_variables = factor(removed_variables,
                                    levels = names(sort(table(removed_variables),
                                                        decreasing = TRUE))))

fixed_factor_data <- summaries %>%
  separate_rows(current_best_coordinate, sep = ",")  %>%
  select(current_best_coordinate, step, experiment_id) %>%
  mutate(current_best_coordinate = sapply(current_best_coordinate,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%
  #separate(current_best_coordinate, c("fixed_factor", "fixed_value"), " ")

fixed_factor_data$current_best_coordinate[fixed_factor_data$current_best_coordinate == ""] <- "None"

fixed_steps_data <- summaries %>%
  separate_rows(fixed_factors, sep = ",")  %>%
  select(fixed_factors, step, experiment_id) %>%
  mutate(fixed_factors = sapply(fixed_factors,
                                function (x) str_trim(str_replace_all(x,
                                                                      c("'" = "",
                                                                        " " = "",
                                                                        "\\{" = "",
                                                                        "\\}" = "",
                                                                        ":" = "->")))))#%>%

fixed_steps_data$fixed_factors[fixed_steps_data$fixed_factors == ""] <- "None"

fixed_steps_data <- fixed_steps_data %>%
  group_by(experiment_id) %>%
  distinct(fixed_factors, .keep_all = TRUE) %>%
  ungroup() %>%
  dplyr::filter(fixed_factors != "None")

str(eliminated_terms)
str(fixed_factor_data)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	56 obs. of  3 variables:
 $ removed_variables: Factor w/ 14 levels "","OMP","SCR",..: 1 1 1 2 1 2 4 3 7 1 ...
 $ step             : int  1 2 3 4 1 2 2 2 2 3 ...
 $ experiment_id    : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...

'data.frame':	520 obs. of  3 variables:
 $ current_best_coordinate: chr  "T1_I->32" "T1_J->1" "U_J->19" "U_I->1" ...
 $ step                   : int  1 1 1 1 1 1 1 1 1 1 ...
 $ experiment_id          : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
#+end_example

******* Loading Data for Histograms and Iterations           :noexport:
#+HEADER: :results output :session *R*
#+BEGIN_SRC R
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

data_dir <- current_experiment
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][6], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(data)) {
            data <- target_data
        } else {
            data <- bind_rows(data, target_data)
        }
    }
}

str(data)

plot_data <- data %>%
             group_by(experiment_id) %>%
             mutate(mean_cost_baseline = mean(cost_baseline)) %>%
             mutate(label_center_x = mean(cost_mean)) %>%
             mutate(label_center_y = mean(best_iteration)) %>%
             ungroup() %>%
             distinct(experiment_id, .keep_all = TRUE)

complete_plot_data <- plot_data

str(complete_plot_data)
#+END_SRC

#+RESULTS:
#+begin_example

'data.frame':	1286 obs. of  7 variables:
 $ cost_mean     : num  0.747 0.916 0.83 0.642 0.68 ...
 $ experiment_id : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
 $ technique     : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ cost_baseline : num  0.869 0.869 0.869 0.869 0.869 ...
 $ min_run_cost  : num  0.456 0.456 0.456 0.456 0.456 ...
 $ best_iteration: num  90 90 90 90 90 90 90 90 90 90 ...
 $ application   : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	11 obs. of  10 variables:
 $ cost_mean         : num  0.747 0.855 0.898 0.783 0.638 ...
 $ experiment_id     : chr  "parasilo-1" "parasilo-10" "parasilo-12" "parasilo-13" ...
 $ technique         : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ cost_baseline     : num  0.869 0.872 0.871 0.871 0.879 ...
 $ min_run_cost      : num  0.456 0.442 0.445 0.536 0.553 ...
 $ best_iteration    : num  90 29 94 40 37 46 65 22 109 49 ...
 $ application       : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline: num  0.874 0.874 0.874 0.874 0.874 ...
 $ label_center_x    : num  0.729 0.729 0.729 0.729 0.729 ...
 $ label_center_y    : num  59.3 59.3 59.3 59.3 59.3 ...
#+end_example

#+HEADER: :results output :session *R*
#+BEGIN_SRC R
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

data_dir <- "dlmt_spapt_experiments/data/results"
target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(str_split(csv_file, "/")[[1]][5], "_")[[1]][5]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$speedup == max(data$speedup), ])), nrow(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel")

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup() %>%
  distinct(experiment_id, .keep_all = TRUE)

complete_plot_data <- bind_rows(filter(plot_data, technique == "DLMT"),
                                rs_plot_data)


str(complete_plot_data)
#+END_SRC


#+RESULTS:
#+begin_example

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	22 obs. of  10 variables:
 $ cost_mean         : num  0.747 0.855 0.898 0.783 0.638 ...
 $ experiment_id     : chr  "parasilo-1" "parasilo-10" "parasilo-12" "parasilo-13" ...
 $ technique         : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ cost_baseline     : num  0.869 0.872 0.871 0.871 0.879 ...
 $ min_run_cost      : num  0.456 0.442 0.445 0.536 0.553 ...
 $ best_iteration    : num  90 29 94 40 37 46 65 22 109 49 ...
 $ application       : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline: num  0.874 0.874 0.874 0.874 0.874 ...
 $ label_center_x    : num  0.729 0.729 0.729 0.729 0.729 ...
 $ label_center_y    : num  59.3 59.3 59.3 59.3 59.3 ...

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	22 obs. of  10 variables:
 $ cost_mean         : num  0.747 0.855 0.898 0.783 0.638 ...
 $ experiment_id     : chr  "parasilo-1" "parasilo-10" "parasilo-12" "parasilo-13" ...
 $ technique         : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ cost_baseline     : num  0.869 0.872 0.871 0.871 0.879 ...
 $ min_run_cost      : num  0.456 0.442 0.445 0.536 0.553 ...
 $ best_iteration    : num  90 29 94 40 37 46 65 22 109 49 ...
 $ application       : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline: num  0.874 0.874 0.874 0.874 0.874 ...
 $ label_center_x    : num  0.729 0.729 0.729 0.729 0.729 ...
 $ label_center_y    : num  59.3 59.3 59.3 59.3 59.3 ...
#+end_example
******* Loading Data Step-by-step Plots                      :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)
library(openssl)

read_experiment <- function(x) {
  data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  return(data)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

summary_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "run_summary.csv",
                                  recursive = TRUE),
                       sep = "/")

summary_files <- summary_files[file.info(summary_files)$size != 0]

summaries <- bind_rows(lapply(summary_files, read_experiment))

spread_data <- summaries %>%
  separate_rows(removed_variables, sep = ", ")  %>%
  mutate(removed_variables = sapply(removed_variables,
                                    function (x) str_trim(str_replace_all(x,
                                                                          c("'" = "",
                                                                            "\\[" = "",
                                                                            "\\]" = "")))))

spread_data$removed_variables[spread_data$removed_variables == ""] <- "None"
spread_data <- spread_data %>% dplyr::filter(removed_variables != "None")

spread_data <- spread_data[order(spread_data$step), ]

search_spaces_files <- paste(target_path,
                             list.files(path = target_path,
                                        pattern = "search_space.csv",
                                        recursive = TRUE),
                             sep = "/")

search_spaces_files <- search_spaces_files[file.info(search_spaces_files)$size != 0]

search_spaces <- bind_rows(lapply(search_spaces_files, read_experiment))

str(spread_data)
str(search_spaces)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	30 obs. of  17 variables:
 $ id                     : int  1 1 1 1 1 1 1 2 2 2 ...
 $ valid_configurations   : int  37440 37440 37440 37440 37440 37440 37440 37440 37440 37440 ...
 $ D                      : num  0.205 0.206 0.206 0.206 0.206 ...
 $ used_budget            : int  0 0 0 0 0 0 0 24 24 24 ...
 $ model_size             : int  22 22 22 22 22 22 22 22 22 22 ...
 $ current_best           : num  0.69 0.733 0.733 0.733 0.733 ...
 $ trials                 : int  26 26 26 26 26 26 26 26 26 26 ...
 $ current_best_coordinate: chr  "{'T1_I': 256, 'T1_J': 128, 'U_J': 1, 'U_I': 5, 'T2_I': 512, 'T2_J': 512, 'U1_I': 18, 'OMP': True, 'VEC2': False"| __truncated__ "{'T1_I': 1024, 'T1_J': 2048, 'U_J': 7, 'U_I': 1, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 1, 'OMP': True, 'VEC2': Tr"| __truncated__ "{'T1_I': 1024, 'T1_J': 2048, 'U_J': 7, 'U_I': 1, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 1, 'OMP': True, 'VEC2': Tr"| __truncated__ "{'T1_I': 1024, 'T1_J': 2048, 'U_J': 7, 'U_I': 1, 'T2_I': 2048, 'T2_J': 2048, 'U1_I': 1, 'OMP': True, 'VEC2': Tr"| __truncated__ ...
 $ tested_configurations  : int  1796751 1787270 1787270 1787270 1787270 1787270 1789531 1801962 1801962 1801962 ...
 $ fixed_factors          : chr  "{'OMP': 1}" "{'U1_I': 0, 'OMP': 1, 'RT_J': 0, 'T1_J': 11, 'SCR': 1}" "{'U1_I': 0, 'OMP': 1, 'RT_J': 0, 'T1_J': 11, 'SCR': 1}" "{'U1_I': 0, 'OMP': 1, 'RT_J': 0, 'T1_J': 11, 'SCR': 1}" ...
 $ step                   : int  1 1 1 1 1 1 1 2 2 2 ...
 $ design_best            : num  0.752 0.74 0.74 0.74 0.74 ...
 $ total_budget           : int  1000 1000 1000 1000 1000 1000 1000 1000 1000 1000 ...
 $ removed_variables      : chr  "OMP" "OMP" "I(T1_J^2)" "SCR" ...
 $ model                  : chr  "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ "~ I(T1_I ^ 2)
I(T1_J ^ 2)
I(T2_I ^ 2)
I(T2_J ^ 2)
I(U1_I ^ 2)
I(U_I ^ 2)
I(U_J ^ 2)
I(RT_I ^ 2) +"| __truncated__ ...
 $ predicted_best         : num  0.69 0.733 0.733 0.733 0.733 ...
 $ experiment_id          : chr  "parasilo-14" "parasilo-17" "parasilo-17" "parasilo-17" ...

'data.frame':	1019 obs. of  24 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 9 10 ...
 $ T2_J                        : int  2048 512 32 128 1 1024 1024 64 1 64 ...
 $ T2_I                        : int  128 64 1 128 2 1 128 2048 1 512 ...
 $ RT_I                        : int  1 32 32 32 4 1 4 16 8 2 ...
 $ mean_confidence_interval_inf: num  0.908 0.952 0.63 4.683 0.941 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  128 1 8 1 2048 32 4 32 1024 1 ...
 $ technique                   : chr  "DLMT" "DLMT" "DLMT" "DLMT" ...
 $ VEC2                        : chr  "False" "True" "True" "False" ...
 $ VEC1                        : chr  "True" "True" "True" "False" ...
 $ SCR                         : chr  "False" "False" "True" "False" ...
 $ U1_I                        : int  15 10 11 29 10 4 2 21 1 17 ...
 $ RT_J                        : int  32 2 1 1 32 2 4 2 1 4 ...
 $ T1_I                        : int  1 16 2048 8 1 1 1 2 256 1 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.026034 0.039186 0.172632 0.000844 0.037614 ...
 $ cost_mean                   : num  0.925 0.976 0.737 4.684 0.964 ...
 $ U_J                         : int  1 1 1 15 11 21 1 1 28 30 ...
 $ U_I                         : int  16 1 30 1 1 1 30 14 1 1 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "True" "True" "True" "False" ...
 $ mean_confidence_interval_sup: num  0.941 1 0.844 4.684 0.987 ...
 $ experiment_id               : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
#+end_example

******* Loading Data for D-Optimality and ANOVA              :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(tidyr)
library(stringr)
library(AlgDesign)
library(FrF2)

original_factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)
  Y <-  (t(X) %*% X) / nrow(X)

  Z <- abs(Y[, rep(2:ncol(X))])
  Z <- Z %*% rep(1, ncol(X) - 1)

  efficiencies <- (1 / Z) * (1 - abs(Y[, 1]))

  df_efficiencies <- as.data.frame(efficiencies)
  df_efficiencies$factors <- rownames(efficiencies)

  return(df_efficiencies)
}

efficiency <- function(f, normalized_information_matrix, id_matrix) {
  return(solve(t(id_matrix[f, ]) %*% normalized_information_matrix %*% id_matrix[f, ]))
}

factor_efficiency <- function(fac, frml) {
  X <- model.matrix(frml, fac)

  inf_X <- solve((t(X) %*% X) / nrow(X))
  id_matrix <- diag(ncol(inf_X))

  efficiencies <- sapply(1:ncol(inf_X), efficiency, normalized_information_matrix = inf_X, id_matrix = id_matrix)

  df_efficiencies <- data.frame(efficiencies)
  names(df_efficiencies) <- c("metric_value")

  #df_efficiencies$factors <- rownames(df_efficiencies)
  df_efficiencies$factors <- names(as.data.frame(X))

  return(df_efficiencies)
}

compute_factor_efficiencies <- function(design) {
  #frml <- formula(str_replace_all(design$formula[1], "e", ""))
  frml <- formula(design$formula[1])
  factor_efficiencies <- factor_efficiency(design, frml)

  factor_efficiencies$id <- design$id[1]
  factor_efficiencies$step <- design$step[1]

  return(factor_efficiencies)
}

read_experiment <- function(x) {
  design <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
  design$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  design$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  design$X <- NULL
  return(design)
}

read_formula <- function(x) {
  formula <- read.csv(x, header = FALSE, stringsAsFactors = FALSE)
  formula$id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
  formula$step <- as.integer(str_split(str_split(str_split(x, "/")[[1]][7], "_")[[1]][3], "\\.")[[1]][1]) + 1
  return(formula)
}

target_path <- paste(current_experiment, "bicgkernel", sep = "/")

designs_files <- paste(target_path,
                       list.files(path = target_path,
                                  pattern = "design_step_",
                                  recursive = TRUE),
                       sep = "/")

designs_files <- designs_files[file.info(designs_files)$size != 0]
designs <- bind_rows(lapply(designs_files, read_experiment))

formulas_files <- paste(target_path,
                        list.files(path = target_path,
                                   pattern = "formula_step_",
                                   recursive = TRUE),
                        sep = "/")

formulas_files <- formulas_files[file.info(formulas_files)$size != 0]
formulas <- bind_rows(lapply(formulas_files, read_formula))

names(formulas) <- c("formula", "id", "step")

design_data <- inner_join(designs, formulas)

design_data_plot <- design_data %>%
  group_by(id, step) %>%
  do(compute_factor_efficiencies(.)) %>%
  ungroup()

str(design_data_plot)
#+end_SRC

#+RESULTS:
#+begin_example

There were 40 warnings (use warnings() to see them)

Joining, by = c("id", "step")

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	860 obs. of  4 variables:
 $ metric_value: num  0.019 0.0906 0.0788 0.0683 0.071 ...
 $ factors     : chr  "(Intercept)" "I(T1_Ie^2)" "I(T1_Je^2)" "I(T2_Ie^2)" ...
 $ id          : chr  "parasilo-1" "parasilo-1" "parasilo-1" "parasilo-1" ...
 $ step        : num  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

****** Iterations that found the Best Configuration
Figure\nbsp[[fig:nobin-best-found]] shows the iterations where the best configuration of
each of the 10 runs was found, for uniform sampling and for our approach.

#+HEADER: :results graphics output :session *R* :exports results
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10
#+BEGIN_SRC R
library(grid)
library(gtable)
library(ggrepel)
library(utf8)

it_data <- complete_plot_data

it_data <- it_data %>% subset(application %in% c("bicgkernel", "mm", "tensor", "gesummv",
                                                 "lu", "mvt", "seidel", "jacobi"))
it_data$facet <- factor(it_data$application, levels = c("bicgkernel", "mm", "tensor", "gesummv",
                                                        "lu", "mvt", "seidel", "jacobi"))

it_data$header <- rep("0", nrow(it_data))

it_data[it_data$facet %in% c("bicgkernel", "mm", "tensor", "gesummv", "lu", "mvt", "seidel", "jacobi"), "header"] <- "C"

it_data$header <- factor(it_data$header, levels = c("C"))

levels(it_data$facet) <- c("[+] bicgkernel", "[+] mm", "[+] tensor", "[+] gesummv",
                           "[+] lu", "[+] mvt", "[+] seidel", "[+] jacobi")

it_data$mean_cost_baseline <- unique(subset(it_data, technique == "DLMT")$mean_cost_baseline)[1]

p1 <- ggplot(it_data, aes(min_run_cost, best_iteration, color = technique)) +
    facet_wrap(facet ~ ., ncol = 4) +
    geom_point(size = 2, pch = 19) +
    stat_ellipse(type = "t", linetype = 13) +
    geom_vline(aes(xintercept = mean_cost_baseline, size = "-O3"), linetype = 8, color = "black") +
    scale_y_continuous(limits = c(-20, 400), breaks = c(0, 50, 100, 150, 200, 250, 300, 350, 400)) +
    scale_size_manual("", values = 0.45) +
    ggtitle("") +
    ylab("Iteration where Best was Found") +
    xlab("Best Cost in Seconds") +
    guides(color = guide_legend(reverse = TRUE)) +
    theme_bw(base_size = 17) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.title = element_blank(),
          text = element_text(family = "serif"),
          strip.background = element_rect(fill = "white"),
          plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"))  +
    scale_color_grey(start = 0.3, end = 0.7)

dummy <- ggplot(data = it_data, aes(x = min_run_cost, y = best_iteration)) +
                facet_wrap(facet ~ ., scale = "free", ncol = 4) +
                geom_rect(aes(fill = header), xmin = -Inf, xmax = Inf,
                                              ymin = -Inf, ymax = Inf) +
                theme_minimal(base_size = 17) +
                theme(text = element_text(family = "serif"),
                      legend.position = "bottom",
                      legend.direction = "horizontal",
                      legend.title = element_blank(),
                      plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm")
                      )  +
                scale_fill_brewer(palette = "Pastel2", direction = -1)
                #scale_fill_grey()

g1 <- ggplotGrob(p1)
g2 <- ggplotGrob(dummy)

gtable_select <- function (x, ...)
{
  matches <- c(...)
  x$layout <- x$layout[matches, , drop = FALSE]
  x$grobs <- x$grobs[matches]
  x
}

panels <- grepl(pattern = "panel", g2$layout$name)
strips <- grepl(pattern = "strip-t", g2$layout$name)
g2$layout$t[panels] <- g2$layout$t[panels] - 1
g2$layout$b[panels] <- g2$layout$b[panels] - 1

new_strips <- gtable_select(g2, panels | strips)
#grid.newpage()
grid.draw(new_strips)

gtable_stack <- function(g1, g2){
  g1$grobs <- c(g1$grobs, g2$grobs)
  g1$layout <- transform(g1$layout, z = z - max(z), name = "g2")
  g1$layout <- rbind(g1$layout, g2$layout)
  g1
}

new_plot <- gtable_stack(g1, new_strips)
#grid.newpage()
grid.draw(new_plot)
#+END_SRC

#+CAPTION: Iteration where best was found
#+LABEL: fig:nobin-best-found
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-ZwiTvz/figureLNiNH0.pdf]]

****** Eliminated Factors and Fixed Values
#+HEADER: :results graphics :session *R*
#+HEADER: :file (org-babel-temp-file "figure" ".pdf")
#+HEADER: :width 13 :height 10 :exports results
#+begin_SRC R
base_size <- 18

ggplot(subset(eliminated_terms, removed_variables != ""), aes(x = removed_variables, fill = as.factor(step))) +
  geom_bar(stat = "Count", show.legend = TRUE) +
  ylab("Eliminated Terms") +
  xlab("") +
  scale_x_discrete() +
  theme_bw(base_size = base_size) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  guides(fill = guide_legend(nrow = 1)) +
  scale_fill_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Eliminated terms
#+LABEL: fig:eliminated-terms
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-ynhqKR/figure7r6W2z.pdf]]

****** Fixed Model Terms                                      :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_x_discrete(limits = 1:dlmt_steps) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, for all experiments
#+LABEL: fig:et-ss-ae
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurewpm8g4.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(spread_data$removed_variables))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(spread_data, aes(x = as.factor(step), fill = removed_variables)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = removed_variables),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Eliminated Terms by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Eliminated terms, step-by-step, by experiment
#+LABEL: fig:et-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureESVdh5.pdf]]

It is  interesting that  only /parasilo-19/ and  /parasilo-9/ eliminated  any factor
other than =OMP=  and =SCR= on the  first step where any factor  was eliminated, and
also that those  runs eliminated the same  factor =RT_I=.  We will  see later that
=OMP= and  =SCR= were fixed to  the same values  in all experiments where  they were
eliminated, and =RT_I=  was only fixed to  a different value on  2 eliminations on
the fourth step.

****** Fixed Factors & Values                                 :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed factors, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureALkZR6.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(fixed_steps_data, aes(x = as.factor(step), fill = fixed_factors)) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(stat = "Count", show.legend = FALSE) +
  geom_text(aes(label = fixed_factors),
            stat = "count",
            position = position_stack(0.5)) +
  ylab("Fixed Factors by Step") +
  xlab("Steps") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans")) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Fixed Factors, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureuiwQJV.pdf]]

****** Searched Spaces                                        :noexport:
******* Combined Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.56) +
  ylab("Execution Time") +
  xlab("Steps") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, for all experiments
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figureTeckKY.pdf]]

******* Separate Experiments
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(subset(search_spaces, correct_result == "True"),
       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
       aes(x = as.factor(step), y = cost_mean)) +
  geom_jitter(width = 0.3, height = 0, alpha = 0.6) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:encpnc-ff-ss-be
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figuregu9cI1.pdf]]

****** Fixed Factors & Values in the Explored Spaces
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

color_count = length(unique(fixed_steps_data$fixed_factors)) + 10
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

       # aes(x = as.factor(step), y = cost_mean, color = interaction(OMP, SCR))) +
ggplot() +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  geom_bar(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors),
           stat = "Count", show.legend = FALSE, alpha = 1.0, width = 0.5) +
  geom_jitter(data = subset(search_spaces, correct_result == "True"),
              aes(x = step, y = cost_mean),
              width = 0.2, height = 0, alpha = 0.5) +
  geom_text(data = fixed_steps_data, aes(x = step + 0.5, fill = fixed_factors,
                                         label = fixed_factors),
            stat = "count",
            color = "black",
            position = position_stack(0.5)) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = unique(spread_data$step)) +
  scale_fill_manual(values = get_palette(color_count)) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) # +
#  scale_colour_manual(name = "",
#                      values=c("red", "blue", "green", "purple"),
#                      labels=c("OMP & SCR: False",
#                               "OMP: True, SCR: False",
#                               "OMP: False, SCR: True",
#                               "OMP & SCR: True"))
#+end_SRC

#+CAPTION: Execution time of Searched Space, step-by-step, by experiment
#+LABEL: fig:le-ss-ef
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-elHoq9/figure8UQjkW.png]]
****** D-Optimality
******* Performance at Each Step
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = predicted_best, color = "predicted_best"), size = 1) +
  geom_point(aes(x = step, y = predicted_best, color = "predicted_best"), size = 2) +
  geom_path(aes(x = step, y = design_best, color = "design_best"), size = 1) +
  geom_point(aes(x = step, y = design_best, color = "design_best"), size = 2) +
  geom_path(aes(x = step, y = current_best, color = "current_best"), size = 1) +
  geom_point(aes(x = step, y = current_best, color = "current_best"), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("Execution Time") +
  xlab("Step") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: Performance of best points, step-by-step, by experiment
#+LABEL: fig:pf-bp-ss
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

******* D-Criterion
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
library(ggplot2)
library(RColorBrewer)

ggplot(summaries) +
  geom_path(aes(x = step, y = D), size = 1) +
  geom_point(aes(x = step, y = D), size = 2) +
  facet_wrap(experiment_id ~ ., ncol = 3) +
  ylab("D-Criterion") +
  xlab("Step") +
  scale_x_discrete(limits = 1:dlmt_steps) +
  theme_bw(base_size = 17) +
  theme(text = element_text(family = "sans"),
        legend.position = "top",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  scale_color_brewer(palette = "Set1")
#+end_SRC

#+CAPTION: D-Criterion, step-by-step, by experiment
#+LABEL: fig:dc-bp-ss
#+ATTR_LATEX: :width 0.7\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurey8nlJc.pdf]]

****** D_A-Optimality at Each Step                             :noexport:
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 15 :height 22 :exports results
color_count = length(unique(design_data_plot$factors))
get_palette = colorRampPalette(brewer.pal(9, "Set1"))

ggplot(design_data_plot, aes(x = factors, y = metric_value, fill = factors)) +
  facet_grid(id ~ step) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  geom_text(aes(x = factors, y = 0.0, label = factors),
            stat = "identity",
            hjust = "left",
            size = 1,
            angle = 90) +
  theme_bw(base_size = 17) +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_manual(values = get_palette(color_count))
#+end_SRC

#+CAPTION: Values of D\textsubscript{A}-Optimality for all model terms, considering the model formula used at each step
#+LABEL: fig:brices-metric
#+ATTR_LATEX: :width 0.9\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-w5lAu8/figurehpLRFI.pdf]]
** November
*** [2019-11-25 Mon]
**** Gaussian Process Regression on SPAPT kernels      :ExportableReports:
:PROPERTIES:
:EXPORT_FILE_NAME: gpr-spapt-kernels.pdf
:END:
***** Loading Data Functions                                   :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(dplyr)
library(stringr)
library(ggplot2)
library(rPref)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

read_gpr <- function(current_path, application) {
  read_experiment <- function(x) {
    data <- read.csv(x, header = TRUE, stringsAsFactors = FALSE)
    data$experiment_id <- str_split(str_split(x, "/")[[1]][6], "_")[[1]][5]
    return(data)
  }

  current_experiment <- current_path
  target_path <- paste(current_experiment, application, sep = "/")

  data_dir <- target_path
  target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
  data <- NULL

  read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)

    data$experiment_id <- str_split(csv_file, "/")[[1]][6]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$cost_mean == min(data$cost_mean), ])), nrow(data))
    data$iteration <- as.numeric(rownames(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
  }

  for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
      csv_files <- paste0(target_path, csv_files)

      info <- file.info(csv_files)
      non_empty <- rownames(info[info$size != 0, ])
      csv_files <- csv_files[csv_files %in% non_empty]
      target_data <- lapply(csv_files, read.csv.iterations.cost)
      target_data <- bind_rows(target_data)
      target_data$application <- rep(target_dir, nrow(target_data))

      if (is.null(data)) {
        data <- target_data
      } else {
        data <- bind_rows(data, target_data)
      }
    }
  }


  full_data <- data

  plot_data <- data %>%
    group_by(experiment_id) %>%
    mutate(mean_cost_baseline = mean(cost_baseline)) %>%
    mutate(label_center_x = mean(cost_mean)) %>%
    mutate(label_center_y = mean(best_iteration)) %>%
    ungroup()

  complete_plot_data <- plot_data

  return(list(complete_plot_data, full_data))
}

read_rs <- function(current_path, application, complete_plot_data, full_data){
  data_dir <- current_path
  target_dirs <- c(application)
  rs_data <- NULL

  read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(csv_file, "/")[[1]][6]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$cost_mean == min(data$cost_mean), ])), nrow(data))
    data$iteration <- as.numeric(rownames(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
  }

  for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
      csv_files <- paste0(target_path, csv_files)

      info <- file.info(csv_files)
      non_empty <- rownames(info[info$size != 0, ])
      csv_files <- csv_files[csv_files %in% non_empty]
      target_data <- lapply(csv_files, read.csv.iterations.cost)
      target_data <- bind_rows(target_data)
                                        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
      target_data$application <- rep(target_dir, nrow(target_data))

      if (is.null(rs_data)) {
        rs_data <- target_data
      } else {
        rs_data <- bind_rows(rs_data, target_data)
      }
    }
  }

  full_data <- bind_rows(filter(full_data, technique == "GPR"),
                         filter(rs_data, technique == "RS"))

  rs_plot_data <- rs_data %>%
    filter(technique == "RS") %>%
    group_by(experiment_id) %>%
    mutate(mean_cost_baseline = mean(cost_baseline)) %>%
    mutate(label_center_x = mean(cost_mean)) %>%
    mutate(label_center_y = mean(best_iteration)) %>%
    ungroup()

  complete_plot_data <- bind_rows(filter(complete_plot_data, technique == "GPR"),
                                  rs_plot_data)

  return(list(complete_plot_data, full_data))
}
#+end_SRC

#+RESULTS:
#+begin_example

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Warning message:
replacing previous import ‘vctrs::data_frame’ by ‘tibble::data_frame’ when loading ‘dplyr’

Attaching package: ‘rPref’

The following object is masked from ‘package:dplyr’:

    between
Registering fonts with R
#+end_example
***** Results for =bicgkernel=
****** Loading Data                                           :noexport:
#+begin_SRC R :results output :session *R* :exports none
gpr_data <- read_gpr("dlmt_spapt_experiments/data/tests/gpr_expanded_ss", "bicgkernel")
rs_data <- read_rs("dlmt_spapt_experiments/data/tests/rs_baseline", "bicgkernel", gpr_data[[1]], gpr_data[[2]])

complete_plot_data <- rs_data[[1]]
full_data <- rs_data[[2]]
#+end_SRC

#+RESULTS:

****** Figures
#+begin_SRC R :results graphics output :session *R* :file "./img/bicgkernel_gaussian_pareto.pdf" :width 13 :height 10 :exports results
gpr_plot_data <- subset(complete_plot_data, technique == "GPR")

pareto_data <- gpr_plot_data %>%
    group_by(experiment_id) %>%
    psel(low(iteration) * low(cost_mean)) %>%
    ungroup()

gpr_plot_data <- gpr_plot_data %>%
    mutate(first_step = factor(step == 1,
                               levels = c(TRUE, FALSE),
                               labels = c("Sobol sample",
                                          "Optimization")))

ggplot(gpr_plot_data, aes(y = cost_mean, x = iteration)) +
    facet_wrap(experiment_id ~ .) +
    geom_point(aes(color = first_step,
                   shape = first_step),
               size = 2,
               alpha = .45,
               show.legend = TRUE) +
    geom_step(data = pareto_data,
              size = 1.4,
              alpha = 0.5) +
    ylim(0, NA) +
    ylab("Execution Time (s)") +
    xlab("Iteration") +
    theme_bw(base_size = 20) +
    geom_hline(aes(yintercept = mean_cost_baseline[1],
                   linetype = "-O3"),
               stat = "unique",
               size = 0.8,
               color = "blue") +
    scale_linetype_manual(name = "limit", values = c(2),
                          guide = guide_legend(override.aes =
                                                   list(size = 2, color = c("blue")))) +
    scale_color_brewer(palette = "Dark2") +
    scale_y_log10() +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          strip.background = element_blank(),
          strip.text = element_blank(),
          legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1, size = 4)))
#+end_SRC

#+CAPTION: Execution time of points measured by GPR along iterations, with pareto border in red
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:./img/bicgkernel_gaussian_pareto.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports none :eval no-export
gpr_plot_data <- subset(complete_plot_data, technique == "GPR")

pareto_data <- gpr_plot_data %>%
  group_by(experiment_id) %>%
  psel(low(iteration) * low(cost_mean)) %>%
  ungroup()

ggplot(gpr_plot_data, aes(y = cost_mean, x = iteration)) +
  facet_wrap(experiment_id ~ .) +
  geom_point() +
  geom_step(data = pareto_data, color = "red") +
  ylim(0.35, 0.6) +
  ylab("Execution Time") +
  xlab("Iteration") +
  theme_bw(base_size = 18) +
  geom_hline(aes(yintercept = mean_cost_baseline[1], linetype = "-O3"), color = "blue") +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("blue")))) +
  scale_color_brewer(palette = "Set3") +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of points measured by GPR along iterations, with pareto border in red.
#+CAPTION: A closer look at the data from the previous figure
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-TX7U1J/figurenax9MM.pdf]]

#+begin_SRC R :results graphics output :session *R* :file "./img/bicgkernel_rs_pareto.pdf" :width 13 :height 10 :exports results
rs_plot_data <- subset(complete_plot_data, technique == "RS")

pareto_data <- rs_plot_data %>%
    group_by(experiment_id) %>%
    psel(low(iteration) * low(cost_mean)) %>%
    ungroup()

ggplot(rs_plot_data, aes(y = cost_mean, x = iteration)) +
    facet_wrap(experiment_id ~ .) +
    geom_point(alpha = 0.4, stat = "unique") +
    geom_step(data = pareto_data,
              color = "black",
              size = 1.4,
              alpha = 0.5) +
    ylim(0, NA) +
    ylab("Execution Time") +
    xlab("Iteration") +
    theme_bw(base_size = 20) +
    scale_color_brewer(palette = "Set3") +
    geom_hline(aes(yintercept = mean_cost_baseline[1],
                   linetype = "-O3"),
               stat = "unique",
               size = 0.8,
               color = "blue") +
    scale_y_log10() +
    scale_linetype_manual(name = "limit", values = c(2),
                          guide = guide_legend(override.aes =
                                                   list(size = 2, color = c("blue")))) +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          strip.background = element_blank(),
          strip.text = element_blank(),
          legend.title = element_blank()) +
    guides(color = guide_legend(override.aes = list(alpha = 1, size = 4)))
#+end_SRC

#+CAPTION: Execution time of points measured by RS along iterations
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:./img/bicgkernel_rs_pareto.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports none :eval no-export
rs_plot_data <- subset(complete_plot_data, technique == "RS")

pareto_data <- rs_plot_data %>%
  group_by(experiment_id) %>%
  psel(low(iteration) * low(cost_mean)) %>%
  ungroup()


ggplot(rs_plot_data, aes(y = cost_mean, x = iteration)) +
  facet_wrap(experiment_id ~ .) +
  geom_point() +
  geom_step(data = pareto_data, color = "red") +
  ylim(0.35, 0.6) +
  ylab("Execution Time") +
  xlab("Iteration") +
  theme_bw(base_size = 18) +
  scale_color_brewer(palette = "Set3") +
  geom_hline(aes(yintercept = mean_cost_baseline[1], linetype = "-O3"), color = "blue") +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("blue")))) +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of points measured by RS along iterations,
#+CAPTION: a closer look at the data from the previous figure
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-cKpmYZ/figure2AEhBI.pdf]]

#+begin_SRC R :results graphics output :session *R* :file "img/gp_rs_comparison.pdf" :width 13 :height 7.5 :exports none :eval no-export
library(dplyr)

large_plot_data <- complete_plot_data %>%
    dplyr::group_by(technique, experiment_id) %>%
    dplyr::filter(cost_mean == min_run_cost) %>%
    dplyr::ungroup()

alpha <- 0.05

large_plot_data <- large_plot_data %>%
    dplyr::group_by(technique) %>%
    dplyr::mutate(mean_runs = mean(min_run_cost)) %>%
    dplyr::mutate(sd_runs = sd(min_run_cost)) %>%
    dplyr::mutate(ci95_runs = qt((1 - (alpha / 2)), df = n() - 1) *
                      (sd(min_run_cost) /
                       sqrt(n()))) %>%
    dplyr::ungroup()

ggplot(large_plot_data, aes(y = min_run_cost,
                            x = best_iteration,
                            color = technique)) +
    facet_wrap(technique ~ ., scales = "free_x") +
    geom_hline(aes(yintercept = mean_runs),
               linetype = 2,
               size = 0.8) +
    # geom_smooth(method = "lm",
    #             formula = "y ~ 1") +
    geom_ribbon(aes(ymin = mean_runs - ci95_runs,
                    ymax = mean_runs + ci95_runs),
                fill = "grey70",
                alpha = 0.35,
                colour = NA) +
    geom_point(size = 3.5,
               shape = 1,
               show.legend = FALSE) +
    xlab("Iteration finding the Best Point") +
    ylab("Execution Time (s)") +
    # geom_hline(aes(yintercept = mean_cost_baseline[1],
    #                linetype = "-O3"),
    #            color = "black") +
    theme_bw(base_size = 25) +
    scale_color_brewer(palette = "Set1") +
    scale_linetype_manual(name = "limit", values = c(2),
                          guide = guide_legend(override.aes = list(color = c("black")))) +
    theme(strip.background = element_rect(fill = "white"))
#+end_SRC

#+CAPTION: Results with a starting sample of size 15, steps add the 13 best predictions
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:img/gp_rs_comparison.pdf]]

#+begin_SRC R :results graphics output :session *R* :file "img/old_gp_rs_comparison.pdf" :width 13 :height 7.5 :exports none :eval no-export
short_plot_data <- complete_plot_data %>%
    dplyr::group_by(technique, experiment_id) %>%
    dplyr::filter(cost_mean == min_run_cost) %>%
    dplyr::ungroup()

short_plot_data <- short_plot_data %>%
    dplyr::group_by(technique) %>%
    dplyr::mutate(mean_runs = mean(min_run_cost)) %>%
    dplyr::mutate(sd_runs = sd(min_run_cost)) %>%
    dplyr::mutate(ci95_runs = qt((1 - (alpha / 2)), df = n() - 1) *
                      (sd(min_run_cost) /
                       sqrt(n()))) %>%
    dplyr::ungroup()

ggplot(short_plot_data, aes(y = min_run_cost,
                            x = best_iteration,
                            color = technique,
                            group = technique)) +
    facet_wrap(. ~ technique) +
    geom_hline(aes(yintercept = mean_runs),
               linetype = 3) +
    geom_ribbon(aes(ymin = mean_runs - ci95_runs,
                    ymax = mean_runs + ci95_runs),
                fill = "grey70",
                alpha = 0.4,
                colour = NA) +
    # geom_smooth(method = "lm",
    #             formula = "y ~ 1") +
    geom_point(stat = "unique") +
    xlab("Iteration finding the Best Point") +
    ylab("Execution Time (s)") +
    theme_bw(base_size = 24) +
    scale_color_brewer(palette = "Set1") +
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          strip.background = element_rect(fill = "white"),
          legend.title = element_blank())
#+end_SRC

#+CAPTION: Results with a starting sample of size 15, steps add the 13 best predictions,
#+CAPTION: a closer look at the data from the previous figure
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:img/old_gp_rs_comparison.pdf]]
***** Results for =atax=
****** Loading Data                                           :noexport:
#+begin_SRC R :results output :session *R* :exports results
complete_plot_data <- NULL
full_data <- NULL

gpr_data <- read_gpr("dlmt_spapt_experiments/data/tests/gpr_expanded_ss", "atax")
rs_data <- read_rs("dlmt_spapt_experiments/data/tests/rs_baseline", "atax", gpr_data[[1]], gpr_data[[2]])

complete_plot_data <- rs_data[[1]]
full_data <- rs_data[[2]]
#+end_SRC

#+RESULTS:

****** Figures
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
gpr_plot_data <- subset(complete_plot_data, technique == "GPR")

pareto_data <- gpr_plot_data %>%
  group_by(experiment_id) %>%
  psel(low(iteration) * low(cost_mean)) %>%
  ungroup()

gpr_plot_data <- gpr_plot_data %>%
  mutate(first_step = as.factor(step == 1))

ggplot(gpr_plot_data, aes(y = cost_mean, x = iteration)) +
  facet_wrap(experiment_id ~ .) +
  geom_point(aes(color = first_step), alpha = .5, show.legend = FALSE) +
  geom_step(data = pareto_data) +
  ylim(0, NA) +
  ylab("Execution Time") +
  xlab("Iteration") +
  theme_bw(base_size = 18) +
  geom_hline(aes(yintercept = mean_cost_baseline[1], linetype = "-O3"), color = "blue") +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("blue")))) +
  scale_color_brewer(palette = "Set1") +
  scale_y_log10() +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of points measured by GPR along iterations, with pareto border in red
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-TX7U1J/figurek1JPiJ.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10  :exports none :eval no-export
gpr_plot_data <- subset(complete_plot_data, technique == "GPR")

pareto_data <- gpr_plot_data %>%
  group_by(experiment_id) %>%
  psel(low(iteration) * low(cost_mean)) %>%
  ungroup()

ggplot(gpr_plot_data, aes(y = cost_mean, x = iteration)) +
  facet_wrap(experiment_id ~ .) +
  geom_point() +
  geom_step(data = pareto_data, color = "red") +
  ylim(0.0, 2.5) +
  ylab("Execution Time") +
  xlab("Iteration") +
  theme_bw(base_size = 18) +
  geom_hline(aes(yintercept = mean_cost_baseline[1], linetype = "-O3"), color = "blue") +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("blue")))) +
  scale_color_brewer(palette = "Set3") +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of points measured by GPR along iterations, with pareto border in red.
#+CAPTION: A closer look at the data from the previous figure
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-TX7U1J/figureKyVisb.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
rs_plot_data <- subset(complete_plot_data, technique == "RS")

pareto_data <- rs_plot_data %>%
  group_by(experiment_id) %>%
  psel(low(iteration) * low(cost_mean)) %>%
  ungroup()

ggplot(rs_plot_data, aes(y = cost_mean, x = iteration)) +
  facet_wrap(experiment_id ~ .) +
  geom_point() +
  geom_step(data = pareto_data, color = "red") +
  ylim(0, NA) +
  ylab("Execution Time") +
  xlab("Iteration") +
  theme_bw(base_size = 18) +
  scale_color_brewer(palette = "Set3") +
  geom_hline(aes(yintercept = mean_cost_baseline[1], linetype = "-O3"), color = "blue") +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("blue")))) +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of points measured by RS along iterations
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-TX7U1J/figure5ifJok.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports none :eval no-export
rs_plot_data <- subset(complete_plot_data, technique == "RS")

pareto_data <- rs_plot_data %>%
  group_by(experiment_id) %>%
  psel(low(iteration) * low(cost_mean)) %>%
  ungroup()


ggplot(rs_plot_data, aes(y = cost_mean, x = iteration)) +
  facet_wrap(experiment_id ~ .) +
  geom_point() +
  geom_step(data = pareto_data, color = "red") +
  ylim(0.35, 0.6) +
  ylab("Execution Time") +
  xlab("Iteration") +
  theme_bw(base_size = 18) +
  scale_color_brewer(palette = "Set3") +
  geom_hline(aes(yintercept = mean_cost_baseline[1], linetype = "-O3"), color = "blue") +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("blue")))) +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of points measured by RS along iterations,
#+CAPTION: a closer look at the data from the previous figure
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-6kiapU/figure8E0drB.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 7 :exports results
library(dplyr)

large_plot_data <- complete_plot_data %>%
  group_by(technique, experiment_id) %>%
  filter(cost_mean == min_run_cost) %>%
  ungroup()

alpha <- 0.05

# large_plot_data <- large_plot_data %>%
#   group_by(technique) %>%
#   mutate(mean_runs = mean(min_run_cost)) %>%
#   mutate(sd_runs = sd(min_run_cost)) %>%
#   mutate(ci95_runs = qnorm(.95) * (mean(min_run_cost) / sqrt(length(subset(large_plot_data, technique == technique)$cost_mean)))) %>%
#   ungroup()

large_plot_data <- large_plot_data %>%
  group_by(technique) %>%
  mutate(mean_runs = mean(min_run_cost)) %>%
  mutate(sd_runs = sd(min_run_cost)) %>%
  mutate(ci95_runs = qt((1 - (alpha / 2)), df = n() - 1) *
           (sd(min_run_cost) /
            sqrt(n()))) %>%
  ungroup()

ggplot(large_plot_data, aes(y = min_run_cost,
                            x = best_iteration,
                            color = technique)) +
  facet_wrap(technique ~ ., scales = "free_x") +
  geom_hline(aes(yintercept = mean_runs), linetype = 3) +
  # geom_smooth(method = "lm",
  #             formula = "y ~ 1") +
  # geom_ribbon(aes(ymin = mean_runs - sd_runs,
  #                 ymax = mean_runs + sd_runs),
  #             fill = "red",
  #             alpha = 0.1,
  #             colour = NA) +
  geom_ribbon(aes(ymin = mean_runs - ci95_runs,
                  ymax = mean_runs + ci95_runs),
              fill = "grey70",
              alpha = 0.4,
              colour = NA) +
  geom_point(size = 3) +
  xlab("Iteration where Best was Found") +
  ylab("Best Cost in Seconds") +
  # geom_hline(aes(yintercept = mean_cost_baseline[1],
  #                linetype = "-O3"),
  #            color = "black") +
  theme_bw(base_size = 25) +
  scale_color_brewer(palette = "Set1") +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("black")))) +
  theme(legend.position = c(0.8, 0.1),
        legend.direction = "horizontal",
        strip.background = element_rect(fill = "white"),
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Results with a starting sample of size 15, steps add the 13 best predictions
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-TX7U1J/figureMcsVvv.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 7 :exports none :eval no-export
short_plot_data <- complete_plot_data %>%
  group_by(technique) %>%
  mutate(mean_runs = mean(min_run_cost)) %>%
  mutate(sd_runs = sd(min_run_cost)) %>%
  ungroup()

short_plot_data <- short_plot_data %>%
  group_by(technique, experiment_id) %>%
  subset(cost_mean == min_run_cost) %>%
  ungroup()

ggplot(short_plot_data, aes(y = min_run_cost,
                            x = best_iteration,
                            color = technique,
                            group = technique)) +
  facet_wrap(technique ~ .) +
  # geom_hline(aes(yintercept = mean_runs), linetype = 3) +
  # geom_ribbon(aes(ymin = mean_runs - sd_runs, ymax = mean_runs + sd_runs), fill = "grey70", alpha = 0.4, colour = NA) +
  geom_smooth(method = "lm",
              formula = "y ~ 1") +
  geom_point() +
  xlab("Iteration where Best was Found") +
  ylab("Best Cost in Seconds") +
  theme_bw(base_size = 18) +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Results with a starting sample of size 15, steps add the 13 best predictions,
#+CAPTION: a closer look at the data from the previous figure
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-oICNIQ/figure7QGS5X.pdf]]
***** Results for =dgemv=
****** Loading Data                                           :noexport:
#+begin_SRC R :results output :session *R* :exports results
complete_plot_data <- NULL
full_data <- NULL

#gpr_data <- read_gpr("dlmt_spapt_experiments/data/tests/gpr_expanded_ss", "dgemv")
gpr_data <- read_gpr("dlmt_spapt_experiments/data/tests/gpr_trend_sd", "dgemv")
rs_data <- read_rs("dlmt_spapt_experiments/data/tests/rs_baseline", "dgemv", gpr_data[[1]], gpr_data[[2]])

complete_plot_data <- rs_data[[1]]
full_data <- rs_data[[2]]
#+end_SRC

#+RESULTS:
****** Figures
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(ggplot2)
library(dplyr)
library(sensitivity)
library(DiceKriging)

gpr_plot_data <- subset(complete_plot_data, technique == "GPR") %>%
  mutate(first_step = as.factor(step == 1)) %>%
  filter(first_step == TRUE) %>%
  filter(SCR == "True") %>%
  select(-SCR) %>%
  ungroup()

samples <- gpr_plot_data %>%
  select(-id, -technique, -mean_confidence_interval_inf,
         -mean_confidence_interval_sup, -cost_std,
         -baseline, -runs, -step,
         -correct_result, -experiment_id, -cost_baseline, -cost_baseline,
         -speedup,-max_run_speedup, -min_run_cost, -best_iteration,
         -iteration, -points, -application, -mean_cost_baseline,
         -label_center_x, -label_center_y, -first_step) %>%
  mutate_if(is.character, as.factor) %>%
  mutate_if(is.factor, as.numeric)


#km_design <- sample_n(samples, 200)
km_design <- samples

model <- km(design = select(km_design, -cost_mean),
            response = km_design$cost_mean)

x <- sobolGP(model = model,
             type = "UK",
             X1 = samples %>%
               head(n = floor(nrow(.) / 2)) %>%
               select(-cost_mean),
             X2 = samples %>%
               tail(n = floor(nrow(.) / 2)) %>%
               select(-cost_mean),
             nboot = 100)
#+end_SRC

#+RESULTS:
#+begin_example


optimisation start
------------------
,* estimation method   : MLE
,* optimisation method : BFGS
,* analytical gradient : used
,* trend model : ~1
,* covariance model :
  - type :  matern5_2
  - nugget : NO
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10
  - parameters upper bounds :  4094 4094 62 62 2 62 4094 2 4094 4094 62 2 4094 4094 4094 4094 2 2 2 4094 2 4094 2 4094 2 30 30 4094 2 30 30 30 30 30 30 30 30 30 62 62 4094 4094 30 4094 30 62 62 30
  - best initial criterion value(s) :  -712.9143

N = 48, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=       712.91  |proj g|=      0.15272
At iterate     1  f =       712.88  |proj g|=       0.15294
ys=-1.679e-05  -gs= 3.601e-02, BFGS update SKIPPED
At iterate     2  f =       711.11  |proj g|=       0.16401
At iterate     3  f =       708.01  |proj g|=       0.18559
ys=-1.555e-01  -gs= 3.027e+00, BFGS update SKIPPED
At iterate     4  f =       703.39  |proj g|=       0.22168
ys=-4.679e-01  -gs= 4.374e+00, BFGS update SKIPPED
At iterate     5  f =       698.95  |proj g|=       0.25502
ys=-3.892e-01  -gs= 4.231e+00, BFGS update SKIPPED
At iterate     6  f =       690.43  |proj g|=        0.2156
At iterate     7  f =       688.99  |proj g|=        0.1577
At iterate     8  f =          688  |proj g|=      0.010538
At iterate     9  f =       687.94  |proj g|=      0.013195
At iterate    10  f =       687.66  |proj g|=       0.04427
At iterate    11  f =       687.49  |proj g|=      0.023682
At iterate    12  f =       687.24  |proj g|=      0.010114
At iterate    13  f =       687.22  |proj g|=      0.010098
At iterate    14  f =       687.17  |proj g|=      0.010069
At iterate    15  f =       686.88  |proj g|=       0.01359
At iterate    16  f =       686.58  |proj g|=     0.0094514
At iterate    17  f =       686.45  |proj g|=       0.02374
At iterate    18  f =       686.28  |proj g|=       0.03131
At iterate    19  f =       686.14  |proj g|=      0.015667
At iterate    20  f =       685.98  |proj g|=     0.0087571
At iterate    21  f =       685.91  |proj g|=     0.0086694
At iterate    22  f =       685.87  |proj g|=     0.0086355
At iterate    23  f =       685.25  |proj g|=      0.028855
At iterate    24  f =        684.9  |proj g|=      0.015802
At iterate    25  f =       684.16  |proj g|=      0.006761
At iterate    26  f =       682.51  |proj g|=      0.012195
At iterate    27  f =       682.18  |proj g|=     0.0074427
At iterate    28  f =       682.16  |proj g|=     0.0048397
At iterate    29  f =       681.51  |proj g|=      0.046568
At iterate    30  f =       681.47  |proj g|=       0.01972
At iterate    31  f =       681.46  |proj g|=     0.0042831
At iterate    32  f =       681.45  |proj g|=     0.0042837
At iterate    33  f =       681.45  |proj g|=     0.0042772
At iterate    34  f =       681.44  |proj g|=      0.016674
At iterate    35  f =       680.36  |proj g|=       0.03849
At iterate    36  f =       677.18  |proj g|=     0.0067063
At iterate    37  f =          677  |proj g|=     0.0030387
At iterate    38  f =       676.96  |proj g|=     0.0038301
At iterate    39  f =       676.81  |proj g|=     0.0046546
At iterate    40  f =       676.64  |proj g|=      0.063529
At iterate    41  f =       676.54  |proj g|=     0.0050253
At iterate    42  f =       676.39  |proj g|=      0.016501
At iterate    43  f =       675.15  |proj g|=        0.1002
At iterate    44  f =       674.62  |proj g|=      0.063694
At iterate    45  f =       674.47  |proj g|=      0.013433
At iterate    46  f =       674.38  |proj g|=      0.016088
At iterate    47  f =       674.23  |proj g|=      0.045203
At iterate    48  f =       673.83  |proj g|=      0.081005
At iterate    49  f =       672.99  |proj g|=       0.10431
At iterate    50  f =       672.61  |proj g|=      0.053047
At iterate    51  f =       672.01  |proj g|=      0.022967
At iterate    52  f =       671.77  |proj g|=      0.042637
At iterate    53  f =       671.06  |proj g|=      0.071004
At iterate    54  f =       670.98  |proj g|=      0.021088
At iterate    55  f =       670.97  |proj g|=    0.00061831
At iterate    56  f =       670.97  |proj g|=    0.00083355
At iterate    57  f =       670.97  |proj g|=     0.0025396
At iterate    58  f =       670.97  |proj g|=     0.0051888
At iterate    59  f =       670.96  |proj g|=     0.0094556
At iterate    60  f =       670.96  |proj g|=      0.015551
At iterate    61  f =       670.95  |proj g|=      0.023173
At iterate    62  f =       670.93  |proj g|=      0.028516
At iterate    63  f =       670.89  |proj g|=      0.021213
At iterate    64  f =       670.87  |proj g|=      0.014479
At iterate    65  f =       670.83  |proj g|=     0.0023803
At iterate    66  f =       670.77  |proj g|=      0.018208
At iterate    67  f =       670.66  |proj g|=      0.032607
At iterate    68  f =       670.64  |proj g|=     0.0050425
At iterate    69  f =        670.4  |proj g|=     0.0040009
At iterate    70  f =       670.17  |proj g|=     0.0085998
At iterate    71  f =       669.94  |proj g|=     0.0020373
At iterate    72  f =       669.93  |proj g|=     0.0073922
At iterate    73  f =        669.9  |proj g|=      0.021443
At iterate    74  f =       669.81  |proj g|=      0.048122
At iterate    75  f =       669.61  |proj g|=      0.079202
At iterate    76  f =       669.41  |proj g|=      0.080633
At iterate    77  f =       669.22  |proj g|=      0.028117
At iterate    78  f =       669.18  |proj g|=     0.0045062
At iterate    79  f =       669.18  |proj g|=     0.0010684
At iterate    80  f =       669.18  |proj g|=     0.0019219
At iterate    81  f =       669.18  |proj g|=     0.0021834
At iterate    82  f =       669.17  |proj g|=    0.00082061
At iterate    83  f =       669.16  |proj g|=     0.0052274
At iterate    84  f =       669.14  |proj g|=     0.0096021
At iterate    85  f =        669.1  |proj g|=     0.0028422
At iterate    86  f =       669.06  |proj g|=      0.033474
At iterate    87  f =       668.99  |proj g|=      0.026382
At iterate    88  f =       668.66  |proj g|=      0.010887
At iterate    89  f =       668.62  |proj g|=     0.0090599
At iterate    90  f =       668.57  |proj g|=     0.0061299
At iterate    91  f =       668.26  |proj g|=      0.014394
At iterate    92  f =       667.89  |proj g|=      0.028062
At iterate    93  f =       667.26  |proj g|=      0.063625
At iterate    94  f =       666.72  |proj g|=      0.027098
At iterate    95  f =       666.13  |proj g|=      0.011637
At iterate    96  f =       665.98  |proj g|=     0.0075273
At iterate    97  f =       665.86  |proj g|=      0.011719
At iterate    98  f =       665.54  |proj g|=      0.023306
At iterate    99  f =       665.46  |proj g|=         0.026
At iterate   100  f =       665.33  |proj g|=      0.012704
At iterate   101  f =       664.82  |proj g|=       0.01516
final  value 664.821889
stopped after 101 iterations
#+end_example

#+begin_SRC R :results graphics output :session *R* :file "/tmp/figure21213.pdf") :width 13 :height 10 :eval no-export
library(ggplot2)
df <- data.frame(mean = x$S$mean[1, ],
                 var = x$S$var[1, ],
                 varPG = x$S$varPG[1, ],
                 ci = sqrt(x$S$var[1, ]) * 1.96,
                 ci_inf = x$S$ci[1, ],
                 ci_sup = x$S$ci[2, ]
                 )

df <- df %>%
  dplyr::mutate(id = row_number())

ggplot(df) +
  geom_point(aes(x = id, y = mean), size = 4) +
  geom_errorbar(aes(x = id, ymin = mean - ci, ymax = mean + ci)) +
  #geom_errorbar(aes(x = id, ymin = mean - varPG, ymax = mean + varPG)) +
  theme_bw(base_size = 28)
#+end_SRC

#+RESULTS:
[[file:/tmp/figure21213.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
gpr_plot_data <- subset(complete_plot_data, technique == "GPR")

pareto_data <- gpr_plot_data %>%
  group_by(experiment_id, technique) %>%
  psel(low(iteration) * low(cost_mean)) %>%
  ungroup()

gpr_plot_data <- gpr_plot_data %>%
  mutate(first_step = as.factor(step == 1)) %>%
  mutate(scr_on = as.factor(SCR == "True"))

ggplot(gpr_plot_data, aes(y = cost_mean, x = iteration)) +
  #geom_rect(aes(xmin = 1.0, xmax = dim(filter(gpr_plot_data, step == 1))[1], ymin = 1., ymax = 5.), alpha = 0.5) +
  geom_point(aes(color = scr_on), alpha = .5, show.legend = FALSE) +
  geom_step(data = pareto_data) +
  ylim(0, NA) +
  ylab("Execution Time") +
  xlab("Iteration") +
  theme_bw(base_size = 18) +
  geom_hline(aes(yintercept = mean_cost_baseline[1], linetype = "-O3"), color = "blue") +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("blue")))) +
  scale_color_brewer(palette = "Set1") +
  #scale_y_log10() +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank()) +
  facet_wrap(~ experiment_id)
#+end_SRC

#+CAPTION: Execution time of points measured by GPR along iterations, with pareto border in red
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-GhpmaA/figurewW2gDS.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
gpr_plot_data <- subset(complete_plot_data, technique == "GPR")

pareto_data <- gpr_plot_data %>%
  group_by(experiment_id, technique) %>%
  psel(low(iteration) * low(cost_mean)) %>%
  ungroup()

gpr_plot_data <- gpr_plot_data %>%
  mutate(first_step = as.factor(step == 1)) %>%
  mutate(scr_on = as.factor(SCR == "True"))

gpr_plot_data <- gpr_plot_data %>%
    filter(first_step == TRUE) %>%
    select(-scr_on, -first_step, -label_center_y, -label_center_x,
           -mean_cost_baseline, -application, -points, -iteration,
           -best_iteration, -min_run_cost, -max_run_speedup, -speedup,
           -cost_baseline, -experiment_id, -correct_result, -step,
           -cost_mean, -mean_confidence_interval_sup, -baseline, -runs,
           -mean_confidence_interval_inf, -cost_std, -technique, -id) %>%
    mutate(across(where(is.character), as.factor)) %>%
    mutate(across(where(is.factor), as.numeric)) %>%
    gather("Parameter", "Value")

ggplot(gpr_plot_data) +
    geom_histogram(aes(x = Value)) +
    ylab("Execution Time") +
    xlab("Iteration") +
    theme_bw(base_size = 18) +
    facet_wrap(~ Parameter, scale = "free_x")
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-VnHilA/figureqnxBTV.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports none :eval no-export
gpr_plot_data <- subset(complete_plot_data, technique == "GPR")

pareto_data <- gpr_plot_data %>%
  group_by(experiment_id) %>%
  psel(low(iteration) * low(cost_mean)) %>%
  ungroup()

ggplot(gpr_plot_data, aes(y = cost_mean, x = iteration)) +
  facet_wrap(experiment_id ~ .) +
  geom_rect(aes(xmin = 1.0, xmax = 150., ymin = 1., ymax = 5.), alpha = 0.2) +
  geom_point() +
  geom_step(data = pareto_data, color = "red") +
  ylim(0.0, 2.5) +
  ylab("Execution Time") +
  xlab("Iteration") +
  theme_bw(base_size = 18) +
  geom_hline(aes(yintercept = mean_cost_baseline[1], linetype = "-O3"), color = "blue") +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("blue")))) +
  scale_color_brewer(palette = "Set3") +
  scale_y_log10() +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of points measured by GPR along iterations, with pareto border in red.
#+CAPTION: A closer look at the data from the previous figure
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-VnHilA/figure00gRaE.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports results
rs_plot_data <- subset(complete_plot_data, technique == "RS")

pareto_data <- rs_plot_data %>%
  group_by(experiment_id) %>%
  psel(low(iteration) * low(cost_mean)) %>%
  ungroup()

ggplot(rs_plot_data, aes(y = cost_mean, x = iteration)) +
  facet_wrap(experiment_id ~ .) +
  geom_rect(aes(xmin = 1.0, xmax = 150., ymin = 1., ymax = 5.), alpha = 0.2) +
  geom_point() +
  geom_step(data = pareto_data, color = "red") +
  ylim(0, NA) +
  ylab("Execution Time") +
  xlab("Iteration") +
  theme_bw(base_size = 18) +
  scale_color_brewer(palette = "Set3") +
  geom_hline(aes(yintercept = mean_cost_baseline[1], linetype = "-O3"), color = "blue") +
  scale_y_log10() +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("blue")))) +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of points measured by RS along iterations
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-XCC5io/figurenXziDX.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 10 :exports none :eval no-export
rs_plot_data <- subset(complete_plot_data, technique == "RS")

pareto_data <- rs_plot_data %>%
  group_by(experiment_id) %>%
  psel(low(iteration) * low(cost_mean)) %>%
  ungroup()


ggplot(rs_plot_data, aes(y = cost_mean, x = iteration)) +
  facet_wrap(experiment_id ~ .) +
  geom_point() +
  geom_step(data = pareto_data, color = "red") +
  ylim(0.35, 0.6) +
  ylab("Execution Time") +
  xlab("Iteration") +
  theme_bw(base_size = 18) +
  scale_color_brewer(palette = "Set3") +
  geom_hline(aes(yintercept = mean_cost_baseline[1], linetype = "-O3"), color = "blue") +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("blue")))) +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Execution time of points measured by RS along iterations,
#+CAPTION: a closer look at the data from the previous figure
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-6kiapU/figure8E0drB.pdf]]

#+begin_SRC R :results graphics output :session *R* :file "./img/gp_rs_dgemv_comparison.pdf" :width 13 :height 7 :exports results
library(dplyr)

large_plot_data <- complete_plot_data %>%
  group_by(technique, experiment_id) %>%
  filter(cost_mean == min_run_cost) %>%
  ungroup()

alpha <- 0.05

# large_plot_data <- large_plot_data %>%
#   group_by(technique) %>%
#   mutate(mean_runs = mean(min_run_cost)) %>%
#   mutate(sd_runs = sd(min_run_cost)) %>%
#   mutate(ci95_runs = qnorm(.95) * (mean(min_run_cost) / sqrt(length(subset(large_plot_data, technique == technique)$cost_mean)))) %>%
#   ungroup()

large_plot_data <- large_plot_data %>%
  group_by(technique) %>%
  mutate(mean_runs = mean(min_run_cost)) %>%
  mutate(sd_runs = sd(min_run_cost)) %>%
  mutate(ci95_runs = qt((1 - (alpha / 2)), df = n() - 1) *
           (sd(min_run_cost) /
            sqrt(n()))) %>%
  ungroup()

ggplot(large_plot_data, aes(y = min_run_cost,
                            x = best_iteration,
                            color = technique)) +
  facet_wrap(technique ~ ., scales = "free_x") +
  geom_hline(aes(yintercept = mean_runs), linetype = 3) +
  # geom_smooth(method = "lm",
  #             formula = "y ~ 1") +
  # geom_ribbon(aes(ymin = mean_runs - sd_runs,
  #                 ymax = mean_runs + sd_runs),
  #             fill = "red",
  #             alpha = 0.1,
  #             colour = NA) +
  geom_ribbon(aes(ymin = mean_runs - ci95_runs,
                  ymax = mean_runs + ci95_runs),
              fill = "grey70",
              alpha = 0.4,
              colour = NA) +
  geom_point(size = 3) +
  xlab("Iteration where Best was Found") +
  ylab("Best Cost in Seconds") +
  # geom_hline(aes(yintercept = mean_cost_baseline[1],
  #                linetype = "-O3"),
  #            color = "black") +
  theme_bw(base_size = 25) +
  scale_color_brewer(palette = "Set1") +
  scale_linetype_manual(name = "limit", values = c(2),
                        guide = guide_legend(override.aes = list(color = c("black")))) +
  theme(legend.position = c(0.8, 0.1),
        legend.direction = "horizontal",
        strip.background = element_rect(fill = "white"),
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Results with a starting sample of size 15, steps add the 13 best predictions
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:./img/gp_rs_dgemv_comparison.pdf]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".pdf") :width 13 :height 7 :exports none :eval no-export
short_plot_data <- complete_plot_data %>%
  group_by(technique) %>%
  mutate(mean_runs = mean(min_run_cost)) %>%
  mutate(sd_runs = sd(min_run_cost)) %>%
  ungroup()

short_plot_data <- short_plot_data %>%
  group_by(technique, experiment_id) %>%
  subset(cost_mean == min_run_cost) %>%
  ungroup()

ggplot(short_plot_data, aes(y = min_run_cost,
                            x = best_iteration,
                            color = technique,
                            group = technique)) +
  facet_wrap(technique ~ .) +
  # geom_hline(aes(yintercept = mean_runs), linetype = 3) +
  # geom_ribbon(aes(ymin = mean_runs - sd_runs, ymax = mean_runs + sd_runs), fill = "grey70", alpha = 0.4, colour = NA) +
  geom_smooth(method = "lm",
              formula = "y ~ 1") +
  geom_point() +
  xlab("Iteration where Best was Found") +
  ylab("Best Cost in Seconds") +
  theme_bw(base_size = 18) +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.title = element_blank())
#+end_SRC

#+CAPTION: Results with a starting sample of size 15, steps add the 13 best predictions,
#+CAPTION: a closer look at the data from the previous figure
#+LABEL: fig:a
#+ATTR_LATEX: :width 0.65\textwidth :placement [H]
#+RESULTS:
[[file:/tmp/babel-VnHilA/figureOaBE6i.pdf]]
** December
*** [2019-12-10 Tue]
**** Graphs for Gaussian Process Regression
***** Sampling from Multivariate Normal Distributions
****** 2-Dimensional Example
Sampling from  a 2-dimension  normal distribution,  with no  correlation between
dimensions, that is, identity covariance matrix:

|----+-----+-----|
|    |  v1 |  v2 |
|----+-----+-----|
| v1 | 1.0 | 0.0 |
| v2 | 0.0 | 1.0 |
|----+-----+-----|

#+begin_SRC R :results output :session *R*
library(latex2exp)
library(MASS)

n <- 2
sigma <- data.frame(d1 = c(1, 0), d2 = c(0, 1))
means <- c(0, 0)

mv_sample <- mvrnorm(n = 300, means, as.matrix(sigma))
mv_sample <- as.data.frame(mv_sample)
#+end_SRC

#+RESULTS:
#+begin_example

Attaching package: ‘MASS’

The following object is masked from ‘package:patchwork’:

    area

The following object is masked from ‘package:dplyr’:

    select
#+end_example

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
library(ggplot2)
library(GGally)

ggpairs(mv_sample) +
  theme_bw(base_size = 28)
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-oICNIQ/figureUeKgAu.png]]

To get strong correlations, the covariance matrix could be:

|----+-----+-----|
|    |  v1 |  v2 |
|----+-----+-----|
| v1 | 1.0 | 0.8 |
| v2 | 0.8 | 1.0 |
|----+-----+-----|

#+begin_SRC R :results output :session *R*
library(MASS)

n <- 2
sigma <- data.frame(d1 = c(1, 0.8), d2 = c(0.8, 1))
means <- c(0, 0)

mv_sample <- mvrnorm(n = 600, means, as.matrix(sigma))
mv_sample <- as.data.frame(mv_sample)

names(mv_sample) <- paste("V", seq(1, n), sep = "")
#+end_SRC

#+RESULTS:

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
library(ggplot2)
library(GGally)

ggpairs(mv_sample) +
  theme_bw(base_size = 26)
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-oICNIQ/figureiaJjWN.png]]

****** 10-Dimensional Example: Reinterpreting Samples
#+begin_SRC R :results output :session *R*
library(latex2exp)
library(MASS)

n <- 10
sigma <- data.frame(diag(10))
names(sigma) <- paste("d", seq(1, n), sep = "")

means <- rep(0, n)

mv_sample <- mvrnorm(n = 300, means, as.matrix(sigma))
mv_sample <- as.data.frame(mv_sample)

names(mv_sample) <- paste("d", seq(1, n), sep = "")
#+end_SRC

#+RESULTS:

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
library(ggplot2)
library(GGally)

ggpairs(mv_sample) +
  theme_bw(base_size = 22)
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-oICNIQ/figurec4TROr.png]]

#+begin_SRC R :results output :session *R*
library(latex2exp)
library(MASS)

n <- 10
sigma <- data.frame(diag(10))
names(sigma) <- paste("d", seq(1, n), sep = "")

means <- rep(0, n)

mv_sample <- mvrnorm(n = 1000, means, as.matrix(sigma))
mv_sample <- as.data.frame(mv_sample)

names(mv_sample) <- paste("d", seq(1, n), sep = "")
#+end_SRC

#+RESULTS:

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
library(dplyr)
library(tidyr)
library(ggplot2)
library(latex2exp)

plot_data <- mv_sample
sampled_function <- sample_n(plot_data, 1)

plot_data <- plot_data %>%
  gather("x", "f_x") %>%
  mutate(x = ordered(x, levels = names(mv_sample)))

sampled_function <- sampled_function %>%
  gather("x", "f_x") %>%
  mutate(x = ordered(x, levels = names(mv_sample)))

ggplot(plot_data, aes(x = x, y = f_x)) +
  geom_jitter(color = "gray48", size = 3, width = 0.25, alpha = 0.2) +
  geom_point(data = sampled_function,
             aes(color = "Sample of Multivariate Normal"),
             size = 4) +
  geom_line(data = sampled_function,
            color = "red",
            size = 1,
            alpha = 0.3) +
  ylab(TeX("Sampled Values")) +
  xlab(TeX("Dimensions")) +
  scale_fill_manual("", values = "gray48") +
  scale_color_brewer(palette = "Set1") +
  theme_bw(base_size = 26) +
  theme(legend.title = element_blank(),
        legend.background = element_rect(fill = "transparent"),
        legend.position = c(0.24, 0.06))

#+end_SRC

#+RESULTS:
[[file:/tmp/babel-oICNIQ/figureNntbaA.png]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
library(dplyr)
library(tidyr)
library(ggplot2)
library(latex2exp)

n <- 10

plot_data <- mv_sample
names(plot_data) <- seq(1, n)

sampled_function <- sample_n(plot_data, 1)

plot_data <- plot_data %>%
  gather("x", "f_x") %>%
  mutate(x = as.numeric(x))

sampled_function <- sampled_function %>%
  gather("x", "f_x") %>%
  mutate(x = as.numeric(x))

ggplot(plot_data, aes(x = x, y = f_x)) +
  geom_jitter(color = "gray48", size = 3, width = 0.25, alpha = 0.2) +
  geom_point(data = sampled_function,
             aes(color = "Sampled Function"),
             size = 4) +
  geom_line(data = sampled_function,
            color = "red",
            size = 1,
            alpha = 0.3) +
  ylab(TeX("Samples of $(d_1,\\ldots,d_{10})$ interpreted as $f(x \\in \\lbrack 1,10 \\rbrack)$")) +
  xlab(TeX("$(d_1,\\ldots,d_{10})$ interpreted as discrete $x \\in \\lbrack 1,10 \\rbrack$")) +
  scale_x_discrete(limits = seq(1, 10)) +
  scale_fill_manual("", values = "gray48") +
  scale_color_brewer(palette = "Set1") +
  theme_bw(base_size = 26) +
  theme(legend.title = element_blank(),
        legend.background = element_rect(fill = "transparent"),
        legend.position = c(0.2, 0.06))

#+end_SRC

#+RESULTS:
[[file:/tmp/babel-oICNIQ/figure128cP4.png]]

***** Sampling Functions
#+begin_SRC R :results output :session *R*
d <- 2
n <- 30

target_X <- expand.grid(x1 = seq(-1, 1, length = n), x2 = seq(-1, 1, length = n))
#+end_SRC

#+RESULTS:

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
library(ggplot2)
library(GGally)

ggpairs(target_X) +
  theme_bw(base_size = 26)
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-oICNIQ/figure1PC6N4.png]]

#+begin_SRC R :results output :session *R*
library(Rcpp)
library(dplyr)
library(MASS)

src <-
"#include <Rcpp.h>
#include <math.h>

using namespace Rcpp;

// [[Rcpp::export]]
NumericMatrix rcpp_squared_exponential_kernel(NumericMatrix x,
                                              NumericMatrix y,
                                              float amplitude,
                                              NumericVector lengthscale){
  NumericMatrix output(x.nrow(), y.nrow());
  float distance;

  for(int i = 0; i < x.nrow(); i++) {
    for(int j = 0; j < y.nrow(); j++) {
      distance = 0;
      for(int k = 0; k < x.ncol(); k++) {
        distance += (((x(i, k) - y(j, k)) *
                      (x(i, k) - y(j, k))) /
                      (lengthscale(k) * lengthscale(k)));
      }

      output(i, j) = amplitude *
                     amplitude *
                     exp(-0.5 * distance);
    }
  }
  return(output);
}"

sourceCpp(code = src)

random_design <- function(factors, size) {
  data.frame(replicate(factors, runif(size)))
}

simulate_gp <- function(covariance_matrix) {
  return(unname(mvrnorm(n = 1,
                        rep(0.0, nrow(covariance_matrix)),
                        covariance_matrix)))
}

sqexp_covariance_matrix <- function(data, amplitude, lengthscale) {
  return(rcpp_squared_exponential_kernel(as.matrix(data),
                                         as.matrix(data),
                                         amplitude,
                                         lengthscale))
}

significance_probability <- 0.10
amplitude <- 1.0
lengthscale <- rep(0.2, n)

cov_matrix <- sqexp_covariance_matrix(target_X, amplitude, lengthscale)
plot_data <- target_X
#+end_SRC

#+RESULTS:

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
library(DiceKriging)
library(dplyr)
library(RColorBrewer)
library(lattice)

se_kernel <- function(x, x_p, l = 0.2) {
  return(exp(-(
    ((x - x_p) ^ 2) /
    ((2 * l) ^ 2)
  )))
}

d <- 2
n <- 32

point_grid <- data.frame(x1 = seq(-1, 1, length = n), x2 = rep(0, n))
evaluated_grid <- data.frame(point_grid)

evaluated_grid$y <- se_kernel(point_grid$x1, point_grid$x2)

colors = colorRampPalette(brewer.pal(11, "RdYlBu"))(69)

ggplot(evaluated_grid, aes(x = x1, y = y)) +
  geom_point() +
  theme_bw(base_size = 18)
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-oICNIQ/figureGmKWqY.png]]

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
library(lattice)
library(RColorBrewer)

plot_data$y <- simulate_gp(cov_matrix)

colors = colorRampPalette(brewer.pal(11, "RdYlBu"))(69)

wireframe(y ~ x1 * x2,
          data = plot_data,
          xlab = "x1",
          ylab = "x2",
          zlab = list("k(x,x')",
                      rot = "90"),
          #zlim = range(seq(0.0, 1.0, by = 0.5)),
          colorkey = FALSE,
          col.regions = colors,
          drape = TRUE,
          #shade = TRUE,
          lattice.options = lattice.options(list(border = FALSE)),
          scales = list(arrows = FALSE),
          screen = list(z = 20, x = -60, y = 0),
          par.settings = list(axis.line = list(col = "transparent")))
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-oICNIQ/figureoOKTS3.png]]

***** Regression, Sampling, EI
#+begin_SRC R :results output :session *R*
library(ggplot2)
library(dplyr)
library(DiceKriging)
library(DiceOptim)

gpr_data <- data.frame(x = c(0.1, 0.25, 0.3, 0.67, 0.8),
                       y = c(0.1, 0.1, 0.6, -0.02, 0.1))

# gpr_data <- data.frame(x = c(0.45, 0.5, 0.55),
#                        y = c(-0.1, 0.08, 0.2))

x_allowed <- data.frame(x = seq(0, 1, length = 300))

# reg <- km(formula = ~ I(x^2), design = dplyr::select(gpr_data, -y),
#           control = list(pop.size = 40,
#                          BFGSburnin = 4),
#           response = gpr_data$y)

reg <- km(design = dplyr::select(gpr_data, -y),
          control = list(pop.size = 400,
                         BFGSburnin = 400),
          response = gpr_data$y)

pred <- predict(reg, x_allowed, "UK")

x_allowed$y <- pred$mean
x_allowed$ymin <- pred$mean - (2 * pred$sd)
x_allowed$ymax <- pred$mean + (2 * pred$sd)
x_allowed$ei <- apply(dplyr::select(x_allowed, x), 1, EI, reg)
x_allowed$sampled_y <- simulate(reg, cond = TRUE, newdata = dplyr::select(x_allowed, x))[1, ]
x_allowed$uncond_y <- simulate(reg, cond = FALSE, newdata = dplyr::select(x_allowed, x))[1, ]
#+end_SRC

#+RESULTS:
#+begin_example


optimisation start
------------------
,* estimation method   : MLE
,* optimisation method : BFGS
,* analytical gradient : used
,* trend model : ~1
,* covariance model :
  - type :  matern5_2
  - nugget : NO
  - parameters lower bounds :  1e-10
  - parameters upper bounds :  1.4
  - best initial criterion value(s) :  0.5438007

N = 1, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=      -0.5438  |proj g|=   1.6681e-60
Derivative >= 0, backtracking line search impossible.final  value -0.543801
stopped after 0 iterations
#+end_example

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
ggplot(data = gpr_data, aes(x = x, y = y)) +
  geom_ribbon(data = x_allowed, aes(x = x, ymin = ymin, ymax = ymax, fill = "CI of the Mean"), alpha = 0.3) +
  geom_line(data = x_allowed, size = 1, aes(color = "Predicted Mean")) +
  #geom_line(data = x_allowed, size = 1, aes(x = x, y = sampled_y, color = "Conditioned Sample")) +
  #geom_line(data = x_allowed, size = 1, aes(x = x, y = uncond_y, color = "Prior Sample")) +
  geom_line(data = x_allowed, size = 1, aes(x = x, y = ei, color = "Expected Improvement")) +
  geom_point(stroke = 2, shape = 3, size = 3, aes(color = "Observed")) +
  geom_point(data = subset(x_allowed, ei == max(ei)), size = 4, stroke = 2, shape = 3, aes(x = x, y = ei, color = "Maximum EI")) +
  scale_color_brewer(palette = "Set1") +
  scale_fill_manual("", values = "gray48") +
  theme_bw(base_size = 26) +
  theme(legend.title = element_blank(),
        legend.background = element_rect(fill = "transparent"),
        legend.position = c(0.2, 0.2))
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-VOewyd/figure4dUwKd.png]]

**** Plotting Covariance Kernels
***** Constant
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
library(DiceKriging)
library(dplyr)
library(lattice)

constant_kernel <- function(x) {
  return(1.0)
}

d <- 2
n <- 16

point_grid <- expand.grid(x1 = seq(0, 1, length = n), x2 = seq(0, 1, length = n))
evaluated_grid <- data.frame(point_grid)

evaluated_grid$y <- apply(point_grid, 1, constant_kernel)

str(evaluated_grid)

colors = colorRampPalette(brewer.pal(11, "RdYlBu"))(69)

wireframe(y ~ x1 * x2,
          data = evaluated_grid,
          xlab = "x1",
          ylab = "x2",
          zlab = list("k(x,x')",
                      rot = "90"),
          zlim = range(seq(0.0, 2.0, by = 0.5)),
          colorkey = FALSE,
          col.regions = colors,
          drape = TRUE,
          #shade = TRUE,
          lattice.options = lattice.options(list(border = FALSE)),
          scales = list(arrows = FALSE),
          screen = list(z = 140, x = -60, y = 0),
          par.settings = list(axis.line = list(col = "transparent")))
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-jn9WIm/figure7Zu2B4.png]]
***** Squared Exponential
#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
library(DiceKriging)
library(dplyr)
library(lattice)

se_kernel <- function(x, x_p, l = 0.2) {
  return(exp(-(
    ((x - x_p) ^ 2) /
    ((2 * l) ^ 2)
  )))
}

d <- 2
n <- 32

point_grid <- data.frame(x1 = seq(-1, 1, length = n), x2 = rep(0, n))
evaluated_grid <- data.frame(point_grid)

evaluated_grid$y <- se_kernel(point_grid$x1, point_grid$x2)

colors = colorRampPalette(brewer.pal(11, "RdYlBu"))(69)

ggplot(evaluated_grid, aes(x = x1, y = y)) +
  geom_point() +
  theme_bw(base_size = 18)
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-jn9WIm/figurehyJIns.png]]
*** [2019-12-19 Thu]
**** Estimating GPR Parameters using RS Data
***** Loading Data                                             :noexport:
#+HEADER: :results output :session *R* :exports none
#+BEGIN_SRC R
library(plyr)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(rPref)
library(reshape2)
library(openssl)
library(RColorBrewer)
library(extrafont)

# data_dir <- "dlmt_spapt_experiments/data/results"
# data_dir <- "dlmt_spapt_experiments/data/tests/no_binary_random"
# data_dir <- "dlmt_spapt_experiments/data/results"
data_dir <- "dlmt_spapt_experiments/data/tests/random_300_graoully_debnew"
#target_dirs <- list.dirs(path = data_dir, full.names = FALSE, recursive = FALSE)
target_dirs <- c("bicgkernel")
rs_data <- NULL

read.csv.iterations.cost <- function(csv_file) {
    data <- read.csv(csv_file, header = TRUE, stringsAsFactor = FALSE)
    data$experiment_id <- str_split(csv_file, "/")[[1]][6]
    data_baseline <- data[data$baseline == "True", "cost_mean"]
    data$cost_baseline <- rep(data_baseline, nrow(data))
    data$speedup <- data_baseline / data$cost_mean
    data$max_run_speedup <- rep(max(data$speedup), nrow(data))
    data$min_run_cost <- rep(min(data$cost_mean), nrow(data))

    data <- data[data$baseline == "False", ]
    data <- data[data$correct_result == "True", ]

    data$best_iteration <- rep(as.numeric(rownames(data[data$cost_mean == min(data$cost_mean), ])), nrow(data))
    data$iteration <- as.numeric(rownames(data))
    data$points <- rep(nrow(data), nrow(data))

    return(data)
}

for (target_dir in target_dirs) {
    target_path <- paste(data_dir, "/", target_dir, "/", sep = "")

    csv_files <- list.files(path = target_path, pattern = "search_space.csv", recursive = TRUE)
    if (length(csv_files) != 0) {
        csv_files <- paste0(target_path, csv_files)

        info <- file.info(csv_files)
        non_empty <- rownames(info[info$size != 0, ])
        csv_files <- csv_files[csv_files %in% non_empty]
        target_data <- lapply(csv_files, read.csv.iterations.cost)
        target_data <- bind_rows(target_data)
        # target_data <- target_data[, c("cost_mean", "experiment_id", "technique", "cost_baseline", "min_run_cost", "best_iteration")]
        target_data$application <- rep(target_dir, nrow(target_data))

        if (is.null(rs_data)) {
            rs_data <- target_data
        } else {
            rs_data <- bind_rows(rs_data, target_data)
        }
    }
}

full_data <- filter(rs_data, technique == "RS", application == "bicgkernel")

rs_plot_data <- rs_data %>%
  filter(technique == "RS", application == "bicgkernel") %>%
  group_by(experiment_id) %>%
  mutate(mean_cost_baseline = mean(cost_baseline)) %>%
  mutate(label_center_x = mean(cost_mean)) %>%
  mutate(label_center_y = mean(best_iteration)) %>%
  ungroup()

complete_plot_data <- rs_plot_data

str(complete_plot_data)
#+end_SRC

#+RESULTS:
#+begin_example

Classes ‘tbl_df’, ‘tbl’ and 'data.frame':	11927 obs. of  35 variables:
 $ id                          : int  1 2 3 4 5 6 7 8 10 11 ...
 $ T2_J                        : int  512 128 1 4 1 1024 2048 16 128 1024 ...
 $ T2_I                        : int  1 1024 16 2048 2048 32 512 16 256 32 ...
 $ RT_I                        : int  4 1 2 1 1 1 4 32 1 1 ...
 $ mean_confidence_interval_inf: num  3.844 0.439 0.574 0.432 5.218 ...
 $ baseline                    : chr  "False" "False" "False" "False" ...
 $ T1_J                        : int  32 2 32 4 4 64 2048 1 64 512 ...
 $ technique                   : chr  "RS" "RS" "RS" "RS" ...
 $ VEC2                        : chr  "True" "False" "True" "False" ...
 $ VEC1                        : chr  "False" "False" "True" "True" ...
 $ SCR                         : chr  "False" "False" "False" "True" ...
 $ U1_I                        : int  16 26 11 18 24 17 20 5 10 27 ...
 $ RT_J                        : int  16 2 4 32 8 4 2 4 4 4 ...
 $ T1_I                        : int  128 8 4 16 2048 1 1 1 8 16 ...
 $ runs                        : int  10 10 10 10 10 10 10 10 10 10 ...
 $ cost_std                    : num  0.11057 0.15496 0.09848 0.11809 0.00476 ...
 $ cost_mean                   : num  3.912 0.535 0.635 0.505 5.221 ...
 $ U_J                         : int  21 1 24 1 15 1 2 17 29 11 ...
 $ U_I                         : int  1 8 1 12 1 1 1 1 1 1 ...
 $ step                        : int  1 1 1 1 1 1 1 1 1 1 ...
 $ correct_result              : chr  "True" "True" "True" "True" ...
 $ OMP                         : chr  "False" "True" "True" "True" ...
 $ mean_confidence_interval_sup: num  3.981 0.631 0.696 0.578 5.224 ...
 $ experiment_id               : chr  "xeon_e5_2630_v3_graoully-10_1573846466" "xeon_e5_2630_v3_graoully-10_1573846466" "xeon_e5_2630_v3_graoully-10_1573846466" "xeon_e5_2630_v3_graoully-10_1573846466" ...
 $ cost_baseline               : num  4.58 4.58 4.58 4.58 4.58 ...
 $ speedup                     : num  1.172 8.57 7.215 9.075 0.878 ...
 $ max_run_speedup             : num  10 10 10 10 10 ...
 $ min_run_cost                : num  0.458 0.458 0.458 0.458 0.458 ...
 $ best_iteration              : num  146 146 146 146 146 146 146 146 146 146 ...
 $ iteration                   : num  1 2 3 4 5 6 7 8 10 11 ...
 $ points                      : int  297 297 297 297 297 297 297 297 297 297 ...
 $ application                 : chr  "bicgkernel" "bicgkernel" "bicgkernel" "bicgkernel" ...
 $ mean_cost_baseline          : num  4.58 4.58 4.58 4.58 4.58 ...
 $ label_center_x              : num  2.1 2.1 2.1 2.1 2.1 ...
 $ label_center_y              : num  146 146 146 146 146 146 146 146 146 146 ...
#+end_example
***** Analyzing Data
#+begin_SRC R :results output :session *R*
results_data <- select(complete_plot_data,
                       OMP, SCR, VEC1, VEC2,
                       RT_I, RT_J, U1_I, T1_I,
                       T1_J, T2_I, T2_J, U_I, U_J,
                       cost_mean)
#+end_SRC

#+RESULTS:

#+begin_SRC R :results output :session *R*
summary(aov(cost_mean ~ .*., results_data))
#+end_SRC

#+RESULTS:
#+begin_example
               Df Sum Sq Mean Sq   F value   Pr(>F)
OMP             1  19192   19192 38112.189  < 2e-16 ***
SCR             1   3272    3272  6498.543  < 2e-16 ***
VEC1            1      0       0     0.001 0.970549
VEC2            1      1       1     1.624 0.202602
RT_I            1    169     169   336.253  < 2e-16 ***
RT_J            1     65      65   129.166  < 2e-16 ***
U1_I            1      0       0     0.283 0.594502
T1_I            1      5       5     9.617 0.001933 **
T1_J            1     36      36    71.053  < 2e-16 ***
T2_I            1      2       2     3.997 0.045608 *
T2_J            1     12      12    24.159 8.99e-07 ***
U_I             1     64      64   127.359  < 2e-16 ***
U_J             1     59      59   117.487  < 2e-16 ***
OMP:SCR         1   2844    2844  5647.467  < 2e-16 ***
OMP:VEC1        1      0       0     0.259 0.611151
OMP:VEC2        1      1       1     2.758 0.096771 .
OMP:RT_I        1    150     150   298.553  < 2e-16 ***
OMP:RT_J        1     62      62   123.269  < 2e-16 ***
OMP:U1_I        1      0       0     0.092 0.761103
OMP:T1_I        1      5       5     9.749 0.001799 **
OMP:T1_J        1     35      35    69.874  < 2e-16 ***
OMP:T2_I        1      3       3     5.981 0.014475 *
OMP:T2_J        1     10      10    20.631 5.62e-06 ***
OMP:U_I         1     45      45    88.417  < 2e-16 ***
OMP:U_J         1     43      43    84.456  < 2e-16 ***
SCR:VEC1        1      1       1     1.040 0.307732
SCR:VEC2        1      2       2     3.950 0.046888 *
SCR:RT_I        1     10      10    19.513 1.01e-05 ***
SCR:RT_J        1      1       1     1.041 0.307683
SCR:U1_I        1      0       0     0.809 0.368458
SCR:T1_I        1      0       0     0.944 0.331208
SCR:T1_J        1     14      14    26.834 2.25e-07 ***
SCR:T2_I        1      0       0     0.061 0.804390
SCR:T2_J        1     11      11    22.349 2.30e-06 ***
SCR:U_I         1      2       2     4.720 0.029841 *
SCR:U_J         1      1       1     1.997 0.157646
VEC1:VEC2       1      0       0     0.068 0.793657
VEC1:RT_I       1      0       0     0.526 0.468237
VEC1:RT_J       1      0       0     0.267 0.605334
VEC1:U1_I       1      0       0     0.306 0.580000
VEC1:T1_I       1      1       1     1.181 0.277249
VEC1:T1_J       1      0       0     0.371 0.542290
VEC1:T2_I       1      0       0     0.001 0.976130
VEC1:T2_J       1      0       0     0.935 0.333683
VEC1:U_I        1      0       0     0.332 0.564436
VEC1:U_J        1      0       0     0.240 0.624535
VEC2:RT_I       1      2       2     4.620 0.031620 *
VEC2:RT_J       1      0       0     0.109 0.740790
VEC2:U1_I       1      0       0     0.742 0.389009
VEC2:T1_I       1      2       2     3.216 0.072926 .
VEC2:T1_J       1      0       0     0.470 0.493163
VEC2:T2_I       1      0       0     0.158 0.690606
VEC2:T2_J       1      0       0     0.429 0.512448
VEC2:U_I        1      1       1     2.582 0.108095
VEC2:U_J        1      0       0     0.576 0.447972
RT_I:RT_J       1     43      43    85.147  < 2e-16 ***
RT_I:U1_I       1      1       1     1.256 0.262507
RT_I:T1_I       1      5       5     9.666 0.001881 **
RT_I:T1_J       1      4       4     7.960 0.004791 **
RT_I:T2_I       1      3       3     5.370 0.020508 *
RT_I:T2_J       1      4       4     7.676 0.005605 **
RT_I:U_I        1      3       3     5.409 0.020053 *
RT_I:U_J        1      1       1     2.243 0.134269
RT_J:U1_I       1      0       0     0.031 0.859404
RT_J:T1_I       1      6       6    11.039 0.000895 ***
RT_J:T1_J       1      0       0     0.282 0.595687
RT_J:T2_I       1      0       0     0.433 0.510771
RT_J:T2_J       1      1       1     1.434 0.231172
RT_J:U_I        1      0       0     0.217 0.641335
RT_J:U_J        1      0       0     0.585 0.444387
U1_I:T1_I       1      1       1     1.514 0.218576
U1_I:T1_J       1      1       1     2.152 0.142439
U1_I:T2_I       1      0       0     0.087 0.768016
U1_I:T2_J       1      4       4     7.919 0.004899 **
U1_I:U_I        1      0       0     0.635 0.425402
U1_I:U_J        1      0       0     0.107 0.743765
T1_I:T1_J       1      1       1     1.064 0.302230
T1_I:T2_I       1      4       4     8.085 0.004471 **
T1_I:T2_J       1      0       0     0.116 0.733167
T1_I:U_I        1      0       0     0.084 0.772076
T1_I:U_J        1      1       1     2.303 0.129124
T1_J:T2_I       1      0       0     0.390 0.532562
T1_J:T2_J       1      7       7    13.810 0.000203 ***
T1_J:U_I        1      6       6    12.445 0.000421 ***
T1_J:U_J        1      5       5    10.613 0.001126 **
T2_I:T2_J       1      0       0     0.073 0.786504
T2_I:U_I        1      0       0     0.233 0.629516
T2_I:U_J        1      1       1     2.282 0.130881
T2_J:U_I        1      3       3     4.965 0.025886 *
T2_J:U_J        1      0       0     0.329 0.566421
Residuals   11836   5960       1
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#+end_example

#+begin_SRC R :results output :session *R*
nobin_results_data <- results_data %>%
                      filter(OMP == "True", SCR == "True",
                             VEC1 == "True", VEC2 == "True") %>%
                      select(-OMP, -VEC1,
                             -VEC2, -SCR)

summary(aov(cost_mean ~ .*., nobin_results_data))
#+end_SRC

#+RESULTS:
#+begin_example

             Df Sum Sq Mean Sq F value   Pr(>F)
RT_I          1  0.002 0.00151   0.263  0.60846
RT_J          1  0.128 0.12832  22.306 2.84e-06 ***
U1_I          1  0.006 0.00619   1.076  0.30006
T1_I          1  0.109 0.10865  18.887 1.60e-05 ***
T1_J          1  0.013 0.01290   2.242  0.13482
T2_I          1  0.026 0.02609   4.535  0.03357 *
T2_J          1  0.006 0.00608   1.057  0.30423
U_I           1  0.057 0.05742   9.982  0.00165 **
U_J           1  0.055 0.05450   9.474  0.00217 **
RT_I:RT_J     1  0.059 0.05861  10.187  0.00148 **
RT_I:U1_I     1  0.043 0.04340   7.544  0.00618 **
RT_I:T1_I     1  0.002 0.00154   0.267  0.60549
RT_I:T1_J     1  0.000 0.00016   0.028  0.86628
RT_I:T2_I     1  0.031 0.03055   5.311  0.02150 *
RT_I:T2_J     1  0.001 0.00096   0.167  0.68337
RT_I:U_I      1  0.002 0.00151   0.262  0.60909
RT_I:U_J      1  0.002 0.00162   0.281  0.59596
RT_J:U1_I     1  0.004 0.00402   0.698  0.40370
RT_J:T1_I     1  0.000 0.00044   0.076  0.78225
RT_J:T1_J     1  0.014 0.01435   2.495  0.11469
RT_J:T2_I     1  0.004 0.00413   0.718  0.39700
RT_J:T2_J     1  0.001 0.00137   0.238  0.62601
RT_J:U_I      1  0.000 0.00014   0.025  0.87394
RT_J:U_J      1  0.015 0.01523   2.647  0.10421
U1_I:T1_I     1  0.000 0.00048   0.083  0.77362
U1_I:T1_J     1  0.001 0.00129   0.224  0.63606
U1_I:T2_I     1  0.016 0.01631   2.835  0.09271 .
U1_I:T2_J     1  0.005 0.00464   0.807  0.36947
U1_I:U_I      1  0.001 0.00057   0.099  0.75268
U1_I:U_J      1  0.001 0.00094   0.164  0.68540
T1_I:T1_J     1  0.003 0.00301   0.523  0.47001
T1_I:T2_I     1  0.000 0.00012   0.021  0.88580
T1_I:T2_J     1  0.000 0.00019   0.032  0.85730
T1_I:U_I      1  0.000 0.00009   0.015  0.90240
T1_I:U_J      1  0.003 0.00323   0.562  0.45385
T1_J:T2_I     1  0.019 0.01927   3.349  0.06769 .
T1_J:T2_J     1  0.017 0.01686   2.930  0.08739 .
T1_J:U_I      1  0.005 0.00468   0.814  0.36729
T1_J:U_J      1  0.000 0.00033   0.058  0.80961
T2_I:T2_J     1  0.016 0.01560   2.713  0.10004
T2_I:U_I      1  0.001 0.00127   0.220  0.63927
T2_I:U_J      1  0.001 0.00131   0.227  0.63385
T2_J:U_I      1  0.006 0.00608   1.056  0.30450
T2_J:U_J      1  0.002 0.00159   0.276  0.59942
Residuals   664  3.820 0.00575
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#+end_example
***** Estimating GPR Kernel Parameters
#+begin_SRC R :results output :session *R*
results_data <- select(complete_plot_data,
                       OMP, SCR, VEC1, VEC2,
                       RT_I, RT_J, U1_I, T1_I,
                       T1_J, T2_I, T2_J, U_I, U_J,
                       cost_mean)
#+end_SRC

#+RESULTS:

#+begin_SRC R :results output :session *R*
library(DiceKriging)
library(dplyr)
library(rsm)

sampled_results_data <- sample_n(results_data, 5000)

sampled_results_data <- sampled_results_data %>% mutate_all(funs(str_replace(., "True", "1"))) %>%
  mutate_all(funs(str_replace(., "False", "0"))) %>%
  mutate_all(funs(as.integer(.)))

coded_sampled_design <- coded.data(select(sampled_results_data, -cost_mean),
                                   formulas = list(T1_Ie = T1_Ie ~ (T1_I - 5.5) / 5.5,
                                                   T1_Je = T1_Je ~ (T1_J - 5.5) / 5.5,
                                                   U_Je = U_Je ~ (U_J - 14.5) / 14.5,
                                                   U_Ie = U_Ie ~ (U_I - 14.5) / 14.5,
                                                   T2_Ie = T2_Ie ~ (T2_I - 5.5) / 5.5,
                                                   T2_Je = T2_Je ~ (T2_J - 5.5) / 5.5,
                                                   U1_Ie = U1_Ie ~ (U1_I - 14.5) / 14.5,
                                                   OMPe = OMPe ~ (OMP - 0.5) / 0.5,
                                                   SCRe = SCRe ~ (SCR - 0.5) / 0.5,
                                                   VEC1e = VEC1e ~ (VEC1 - 0.5) / 0.5,
                                                   VEC2e = VEC2e ~ (VEC2 - 0.5) / 0.5,
                                                   RT_Ie = RT_Ie ~ (RT_I - 2.5) / 2.5,
                                                   RT_Je = RT_Je ~ (RT_J - 2.5) / 2.5))

reg <- km(design = coded_sampled_design,
          response = sampled_results_data$cost_mean)
#+end_SRC

#+RESULTS:
#+begin_example


optimisation start
------------------
,* estimation method   : MLE
,* optimisation method : BFGS
,* analytical gradient : used
,* trend model : ~1
,* covariance model :
  - type :  matern5_2
  - nugget : NO
  - parameters lower bounds :  1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10 1e-10
  - parameters upper bounds :  4 4 4 4 24.8 24.8 4 744.3636 744.3636 744.3636 744.3636 4 4
  - best initial criterion value(s) :  -7562.03

N = 13, M = 5 machine precision = 2.22045e-16
At X0, 0 variables are exactly at the bounds
At iterate     0  f=         7562  |proj g|=        24.25
At iterate     1  f =       7413.9  |proj g|=        23.848
At iterate     2  f =       7392.2  |proj g|=        23.778
At iterate     3  f =       7325.1  |proj g|=        9.7341
At iterate     4  f =       7296.3  |proj g|=        9.6407
At iterate     5  f =       6766.4  |proj g|=        6.9176
At iterate     6  f =       6709.6  |proj g|=        7.5269
At iterate     7  f =       6694.2  |proj g|=        7.5742
At iterate     8  f =       6663.7  |proj g|=        7.5463
At iterate     9  f =       6620.9  |proj g|=        6.3228
At iterate    10  f =       6571.9  |proj g|=         5.853
At iterate    11  f =       6533.7  |proj g|=        5.0285
At iterate    12  f =       6464.6  |proj g|=        5.2125
At iterate    13  f =       6342.8  |proj g|=         7.443
At iterate    14  f =       6324.5  |proj g|=        7.3488
At iterate    15  f =       6323.4  |proj g|=        7.3507
At iterate    16  f =       6321.3  |proj g|=        7.4102
At iterate    17  f =       6318.6  |proj g|=        7.4496
At iterate    18  f =       6316.4  |proj g|=        7.3897
At iterate    19  f =       6313.5  |proj g|=        7.5038
At iterate    20  f =       6310.5  |proj g|=        7.7871
At iterate    21  f =       6310.2  |proj g|=        7.7868
At iterate    22  f =       6309.9  |proj g|=        7.7872
At iterate    23  f =       6308.1  |proj g|=        7.7314
At iterate    24  f =       6303.1  |proj g|=        6.9893
At iterate    25  f =         6301  |proj g|=        6.9916
At iterate    26  f =       6300.5  |proj g|=        6.9778
At iterate    27  f =       6297.4  |proj g|=        6.9241
At iterate    28  f =       6290.7  |proj g|=        6.7774
At iterate    29  f =       6283.6  |proj g|=        6.5873
At iterate    30  f =       6282.4  |proj g|=        6.4988
At iterate    31  f =       6282.2  |proj g|=        6.4529
At iterate    32  f =       6281.9  |proj g|=        6.4503
At iterate    33  f =       6280.7  |proj g|=         6.434
At iterate    34  f =       6279.2  |proj g|=        6.4062
At iterate    35  f =       6276.6  |proj g|=         6.345
At iterate    36  f =       6275.7  |proj g|=        6.3308
At iterate    37  f =       6275.3  |proj g|=        6.3282
At iterate    38  f =       6274.8  |proj g|=        6.3181
At iterate    39  f =       6274.2  |proj g|=        6.2935
At iterate    40  f =       6273.6  |proj g|=        6.2499
At iterate    41  f =       6273.1  |proj g|=        6.1728
At iterate    42  f =       6272.8  |proj g|=        6.0966
At iterate    43  f =       6272.4  |proj g|=        6.0309
At iterate    44  f =       6272.2  |proj g|=        6.0113
At iterate    45  f =       6271.9  |proj g|=        5.9816
At iterate    46  f =       6271.4  |proj g|=        5.9122
At iterate    47  f =         6270  |proj g|=        6.0153
At iterate    48  f =       6266.5  |proj g|=        6.8669
At iterate    49  f =       6265.1  |proj g|=        4.2789
At iterate    50  f =       6261.3  |proj g|=        5.3392
At iterate    51  f =       6258.6  |proj g|=        5.1225
At iterate    52  f =       6255.9  |proj g|=        3.7405
At iterate    53  f =       6255.4  |proj g|=        2.8486
At iterate    54  f =       6255.2  |proj g|=        3.8057
At iterate    55  f =       6255.1  |proj g|=        3.8055
At iterate    56  f =       6254.8  |proj g|=        3.5039
At iterate    57  f =       6254.6  |proj g|=        3.8092
At iterate    58  f =       6254.3  |proj g|=        3.7397
At iterate    59  f =         6254  |proj g|=        3.4176
At iterate    60  f =         6254  |proj g|=        2.7449
At iterate    61  f =         6254  |proj g|=        2.1714
At iterate    62  f =         6254  |proj g|=        2.1588
At iterate    63  f =         6254  |proj g|=        3.7402
At iterate    64  f =       6253.9  |proj g|=        3.7424
At iterate    65  f =       6253.8  |proj g|=        3.7462
At iterate    66  f =       6253.6  |proj g|=        3.4908
At iterate    67  f =       6253.4  |proj g|=        3.7551
At iterate    68  f =       6253.3  |proj g|=        3.7525
At iterate    69  f =       6253.2  |proj g|=        2.7038
At iterate    70  f =       6253.2  |proj g|=        3.1047
At iterate    71  f =       6253.1  |proj g|=        2.0107
At iterate    72  f =       6253.1  |proj g|=        1.9014
At iterate    73  f =       6253.1  |proj g|=         3.809
At iterate    74  f =       6253.1  |proj g|=        2.9691
At iterate    75  f =       6253.1  |proj g|=        2.3959
At iterate    76  f =       6253.1  |proj g|=        2.4247
At iterate    77  f =       6253.1  |proj g|=        1.2962
At iterate    78  f =       6253.1  |proj g|=        1.5339
At iterate    79  f =         6253  |proj g|=        3.8108
At iterate    80  f =         6253  |proj g|=        3.8109
At iterate    81  f =         6253  |proj g|=        3.8109
At iterate    82  f =         6253  |proj g|=       0.96266
At iterate    83  f =       6252.9  |proj g|=       0.96558
At iterate    84  f =       6252.7  |proj g|=        3.7463
At iterate    85  f =       6252.6  |proj g|=        3.7469
At iterate    86  f =       6252.6  |proj g|=        1.5952
At iterate    87  f =       6252.5  |proj g|=        2.0364
At iterate    88  f =       6252.5  |proj g|=        3.7467
At iterate    89  f =       6252.5  |proj g|=        2.2482
At iterate    90  f =       6252.5  |proj g|=        2.2013
At iterate    91  f =       6252.5  |proj g|=        2.5787
At iterate    92  f =       6252.4  |proj g|=        3.8048
At iterate    93  f =       6252.4  |proj g|=        3.5006
At iterate    94  f =       6252.4  |proj g|=        2.4506
At iterate    95  f =       6252.4  |proj g|=        2.5164
At iterate    96  f =       6252.4  |proj g|=        3.8054
At iterate    97  f =       6252.3  |proj g|=        3.8053
At iterate    98  f =       6252.2  |proj g|=        3.8082
At iterate    99  f =       6251.9  |proj g|=        3.8117
At iterate   100  f =       6251.8  |proj g|=        3.8177
At iterate   101  f =       6251.6  |proj g|=        3.8191
final  value 6251.598219
stopped after 101 iterations
#+end_example

#+begin_SRC R :results output :session *R*
reg
#+end_SRC

#+RESULTS:
#+begin_example

Call:
km(design = coded_sampled_design, response = sampled_results_data$cost_mean)

Trend  coeff.:
               Estimate
 (Intercept)     1.4689

Covar. type  : matern5_2
Covar. coeff.:
               Estimate
 theta(OMPe)     0.0000
 theta(SCRe)     1.3433
theta(VEC1e)     4.0000
theta(VEC2e)     4.0000
theta(RT_Ie)     4.0576
theta(RT_Je)     7.0118
theta(U1_Ie)     0.2681
theta(T1_Ie)   648.8870
theta(T1_Je)   290.8718
theta(T2_Ie)   174.3350
theta(T2_Je)   744.2121
 theta(U_Ie)     0.4684
 theta(U_Je)     0.1809

Variance estimate: 1.510738
#+end_example

* 2020
** February
*** [2020-02-05 Wed]
**** Review for COMCOM                                       :PaperReview:
The  paper  presents  the  \varepsilon-sticky  algorithm, an  extension  of  the  \varepsilon-greedy
algorithm for the  Multi-Armed Bandit problem to the selection  of Access Points
by user stations, and evaluates the  performance of the proposed approach in two
scenarios, varying in the distribution  of user stations.  The proposed approach
presents significant improvements in user station satisfaction, in relation to a
Strongest  Signal Access  Point  selection algorithm.   The paper  significantly
extends  the authors'  previous  work,  providing a  brief  introduction to  the
Multi-Armed Bandit  problem and  its different types,  and a  significantly more
extensive evaluation and validation of  the proposed approach.  The experimental
methodology is  solid, and  the proposed  approach convincingly  performs better
than a Strongest Signal selection algorithm, in all scenarios studied. The study
of the best  values of \varepsilon was  also interesting, since choosing a  good value for
the parameter has a significant impact on the observed throughput.
**** Applications of Program Autotuning: Call for Proposals for Funding for Undergraduates, Masters, and PhD Students
We are glad to  announce a call for masters and PhD  scholarship proposals for a
research project, done in the context  of a collaboration between the University
of  São  Paulo   and  the  Hewlett  Packard  Enterprise   company,  starting  on
February 2020.

The work to be performed by candidates  will require 10 hours per week, and will
involve the application of techniques for statistical optimization and design of
experiments to a problem presented by the candidate. We are looking for students
interested in optimizing their applications, or applications used in their work,
targeting different metrics, such as performance, memory or network usage.

Ideal  problems  for this  project  include  problems  where the  search  spaces
involved  are  too large  to  be  explored  exhaustively,  and have  no  trivial
configuration. Examples of problems include  the selection of hyperparameters of
Machine Learning algorithms to  increase prediction accuracy, selecting compiler
flags  to improve  performance, and  configuring user-developed  applications to
improve user-defined metrics.

We would like students who have  already stated their research problems and have
had some progress towards measuring  and evaluating their objectives, but highly
motivated students who are just starting are also welcome to apply.

Up to  5 accepted  candidates will receive  funding, comparable  to scholarships
from  CAPES,   payed  by  IME/USP   for  eight  months,  between   February  and
September 2020. Students currently without funding are preferred.

We invite  interested students to  submit a CV  and a cover  letter, summarizing
their problem and  their interest in applying optimization techniques  to it, by
February  20th 2020.  We assume  your advisor  is aware  and consents  with your
participation in this project. Accepted candidates  will be invited to a two-day
workshop at IME/USP, where techniques and libraries for statistical optimization
and design  of experiments will  be presented, and  candidates will be  asked to
give short presentations about their work. Final acceptance notification will be
sent by February 29th.

Project Coordinator: Prof. Dr. Alfredo Goldman
Project Manager: Pedro Bruel
*** [2020-02-06 Thu]
**** Autotuning for GCC
***** Some References
- https://en.wikipedia.org/wiki/MILEPOST_GCC
- https://github.com/ctuning
- https://github.com/ctuning/ck/wiki
***** Ideas
****** Benchmark
- Ofast
  - unsafe optim
  - error rate
****** Search Space
- Focus on *flags* at first:
  - Explore *numerical, categorical parameters* later
  - LTO
- Which flags should be chosen?
- Baselines:
  - O0, ..., O3, (Ofast, ...?)
  - Random sample of flag configurations
****** Metrics / Search Objectives
- Performance, memory, binary size, ...
- Focus on *one metric* first
  - Pareto frontier of the others
- We could try something like a normalized, weighted sum of metrics
****** Experiments and Analysis Plan
- Plan a screening experiment: Identify Main Effects
- Leverage expert knowledge plus screening to plan next experiments
- Low-discrepancy sampling, linear model, ANOVA
- Gaussian Process Regression?
***** Plan
1. Define a benchmark
   - Firefox
   - SPEC
   - BLAS Lapack
2. Define metrics
3. Define the search space
   1. Flags
   2. Others
4. Start experiments
   1. Random sample
   2. Screening
   3. Linear models + ANOVA
   4. Linear models + ANOVA + Optimal Design
   5. Gaussian Process Regression
*** [2020-02-13 Thu]
**** Experimental Design for a 2D Problem
***** Defining a Problem
Consider the following function of two factors $(x_1, x_2)$:

\[
f(x_1, x_2) + \varepsilon = 2.3 + (1.1x_1) + (1.6x_{1}^{2}) + (2.2x_2) + (3.2x_{2}^{2}) + \varepsilon
\]

That is, $f(x_1, x_2)$ has linear and quadratic dependence on $(x_1, x_2)$.  Here, \varepsilon
is a normally distributed added error with mean zero and variance one.

In R, we can write $f$ as:

#+begin_SRC R :results output :session *R*
f <- function(x1, x2) {
  return(2.3 + (1.1 * x1) + (1.6 * x1 * x1) +
         (2.2 * x2) + (3.2 * x2 * x2) + (2.7 * x1 * x2) + rnorm(length(x1)))
}

# Measuring 5 values of f(x1, x2)
f(rnorm(5), rnorm(5))
#+end_SRC

#+RESULTS:
:
: [1]  1.022636 11.213378  5.611775  5.246327  5.553409

The inputs of $f$ are defined to  be real numbers in the interval $[-1.0, 1.0]$.
Since we cannot generate  the set of *all possible inputs* of $f$,  we have to set
for a *sample of limited size*. Say that we cover the $(x_1, x_2)$ space with a grid
of points in $[-1.0, 1.0]$, spaced by $0.05$ in each axis. In R, we can write:

#+begin_SRC R :results output :session *R*
resolution <- 0.05

sample_grid <- expand.grid(x1 = seq(-1.0, 1.0, by = resolution),
                           x2 = seq(-1.0, 1.0, by = resolution))

sample_grid$f <- f(sample_grid$x1, sample_grid$x2)

str(sample_grid)
#+end_SRC

#+RESULTS:
#+begin_example

'data.frame':	1681 obs. of  3 variables:
 $ x1: num  -1 -0.95 -0.9 -0.85 -0.8 -0.75 -0.7 -0.65 -0.6 -0.55 ...
 $ x2: num  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
 $ f : num  7.32 7.01 7.26 7.09 5.93 ...
 - attr(*, "out.attrs")=List of 2
  ..$ dim     : Named int  41 41
  .. ..- attr(*, "names")= chr  "x1" "x2"
  ..$ dimnames:List of 2
  .. ..$ x1: chr  "x1=-1.00" "x1=-0.95" "x1=-0.90" "x1=-0.85" ...
  .. ..$ x2: chr  "x2=-1.00" "x2=-0.95" "x2=-0.90" "x2=-0.85" ...
#+end_example

Plotting this low-resolution view the space, we get:

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720
library(lattice)
library(RColorBrewer)

colors = colorRampPalette(brewer.pal(11, "RdYlBu"))(69)

wireframe(f ~ x1 * x2,
          data = sample_grid,
          xlab = "x1",
          ylab = "x2",
          zlab = list("f(x1,x2)",
                      rot = "90"),
          zlim = range(seq(min(sample_grid$f) - 2.0, max(sample_grid$f) + 2.0, by = 0.5)),
          colorkey = FALSE,
          col.regions = colors,
          drape = TRUE,
          #shade = TRUE,
          lattice.options = lattice.options(list(border = FALSE)),
          scales = list(arrows = FALSE),
          screen = list(z = 20, x = -60, y = 0),
          par.settings = list(axis.line = list(col = "transparent")))
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-qRrjQN/figureElZ1TS.png]]
***** Design of Experiments
Suppose we want to minimize $f$, but we do not have access to the computation of
$f(x_1, x_2)$, and  suppose that it is really expensive  to obtain each evaluation
for the inputs, so expensive in fact,  that we can only afford 20 evaluations of
$f$.  In this scenario, how to best explore the search space?

#+begin_SRC R :results output :session *R*
library(dplyr)
library(AlgDesign)

budget <- 200
sample_rs <- sample_n(sample_grid, budget)

sample_rs$method <- "Random Design"
exploration <- sample_rs

sample_linear_model <- optFederov(~ x1 + x2 + x1:x2,
                                  data = sample_grid,
                                  nTrials = budget)$design
sample_linear_model$method <- "Linear Model Design"
exploration <- bind_rows(exploration,
                         sample_linear_model)

sample_quadratic_model <- optFederov(~ (x1 + x2) + (x1:x2) + I(x1 ^ 2) + I(x2 ^ 2),
                                     data = sample_grid,
                                     nTrials = budget)$design

sample_quadratic_model$method <- "Quadratic Model Design"
exploration <- bind_rows(exploration,
                         sample_quadratic_model)

str(exploration)
#+end_SRC

#+RESULTS:
:
: 'data.frame':	600 obs. of  4 variables:
:  $ x1    : num  1 -0.45 0.35 -0.7 -0.5 1 0.6 -0.25 -0.65 0.2 ...
:  $ x2    : num  0.4 0.65 0.4 -0.15 0.1 -0.15 -0.15 -1 0.8 0.1 ...
:  $ f     : num  8.29 5.12 6.08 1.46 1.86 ...
:  $ method: chr  "Random Design" "Random Design" "Random Design" "Random Design" ...

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 400
library(ggplot2)

ggplot(data = exploration, aes(x = x1, y = x2)) +
  facet_wrap(method ~ ., ncol = 3) +
  geom_point(size = 3) +
  theme_bw(base_size = 22)
#+end_SRC

#+RESULTS:
[[file:/tmp/babel-qRrjQN/figuretwUzsW.png]]

***** Fitting and Predicting Values
We now remember the definition of $f$:

\[
f(x_1, x_2) = 2.3 + (1.1x_1) + (1.6x_{1}^{2}) + (2.2x_2) + (3.2x_{2}^{2}) + \varepsilon
\]

If  we try  to  obtain a  regression  function for  $f$,  testing the  quadratic
hypotheses using the different designs, we would get:

#+begin_SRC R :results output :session *R*
rs_lm <- lm(f ~ x1 * x2 * I(x1 ^ 2) * I(x2 ^ 2), data = filter(exploration, method == "Random Design"))
lin_lm <- lm(f ~ x1 * x2 * I(x1 ^ 2) * I(x2 ^ 2), data = filter(exploration, method == "Linear Model Design"))
quad_lm <- lm(f ~ x1 * x2 * I(x1 ^ 2) * I(x2 ^ 2), data = filter(exploration, method == "Quadratic Model Design"))

coef(rs_lm)
coef(lin_lm)
coef(quad_lm)
#+end_SRC

#+RESULTS:
#+begin_example

          (Intercept)                    x1                    x2
           2.27465946            0.53902138            1.79331229
              I(x1^2)               I(x2^2)                 x1:x2
           1.83183371            3.21003163            2.89395296
           x1:I(x1^2)            x2:I(x1^2)            x1:I(x2^2)
           0.55369765            0.65345353            1.82588396
           x2:I(x2^2)       I(x1^2):I(x2^2)         x1:x2:I(x1^2)
           0.44999902           -0.16324027           -0.94369167
        x1:x2:I(x2^2)    x1:I(x1^2):I(x2^2)    x2:I(x1^2):I(x2^2)
           0.08833311           -2.20304930           -1.10485608
x1:x2:I(x1^2):I(x2^2)
           1.20883837

          (Intercept)                    x1                    x2
            2.3489419            -0.4718219             0.6435793
              I(x1^2)               I(x2^2)                 x1:x2
            1.4927455             3.0955042             0.1057755
           x1:I(x1^2)            x2:I(x1^2)            x1:I(x2^2)
            1.9184213             2.1306245             2.0737388
           x2:I(x2^2)       I(x1^2):I(x2^2)         x1:x2:I(x1^2)
            1.9934353             0.3227596             2.2008337
        x1:x2:I(x2^2)    x1:I(x1^2):I(x2^2)    x2:I(x1^2):I(x2^2)
            2.9995394            -2.6608638            -2.7244153
x1:x2:I(x1^2):I(x2^2)
           -2.5155163

          (Intercept)                    x1                    x2
            2.0576184             2.0389072             1.2520964
              I(x1^2)               I(x2^2)                 x1:x2
            1.8942690             3.7012931             1.3285130
           x1:I(x1^2)            x2:I(x1^2)            x1:I(x2^2)
           -1.0086035             1.6426495            -0.4026176
           x2:I(x2^2)       I(x1^2):I(x2^2)         x1:x2:I(x1^2)
            1.0391508            -0.4528896             0.6970911
        x1:x2:I(x2^2)    x1:I(x1^2):I(x2^2)    x2:I(x1^2):I(x2^2)
            1.5442947             0.2870124            -1.9088828
x1:x2:I(x1^2):I(x2^2)
           -0.6770010
#+end_example

#+begin_SRC R :results output :session *R*
rs_lm <- aov(f ~ x1 * x2 + I(x1 ^ 2) + I(x2 ^ 2), data = filter(exploration, method == "Random Design"))
quad_lm <- aov(f ~ x1 * x2 + I(x1 ^ 2) + I(x2 ^ 2), data = filter(exploration, method == "Quadratic Model Design"))
summary.aov(rs_lm)
#+end_SRC

#+RESULTS:
#+begin_example

             Df Sum Sq Mean Sq F value   Pr(>F)
x1            1   67.3    67.3   66.44 4.37e-14 ***
x2            1  324.3   324.3  320.20  < 2e-16 ***
I(x1^2)       1   39.8    39.8   39.28 2.32e-09 ***
I(x2^2)       1  195.4   195.4  192.94  < 2e-16 ***
x1:x2         1  166.6   166.6  164.49  < 2e-16 ***
Residuals   194  196.5     1.0
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#+end_example

#+begin_SRC R :results output :session *R*
prediction_rs <- predict(rs_lm, newdata = select(sample_grid, -f))
prediction_error <- data.frame(error = sample_grid[prediction_rs == min(prediction_rs), ]$f - min(prediction_rs))
prediction_error$method <- "Random Design"

prediction_lin <- predict(lin_lm, newdata = select(sample_grid, -f))
prediction_error_lin <- data.frame(error = sample_grid[prediction_lin == min(prediction_lin), ]$f - min(prediction_lin))
prediction_error_lin$method <- "Linear Model Design"

prediction_error <- bind_rows(prediction_error,
                              prediction_error_lin)

prediction_quad <- predict(quad_lm, newdata = select(sample_grid, -f))
prediction_error_quad <- data.frame(error = sample_grid[prediction_quad == min(prediction_quad), ]$f - min(prediction_quad))
prediction_error_quad$method <- "Quadratic Model Design"

prediction_error <- bind_rows(prediction_error,
                              prediction_error_quad)

prediction_error
#+end_SRC

#+RESULTS:
:
:        error                 method
: 1 -1.2170481          Random Design
: 2  0.6531471    Linear Model Design
: 3  0.3871706 Quadratic Model Design
**** Underlying Hypotheses of Autotuning Methods       :ExportableReports:
***** Introduction                                             :noexport:
Given  a program  with $X  \in \mathcal{X}$  configurable parameters,  we want  to
choose the best parameter values according  to a performance metric given by the
function  $f(X)$.   Autotuning methods  attempt  find  the $X_{*}$  that  minimizes
$f(\cdot)$.   Despite  their different  approaches,  autotuning  methods share  some
common hypotheses:

- There is no knowledge about the global optimal configuration
- There could be some problem-specific knowledge to exploit
- Measuring the effects of a choice of parameter values is possible but costly

Each  autotuning method  has  assumptions that  justify  its implementation  and
usage. Some of  these hypotheses are explicit,  such as the ones  that come from
the  linear model.   Others are  implicit,  such as  the ones  that support  the
implementation and the justification of optimization heuristics.
***** Overview of Autotuning Methods
#+begin_export latex
\begin{sidewaysfigure}[t]
  \centering
  \resizebox{\textwidth}{!}{%
    \begin{forest}
      for tree={%
        anchor = north,
        align = center,
        l sep+=1em
      },
      [{Minimize $f: \mathcal{X} \mapsto \mathbb{R}$,\\$Y = f(X = (x_1,\dots,x_k) \in \mathcal{X}) + \varepsilon$},
        draw,
        [{Constructs surrogate estimate $\hat{f}(\cdot, \theta(X))$?},
          draw,
          color = NavyBlue
          [{Search Heuristics},
            draw,
            color = BurntOrange,
            edge label = {node[midway, fill=white, font = \scriptsize]{No}}
            [{\textbf{Random} \textbf{Sampling}}, draw]
            [{Reachable Optima},
              draw,
              color = BurntOrange
              [{Strong $corr(f(X),f(X^{\prime}))$,\\for close $X,X^{\prime}$},
                draw,
                color = BurntOrange
                [{Strong $corr(f(X),d(X,X_{*}))$?},
                  draw,
                  color = NavyBlue
                  [{More Global},
                    draw,
                    color = BurntOrange,
                    edge label = {node[midway, fill=white, font = \scriptsize]{No}}
                    [{Introduce a \textit{population} of $X$\\\textbf{Genetic} \textbf{Algorithms}}, draw]
                    [, phantom]]
                  [{More Local},
                    draw,
                    color = BurntOrange,
                    edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
                    [, phantom]
                    [{High local optima density?},
                      draw,
                      color = NavyBlue
                      [{Exploit Steepest Descent},
                        draw,
                        color = BurntOrange,
                        edge label = {node[midway, fill=white, font = \scriptsize]{No}}
                        [{In a neighbourhood:\\\textbf{Greedy} \textbf{Search}}, draw]
                        [{Estimate $f^{\prime}(X)$\\\textbf{Gradient} \textbf{Descent}}, draw]]
                      [{Allows\\exploration},
                        draw,
                        color = BurntOrange,
                        edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
                        [{Allow worse $f(X)$\\\textbf{Simulated} \textbf{Annealing}}, draw]
                        [{Avoid recent $X$\\\textbf{Tabu}\textbf{Search}}, draw]]]]]
                [,phantom]]
              [,phantom]]]
          [{Statistical Learning},
            draw,
            color = BurntOrange,
            edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
            [{Parametric Learning},
              draw,
              color = BurntOrange
              [{$\forall{}i: x_i \in X$ is discrete\\$\hat{f}(X) \approx f_1(x_1) + \dots + f_k(x_k)$},
                draw,
                color = BurntOrange
                [{\textbf{Independent Bandits}\\for each $x_i$:\textbf{UCB},\textbf{EXP3},$\dots$}, draw]
                [, phantom]]
              [{Linear Model\\$\hat{f} = \mathcal{M}(X)\theta{}(X) + \varepsilon$},
                draw,
                color = BurntOrange
                [, phantom]
                [{Check for model adequacy?},
                  draw,
                  alias = adequacy,
                  color = NavyBlue
                  [{Consider interactions?\\{$\exists x_i \neq x_j:\; \theta(x_ix_j) \neq 0$}},
                    draw,
                    alias = interactions,
                    color = NavyBlue,
                    edge label = {node[midway, fill=white, font = \scriptsize]{No}}
                    [{$\forall x_i \in X: x_i \in \{-1, 1\}$\\\textbf{Screening} \textbf{Designs}},
                      edge label = {node[midway, fill=white, font = \scriptsize]{No}},
                      draw
                      [, phantom]
                      [{Select $\hat{X}_{*}$, reduce dimension of $\mathcal{X}$},
                        edge = {-stealth, ForestGreen, semithick},
                        draw,
                        alias = estimate,
                        color = ForestGreen]]
                    [{\textbf{Optimal} \textbf{Design}},
                      draw,
                      alias = optimal,
                      edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}]]
                  [, phantom]
                  [, phantom]
                  [, phantom]
                  [{\textbf{Space-filling} \textbf{Designs}},
                    draw,
                    edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
                    [, phantom]
                    [{Model selection},
                      edge = {-stealth, ForestGreen, semithick},
                      draw,
                      alias = selection,
                      color = ForestGreen]]]]]
            [{Nonparametric Learning},
              draw,
              color = BurntOrange
              [{Splitting rules on X\\\textbf{Decision} \textbf{Trees}},
                  draw
                  [, phantom]
                  [{Estimate $\hat{f}(\cdot)$ and $uncertainty(\hat{f}(\cdot))$},
                    edge = {-stealth, ForestGreen, semithick},
                    draw,
                    alias = uncertainty,
                    color = ForestGreen
                    [{Minimize $uncertainty(\hat{f}(X))$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Explore}},
                      draw,
                      color = ForestGreen]
                    [{Minimize $\hat{f}(X)$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Exploit}},
                      draw,
                      color = ForestGreen]
                    [{Minimize $\hat{f}(X) - uncertainty(\hat{f}(X))$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Exploit$+$Explore}},
                      draw,
                      color = ForestGreen]]]
              [{\textbf{Gaussian} \textbf{Process Regression}},
                alias = gaussian,
                draw]
              [{\textbf{Neural} \textbf{Networks}}, draw]]]]]
      \draw [-stealth, semithick, ForestGreen](selection) to[bend left=22] (adequacy.south);
      \draw [-stealth, semithick, ForestGreen](estimate.east) to[bend right=30] (adequacy.south);
      \draw [-stealth, semithick, ForestGreen](gaussian) to (uncertainty);
      \draw [-stealth, semithick, ForestGreen](optimal) to (estimate);
    \end{forest}
  }
  \caption{A high-level view of autotuning methods, where \textcolor{NavyBlue}{\textbf{blue}} boxes
    denote branching questions, \textcolor{BurntOrange}{\textbf{orange}} boxes
    denote key hypotheses, \textcolor{ForestGreen}{\textbf{green}} boxes
    denote specific method choices, and \textbf{bold} boxes denote specific methods.}
\end{sidewaysfigure}
#+end_export

***** Previous Attempts                                        :noexport:
#+begin_export latex
\forestset{linebreaks/.style={for tree={align = center}}}
\begin{sidewaysfigure}
  \resizebox{\textwidth}{!}{%
    \begin{forest}
      linebreaks
      [{Minimize $f: \mathcal{X} \mapsto \mathbb{R}$,\\ $Y = f(X = (x_1,\dots,x_k) \in \mathcal{X}) + \varepsilon$}
        [{Does not construct\\estimate $Y = \hat{f}(\cdot, \theta{}(X))$}
          [{Reachable\\optima}
            [{Strong $corr(f(X),f(X^{\prime}))$,\\for close $X,X^{\prime}$}
              [{Strong\\$corr(f(X),d(X,X_{*}))$}
                [{Low local\\optima density}
                  [{\textbf{Greedy}\\\textbf{Search}}, draw]
                  [{Estimate $f^{\prime}(X)$}
                    [{\textbf{Gradient}\\\textbf{Descent}}, draw]]]
                [{Introduce a ``population''\\$\mathbf{X} = (X_1,\dots,X_n)$}
                  [{Combination, mutation,\\within $\mathbf{X}$}
                    [{\textbf{Genetic}\\\textbf{Algorithms}}, draw]]
                  [{\textbf{Ant}\\\textbf{Colony}}, draw]]]
              [{Weaker\\$corr(f(X),d(X,X_{*}))$}
                [{Accept\\worst $f(X)$}
                  [{\textbf{Simulated}\\\textbf{Annealing}}, draw]]
                [{Avoid\\recent $X$}
                  [{\textbf{Tabu}\\\textbf{Search}}, draw]]]]]
          [{\textbf{Random}\\\textbf{Sampling}}, draw]]
        [{Constructs surrogate\\estimate $\hat{f}(\cdot, \theta(X))$}
          [{Parametric\\Learning}
            [{$\hat{f}(X) \approx f_1(X_1) + \dots + f_k(X_k)$}
              [{\textbf{Independent}\\\textbf{Bandit}}, draw]]
            [{$\hat{f}(X) = \mathcal{B}(logit(\mathcal{M}(X)\theta(X) + \varepsilon))$}
              [{\textbf{Logistic}\\\textbf{Regression}}, draw]]
            [{$\hat{f}(X) = \mathcal{M}(X)\theta(X) + \varepsilon$}
              [{\textbf{Linear}\\\textbf{Regression}}, draw]
              [{Measure\\properties of $X$}
                [{Independance\\of effects}
                  [{\textbf{Screening}}, draw]]
                [{Homoscedasticity of $\varepsilon$}
                  [{\textbf{Optimal}\\\textbf{Design}}, draw]]]]]
          [{Nonparametric\\Learning}
            [{Splitting\\rules on $X$}
              [{\textbf{Decision}\\\textbf{Trees}}, draw]]
            [{$\hat{f} = \mathcal{GP}(X; \mathcal{K})$}
              [{\textbf{Gaussian}\\\textbf{Process Regression}}, draw]]
            [{\textbf{Neural}\\\textbf{Networks}}, draw]
            [{\textbf{Multi-armed}\\\textbf{Bandit (?)}}, draw]]]]
    \end{forest}
  }
  \caption{Some hypothesis of some autotuning methods}
\end{sidewaysfigure}

#+end_export

#+begin_export latex
\newcommand{\tabitem}{~~\llap{\textbullet}~~}

\begin{table}[ht]
  \center
  \begin{tabular}{@{}p{0.3\textwidth}p{0.5\textwidth}@{}}
    \toprule
    Method &  Hypotheses \\ \midrule
    Metaheuristics & \tabitem There are similarities between natural fenomena and the target problem \\
    & \tabitem Gradual changes in configurations produce gradual changes in performance \\
    & \tabitem The optimal configuration is ``reachable'', by small changes, from non-optimal configurations  \\
    \addlinespace \\
    Machine Learning & \tabitem As more samples are obtained, decreases in ``out-of-sample error'' imply decreases ``in-sample error'' \\
    & \tabitem \textbf{TODO} What are the classes of models? \\
    \addlinespace \\
    Design of Experiments & \tabitem There is ``exploitable search space structure''\\
    & \tabitem Linear model: Response $\bm{Y}$ is an ``unobservable function'' of parameters $\bm{X}$: \\
    & \hspace{0.15\textwidth} $f(\bm{X}) = \bm{Y} = \bm{X\beta} + \bm{\varepsilon}$ \\
    & \tabitem Optimal Design: Variance of estimator $\hat{\bm{\beta}}$ is proportional to $\bm{X}$: \\
    & \hspace{0.15\textwidth} $\bm{\hat{\beta}} = \left(\bm{X}^{\intercal}\bm{X}\right)^{-1}\bm{X}^{\intercal}\bm{Y}$ \\
    \addlinespace \\
    Gaussian Process Regression & \tabitem Response $\bm{Y}$ is a sample from a multidimensional Gaussian distribution, with mean $m(\bf{X})$ and variance $k(\bm{X}, \bm{X}^{\intercal})$: \\
    & \hspace{0.1\textwidth} $\bm{Y} = f(\bm{X}) \sim \mathcal{N}(m(\bm{X}), k(\bm{X}, \bm{X}^{\intercal}))$ \\
    & \tabitem Predictions $\bm{Y_{*}}$ can be made conditioning distribution to observed data\\ \bottomrule
  \end{tabular}%
\end{table}
#+end_export

#+begin_export latex
\resizebox{!}{\textheight}{%
  \begin{tikzpicture}[rotate = -90]
    \begin{scope}
      \tikzset{every tree node/.style = {align = center}}
      \tikzset{level 1+/.style={level distance = 40pt}}
      \Tree [.\node(n0){Minimize $f: X \mapsto \mathbb{R}$ \\ $f(X) = f^{*}(X) + \varepsilon = m$};
        [.{Does not construct \\ estimate $\hat{f}(X; \theta)$}
          [.{Reachability of \\ optima}
            [.{\textbf{Greedy} \\ \textbf{Search}} ]
            [.{$d(x_i, x_j) \to 0$ $\implies$ \\ $d(f(x_i), f(x_j)) \to 0$}
              [.{Abundance of \\ local optima}
                [.{\textbf{Simulated} \\ \textbf{Annealing}} ]]
              [.{Closeness of a \\ ``population'' of $X$}
                [.{\textbf{Genetic} \\ \textbf{Algorithms}} ]]]]
          [.{\textbf{Random} \\ \textbf{Sampling}} ] ]
        [.\node(r1){Constructs surrogate \\ estimate $\hat{f}(X; \theta)$};
          [.{Explicit, variable \\ models of $\theta$}
            [.{$\hat{f} = M(X)\theta + \varepsilon$}
              [.{Independance \\ of effects}
                [.{\textbf{Screening}} ] ]
              [.{Homoscedasticity}
                [.{\textbf{Optimal} \\ \textbf{Design}} ] ] ] ]
          [.{Implicit, fixed \\ models of $\theta$}
            [.{\textbf{Neural Networks}} ] ]
          [.{Samples \\ functions}
            [.{$\hat{f} = \mathcal{GP}(X; \theta, \mathcal{K})$}
              [.{\textbf{Gaussian Process} \\ \textbf{Regression}} ] ] ] ] ]
    \end{scope}
    % \begin{scope}[thick]
    %   \draw [color = orange] (n0) to [bend left = 2] (r1);
    %   \draw [color = green] (n0) to [bend right = 2] (r1);
    % \end{scope}
  \end{tikzpicture}
}
#+end_export

*** [2020-02-18 Tue]
**** Functions in R
#+begin_SRC R :results output :session *R*
my_function <- function(x, y, z) {
  x + y
  paste(z, collapse = "", sep = "")
}

my_function(2, 3, c("a", "v", "c"))
#+end_SRC

#+RESULTS:
:
: [1] "avc"
**** PARCO Review                                            :PaperReview:
- Title: A Comparative Study of Parallel and Serial Implementations of Content-Based Filtering
***** Review
****** Summary
The paper  presents a shared  memory and a  message passing implementation  of a
recommender system, and  evaluates the performance of  these two implementations
on a data set produced for the study.
****** Writing
- There is no need to use the he/she formula, use the neutral singular "they".
****** Experimental Validation
The results  shown in Figures  17 to 19 compare  the performance of  the serial,
shared memory and message passing implementations, but experimental settings are
not clearly stated.  Without the  information of how many experiment repetitions
were performed, and what was the standard deviation of the samples collected, it
is  harder  to support  the  conclusions  of  the  paper, especially  since  the
variations on performance  that is shown in the Figures  show large amplitude. A
major  revision  of  this  paper  would involve  running  more  experiments  and
analyzing the mean and standard deviation of the samples.
****** Recommendation
I recommend this  paper to be rejected,  since its contributions seem  to be the
performance evaluation of  well known and studied  parallelization libraries, in
the  context of  an existing  recommender  system.  The  data sets  used in  the
experiments are also limited  in scope, and it would be  useful for the analyses
presented  here to  use  data sets  from  real scenarios.   The  paper could  be
resubmitted to this paper after a statistically sound evaluation and analysis of
the  performance of  more parallel  recommender systems  in more  representative
scenarios.
*** [2020-02-27 Thu]
**** Reproducible Science for SBC
Write a small  manifesto for reproducible science, in  portuguese, for brazilian
CS conferences.

- https://github.com/ReScience
- https://www.nature.com/articles/s41562-016-0021
- https://www.semanticscholar.org/paper/A-manifesto-for-reproducible-science-Munaf%C3%B2-Nosek/a68ce412e92d87ca0116519651bbc484d98c76ae
- https://rescience.github.io/faq/
- https://www.bipm.org/utils/common/documents/jcgm/JCGM_200_2012.pdf

***** Manifesto pela Reprodutibilidade da Ciência da Computação no Brasil
Conclusões produzidas a partir de  dados obtidos experimentalmente não podem ser
consideradas  validadas  até  que   seja  possível  reproduzi-las  em  condições
experimentais independentes. Esse princípio  orienta todo o progresso científico
baseado em  metodologias experimentais.  A  pesquisa experimental em  Ciência da
Computação está em posição singular para reforçar e promover a reprodutibilidade
científica,  pois experimentos  computacionais em  determinados casos  podem ser
acompanhados,  registrados, e  repetidos  com precisão  e controle  praticamente
impossíveis em áreas  como a biologia e  a química.  As organizações  em prol da
ciência brasileira têm portanto grandes  justificativas para promover e reforçar
a reprodutibilidade científica.

Os  [[https://www.acm.org/publications/policies/artifact-review-badging][esforços da  ACM]] são  um bom  exemplo dos  esforços iniciais  que podem  ser
realizados em prol da reprodutibilidade.   Diversas conferências e periódicos da
ACM adotam  um sistema de  insígnias para  marcar trabalhos cujos  esforços para
reprodutibilidade  de  seus  experimentos são  significativos.   A  nomenclatura
utilizada pela ACM é derivada  do [[https://www.bipm.org/utils/common/documents/jcgm/JCGM_200_2012.pdf][Vocabulário Internacional de Metrologia]] (VIM),
e distingue entre resultados e conclusões que podem ser reproduzidos:

- Pela mesma equipe, nas mesmas condições experimentais (Repetibilidade)
- Por uma equipe diferente, nas mesmas condições experimentais (Replicabilidade)
- Por   uma   equipe   diferente,    em   condições   experimentais   diferentes
  (Reprodutibilidade)

O código e os dados que dão  suporte às conclusões de um estudo científico devem
ser submetidos  junto ao  documento que será  publicado.  Esses  /artefatos/ são
avaliados pelos  revisores e insígnias são  conferidas de acordo com  o nível de
reprodutibilidade   alcançado.    Outras    organizações   também   promovem   a
reprodutibilidade,   como    a   [[https://rescience.github.io/faq/][ReScience]],   que   recentemente    promoveu   o
[[https://rescience.github.io/ten-years/][Desafio     de      10     Anos     da
Reprodutibilidade]], onde  pesquisadores foram  incentivados a  submeter artigos
com a reprodução de seus próprios resultados de no mínimo 10 anos de idade.

Ações  como as  tomadas pela  ACM  podem ter  um  grande impacto  no reforço  da
credibilidade  do método  científico e  no  avanço da  descoberta científica  no
Brasil.
** March
*** [2020-03-11 Wed]
**** Review for ICS2020
***** Summary
The  paper presents  an  interesting study  of the  performance  of a  redundant
operation detection tool,  CIDetector.  The tool is used to  identify regions in
the  machine code  generated by  a compiler  that contain  redundant operations.
These regions  are then modified to  remove redundancies, and the  percentage of
redundancy  reduction and  the resulting  speedups are  reported.  The  paper is
clearly structured and easy to follow.

The  paper  evaluates   the  detection  tool  on  14   programs,  composing  the
CIBenchmark, which  is also introduced by  the paper. CIDetector is  tested on 3
GCC  versions,  1 ICC,  and  1  LLVM versions,  by  measuring  the reduction  on
redundant operations,  caused by  changes in regions  detected to  produce these
kinds  of redundancies.   In  some scenarios,  eliminating redundant  operations
produces execution time speedups.

Strangely, the paper does not provide access  to any of its source code or data,
but mentions that the code will  be open-sourced provided the paper is accepted.
On top of being  a strange practice, this means I was  not able to independently
verify or validate any of the data or the code presented in this paper.

The paper does not discuss whether the  results reported are a mean of a certain
number of  executions, and no standard  deviation or confidence interval  of the
mean  is  presented.   It  is  strongly  suggested  that  these  statistics  and
discussions are added to the paper, in order to strengthen its conclusions.

Overall,  the  paper  presents  valuable insights  and  careful  evaluation  and
discussion of the results. I believe this  to be a borderline paper, which could
be accepted provided  the statistical analysis methodology  is clearly presented
and discussed. I also believe it would be interesting to compare the performance
of the code generated by different compilers.
*** [2020-03-13 Fri]
**** First results from Emanuel's work
***** Cloning the Git Repository                               :noexport:
#+begin_SRC shell :results output :session *Shell*
git clone git@github.com:phrb/matrix-multiply-test.git || (cd matrix-multiply-test && git pull)
#+end_SRC

#+RESULTS:
: git clone git@github.com:phrb/matrix-multiply-test.git || (cd matrix-multiply-test && git p<test.git || (cd matrix-multiply-test && git pu                                               <test.git || (cd matrix-multiply-test && git pull)<test.git || [33m([39m[32mc[32md[39m matrix-multiply-test && [32mg[32mi[32mt[39m pull[33m)[39m[?2004l
: fatal: destination path 'matrix-multiply-test' already exists and is not an empty directory.
: Already up to date.
***** Boxplots of Selected Flags
#+begin_SRC R :results graphics output :session *R* :file "/tmp/heap_vec_nolib_30.pdf" :width 20 :height 7 :eval no-export
library(ggplot2)

df <- read.csv("matrix-multiply-test/results/results.csv", header = TRUE)

ggplot(df, aes(x = as.factor(id), y = execution_time)) +
  geom_jitter(alpha = 0.6, size = 4, height = 0, width = 0.2) +
  ylab("Execution Time (s)") +
  theme_bw(base_size = 38) +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(size = 25))
#+end_SRC

#+RESULTS:
[[file:/tmp/heap_vec_nolib_30.pdf]]
***** LLVM Command to Spit Flags
#+begin_SRC shell :results output :session *Shell* :eval no-export :exports results
llvm-as < /dev/null | opt -O2 -disable-output -debug-pass=Arguments
#+end_SRC

#+RESULTS:
: [32ml[32ml[32mv[32mm[32m-[32ma[32ms[39m < /dev/null | [32mo[32mp[32mt[39m -O2 -disable-output -debug-pass=Arguments[?2004l
: Pass Arguments:  -tti -tbaa -scoped-noalias -assumption-cache-tracker -targetlibinfo -verify -ee-instrument -simplifycfg -domtree -sroa -early-cse -lower-expect
: Pass Arguments:  -targetlibinfo -tti -tbaa -scoped-noalias -assumption-cache-tracker -profile-summary-info -forceattrs -inferattrs -ipsccp -called-value-propagation -attributor -globalopt -domtree -mem2reg -deadargelim -domtree -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -simplifycfg -basiccg -globals-aa -prune-eh -inline -functionattrs -domtree -sroa -basicaa -aa -memoryssa -early-cse-memssa -speculative-execution -basicaa -aa -lazy-value-info -jump-threading -correlated-propagation -simplifycfg -domtree -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -libcalls-shrinkwrap -loops -branch-prob -block-freq -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -pgo-memop-opt -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -tailcallelim -simplifycfg -reassociate -domtree -loops -loop-simplify -lcssa-verification -lcssa -basicaa -aa -scalar-evolution -loop-rotate -licm -loop-unswitch -simplifycfg -domtree -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -loop-simplify -lcssa-verification -lcssa -scalar-evolution -indvars -loop-idiom -loop-deletion -loop-unroll -mldst-motion -phi-values -basicaa -aa -memdep -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -gvn -phi-values -basicaa -aa -memdep -memcpyopt -sccp -demanded-bits -bdce -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -lazy-value-info -jump-threading -correlated-propagation -basicaa -aa -phi-values -memdep -dse -loops -loop-simplify -lcssa-verification -lcssa -basicaa -aa -scalar-evolution -licm -postdomtree -adce -simplifycfg -domtree -basicaa -aa -loops -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -barrier -elim-avail-extern -basiccg -rpo-functionattrs -globalopt -globaldce -basiccg -globals-aa -float2int -domtree -loops -loop-simplify -lcssa-verification -lcssa -basicaa -aa -scalar-evolution -loop-rotate -loop-accesses -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -loop-distribute -branch-prob -block-freq -scalar-evolution -basicaa -aa -loop-accesses -demanded-bits -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -loop-vectorize -loop-simplify -scalar-evolution -aa -loop-accesses -lazy-branch-prob -lazy-block-freq -loop-load-elim -basicaa -aa -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -simplifycfg -domtree -loops -scalar-evolution -basicaa -aa -demanded-bits -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -slp-vectorizer -opt-remark-emitter -instcombine -loop-simplify -lcssa-verification -lcssa -scalar-evolution -loop-unroll -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instcombine -loop-simplify -lcssa-verification -lcssa -scalar-evolution -licm -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -transform-warning -alignment-from-assumptions -strip-dead-prototypes -globaldce -constmerge -domtree -loops -branch-prob -block-freq -loop-simplify -lcssa-verification -lcssa -basicaa -aa -scalar-evolution -block-freq -loop-sink -lazy-branch-prob -lazy-block-freq -opt-remark-emitter -instsimplify -div-rem-pairs -simplifycfg -verify
: Pass Arguments:  -domtree
: Pass Arguments:  -targetlibinfo -domtree -loops -branch-prob -block-freq
: Pass Arguments:  -targetlibinfo -domtree -loops -branch-prob -block-freq
*** [2020-03-16 Mon]
**** Tests
#+begin_SRC R :results output :session *R* :eval no-export :exports results
print("test")
1 + 2
a <- 3
a
#+end_SRC

#+RESULTS:
: [1] "test"
:
: [1] 3
:
: [1] 3

#+begin_SRC julia :eval no-export :exports results
println("test")
1 + 3
#+end_SRC

#+RESULTS:
:RESULTS:
: test
: 4
:END:
*** [2020-03-17 Tue]
**** Map Intervals
#+begin_SRC R :results output :session *R* :eval no-export :exports results
map_intervals <- function(x, interval_from, interval_to) {
    new_x <- x - interval_from[1]
    new_x <- new_x / (interval_from[2] - interval_from[1])
    new_x <- new_x * (interval_to[2] - interval_to[1])
    new_x <- new_x + interval_to[1]

    return(new_x)
}
#+end_SRC

#+RESULTS:

**** "Circle Regression"

#+begin_SRC R :results graphics output :session *R* :file (org-babel-temp-file "figure" ".png") :width 800 :height 720 :eval no-export
library(dplyr)
library(ggplot2)

map_intervals <- function(x, interval_from, interval_to) {
    new_x <- x - interval_from[1]
    new_x <- new_x / (interval_from[2] - interval_from[1])
    new_x <- new_x * (interval_to[2] - interval_to[1])
    new_x <- new_x + interval_to[1]

    return(new_x)
}

df <- data.frame(x = map_intervals(runif(100), c(0.0, 1.0), c(-1.0, 1.0)),
                 y = map_intervals(runif(100), c(0.0, 1.0), c(-1.0, 1.0)))

df$y <-
#+end_SRC

*** [2020-03-24 Tue]
**** Meeting May 24
#+begin_export markdown
# Réunion 24 Mars

- Arbre « taxonomie »
- Structure de thèse
  - Il faut comprendre la figure quand elle est présenté
- Résultats GPR « 2 objectifs » précision DNN
  - Expériences avec des poids plus forts pour le taille (1/10 et 9/10 par exemple, voir 0, 1 pour vérifier que ça optimise bien la taille)
  - Calcul des indices de sobol et autres pas possible car pas assez de points
  - Estimer $\theta$ à chaque étape d'exploitation (donc ça utilisera tous les points de l'exploration initiale plus les nouveaux d'EGO). Pour vérifier si ça converge. Faire la même chose en virant les 120 premières étapes où on explore histoire de voir si le $\theta$ dans l'espace où on exploite a la même variance que l'espace entier.

- Résultats SPAPT
  - Ajouter l'amélioration relative pour GPR, RS (logscale, normalisation à O3)
  - Essayer de calculer les indices de Sobol. Peut être fait aussi bien sur les échantillons RS que sur les échantillons de l'exploration SOBOL initiale. Aucune idée de ce que ça va donner...
  - Regarder comment GPR explore l'espace (ggpairs). On s'attends à ce que certaines régions de l'espace soient plus explorées, que ça soit moins uniforme que dans le LHS/Sobol de départ. S'il y a une (ou plusieur) région particulièrement explorée, on voudra vérifier que c'est bien consistant d'une répétion de l'expérience à une autre.

On fait l'hypothèse que $Y=\beta.X + \varepsilon$
on estime $\hat\beta$. l'incertitude sur $\hat\beta = (X^{\intercal}X)^{-1}XY$ provient de la variabilité de $\varepsilon$.

$Y = (X^{\intercal}X)^{-1}X(\beta.X + \varepsilon) = \beta + (X^{\intercal}X)^{-1}X\varepsilon$  Et comme $\varepsilon \sim \mathcal{N}(0,\sigma^2)$, ça te donne ton incertitude du $\hat\beta$. C'est un ellipsoide de confiance. Là, le $X$, c'est les mesures mais pour faire une prédiction sur $x$, tu repropages ton incertitude dans $Y=(\hat\beta + ellipsoide).x$

$y=a.x+b$ avec $a \in [0.9,1.1]$ et $b\in [2.2,2.6]$.
#+end_export
*** [2020-03-27 Fri]
**** Design of Experiments Step-by-Step
Formulas in R:

y = (alpha * x1) + (beta * x2)
y ~ x1 + x2

y = (\alpha_1 * x1) + (\alpha_2 * x2) + (\alpha_3 * x1 * x2)
y ~ x1 * x2

y = (\alpha_3 * x1 * x2)
y ~ x1:x2

y = (\alpha_1 * x1) + (\alpha_2 * x2) + (\alpha_3 * x1 * x2)

#+begin_SRC R :results output :session *R* :eval no-export :exports results :tangle ed_test.r
library(AlgDesign)
library(randtoolbox)
library(quantreg)

y <- function(x) {
  # call supersim

  return(1 + (2.3 * x$inj1) +
         (3.2 * x$inj2) +
         (4.5 * x$inj2 * x$inj1) +
         (1.1 * runif(1)))
}

# temp_sobol <- sobol(n = sobol_n,
#                     dim = sobol_dim,
#                     scrambling = 1,
#                     seed = as.integer((99999 - 10000) * runif(1) + 10000),
#                     init = TRUE)
#
# rm(temp_sobol)
# quiet(gc())
#
# design <- sobol(n = sobol_n,
#                 dim = sobol_dim,
#                 scrambling = 1,
#                 seed = as.integer((99999 - 10000) * runif(1) + 10000),
#                 init = FALSE)

candidate_set <- data.frame(inj1 = runif(1000),
                            inj2 = runif(1000))

experiments <- sample_n(candidate_set, 4)

experiments$response<- y(experiments)

regression <- lm(response ~ inj1 + inj2,
                 data = experiments)


output_lin <- optFederov(~ inj1 + inj2,
                         nTrials = 4,
                         data = candidate_set)

output_quad <- optFederov(~ inj1 + inj2 + I(inj1 ^ 2),
                          nTrials = 4,
                          data = candidate_set)

design <- output_lin$design
design$response <- y(design)

regression <- rq(response ~ inj1 + inj2,
                 tau = 0.05,
                 data = design)
#+end_SRC

#+RESULTS:
:
: Loading required package: SparseM
:
: Attaching package: ‘SparseM’
:
: The following object is masked from ‘package:base’:
:
:     backsolve
** April
*** [2020-04-14 Tue]
**** Reunião HPE Fin
- Gastos de fevereiro?
- Bolsa:
  - Não é um pedido extra
- Hardware: problemas de covid
  - Acesso aos alunos: problema de segurança
*** [2020-04-17 Fri]
**** Sobol and Uniform samples
#+begin_SRC R :results graphics output :session *R* :file /tmp/sampling_histograms.pdf :width 8 :height 16 :eval no-export
library(randtoolbox)
library(dplyr)
library(tidyr)

map_intervals <- function(x, interval_from, interval_to) {
    new_x <- x - interval_from[1]
    new_x <- new_x / (interval_from[2] - interval_from[1])
    new_x <- new_x * (interval_to[2] - interval_to[1])
    new_x <- new_x + interval_to[1]

    return(new_x)
}

n = 216
d = 108

temp_sobol <- torus(n = n,
                    dim = d,
#                     scrambling = 1,
#                     seed = as.integer((99999 - 10000) * runif(1) + 10000),
                    init = TRUE)
rm(temp_sobol)

design <- data.frame(halton(n = n,
                           dim = d,
                           # scrambling = 2,
                           # seed = as.integer((99999 - 10000) * runif(1) + 10000),
                           init = FALSE)) %>%
    map_intervals(c(0.0, 1.0), c(1.0, 8.0)) %>%
    round()

design$method <- "Sobol"

rs_design <- data.frame(matrix(runif(n * 108), ncol = d, nrow = n)) %>%
    map_intervals(c(0.0, 1.0), c(1.0, 8.0)) %>%
    round()

rs_design$method <- "Uniform"

design <- bind_rows(design, rs_design) %>%
    pivot_longer(-method, names_to = "Layer", values_to = "Bitwidth")

ggplot() +
    geom_histogram(data = design,
                   bins = 8,
                   aes(x = Bitwidth,
                       y = ..count..)) +
    facet_wrap(. ~ method, ncol = 1)
#+end_SRC

#+RESULTS:
[[file:/tmp/sampling_histograms.pdf]]

**** Looking at Top500 Data
***** Cloning Repository
#+begin_SRC shell :results output :session *Shell* :eval no-export :exports results
git clone --depth=1 https://github.com/phrb/top500.git || (cd top500 && git pull)
#+end_SRC

#+RESULTS:
: [?2004l
: fatal: destination path 'top500' already exists and is not an empty directory.
: Already up to date.
***** Loading Data
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)

df <- read.csv("top500/TOP500_history.csv")
#+end_SRC

#+RESULTS:
***** Looking at Data
****** Column Names
#+begin_SRC R :results output :session *R* :eval no-export :exports results
str(df)
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	27000 obs. of  52 variables:
 $ Year                           : int  1993 1993 1993 1993 1993 1993 1993 1993 1993 1993 ...
 $ Month                          : int  6 6 6 6 6 6 6 6 6 6 ...
 $ Day                            : int  1 1 1 1 1 1 1 1 1 1 ...
 $ Rank                           : num  1 2 3 4 5 6 7 8 9 10 ...
 $ Site                           : Factor w/ 2467 levels " Institute of Information and Communication Technologies at the Bulgarian Academy of Sciences",..: 1287 1379 1513 1486 1516 135 1507 277 468 563 ...
 $ Manufacturer                   : Factor w/ 147 levels "Acer Group","ACTION",..: 141 141 141 141 98 98 141 76 28 28 ...
 $ Computer                       : Factor w/ 2825 levels " eServer pSeries 655 (1.7 GHz Power4+)",..: 790 799 798 798 2345 2344 796 995 2730 2730 ...
 $ Country                        : Factor w/ 60 levels "Australia","Austria",..: 58 58 58 58 26 7 58 58 58 58 ...
 $ Processors                     : num  1024 544 512 512 4 ...
 $ RMax                           : num  59.7 30.4 30.4 30.4 23.2 20 15.1 13.9 13.7 13.7 ...
 $ RPeak                          : num  131 69.6 65.5 65.5 25.6 ...
 $ Nmax                           : num  52224 36864 36864 36864 6400 ...
 $ Nhalf                          : num  24064 16384 16384 16384 830 ...
 $ Processor.Family               : Factor w/ 26 levels "","Alpha","AMD",..: 25 25 25 25 21 21 25 14 7 7 ...
 $ Processor                      : Factor w/ 463 levels "Alpha","Alpha EV4",..: 267 267 267 267 133 133 267 63 25 25 ...
 $ Processor.Speed..MHz.          : num  32 32 32 32 400 ...
 $ System.Family                  : Factor w/ 179 levels " IBM Power Systems",..: 174 174 174 174 122 122 174 104 33 33 ...
 $ Operating.System               : Factor w/ 85 levels "AIX","Amazon Linux 2",..: 10 10 10 10 59 59 10 30 74 74 ...
 $ Architecture                   : Factor w/ 6 levels "Cluster","Constellations",..: 3 3 3 3 6 6 3 3 6 6 ...
 $ Segment                        : Factor w/ 7 levels "Academic","Classified",..: 6 4 1 2 7 6 6 1 7 6 ...
 $ Application.Area               : Factor w/ 48 levels "","Aerospace",..: 37 37 37 37 37 46 37 37 37 37 ...
 $ Interconnect.Family            : Factor w/ 27 levels "10G","Cray Interconnect",..: 8 8 8 8 3 3 8 17 17 17 ...
 $ Interconnect                   : Factor w/ 90 levels "100G Ethernet",..: 37 37 37 37 67 67 37 71 71 71 ...
 $ Region                         : Factor w/ 16 levels "Australia and New Zealand",..: 6 6 6 6 4 6 6 6 6 6 ...
 $ Continent                      : Factor w/ 5 levels "Africa","Americas",..: 2 2 2 2 3 2 2 2 2 2 ...
 $ Power                          : num  NA NA NA NA NA NA NA NA NA NA ...
 $ System.Model                   : Factor w/ 539 levels "","Acer AR585 F1 Cluster",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Total.Cores                    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Measured.Size                  : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Processor.Cores                : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Accelerator                    : Factor w/ 7 levels "","ATI GPU","IBM PowerXCell 8i",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Name                           : Factor w/ 848 levels "","&#346;wierk Computing Centre",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Accelerator.Cores              : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Efficiency....                 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Mflops.Watt                    : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Processor.Technology           : Factor w/ 26 levels "","AMD x86_64",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ OS.Family                      : Factor w/ 6 levels "","BSD Based",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Cores.per.Socket               : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Processor.Generation           : Factor w/ 75 levels "","AMD Naples",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Previous.Rank                  : num  NA NA NA NA NA NA NA NA NA NA ...
 $ First.Appearance               : num  NA NA NA NA NA NA NA NA NA NA ...
 $ First.Rank                     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Accelerator.Co.Processor.Cores : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Accelerator.Co.Processor       : Factor w/ 59 levels "","AMD FirePro S10000",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Power.Source                   : Factor w/ 4 levels "","Derived","Optimized",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Rmax..TFlop.s.                 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Rpeak..TFlop.s.                : num  NA NA NA NA NA NA NA NA NA NA ...
 $ HPCG..TFlop.s.                 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Power..kW.                     : num  NA NA NA NA NA NA NA NA NA NA ...
 $ Power.Effeciency..GFlops.Watts.: num  NA NA NA NA NA NA NA NA NA NA ...
 $ Site.ID                        : num  NA NA NA NA NA NA NA NA NA NA ...
 $ System.ID                      : int  NA NA NA NA NA NA NA NA NA NA ...
#+end_example

****** Processor Speed
#+begin_SRC R :results graphics output :session *R* :file "top500_processors_speed.pdf" :width 10 :height 10 :eval no-export
library(ggplot2)

ggplot() +
    geom_jitter(data = df,
                alpha = 0.5,
                height = 0.0,
                size = 1.5,
                aes(x = Year,
                    y = Processor.Speed..MHz. / 1000,
                    color = cut(Rank,
                                breaks = c(1, 167, 334, 500),
                                include.lowest = TRUE))) +
                                        #scale_y_log10() +
    scale_x_continuous(breaks = function(x) { seq(floor(min(x)),
                                                  ceiling(max(x)),
                                                  4) }) +
    scale_color_brewer(name = "TOP500 Rank", palette = "Set1") +
    ylab("Processor Speed (GHz)") +
    theme_bw(base_size = 27) +
    theme(legend.position = c(0.25, 0.95),
          legend.direction = "horizontal",
          legend.background = element_rect(fill = "transparent", colour = NA),
          legend.text = element_text(size = 15),
          legend.title = element_text(size = 15)) +
    guides(color = guide_legend(nrow = 3, override.aes = list(alpha = 1.0, size = 4)))
#+end_SRC

#+RESULTS:
[[file:top500_processors_speed.pdf]]

****** NMax
#+begin_SRC R :results graphics output :session *R* :file "top500_nmax.pdf" :width 10 :height 10 :eval no-export
library(ggplot2)

ggplot() +
    geom_jitter(data = df,
                alpha = 0.5,
                height = 0.0,
                size = 1.5,
                aes(x = Year,
                    y = Nmax,
                    color = cut(Rank,
                                breaks = c(1, 167, 334, 500),
                                include.lowest = TRUE))) +
    scale_x_continuous(breaks = function(x) { seq(floor(min(x)),
                                                  ceiling(max(x)),
                                                  4) }) +
    scale_color_brewer(name = "TOP500 Rank", palette = "Set1") +
    ylab("Problem Size to Reach RMax") +
    scale_y_log10() +
    theme_bw(base_size = 27) +
    theme(legend.position = c(0.25, 0.95),
          legend.direction = "horizontal",
          legend.background = element_rect(fill = "transparent", colour = NA),
          legend.text = element_text(size = 15),
          legend.title = element_text(size = 15),
          axis.text.y = element_text(angle = 90, hjust = 0.5)) +
    guides(color = guide_legend(nrow = 3, override.aes = list(alpha = 1.0, size = 4)))
#+end_SRC

#+RESULTS:
[[file:top500_nmax.pdf]]

****** RPeak and RMax
#+begin_SRC R :results graphics output :session *R* :file "top500_rpeak.pdf" :width 17.5 :height 7 :eval no-export
library(ggplot2)

plot_df <- df %>%
    mutate(RMax = RMax / 1e3,
           RPeak = RPeak / 1e3,
           RMaxT = coalesce(RMax, Rmax..TFlop.s.),
           RPeakT = coalesce(RPeak, Rpeak..TFlop.s.)) %>%
    select(Rank,
           Year,
           RMaxT,
           RPeakT,
           HPCG..TFlop.s.) %>%
    gather(-Rank, -Year, key = "Type", value = "Count") %>%
    mutate(Type = factor(Type,
                         levels = c("RPeakT",
                                    "RMaxT",
                                    "HPCG..TFlop.s."),
                         labels = c("RPeak (HPL)",
                                    "RMax (HPL)",
                                    "RMax (HPCG)"))) %>%
    filter(is.finite(Count))

ggplot() +
    geom_jitter(data = plot_df,
                alpha = 0.5,
                height = 0.0,
                size = 1.5,
                aes(x = Year,
                    y = Count,
                    color = cut(Rank,
                                breaks = c(1, 167, 334, 500),
                                include.lowest = TRUE))) +
    scale_x_continuous(breaks = function(x) { seq(floor(min(x)),
                                                  ceiling(max(x)),
                                                  6) }) +
    scale_color_brewer(name = "TOP500 Rank", palette = "Set1") +
    ylab("Performance (TFlops/s)") +
    scale_y_log10() +
    theme_bw(base_size = 27) +
    theme(legend.position = c(0.83, 0.09),
          legend.direction = "horizontal",
          legend.background = element_rect(fill = "transparent", colour = NA),
          legend.text = element_text(size = 15),
          legend.title = element_text(size = 15),
          axis.text.y = element_text(angle = 90, hjust = 0.5)) +
    guides(color = guide_legend(nrow = 3, override.aes = list(alpha = 1.0, size = 4))) +
    facet_wrap(. ~ Type, ncol = 3)
#+end_SRC

#+RESULTS:
[[file:top500_rpeak.pdf]]
****** Processors
#+begin_SRC R :results graphics output :session *R* :file "top500_total_cores.pdf" :width 17.5 :height 7 :eval no-export
library(ggplot2)
library(tidyr)

plot_df <- df %>%
    mutate(Accelerator.Co.Processor.Cores = replace_na(Accelerator.Co.Processor.Cores, 0)) %>%
    mutate(AllCores = coalesce(Processors, Total.Cores) - Accelerator.Co.Processor.Cores) %>%
    select(Rank, Year, AllCores, Accelerator.Co.Processor.Cores) %>%
    gather(-Rank, -Year, key = "Type", value = "Count") %>%
    mutate(Type = factor(Type,
                         levels = c("AllCores",
                                    "Accelerator.Co.Processor.Cores"),
                         labels = c("Processor Cores",
                                    "Accelerator Cores"))) %>%
    filter(is.finite(Count))

ggplot() +
    geom_jitter(data = plot_df,
                alpha = 0.5,
                height = 0.0,
                size = 1.5,
                aes(x = Year,
                    y = Count,
                    color = cut(Rank,
                                breaks = c(1, 167, 334, 500),
                                include.lowest = TRUE))) +
    scale_x_continuous(breaks = function(x) { seq(floor(min(x)),
                                                  ceiling(max(x)),
                                                  6) }) +
    scale_color_brewer(name = "TOP500 Rank", palette = "Set1") +
    ylab("Core Count") +
    scale_y_log10() +
    # annotation_logticks(sides = "l") +
    theme_bw(base_size = 27) +
    theme(legend.position = c(0.67, 0.08),
          legend.direction = "horizontal",
          legend.background = element_rect(fill = "transparent", colour = NA),
          legend.text = element_text(size = 15),
          legend.title = element_text(size = 15),
          axis.text.y = element_text(angle = 90, hjust = 0.5)) +
    guides(color = guide_legend(nrow = 3, override.aes = list(alpha = 1.0, size = 4))) +
    facet_wrap(. ~ Type, ncol = 4)
#+end_SRC

#+RESULTS:
[[file:top500_total_cores.pdf]]
****** RMax / Cores
#+begin_SRC R :results graphics output :session *R* :file "top500_rmax_cores.pdf" :width 17.5 :height 7 :eval no-export
library(ggplot2)


plot_df <- df %>%
    mutate(AllCores = coalesce(Processors, Total.Cores)) %>%
    mutate(RMax = (RMax / 1e3) / AllCores,
           RPeak = (RPeak / 1e3) / AllCores,
           Rmax..TFlop.s. = Rmax..TFlop.s. / AllCores,
           Rpeak..TFlop.s. = Rpeak..TFlop.s. / AllCores,
           RMaxC = coalesce(RMax, Rmax..TFlop.s.),
           RPeakC = coalesce(RPeak, Rpeak..TFlop.s.),
           HPCGC = HPCG..TFlop.s. / AllCores) %>%
    select(Rank,
           Year,
           RMaxC,
           RPeakC,
           HPCGC) %>%
    gather(-Rank, -Year, key = "Type", value = "Count") %>%
    mutate(Type = factor(Type,
                         levels = c("RPeakC",
                                    "RMaxC",
                                    "HPCGC"),
                         labels = c("RPeak / Cores (HPL)",
                                    "RMax / Cores (HPL)",
                                    "RMax / Cores (HPCG)"))) %>%
    filter(is.finite(Count))

ggplot() +
    geom_jitter(data = plot_df,
                alpha = 0.5,
                height = 0.0,
                size = 1.5,
                aes(x = Year,
                    y = Count,
                    color = cut(Rank,
                                breaks = c(1, 167, 334, 500),
                                include.lowest = TRUE))) +
    scale_x_continuous(breaks = function(x) { seq(floor(min(x)),
                                                  ceiling(max(x)),
                                                  6) }) +
    scale_color_brewer(name = "TOP500 Rank", palette = "Set1") +
    ylab("Performance / Core Count") +
    scale_y_log10() +
    theme_bw(base_size = 27) +
    theme(legend.position = c(0.85, 0.1),
          legend.direction = "horizontal",
          legend.background = element_rect(fill = "transparent", colour = NA),
          legend.text = element_text(size = 15),
          legend.title = element_text(size = 15),
          strip.text.x = element_text(size = 17),
          axis.text.y = element_text(angle = 90, hjust = 0.5)) +
    guides(color = guide_legend(nrow = 3, override.aes = list(alpha = 1.0, size = 4))) +
    facet_wrap(. ~ Type, ncol = 5)
#+end_SRC

#+RESULTS:
[[file:top500_rmax_cores.pdf]]

****** Achieved / Max Performance                             :noexport:
#+begin_SRC R :results graphics output :session *R* :file "top500_rmax_rpeak.pdf" :width 10 :height 10 :eval no-export
library(ggplot2)

ggplot() +
    geom_jitter(data = filter(df, Rank <= 5),
                alpha = 0.5,
                height = 0.0,
                size = 1.5,
                aes(x = Year,
                    y = RMax / RPeak,
                    color = cut(Rank,
                                breaks = c(1, 100, 200, 300, 400, 500),
                                include.lowest = TRUE))) +
                                        #scale_y_log10() +
    scale_x_continuous(breaks = function(x) { seq(floor(min(x)),
                                                  ceiling(max(x)),
                                                  4) }) +
    scale_color_brewer(name = "TOP500 Rank", palette = "Dark2") +
    ylab("Achieved / Theoretical Performance (RMax / RPeak)") +
    theme_bw(base_size = 27) +
    theme(legend.position = c(0.5, 0.025),
          legend.direction = "horizontal",
          legend.background = element_rect(fill = "transparent", colour = NA),
          legend.text = element_text(size = 15),
          legend.title = element_text(size = 15),
          axis.text.y = element_text(angle = 90, hjust = 0.5)) +
    guides(color = guide_legend(override.aes = list(alpha = 1.0, size = 4)))
#+end_SRC

#+RESULTS:
[[file:top500_rmax_rpeak.pdf]]

*** [2020-04-27 Mon]
**** KL-Exchange Notes                                            :ATTACH:
:PROPERTIES:
:Attachments: kl_exchange_page1.jpg kl_exchange_page2.jpg
:ID:       cef38015-0504-43cc-99d8-74e5a69cfcfa
:END:
** May
*** [2020-05-16 Sat]
**** CSmith Histogram                                             :ATTACH:
:PROPERTIES:
:Attachments: 100_depth.csv
:ID:       0ece81f1-5ade-41e4-b217-c0d157e93922
:END:

#+begin_SRC R :results graphics output :session *R* :file "histogram.pdf" :width 10 :height 10 :eval no-export
library(dplyr)
library(ggplot2)

df <- read.csv("data/0e/ce81f1-5ade-41e4-b217-c0d157e93922/100_depth.csv")

ggplot(df) +
    geom_col(aes(x = depth,
                 y = occurrences)) +
    theme_bw(base_size = 28)
#+end_SRC

#+RESULTS:
[[file:histogram.pdf]]

#+begin_SRC R :results graphics output :session *R* :file "fit.pdf" :width 10 :height 10 :eval no-export
library(dplyr)
library(ggplot2)

df <- read.csv("data/0e/ce81f1-5ade-41e4-b217-c0d157e93922/100_depth.csv")

ggplot(df, aes(x = depth,
               y = occurrences)) +
    geom_point() +
    geom_smooth(formula = y ~ I(1 / x),
                method = "lm") +
    theme_bw(base_size = 28)
#+end_SRC

#+RESULTS:
[[file:fit.pdf]]
** July
*** [2020-07-03 Fri]
**** Review for CLUSTER
***** Summary
The paper  presents a series  of performance  comparisons between Julia,  a High
Level Language capable  of parallel and distributed computing,  and the pthreads
and MPI APIs for C and C++.

The paper  compares the  performance of Julia  with that of  the pthreads  C API
using atomic operations and simple  synchronization tasks, and also compares the
performance  of  Julia and  that  of  the MPI  C++  API  in microbenchmarks  for
communication, reads, and writes.

The paper presents  an implementation of HPCG,  a standard, communication-heavy,
and large scale benchmark for HPC.

The paper  argues that  the Julia  HPCG implementation  outperforms the  C++ MPI
implementation in certain experimental conditions,  and that Julia is capable of
performing certain synchronization operations faster than the pthreads API.

***** Strengths and Weaknesses
****** Strengths
The paper  is clearly written and  easy to read.  The  paper reports statistical
analysis choices and  experiment and experimental design, such as  the number of
repeated  measurements and  under  which criteria  were  some outliers  removed.
Interesting  discussions  are made  in  the  paper,  such  as regarding  be  the
underlying causes  of each observation,  and some of the  implementation choices
for HPCG.

****** Weaknesses
The paper  does not make available  any artifacts for the  verification of data,
code, or  statistical analysis,  mentioning these will  be made  available after
acceptance. Under  these conditions  it is  impossible to  verify or  attempt to
reproduce  results.   The   claims  that  the  Julia  language   is  capable  of
outperforming the  C++ MPI implementation  on HPCG  seem rushed, given  the data
presented.

***** Detailed Comments
I believe that a more comprehensive  experimental analysis of the performance of
Julia in  parallel and distributed  settings should be  performed to be  able to
claim improvements over well established technologies such as MPI and pthreads.

Although  motivating  and  interesting,   the  microbenchmarks  and  small-scale
threading comparisons  do not provide  a solid basis for  claiming improvements,
and  the  same  is  valid  for  HPCG. Further  work  should  aim  to  compile  a
comprehensive set  of large-scale, possibly real-world,  applications written in
Julia and C++ MPI.

The paper mentions that the variance of  the HPCG measurements were large on the
Julia  code. It  would  enrich and  better  support the  discussion  to add  the
confidence  intervals of  these  measurements,  and for  the  other graphs  also
presented.  It is  usual to compute an interval of  twice the standard deviation
of the mean, in order to obtain an approximately 95% confidence interval.
***** Suggestions for Improvement
- Add the  95% confidence intervals for  the mean, on all  plots, but especially
  for Figure 10

- Perform performance evaluations on a more comprehensive benchmark, in order to
  better support claims of improvement

- "Figure III-A shows the results." ~> Should be "Figure 4", at page 6
- "perfromance" ~> "performance", at page 10
*** [2020-07-20 Mon]
**** Extension Request
The experimental validation of the approaches studied during this thesis, namely
Design of Experiments and Gaussian Process Regression, took longer than expected
in  the  initial SPAPT  benchmark.  The  large set  of  problems  and number  of
configurable parameters slowed down a  comprehensive and careful analysis of the
relationships between parameters and performance for many problems.

The  Gaussian  Process  Regression  approach introduced  further  questions  and
restrictions for experimental  validation, and the method was also  applied to a
different  domain, the  selection of  bit precision  for layers  of Deep  Neural
Networks, where completing a single experimental run takes a full week.

I have  already started my efforts  towards writing the thesis,  but our current
assessment of  the state of the  work indicates that  I most likely will  not be
able to finish before the end of the third year's limit date.

Compounding the  experimental difficulties sustained  during the last  year, the
difficulties generated from  the COVID-19 pandemic greatly hindered  the pace of
my work,  as they did for  many others. I  continue my cotutelle from  Brazil, a
country that is at the moment the epicenter of the current pandemic.  During the
final stages of my thesis, I had to relocate to a different city and
*** [2020-07-25 Sat]
**** Review for Fabio (Middleware 2020)
***** Paper #72
Title: ROBOTune: High-Dimensional Configuration Tuning for Cluster-Based Data
Analytics

****** A. Overall merit
2. Weak reject (I don't want to publish this)

****** B. Reviewer expertise
5. I have published/worked on most/all this paper’s topics

****** C. Paper summary
The paper presents an autotuner for 44 parameters of the Spark data analytics
framework.  The optimization approach is a composite of Random Forests to
identify the most significant parameters, Latin Hypercube Sampling to better
cover the search space, and Gaussian Process Regression to determine
configurations to test, balancing exploitation of detected relationships and
exploration of the search space. The paper performs experimental evaluation on
five SparkBench workloads with three datasets each. Although the proposed
approach achieves small but statistically significant improvements in relation
to the optimization methods compared in the study, the paper does not present
performance or optimization baselines.  The paper does not compare the achieved
performance to the performance of default, or sensibly picked, Spark
configurations. The results of the optimizers are also not compared to the best
configurations found by naive methods such as Random Search.

****** D. Strengths
- Adapts well-established optimization techniques from Bayesian Optimization and
  Statistical Learning to the Spark tuning problem, exploring better-performing
  regions of search spaces and decreasing tuning costs with respect to other
  tuning strategies

****** E. Weaknesses
- Proposes an interesting high-dimensional optimization problem, with around 200
  dimensions, but the actual studied problem targets a more tractable search
  space, one order of magnitude smaller, with only 44 parameters. The paper does
  not mention the number of possible configurations
- Performance improvements over established work seem to be statistically
  significant although small, but the paper does not compare the results with
  proper baselines.  Performance is never compared to the sensible default Spark
  configurations for each workload, or to optimizations from more naive methods

****** F. Comments for author
******* Major Comments
- The paper does not compare the performance achieved by autotuning strategies
  to the performance achieved by more naive optimization strategies using the
  same budget, such as Random Search, which could also be based on LHS.  Without
  optimization and performance baselines it is difficult to measure the
  effectiveness of the autotuners

- The comparisons between the proposed system and others are not balanced.  The
  study allows the proposed system to reuse results from previous runs in two of
  the three datasets for each problem, which increases the effective
  experimental budget and the optimization time used by the technique. The
  author should modify figures to reflect this imbalance

- Page 8: "For ROBOTune, we treat each workload to be an unseen one for the
  first dataset, and for the remaining two, ROBOTune uses cached parameters and
  configurations through memoized sampling."
  - This means that the optimization time and budget comparisons presented in
    Figures 4 and 6 are not balanced between methods. If the proposed approach
    reuses measurements, its optimization costs must be updated accordingly

******* Minor Comments
- Page 3: "Eventually, it [Bayesian Optimization] locates the global extremum
  for the objective function, or nearly so within a limited number of
  observations."
  - Finding the global optimum in a limited number of measurements is not a
    guarantee of Bayesian Optimization

- Page 5: "Furthermore, LHS is dimension agnostic, meaning that the number of
  samples required is not tied to the dimensionality of the configuration
  space."
  - Obtaining an effective search space covering using Latin Hypercube Sampling
    is tied to the problem dimension. A sample with only a handful of LHS
    samples in high-dimensional spaces suffers from the same issues than uniform
    samples, that is, most samples would be located in the grid regions near the
    "shell" of the search space

- Wrong date on page headers: "Conference’17, July 2017"

- Page 5: "Another way of computing feature importances is through tree-based
  estimators. Unlike linear models, they apply to non-linear relationships."
  - Linear models can represent non-linear factor relationships, and are only
    restricted in the sense of linear, or linearizable, relationships between
    the estimated parameters

- Page 5: "We compare the coefficient of determination (R2) for two linear and
  two tree-based models in Figure 2."
  - It is hard to compare the qualities of fit of the models in Figure 2 without
    knowing the underlying models for the Lasso and the Lasso + Ridge (ENet)
    approaches, since adding polynomial terms would increase flexibility of
    these approaches and consequently increase R^2

- Reference could be improved adding publisher information: "[11] L.  Breiman, J.
  Friedman, C.J.  Stone, and R.A.  Olshen.  1984.Classification and Regression
  Trees.  Taylor & Francis.https://books.google.com/books?id=JwQx-WOmSyQC"

****** G. Comments for PC

***** Final Opinion

The response did  not address my most concerning comments  satisfactorily, and I
recommend  rejecting the  paper.   My comments  regard  mostly the  experimental
validation of the approach. Detailed comments are listed below.

****** Comments on the Rebuttal
> Comment-72E-2: Comparison to the default/naive?
>
> We compared our  results to the default in Section-5.2.  It resulted in frequent
> Out-Of-Memory/Runtime errors. We  need 5 runs for each dataset,  each run taking
> up  to ~10  hours. Due  to time  constraints we  chose to  focus on  established
> methods.

A fair comparison  baseline would be a configuration considered  good enough for
each dataset, that is,  a configuration that was used in other  work, or that is
well established in  the industry for this  type of data, or at  least that does
not  result   in  frequent   errors.   An  equivalent   example  would   be  the
Spark-equivalent of the  "-O3" compiler option for the GCC  compiler, which is a
common baseline  for works  on compiler  optimization. In  that way,  gains over
sensible  defaults  could be  properly  assessed.   Another  fair option  for  a
baseline would be picking the best  configuration found by a random search using
the same experimental  budget. The paper should be  resubmitted after sufficient
data is collected.

> Comment-72E-3: Comparison not balanced.
>
> This could be a misunderstanding. In Section-5.3 we exclude the initial one-time
> cost of parameter selection  as this is a fixed cost.  This overhead varies with
> the number  of datasets tuned, 3  used in our  evaluation. Using more (5  or 10)
> will change the overhead.

In my  previous comment I argued  under the impression that  the proposed method
leveraged  cached  results  from  previous  runs.  If  that  is  the  case,  the
comparisons between  approaches must consider  the experimental cost  of caching
these initial runs as  part of the optimization cost. The  cost of these initial
evaluations, that  are then cached and  reused, should be included  in the total
optimization cost of the approach.  If the  method does not in fact reuse cached
results in further optimization, please ignore my comment.
** September
*** [2020-09-13 Sun]
**** Running GPR on Steven's Data
***** Loading Data for Analysis
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(DiceKriging)
library(dplyr)

complete_data <- read.csv("dopt_anova_experiments/data/search_space.csv",
                          header = TRUE)
complete_data <- complete_data %>%
    select(-vector_recompute) %>%
    mutate(row_number = row_number(),
           load_overlap = as.numeric(as.factor(load_overlap)))

str(complete_data)
#+end_SRC

#+RESULTS:
#+begin_example

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union
'data.frame':	23120 obs. of  9 variables:
 $ elements_number   : int  3 2 4 2 2 2 2 4 4 3 ...
 $ y_component_number: int  3 2 1 1 1 2 2 2 4 1 ...
 $ vector_length     : int  4 1 4 1 8 2 1 8 16 4 ...
 $ temporary_size    : int  4 2 2 2 2 2 4 4 2 4 ...
 $ load_overlap      : num  2 1 2 1 2 2 1 2 2 2 ...
 $ threads_number    : int  64 128 64 256 128 128 128 64 128 32 ...
 $ lws_y             : int  64 1 32 64 32 8 2 2 128 32 ...
 $ time_per_pixel    : num  1.11e-08 1.58e-10 2.34e-09 1.39e-09 3.40e-09 ...
 $ row_number        : int  1 2 3 4 5 6 7 8 9 10 ...
#+end_example

***** GPR Code
#+begin_SRC R :results output :session *R3* :eval no-export :exports results :tangle "dopt_anova_experiments/src/gpr.r"
library(DiceKriging)
library(dplyr)

complete_data <- read.csv("dopt_anova_experiments/data/search_space.csv",
                          header = TRUE)
complete_data <- complete_data %>%
    select(-vector_recompute) %>%
    mutate(row_number = row_number(),
           load_overlap = as.numeric(as.factor(load_overlap)))

str(complete_data)

global_optimum <- filter(complete_data, time_per_pixel == min(time_per_pixel))

initial_budget <- 120
initial_sample <- 24
added_training_points <- 6
iterations = round((initial_budget - initial_sample) / added_training_points)
print(iterations)

repetitions <- 1000
# sd_range <- 1.96
sd_range <- 0.3
nugget <- 1e-12

results <- NULL

delta <- 0.5 # (0, 1)
scale_factor <- 30

variance_dampening <- function(dimension, delta, time) {
    return(sqrt((log((dimension * ((time * pi) ^ 2)) /
                         (6 * delta))) /
                scale_factor))
}

variance_dampening_ucb <- function(dimension, delta, time) {
    return(sqrt(log(time)))
}

for(j in 1:repetitions){
    testing_sample <- complete_data
    training_sample <- NULL

    for(i in 1:iterations){
        if(is.null(training_sample)){
            training_sample <- slice_sample(testing_sample,
                                            n = initial_sample)
        }

        testing_sample <- testing_sample %>%
            filter(!(row_number %in% training_sample$row_number))

        invisible(
            capture.output(
                gp_model <-
                    km(formula = ~ y_component_number + I(1 / y_component_number) +
                           vector_length + lws_y + I(1 / lws_y) +
                           load_overlap + temporary_size +
                           elements_number + I(1 / elements_number) +
                           threads_number + I(1 / threads_number),
                       design = select(training_sample,
                                       -row_number,
                                       -time_per_pixel),
                       response = training_sample$time_per_pixel,
                       #nugget = nugget * var(training_sample$time_per_pixel),
                       nugget = 1e-1,
                       control = list(pop.size = 400,
                                      BFGSburnin = 500))
            ))

        gp_prediction <- predict(gp_model,
                                 select(testing_sample,
                                        -row_number,
                                        -time_per_pixel),
                                 "UK")

        # testing_sample$expected_improvement <- gp_prediction$mean -
        #     (sd_range * gp_prediction$sd)

        print(c(length(training_sample[, 1]),
                variance_dampening(length(training_sample) - 2,
                                   delta,
                                   i)))

        testing_sample$expected_improvement <- gp_prediction$mean -
            (variance_dampening(length(training_sample),
                                delta,
                                length(training_sample[, 1])) * gp_prediction$sd)

        new_training_sample <- testing_sample %>%
            arrange(expected_improvement)

        testing_sample <- select(testing_sample, -expected_improvement)

        new_training_sample <- select(new_training_sample[1:added_training_points, ],
                                      -expected_improvement)

        training_sample <- bind_rows(training_sample,
                                     new_training_sample)
    }

    training_sample <- training_sample %>%
        mutate(measurement_order = row_number(),
               experiment_id = j,
               slowdown = time_per_pixel /
                   global_optimum$time_per_pixel)

    if(is.null(results)){
        results <- training_sample
    } else{
        results <- bind_rows(results,
                             training_sample)
    }

    best_points <- results %>%
        mutate(method = "GPR_dampening") %>%
        group_by(experiment_id)

    write.csv(best_points %>%
              filter(time_per_pixel == min(time_per_pixel)),
              "gpr_dampening_sc30_d05_best_points.csv")

    write.csv(best_points, "gpr_dampening_sc30_d05_all_points.csv")
}
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	23120 obs. of  9 variables:
 $ elements_number   : int  3 2 4 2 2 2 2 4 4 3 ...
 $ y_component_number: int  3 2 1 1 1 2 2 2 4 1 ...
 $ vector_length     : int  4 1 4 1 8 2 1 8 16 4 ...
 $ temporary_size    : int  4 2 2 2 2 2 4 4 2 4 ...
 $ load_overlap      : num  2 1 2 1 2 2 1 2 2 2 ...
 $ threads_number    : int  64 128 64 256 128 128 128 64 128 32 ...
 $ lws_y             : int  64 1 32 64 32 8 2 2 128 32 ...
 $ time_per_pixel    : num  1.11e-08 1.58e-10 2.34e-09 1.39e-09 3.40e-09 ...
 $ row_number        : int  1 2 3 4 5 6 7 8 9 10 ...
[1] 18
Error in t.default(T) : argument is not a matrix
#+end_example

***** Sub-spaces Reached by each Method
#+begin_SRC R :results graphics output :session *R* :file "dopt_anova_experiments/img/subspaces.pdf" :width 20 :height 20 :eval no-export
library(GGally)
library(dplyr)
library(grid)
library(patchwork)
library(gridExtra)

gpr_data <- read.csv("dopt_anova_experiments/data/gpr_nugget_best_points.csv") %>%
    select(-slowdown, -time_per_pixel, -measurement_order,
           -experiment_id, -X, -row_number) %>%
    mutate(method = "GPRN")

# names(gpr_data) <- c("slowdown", "method", "point_number", "time_per_pixel")

gpr_lin_data <- read.csv("dopt_anova_experiments/data/gpr_nosd_best_points.csv") %>%
    select(-slowdown, -time_per_pixel, -measurement_order,
           -experiment_id, -X, -row_number) %>%
    mutate(method = "GPR")

# names(gpr_lin_data) <- c("slowdown", "method", "point_number", "time_per_pixel")

df_all_methods <- read.csv("dopt_anova_experiments/data/complete_1000.csv",
                           strip.white = TRUE, header = TRUE) %>%
    select(-slowdown, -point_number, -vector_recompute, -time_per_pixel)

levels <- c("RS", "LHS", "GS", "GSR",
            "GA","LM", "LMB", "LMBT",
            "RQ", "DOPT", "DLM", "DLMT",
            "GPR", "GPRN")

selected_methods <- c("RS", "LHS", "GS", "GSR",
                      "GA", "LM", "DLMT", "GPR", "GPRN")

df_all_methods <- df_all_methods %>%
    mutate(load_overlap = as.numeric(as.factor(load_overlap))) %>%
    bind_rows(gpr_data, gpr_lin_data) %>%
    mutate(method = factor(method,
                           levels = levels)) %>%
    filter(method %in% selected_methods) %>%
    group_by(method) %>%
    ungroup()

gprn <- ggpairs(df_all_methods %>%
                filter(method == "GPRN") %>%
                select(-method)) +
    ggtitle("GPRN: Trend + Nugget")

gpr <- ggpairs(df_all_methods %>%
               filter(method == "GPR") %>%
               select(-method)) +
    ggtitle("GPR: Trend")

dlmt <- ggpairs(df_all_methods %>%
                filter(method == "DLMT") %>%
                select(-method)) +
    ggtitle("DLMT")

dlm <- ggpairs(df_all_methods %>%
               filter(method == "LM") %>%
               select(-method)) +
    ggtitle("LM")

p1 <- grid.grabExpr(print(dlm))
p2 <- grid.grabExpr(print(dlmt))
p3 <- grid.grabExpr(print(gpr))
p4 <- grid.grabExpr(print(gprn))

grid.arrange(p1, p2, p3, p4, ncol = 2)
#+end_SRC

#+RESULTS:
[[file:dopt_anova_experiments/img/subspaces.pdf]]

***** Histogram
#+begin_SRC R :results graphics output :session *R* :file "dopt_anova_experiments/img/comparison_histogram.pdf" :width 7 :height 10.5 :eval no-export :tangle "dopt_anova_experiments/src/build_histogram.r"
library(ggplot2)
library(dplyr)

#gpr_data <- read.csv("dopt_anova_experiments/data/gpr_nugget_best_points.csv") %>%
# gpr_data <- read.csv("gpr_dampening_sc30_d05_best_points.csv") %>%
#     select(slowdown, method, measurement_order, time_per_pixel) %>%
#     mutate(method = "GPRD")
#
# names(gpr_data) <- c("slowdown", "method", "point_number", "time_per_pixel")

#gpr_lin_data <- read.csv("dopt_anova_experiments/data/gpr_nosd_best_points.csv") %>%
gpr_lin_data <- read.csv("dopt_anova_experiments/data/gpr_03sd_nugget_best_points.csv") %>%
    select(slowdown, method, measurement_order, time_per_pixel) %>%
    mutate(method = "GPR")

names(gpr_lin_data) <- c("slowdown", "method", "point_number", "time_per_pixel")

df_all_methods <- read.csv("dopt_anova_experiments/data/complete_1000.csv",
                           strip.white = TRUE, header = TRUE)

levels <- c("RS", "LHS", "GS", "GSR", "GA", "LM", "RQ", "DLMT", "GPR")
labels <- c("RS", "LHS", "GS", "GSR", "GA", "LM", "QR", "DLMT", "GPR")

df_all_methods <- df_all_methods %>%
    select(slowdown, method, point_number, time_per_pixel) %>%
    bind_rows(gpr_lin_data) %>%
    mutate(method = factor(method,
                           levels = levels,
                           labels = labels)) %>%
    filter(method %in% labels) %>%
    group_by(method) %>%
    mutate(mean = mean(slowdown),
           median = median(slowdown),
           ci95 = 1.96 * sd(slowdown) / sqrt(n()),
           max = max(slowdown)) %>%
    ungroup()

ggplot(df_all_methods) +
    facet_grid(method ~ .) +
    theme_bw(base_size = 15) +
    coord_cartesian(xlim = c(.9, 4),
                    ylim = c(0, 1000)) +
    geom_histogram(aes(slowdown),
                   binwidth = .05,
                   fill = "gray48") +
    scale_y_continuous(breaks = c(0, 1000),
                       labels = c("0", "1000")) +
    geom_curve(aes(x = max + .1,
                   y = 500,
                   xend = max,
                   yend = 5),
               arrow = arrow(length = unit(0.05, "npc")),
               curvature = 0.3,
               stat = "unique") +
    geom_text(aes(x = max + .2,
                  y = 550,
                  label = "max"),
              stat = "unique") +
    geom_rect(aes(xmin = mean - ci95,
                  xmax = mean + ci95,
                  ymin = 0,
                  ymax = 1000,
                  fill = "red"),
              alpha = 0.3,
              stat = "unique") +
    geom_vline(aes(xintercept = median),
               color = "darkgreen",
               linetype = 3,
               stat = "unique") +
    geom_vline(aes(xintercept = mean),
               color = "red",
               linetype = 2,
               stat = "unique") +
    labs(y = "Count",
         x = "Slowdown compared to the optimal solution") +
    scale_fill_discrete(name = "",
                        breaks = c("red"),
                        labels = c("Mean error")) +
    ggtitle("") +
    theme(legend.position = "none",
          strip.background = element_rect(fill = "white"))
#+end_SRC

#+RESULTS:
[[file:dopt_anova_experiments/img/comparison_histogram.pdf]]

***** Final Table
#+HEADER: :results output latex :session *R* :exports results :eval no-export
#+BEGIN_SRC R
library(xtable)
library(dplyr)

gpr_lin_data <- read.csv("dopt_anova_experiments/data/gpr_03sd_nugget_best_points.csv") %>%
    select(slowdown, method, measurement_order, time_per_pixel) %>%
    mutate(method = "GPR")

names(gpr_lin_data) <- c("slowdown", "method", "point_number", "time_per_pixel")

df_all_methods = read.csv("./dopt_anova_experiments/data/complete_1000.csv",
                          strip.white = T, header = T) %>%
    select(slowdown, method, point_number) %>%
    bind_rows(gpr_lin_data) %>%
    filter(method %in% c("RS", "LHS", "GS", "GSR", "GA", "LM",
                         "DLMT", "RQ", "GPR")) %>%
    mutate(method =  factor(method,
                            levels = c("RS", "LHS", "GS", "GSR", "GA", "LM",
                                       "RQ", "DLMT", "GPR"),
                            labels = c("Random Sampling (RS)",
                                       "Latin Hypercube Sampling (LHS)",
                                       "Greedy Search (GS)",
                                       "Greedy Search w. Restart (GSR)",
                                       "Genetic Algorithm (GA)",
                                       "Linear Model (LM)",
                                       "Quantile Regression (QR)",
                                       "D-Opt., Linear Model w. Transform (DLMT)",
                                       "Gaussian Process Regression w. EI (GPR)")))

summaries = df_all_methods %>%
    group_by(method) %>%
    summarise(method = method,
              mean_slowdown = mean(slowdown),
              min_slowdown = min(slowdown),
              max_slowdown = max(slowdown),
              mean_budget = mean(point_number),
              max_budget = max(point_number),
              .groups = "keep") %>%
    distinct() %>%
    ungroup()

cap <- paste("Slowdown and budget used by 7 optimization methods on",
             "the Laplacian Kernel, using a budget of 125 points with 1000 repetitions")

x <- xtable(summaries,
            caption = cap,
            digits = 2,
            label = "tab:gpu_laplacian_compare_budget")

align(x) <- xalign(x)
display(x) <- display(x)

header = paste(paste("Method", "Mean", "Min.", "Max.", "Mean", "Max.",
               sep = " & "), "\\\\ \n \\midrule \n")

super_header = paste("\\toprule \n",
                     "& \\multicolumn{3}{c}{Slowdown} & \\multicolumn{2}{c}{Budget}",
                     "\\\\ \n")

bottom = "\\bottomrule\n"

print(x,
      size = "\\small",
      booktabs = TRUE,
      include.rownames = FALSE,
      include.colnames = FALSE,
      hline.after = NULL,
      add.to.row = list(pos = as.list(c(-1,
                                        0,
                                        7,
                                        nrow(summaries))),
                        command = c(super_header,
                                    header,
                                    "\\rowcolor{red!25}",
                                    bottom)),
      math.style.exponents = TRUE,
      table.placement = "b",
      caption.placement = "top")
#+END_SRC

#+RESULTS:
#+begin_export latex
% latex table generated in R 4.0.4 by xtable 1.8-4 package
% Mon Mar 15 17:18:51 2021
\begin{table}[b]
\centering
\caption{Slowdown and budget used by 7 optimization methods on the Laplacian Kernel, using a budget of 125 points with 1000 repetitions}
\label{tab:gpu_laplacian_compare_budget}
\begingroup\small
\begin{tabular}{lrrrrr}
  \toprule
 & \multicolumn{3}{c}{Slowdown} & \multicolumn{2}{c}{Budget} \\
  Method & Mean & Min. & Max. & Mean & Max. \\
 \midrule
Random Sampling (RS) & 1.10 & 1.00 & 1.39 & 120.00 & 120 \\
  Latin Hypercube Sampling (LHS) & 1.17 & 1.00 & 1.52 & 98.92 & 125 \\
  Greedy Search (GS) & 6.46 & 1.00 & 124.76 & 22.17 & 106 \\
  Greedy Search w. Restart (GSR) & 1.23 & 1.00 & 3.16 & 120.00 & 120 \\
  Genetic Algorithm (GA) & 1.12 & 1.00 & 1.65 & 120.00 & 120 \\
  Linear Model (LM) & 1.02 & 1.01 & 3.77 & 119.00 & 119 \\
  Quantile Regression (QR) & 1.02 & 1.01 & 2.06 & 119.00 & 119 \\
   \rowcolor{red!25}D-Opt., Linear Model w. Transform (DLMT) & 1.01 & 1.01 & 1.01 & 54.84 &  56 \\
  Gaussian Process Regression w. EI (GPR) & 1.04 & 1.01 & 1.27 & 71.45 & 120 \\
   \bottomrule
\end{tabular}
\endgroup
\end{table}
#+end_export

*** [2020-09-18 Fri]
**** R session sample
#+begin_SRC R :results output :session *R3* :eval no-export :exports results
library(dplyr)
df <- rnorm(10, 10)
df + 1
#+end_SRC

#+RESULTS:
:
:  [1] 11.025812 11.525666 10.855048 11.342663 11.620696 11.578011 10.151870
:  [8] 10.311008 11.926957  9.512951

#+begin_SRC R :results output :session *R3* :eval no-export :exports results
str(df)
#+end_SRC

#+RESULTS:
:  num [1:10] 10.03 10.53 9.86 10.34 10.62 ...
*** [2020-09-24 Thu]
**** CI for Speedups

#+begin_SRC R :results output :session *R* :eval no-export :exports results
y1 = rnorm(mean = 20, n = 30)
y2 = rnorm(mean = 25, n = 30)

ci_speedup_inf = (mean(y2) - 1.96 * sd(y2)) /
    (mean(y1) + 1.96 * sd(y1))

    ci_speedup_sup = (mean(y2) + 1.96 * sd(y2)) /
    (mean(y1) - 1.96 * sd(y1))

c(25 / 20,
  mean(y2) / mean(y1),
  ci_speedup_inf,
  ci_speedup_sup)
#+end_SRC

#+RESULTS:
: [1] 1.250000 1.253689 1.066590 1.476254
** October
*** [2020-10-06 Tue]
**** Related work Pedro (from Arnaud)
***** Chat notes
- https://www.jmp.com/support/help/en/15.2/index.shtml#page/jmp/gaussian-process-imse-optimal-designs.shtml#ww90928
- https://sites.ualberta.ca/~dwiens/home%20page/publist.htm
- https://sites.ualberta.ca/~dwiens/home%20page/pubs/lof%20discrete.pdf
- https://bookdown.org/rbg/surrogates/
***** Minimisation (f is known)
- [[https://en.wikipedia.org/wiki/Stochastic_gradient_descent][Convex function or Pseudo-convex]]: Briefly, when the learning rates \eta
decrease with
  an appropriate rate, and subject to relatively mild assumptions,
  stochastic gradient descent converges almost surely to a global
  minimum
  - Lipschitz guarantee ?
  - [[https://en.wikipedia.org/wiki/Gradient_descent][Many variants]]
(momentum to avoid zig-zag, Backtracking line
    search so that objective strictly decreases, conjugate gradient
    or Newton if hessian, Nelder-Mead if derivatives cannot be computed
- C^2: converges almost surely to a local minimum
- Meta-heuristics like Hill Climbing, Simulated Annealing
  (stochastic neighborhood exploration, related to
  https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm),
  Genetic Algorithm.
  -
[[https://stackoverflow.com/questions/4092774/what-are-the-differences-between-simulated-annealing-and-genetic-algorithms][In  the  meta-heuristic taxonomy,  SA  is  a single-state  method  and  GA is  a
population method (in  a sub-class along with PSO, ACO,  et al, usually referred
to as biologically-inspired meta-heuristics).]]
- Constrained optimization (requires Lagrangian unless a variable
  change helps). Additional difficulty: avoiding to get stuck on the
  border and following it with ridiculous steps.

Convergence rate degrades with dimension and bad normalization.
***** Learning (f is not known and should be approximated from x samples)
- statistical learning: optimize the loss or maximum likelihood for
  model parameters. In general seeks a good prediction
  "everywhere". Tries to evaluate uncertainty on parameters and predictions.
- "machine" learning: efficient optimization of the loss (i.e.
  E_{x,\theta}[y_\theta(x)-y(x)])

Statistical and Machine learning generally assume that the samples x
are fixed inputs (observations vs. controled experiments), which
raises difficulties regarding generalization/overfitting,
discriminating causation from correlation, counterfactual analysis,
etc.
***** Design of Experiments (find the "best" x to obtain a good model)
Assuming a model for f, propose a set of x to measure to obtain the
best estimates for the model parameters \theta and the prediction.
- Linear models
  - Fractional Designs
  - Screening
  - D-optimal designs
- Unconstrained models (gaussian process)
  - LHS
***** Online and Reinforcement Learning
Choose x_i depending on previous observations and obtain feedback. Same
rules: interact with the world and get feedback, and try to find the
"best" configuration.

- Online machine learning: regret from 1 to T, no discount. Often
  relies on stochastic gradient.
  - Special simple case = Bandit
    - Stochastic: UCB/Thompson, log(T)
    - Adversarial: EXP3, sqrt(T)
  - Many variants Linear UCB, LinRel, Gaussian UCB
- Reinforcement learning: optimize (infinite discounted) regret,
  generally through Markov Decision Process (i.e., dynamic
  programming).
  - Well studied for finite-state space MDPs
  - Does not scale well in high dimension

In both cases, the balance between exploration and exploitation is
lead by (temporally aggregated) regret.
***** Fast exploration of expensive black-box functions
- Reduce dimension by exploiting knowledge on the geometry of f (e.g.,
  identify unsignificant parameters or parameters that need to be set
  to "obvious" values).
- [[https://smt.readthedocs.io/en/latest/_src_docs/applications/ego.html][EGO]]:
Efficient global optimization of expensive black-box
  functions. Journal of Global optimization, 13(4), 455-492.  EGO
  targets the minimization of the expected deviation from the extremum
  of the studied function.
  - EI, Kriging Believer (no guarantee) and GaussianUCB differ by the
*** [2020-10-18 Sun]
**** Brice's Links for Sampling on a Constrained Triangle
- https://cs.stackexchange.com/questions/3227/uniform-sampling-from-a-simplex
- https://cs.stackexchange.com/questions/14007/random-sampling-in-a-polygon
*** [2020-10-21 Wed]
**** Arnaud's References
- [[https://sites.ualberta.ca/~dwiens/home%2520page/publist.htm][List of publications on Maxmin Designs for Lack of Fit, Regression, etc]]
- [[https://sites.ualberta.ca/~dwiens/home%2520page/pubs/nonlinear%2520quantile%2520regression%2520design.pdf][Model-robust designs for nonlinearquantile regression]]
- [[https://sites.ualberta.ca/~dwiens/home%2520page/pubs/lof%2520discrete.pdf][Maximin power designs in testing lack of fit]]
- [[https://sites.ualberta.ca/~dwiens/home%2520page/pubs/uniformdesigns.pdf][Designs for approximately linear regression: Two optimality properties of uniform designs]]
- [[https://www.jmp.com/support/help/en/15.2/index.shtml#page/jmp/gaussian-process-imse-optimal-designs.shtml#ww90928][Gaussian Process IMSE Optimal Designs]]
- [[https://smt.readthedocs.io/en/latest/_src_docs/applications/ego.html][Efficient Global Optimization (EGO): Bayesian Optimization]]
- [[https://www.ressources-actuarielles.net/EXT/ISFA/1226.nsf/0/f84f7ac703bf5862c12576d8002f5259/$FILE/Jones98.pdf][EGO Original Paper]]
**** Surrogates Book
- [[https://bookdown.org/rbg/surrogates/][Surrogates: Gaussian process modeling, design and optimization for the applied sciences]]
*** [2020-10-22 Thu]
**** Student's Justification
The experimental validation of the approaches studied during this thesis, namely
Design of Experiments and Gaussian Process Regression, took longer than expected
in  the  initial SPAPT  benchmark.  The  large set  of  problems  and number  of
configurable parameters slowed down a  comprehensive and careful analysis of the
relationships between parameters and performance for many problems.

The  Gaussian  Process  Regression  approach introduced  further  questions  and
restrictions for experimental  validation, and the method was also  applied to a
different  domain, the  selection of  bit precision  for layers  of Deep  Neural
Networks, where completing a single experimental run takes a full week.

I have  already started my efforts  towards writing the thesis,  but our current
assessment of  the state of the  work indicates that  I most likely will  not be
able to finish before  the end of the third year's limit date.   We intend to to
finish writing the thesis by the end of December 2020, and consequently schedule
the thesis defense to March 2021.
**** Advisor's Justification
The  contribution of  this  thesis  is an  evaluation  of  the effectiveness  of
established  search, learning,  and statistical  methods for  optimization, that
were  nonetheless not  comprehensively  applied and  evaluated  on the  specific
domain of optimization and performance modeling of computer programs.

We initially applied a Design of  Experiments approach to model and optimize the
performance   of  the   code   produced  by   frameworks  for   source-to-source
transformation. One  of the target  frameworks was SPAPT, consisting  of several
programs and configurable  parameters. We published our  initial exploration and
optimization of these programs in 2019, but the more extensive subsequent study,
involving the explicit identification of significant parameters for each kernel,
and  the  exploration  of  different  modeling  assumptions,  such  as  quantile
regression, took more time than expected.

In parallel to our Design of Experiments study, we also applied Gaussian Process
Regression,  a  different   category  of  optimization  methods   to  a  program
optimization problem  on a  different application  domain, namely,  the adaptive
selection  of bit  precision  for  each layer  of  Deep  Neural Networks.   This
experiment involved the  comparison of our optimization method  with a reference
Reinforce Learning algorithm. Experiments  involve training and inference steps,
which are necessary for model validation, and on the experimental scenarios such
as the  ones studied in this  work, experiments take  up to a week  to complete.
Our  exploration  of  the  particular  conditions  that  make  Gaussian  Process
Regression methods perform well in this  sort of problem domain also took longer
than expected. We studied sampling  strategies that enabled local exploration of
promising points, and  compared the adequacy of  different acquisition functions
to  determine  such  points.   We  have also  revisited  previous  work  on  our
source-to-source transformation  benchmark on  GPUs, applying and  studying this
optimization method in its context as well.

Work has started on thesis writing, and is planned to conclude by December 2020.
The defense will then take place on March 2021.
** November
*** [2020-11-11 Wed]
**** Meeting with Alfredo
- Vinicius' payment
- Nathan's payment
- Cotutelle extension agreement @ USP
- Attestation de financement jusqu'à Mars pour mon inscription à l'UGA
- Papers: Luciano, Carlos (iWAPT), Giuliano (?)
- Thesis
- HPE
* 2021
** January
*** [2021-01-22 Fri]
**** Screening for CUDA Parameters
***** Cloning and Updating the Repository
#+begin_SRC shell :results output :session *Shell* :eval no-export :exports results
git clone --depth=1 git@github.com:phrb/autotuning_screening_experiment.git ||
    (cd autotuning_screening_experiment && git pull)
#+end_SRC
***** Quadro M1200
****** Loading Data
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)

parse_data <- function(filename, experiment_id) {
    read.csv(filename, header = TRUE) %>%
        select(-complete,
               -id) %>%
        rename_with(~ gsub("X.", "", .x, fixed = TRUE)) %>%
        rename_with(~ gsub("Xptxas..", "", .x, fixed = TRUE)) %>%
        rename_with(~ gsub("Xnvlink..", "", .x, fixed = TRUE)) %>%
        rename_with(~ gsub(".", "_", .x, fixed = TRUE)) %>%
        mutate(experiment_id = experiment_id)
}

predictions_files = list(c("autotuning_screening_experiment/data/gaussian_quadrom1200",
                           "prediction_results.csv", "Model Prediction (GAU)"),
                         c("autotuning_screening_experiment/data/heartwall_quadrom1200",
                           "prediction_results.csv", "Model Prediction (HWL)"),
                         c("autotuning_screening_experiment/data/needle_quadrom1200",
                           "prediction_results.csv", "Model Prediction (NDL)"))

screening_files = list(c("autotuning_screening_experiment/data/gaussian_quadrom1200",
                         "results.csv", "Screening (GAU)"),
                       c("autotuning_screening_experiment/data/heartwall_quadrom1200",
                         "results.csv", "Screening (HWL)"),
                       c("autotuning_screening_experiment/data/needle_quadrom1200",
                         "results.csv", "Screening (NDL)"))

baseline_files = list(c("autotuning_screening_experiment/data/gaussian_quadrom1200",
                        "baseline_results.csv", "Baseline (GAU)"),
                      c("autotuning_screening_experiment/data/heartwall_quadrom1200",
                        "baseline_results.csv", "Baseline (HWL)"),
                      c("autotuning_screening_experiment/data/needle_quadrom1200",
                        "baseline_results.csv", "Baseline (NDL)"))


experiments_df = bind_rows(lapply(predictions_files,
                                  function(x) {
                                      parse_data(paste(x[1],
                                                       x[2],
                                                       sep = "/"),
                                                 x[3])
                                  })) %>%
    mutate(experiment_type = "screening_prediction",
           GPU = "Quadro M1200") %>%
    filter(!(experiment_id == "Model Prediction (GAU)" &
             response > 3.35)) %>%
    filter(!(experiment_id == "Model Prediction (NDL)" &
             response > 0.102))

str(experiments_df)
quadro_experiments_df = experiments_df

baselines_df = bind_rows(lapply(baseline_files,
                                function(x) {
                                    parse_data(paste(x[1],
                                                     x[2],
                                                     sep = "/"),
                                               x[3])
                                })) %>%
    mutate(experiment_type = "baseline",
           GPU = "Quadro M1200") %>%
    filter(!(experiment_id == "Baseline (GAU)" &
             response > 3.35)) %>%
    filter(!(experiment_id == "Baseline (NDL)" &
             response > 0.102))
str(baselines_df)
quadro_baselines_df = baselines_df

screening_df = bind_rows(lapply(screening_files,
                                function(x) {
                                    parse_data(paste(x[1],
                                                     x[2],
                                                     sep = "/"),
                                               x[3])
                                })) %>%
    mutate(experiment_type = "screening",
           GPU = "Quadro M1200") %>%
    filter(!(experiment_id == "Screening (GAU)" &
             response > 3.35)) %>%
    filter(!(experiment_id == "Screening (NDL)" &
             response > 0.102))

str(screening_df)
quadro_screening_df = screening_df
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	38 obs. of  19 variables:
 $ _use_fast_math                 : chr  "on" "on" "on" "on" ...
 $ _opt_level_                    : int  2 2 2 2 2 2 2 2 2 3 ...
 $ _gpu_architecture_             : chr  "sm_50" "sm_50" "sm_50" "sm_50" ...
 $ _ftz_                          : chr  "false" "false" "false" "false" ...
 $ _force_store_cache_            : chr  "cg" "cg" "cg" "cg" ...
 $ _force_load_cache_             : chr  "cs" "cs" "cs" "cs" ...
 $ _allow_expensive_optimizations_: chr  "false" "false" "false" "false" ...
 $ _fmad_                         : chr  "true" "true" "true" "true" ...
 $ _optimize_                     : int  2 2 2 2 2 2 2 2 2 3 ...
 $ _preserve_relocs               : chr  "on" "on" "on" "on" ...
 $ _relocatable_device_code_      : chr  "false" "false" "false" "false" ...
 $ _prec_div_                     : chr  "true" "true" "true" "true" ...
 $ _maxrregcount_                 : int  32 32 32 32 32 32 32 32 32 63 ...
 $ _prec_sqrt_                    : chr  "false" "false" "false" "false" ...
 $ _no_align_double               : chr  "on" "on" "on" "on" ...
 $ response                       : num  3.32 3.32 3.32 3.32 3.33 ...
 $ experiment_id                  : chr  "Model Prediction (GAU)" "Model Prediction (GAU)" "Model Prediction (GAU)" "Model Prediction (GAU)" ...
 $ experiment_type                : chr  "screening_prediction" "screening_prediction" "screening_prediction" "screening_prediction" ...
 $ GPU                            : chr  "Quadro M1200" "Quadro M1200" "Quadro M1200" "Quadro M1200" ...
'data.frame':	70 obs. of  6 variables:
 $ _opt_level_       : int  2 2 2 2 2 2 2 2 2 2 ...
 $ _gpu_architecture_: chr  "sm_50" "sm_50" "sm_50" "sm_50" ...
 $ response          : num  3.34 3.34 3.34 3.34 3.34 ...
 $ experiment_id     : chr  "Baseline (GAU)" "Baseline (GAU)" "Baseline (GAU)" "Baseline (GAU)" ...
 $ experiment_type   : chr  "baseline" "baseline" "baseline" "baseline" ...
 $ GPU               : chr  "Quadro M1200" "Quadro M1200" "Quadro M1200" "Quadro M1200" ...
'data.frame':	793 obs. of  23 variables:
 $ dummy3                         : int  -1 -1 -1 -1 -1 -1 -1 -1 -1 1 ...
 $ _use_fast_math                 : chr  "off" "off" "off" "off" ...
 $ _opt_level_                    : int  2 2 2 2 2 2 2 2 2 2 ...
 $ _gpu_architecture_             : chr  "sm_50" "sm_50" "sm_50" "sm_50" ...
 $ _ftz_                          : chr  "true" "true" "true" "true" ...
 $ _force_store_cache_            : chr  "cg" "cg" "cg" "cg" ...
 $ _force_load_cache_             : chr  "cs" "cs" "cs" "cs" ...
 $ _allow_expensive_optimizations_: chr  "false" "false" "false" "false" ...
 $ _fmad_                         : chr  "true" "true" "true" "true" ...
 $ _optimize_                     : int  2 2 2 2 2 2 2 2 2 3 ...
 $ dummy2                         : int  1 1 1 1 1 1 1 1 1 -1 ...
 $ _preserve_relocs               : chr  "off" "off" "off" "off" ...
 $ _relocatable_device_code_      : chr  "true" "true" "true" "true" ...
 $ _prec_div_                     : chr  "false" "false" "false" "false" ...
 $ dummy1                         : int  -1 -1 -1 -1 -1 -1 -1 -1 -1 1 ...
 $ _maxrregcount_                 : int  63 63 63 63 63 63 63 63 63 32 ...
 $ dummy4                         : int  1 1 1 1 1 1 1 1 1 -1 ...
 $ _prec_sqrt_                    : chr  "true" "true" "true" "true" ...
 $ _no_align_double               : chr  "off" "off" "off" "off" ...
 $ response                       : num  3.32 3.33 3.33 3.33 3.32 ...
 $ experiment_id                  : chr  "Screening (GAU)" "Screening (GAU)" "Screening (GAU)" "Screening (GAU)" ...
 $ experiment_type                : chr  "screening" "screening" "screening" "screening" ...
 $ GPU                            : chr  "Quadro M1200" "Quadro M1200" "Quadro M1200" "Quadro M1200" ...
#+end_example
****** Computing Main Effects from Screening Data
******* Setup
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)
library(broom)

run_lm <- function(experiment) {
    lm(response ~ .,
       screening_df %>%
       filter(experiment_id == experiment) %>%
       select(-GPU,
              -experiment_id,
              -`_gpu_architecture_`,
              -experiment_type) %>%
       mutate(across(!contains("response"), as.factor)) %>%
       mutate(across(where(is.character), as.factor)) #%>%
       #mutate(across(where(is.factor), as.numeric)))
       )
}

run_aov <- function(experiment) {
    aov(response ~ .,
       screening_df %>%
       filter(experiment_id == experiment) %>%
       select(-GPU,
              -experiment_id,
              -`_gpu_architecture_`,
              -experiment_type) %>%
       mutate(across(!contains("response"), as.factor)) %>%
       mutate(across(where(is.character), as.factor)) #%>%
       #mutate(across(where(is.factor), as.numeric)))
       )
}

lm_gau = run_lm("Screening (GAU)")
lm_hwl = run_lm("Screening (HWL)")
lm_ndl = run_lm("Screening (NDL)")

aov_gau = run_aov("Screening (GAU)")
aov_hwl = run_aov("Screening (HWL)")
aov_ndl = run_aov("Screening (NDL)")
#+end_SRC

#+RESULTS:

******* Plot
#+begin_SRC R :results graphics output :session *R* :file "img/main_effects_quadrom1200.pdf" :width 14 :height 10.5 :eval no-export
library(dplyr)
library(tidyr)
library(tibble)
library(broom)
library(ggplot2)
library(latex2exp)

bind_confint_lm <- function(model, experiment) {
    bind_cols(tidy(model) %>%
              rename(mean = estimate) %>%
              arrange(term),
              data.frame(confint(model)) %>%
              rownames_to_column() %>%
              rename(ci_inf = `X2.5..`,
                     ci_sup = `X97.5..`) %>%
              arrange(rowname)) %>%
        select(-rowname) %>%
        mutate(experiment = experiment)
}

plot_df = bind_rows(bind_confint_lm(lm_gau, "GAU"),
                    bind_confint_lm(lm_hwl, "HWL"),
                    bind_confint_lm(lm_ndl, "NDL")) %>%
    mutate(term = trimws(term, whitespace = "[_, `]")) %>%
    filter(!grepl("dummy", term)) %>%
    filter(!grepl("Intercept", term)) %>%
    mutate(term = gsub("_`", " = ", term,
                       fixed = FALSE)) %>%
    mutate(term = gsub("`", " = ", term,
                       fixed = FALSE)) %>%
    mutate(term = gsub("allow_expensive_optimizations", "exp_opt", term,
                       fixed = FALSE)) %>%
    mutate(term = gsub("gpu_architecture", "arch", term,
                       fixed = FALSE)) %>%
    mutate(term = gsub("no_align_double", "no_align_db", term,
                       fixed = FALSE)) %>%
    mutate(term = gsub("relocatable_device_code", "rel_dev_code", term,
                       fixed = FALSE))

p_effects_quadro = ggplot() +
    geom_point(data = plot_df,
               aes(x = term,
                   y = mean),
               size = 3) +
    geom_errorbar(data = plot_df,
                  aes(x = term,
                      ymin = ci_inf,
                      ymax = ci_sup),
                  width = 0.4) +
    geom_hline(data = plot_df,
               aes(x = term),
               linetype = 2,
               yintercept = 0.0) +
    ylab(TeX("Mean Effect Estimate $\\pm$ 95% CI")) +
    ggtitle("Quadro M1200") +
    facet_grid(experiment ~ .,
               scales = "free_y") +
    theme_bw(base_size = 24) +
    theme(plot.title = element_text(size = 19),
          strip.background = element_rect(fill = "white"),
          axis.title.x = element_blank(),
          axis.text.x = element_text(size = 18,
                                     angle = 30,
                                     hjust = 1,
                                     vjust = 1))

p_effects_quadro
#+end_SRC

#+RESULTS:
[[file:img/main_effects_quadrom1200.pdf]]
****** Execution Times
#+begin_SRC R :results graphics output :session *R* :file "./img/executiontimes_screening_quadrom1200.pdf" :width 11.2 :height 10.5 :eval no-export
library(dplyr)
library(ggplot2)

plot_df = bind_rows(baselines_df %>%
                    filter(`_opt_level_` == 3) %>%
                    select(experiment_type,
                           experiment_id,
                           response),
                    experiments_df %>%
                    distinct() %>%
                    select(experiment_type,
                           experiment_id,
                           response)) %>%
    mutate(experiment_id = gsub("Baseline (",
                                "",
                                experiment_id,
                                fixed = TRUE)) %>%
    mutate(experiment_id = gsub("Model Prediction (",
                                "",
                                experiment_id,
                                fixed = TRUE)) %>%
    mutate(experiment_id = gsub(")",
                                "",
                                experiment_id,
                                fixed = TRUE)) %>%
    mutate(experiment_type = gsub("baseline",
                                  "-O3",
                                  experiment_type,
                                  fixed = TRUE)) %>%
    mutate(experiment_type = gsub("screening_prediction",
                                  "Best Prediction",
                                  experiment_type,
                                  fixed = TRUE)) %>%
    # filter(!(experiment_id == "HWL" &
    #          response > 2.0)) %>%
    group_by(experiment_id, experiment_type) %>%
    mutate(mean_r = mean(response),
           ci95 = 1.96 * sd(response) / sqrt(n()))

p_timing_quadro = ggplot() +
    geom_jitter(data = plot_df,
                size = 4,
                shape = 1,
                alpha = 1,
                aes(x = experiment_type,
                    y = response,
                    color = experiment_type),
                width = 0.3,
                height = 0.0,
                show.legend = FALSE) +
    geom_errorbar(data = plot_df,
                  aes(x = experiment_type,
                      ymin = mean_r - ci95,
                      ymax = mean_r + ci95,
                      color = experiment_type),
                  show.legend = FALSE,
                  width = 0.3) +
    geom_point(data = plot_df,
               size = 4,
               aes(x = experiment_type,
                   y = mean_r,
                   color = experiment_type),
               show.legend = FALSE) +
    facet_grid(experiment_id ~ .,
               scales = "free_y") +
    ylab("Execution Time (s)") +
    ggtitle("Quadro M1200") +
    scale_color_brewer(palette = "Dark2") +
    #scale_y_continuous(labels = scales::number_format(accuracy = 0.01)) +
    ylim(0, NA) +
    theme_bw(base_size = 37) +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_text(size = 29),
          plot.title = element_text(size = 25),
          strip.background = element_rect(fill = "white"))

p_timing_quadro
#+end_SRC

#+RESULTS:
[[file:./img/executiontimes_screening_quadrom1200.pdf]]
****** Speedup
#+begin_SRC R :results graphics output :session *R* :file "./img/speedups_screening_quadrom1200.pdf" :width 11 :height 10.5 :eval no-export
library(dplyr)
library(tidyr)
library(ggplot2)

speedups = bind_cols(baselines_df %>%
                     filter(`_opt_level_` == 3) %>%#,
                            # !(experiment_id == "Baseline (HWL)" &
                            #   response > 2.0)) %>%
                     select(experiment_type,
                            experiment_id,
                            response) %>%
                     group_by(experiment_id) %>%
                     summarise(mean_baseline = mean(response)) %>%
                     ungroup(),
                     experiments_df %>%
                     distinct() %>%
                     select(experiment_type,
                            experiment_id,
                            response) %>%
                     group_by(experiment_id) %>%
                     summarise(mean_predicted = mean(response)) %>%
                     ungroup() %>%
                     select(-experiment_id)) %>%
    mutate(speedup = mean_baseline / mean_predicted) %>%
    mutate(experiment_id = gsub("Baseline (",
                                "",
                                experiment_id,
                                fixed = TRUE)) %>%
    mutate(experiment_id = gsub(")",
                                "",
                                experiment_id,
                                fixed = TRUE))

quadro_screening_speedups = speedups %>%
    mutate(GPU = "Quadro M1200")

p_speedup_quadro = ggplot() +
    geom_point(data = speedups,
               size = 4,
               alpha = 1,
               aes(x = experiment_id,
                   y = speedup,
                   color = experiment_id),
               show.legend = FALSE) +
    geom_hline(data = speedups,
               aes(x = experiment_id),
               linetype = 2,
               yintercept = 1) +
    geom_segment(data = speedups,
                 aes(x = experiment_id,
                     xend = experiment_id,
                     y = 1.0,
                     yend = speedup),
                 linetype = 2) +
    ylab("Speedup vs. -O3") +
    ggtitle("Quadro M1200") +
    scale_color_brewer(palette = "Dark2") +
    theme_bw(base_size = 37) +
    theme(plot.title = element_text(size = 27),
          axis.title.x = element_blank())

p_speedup_quadro
#+end_SRC

#+RESULTS:
[[file:./img/speedups_screening_quadrom1200.pdf]]
***** Titan X
****** Loading Data
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)

parse_data <- function(filename, experiment_id) {
    read.csv(filename, header = TRUE) %>%
        select(-complete,
               -id) %>%
        rename_with(~ gsub("X.", "", .x, fixed = TRUE)) %>%
        rename_with(~ gsub("Xptxas..", "", .x, fixed = TRUE)) %>%
        rename_with(~ gsub("Xnvlink..", "", .x, fixed = TRUE)) %>%
        rename_with(~ gsub(".", "_", .x, fixed = TRUE)) %>%
        mutate(experiment_id = experiment_id)
}

predictions_files = list(c("autotuning_screening_experiment/data/gaussian_titanx",
                           "prediction_results.csv", "Model Prediction (GAU)"),
                         c("autotuning_screening_experiment/data/heartwall_titanx",
                           "prediction_results.csv", "Model Prediction (HWL)"),
                         c("autotuning_screening_experiment/data/needle_titanx",
                           "prediction_results.csv", "Model Prediction (NDL)"))

screening_files = list(c("autotuning_screening_experiment/data/gaussian_titanx",
                         "results.csv", "Screening (GAU)"),
                       c("autotuning_screening_experiment/data/heartwall_titanx",
                         "results.csv", "Screening (HWL)"),
                       c("autotuning_screening_experiment/data/needle_titanx",
                         "results.csv", "Screening (NDL)"))

baseline_files = list(c("autotuning_screening_experiment/data/gaussian_titanx",
                        "baseline_results.csv", "Baseline (GAU)"),
                      c("autotuning_screening_experiment/data/heartwall_titanx",
                        "baseline_results.csv", "Baseline (HWL)"),
                      c("autotuning_screening_experiment/data/needle_titanx",
                        "baseline_results.csv", "Baseline (NDL)"))

experiments_df = bind_rows(lapply(predictions_files,
                                  function(x) {
                                      parse_data(paste(x[1],
                                                       x[2],
                                                       sep = "/"),
                                                 x[3])
                                  })) %>%
    mutate(experiment_type = "screening_prediction",
           GPU = "Titan X") %>%
    filter(!(experiment_id == "Model Prediction (HWL)" &
             response > 2.0))

str(experiments_df)
titan_experiments_df = experiments_df

baselines_df = bind_rows(lapply(baseline_files,
                                function(x) {
                                    parse_data(paste(x[1],
                                                     x[2],
                                                     sep = "/"),
                                               x[3])
                                })) %>%
    mutate(experiment_type = "baseline",
           GPU = "Titan X") %>%
    filter(!(experiment_id == "Baseline (HWL)" &
             response > 2.0))

str(baselines_df)
titan_baselines_df = baselines_df

screening_df = bind_rows(lapply(screening_files,
                                function(x) {
                                    parse_data(paste(x[1],
                                                     x[2],
                                                     sep = "/"),
                                               x[3])
                                })) %>%
    mutate(experiment_type = "screening",
           GPU = "Titan X") %>%
    filter(!(experiment_id == "Screening (HWL)" &
             response > 2.0))


str(screening_df)
titan_screening_df = screening_df
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	30 obs. of  19 variables:
 $ _use_fast_math                 : chr  "on" "on" "on" "on" ...
 $ _opt_level_                    : int  2 2 2 2 2 2 2 2 2 2 ...
 $ _gpu_architecture_             : chr  "sm_50" "sm_50" "sm_50" "sm_50" ...
 $ _ftz_                          : chr  "true" "true" "true" "true" ...
 $ _force_store_cache_            : chr  "cg" "cg" "cg" "cg" ...
 $ _force_load_cache_             : chr  "cg" "cg" "cg" "cg" ...
 $ _allow_expensive_optimizations_: chr  "false" "false" "false" "false" ...
 $ _fmad_                         : chr  "false" "false" "false" "false" ...
 $ _optimize_                     : int  3 3 3 3 3 3 3 3 3 3 ...
 $ _preserve_relocs               : chr  "off" "off" "off" "off" ...
 $ _relocatable_device_code_      : chr  "false" "false" "false" "false" ...
 $ _prec_div_                     : chr  "false" "false" "false" "false" ...
 $ _maxrregcount_                 : int  32 32 32 32 32 32 32 32 32 32 ...
 $ _prec_sqrt_                    : chr  "false" "false" "false" "false" ...
 $ _no_align_double               : chr  "on" "on" "on" "on" ...
 $ response                       : num  1.38 1.28 1.28 1.3 1.29 ...
 $ experiment_id                  : chr  "Model Prediction (GAU)" "Model Prediction (GAU)" "Model Prediction (GAU)" "Model Prediction (GAU)" ...
 $ experiment_type                : chr  "screening_prediction" "screening_prediction" "screening_prediction" "screening_prediction" ...
 $ GPU                            : chr  "Titan X" "Titan X" "Titan X" "Titan X" ...
'data.frame':	60 obs. of  6 variables:
 $ _opt_level_       : int  2 2 2 2 2 2 2 2 2 2 ...
 $ _gpu_architecture_: chr  "sm_50" "sm_50" "sm_50" "sm_50" ...
 $ response          : num  1.33 1.33 1.32 1.31 1.33 ...
 $ experiment_id     : chr  "Baseline (GAU)" "Baseline (GAU)" "Baseline (GAU)" "Baseline (GAU)" ...
 $ experiment_type   : chr  "baseline" "baseline" "baseline" "baseline" ...
 $ GPU               : chr  "Titan X" "Titan X" "Titan X" "Titan X" ...
'data.frame':	600 obs. of  23 variables:
 $ dummy3                         : int  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
 $ _use_fast_math                 : chr  "off" "off" "off" "off" ...
 $ _opt_level_                    : int  2 2 2 2 2 2 2 2 2 2 ...
 $ _gpu_architecture_             : chr  "sm_50" "sm_50" "sm_50" "sm_50" ...
 $ _ftz_                          : chr  "true" "true" "true" "true" ...
 $ _force_store_cache_            : chr  "cg" "cg" "cg" "cg" ...
 $ _force_load_cache_             : chr  "cs" "cs" "cs" "cs" ...
 $ _allow_expensive_optimizations_: chr  "false" "false" "false" "false" ...
 $ _fmad_                         : chr  "true" "true" "true" "true" ...
 $ _optimize_                     : int  2 2 2 2 2 2 2 2 2 2 ...
 $ dummy2                         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ _preserve_relocs               : chr  "off" "off" "off" "off" ...
 $ _relocatable_device_code_      : chr  "true" "true" "true" "true" ...
 $ _prec_div_                     : chr  "false" "false" "false" "false" ...
 $ dummy1                         : int  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...
 $ _maxrregcount_                 : int  63 63 63 63 63 63 63 63 63 63 ...
 $ dummy4                         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ _prec_sqrt_                    : chr  "true" "true" "true" "true" ...
 $ _no_align_double               : chr  "off" "off" "off" "off" ...
 $ response                       : num  1.35 1.3 1.3 1.33 1.3 ...
 $ experiment_id                  : chr  "Screening (GAU)" "Screening (GAU)" "Screening (GAU)" "Screening (GAU)" ...
 $ experiment_type                : chr  "screening" "screening" "screening" "screening" ...
 $ GPU                            : chr  "Titan X" "Titan X" "Titan X" "Titan X" ...
#+end_example
****** Computing Main Effects from Screening Data
******* Setup
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)
library(broom)

run_lm <- function(experiment) {
    lm(response ~ .,
       screening_df %>%
       filter(experiment_id == experiment) %>%
       select(-GPU,
              -experiment_id,
              -`_gpu_architecture_`,
              -experiment_type) %>%
       mutate(across(!contains("response"), as.factor)) %>%
       mutate(across(where(is.character), as.factor)) #%>%
       #mutate(across(where(is.factor), as.numeric)))
       )
}

run_aov <- function(experiment) {
    aov(response ~ .,
       screening_df %>%
       filter(experiment_id == experiment) %>%
       select(-GPU,
              -experiment_id,
              -`_gpu_architecture_`,
              -experiment_type) %>%
       mutate(across(!contains("response"), as.factor)) %>%
       mutate(across(where(is.character), as.factor)) #%>%
       #mutate(across(where(is.factor), as.numeric)))
       )
}

lm_gau = run_lm("Screening (GAU)")
lm_hwl = run_lm("Screening (HWL)")
lm_ndl = run_lm("Screening (NDL)")

aov_gau = run_aov("Screening (GAU)")
aov_hwl = run_aov("Screening (HWL)")
aov_ndl = run_aov("Screening (NDL)")
#+end_SRC

#+RESULTS:

******* Plot
#+begin_SRC R :results graphics output :session *R* :file "img/main_effects_titanx.pdf" :width 14 :height 10.5 :eval no-export
library(dplyr)
library(tidyr)
library(tibble)
library(broom)
library(ggplot2)
library(latex2exp)

bind_confint_lm <- function(model, experiment) {
    bind_cols(tidy(model) %>%
              rename(mean = estimate) %>%
              arrange(term),
              data.frame(confint(model)) %>%
              rownames_to_column() %>%
              rename(ci_inf = `X2.5..`,
                     ci_sup = `X97.5..`) %>%
              arrange(rowname)) %>%
        select(-rowname) %>%
        mutate(experiment = experiment)
}

plot_df = bind_rows(bind_confint_lm(lm_gau, "GAU"),
                    bind_confint_lm(lm_hwl, "HWL"),
                    bind_confint_lm(lm_ndl, "NDL")) %>%
    mutate(term = trimws(term, whitespace = "[_, `]")) %>%
    filter(!grepl("dummy", term)) %>%
    filter(!grepl("Intercept", term)) %>%
    mutate(term = gsub("_`", " = ", term,
                       fixed = FALSE)) %>%
    mutate(term = gsub("`", " = ", term,
                       fixed = FALSE)) %>%
    mutate(term = gsub("allow_expensive_optimizations", "exp_opt", term,
                       fixed = FALSE)) %>%
    mutate(term = gsub("gpu_architecture", "arch", term,
                       fixed = FALSE)) %>%
    mutate(term = gsub("no_align_double", "no_align_db", term,
                       fixed = FALSE)) %>%
    mutate(term = gsub("relocatable_device_code", "rel_dev_code", term,
                       fixed = FALSE))

p_effects_titan = ggplot() +
    geom_point(data = plot_df,
               aes(x = term,
                   y = mean),
               size = 3) +
    geom_errorbar(data = plot_df,
                  aes(x = term,
                      ymin = ci_inf,
                      ymax = ci_sup),
                  width = 0.4) +
    geom_hline(data = plot_df,
               aes(x = term),
               linetype = 2,
               yintercept = 0.0) +
    ylab(TeX("Mean Effect Estimate $\\pm$ 95% CI")) +
    ggtitle("Titan X") +
    facet_grid(experiment ~ .,
               scales = "free_y") +
    theme_bw(base_size = 24) +
    theme(plot.title = element_text(size = 19),
          strip.background = element_rect(fill = "white"),
          axis.title.x = element_blank(),
          axis.text.x = element_text(size = 18,
                                     angle = 30,
                                     hjust = 1,
                                     vjust = 1))

p_effects_titan
#+end_SRC

#+RESULTS:
[[file:img/main_effects_titanx.pdf]]
****** Execution Times
#+begin_SRC R :results graphics output :session *R* :file "./img/executiontimes_screening_titanx.pdf" :width 11.2 :height 10.5 :eval no-export
library(dplyr)
library(ggplot2)

plot_df = bind_rows(baselines_df %>%
                    filter(`_opt_level_` == 2) %>%
                    select(experiment_type,
                           experiment_id,
                           response),
                    experiments_df %>%
                    distinct() %>%
                    select(experiment_type,
                           experiment_id,
                           response)) %>%
    mutate(experiment_id = gsub("Baseline (",
                                "",
                                experiment_id,
                                fixed = TRUE)) %>%
    mutate(experiment_id = gsub("Model Prediction (",
                                "",
                                experiment_id,
                                fixed = TRUE)) %>%
    mutate(experiment_id = gsub(")",
                                "",
                                experiment_id,
                                fixed = TRUE)) %>%
    mutate(experiment_type = gsub("baseline",
                                  "-O3",
                                  experiment_type,
                                  fixed = TRUE)) %>%
    mutate(experiment_type = gsub("screening_prediction",
                                  "Best Prediction",
                                  experiment_type,
                                  fixed = TRUE)) %>%
    filter(!(experiment_id == "HWL" &
             response > 2.0)) %>%
    group_by(experiment_id, experiment_type) %>%
    mutate(mean_r = mean(response),
           ci95 = 1.96 * sd(response) / sqrt(n()))

p_timing_titan = ggplot() +
    geom_jitter(data = plot_df,
                size = 3,
                shape = 1,
                alpha = 1,
                aes(x = experiment_type,
                    y = response,
                    color = experiment_type),
                width = 0.3,
                height = 0.0,
                show.legend = FALSE) +
    facet_grid(experiment_id ~ .,
               scales = "free_y") +
    geom_errorbar(data = plot_df,
                  aes(x = experiment_type,
                      ymin = mean_r - ci95,
                      ymax = mean_r + ci95,
                      color = experiment_type),
                  show.legend = FALSE,
                  width = 0.3) +
    geom_point(data = plot_df,
               size = 3,
               aes(x = experiment_type,
                   y = mean_r,
                   color = experiment_type),
               show.legend = FALSE) +
    ylab("Execution Time (s)") +
    ggtitle("Titan X") +
    scale_color_brewer(palette = "Dark2") +
    ylim(0, NA) +
    # scale_y_continuous(labels = scales::number_format(accuracy = 0.01),
    #                    n.breaks = 4) +
    theme_bw(base_size = 37) +
    theme(axis.title.x = element_blank(),
          axis.text.x = element_text(size = 29),
          plot.title = element_text(size = 25),
          strip.background = element_rect(fill = "white"))

p_timing_titan
#+end_SRC

#+RESULTS:
[[file:./img/executiontimes_screening_titanx.pdf]]
****** Speedup
#+begin_SRC R :results graphics output :session *R* :file "./img/speedups_screening_titanx.pdf" :width 11 :height 10.5 :eval no-export
library(dplyr)
library(tidyr)
library(ggplot2)

speedups = bind_cols(baselines_df %>%
                     filter(`_opt_level_` == 3,
                            !(experiment_id == "Baseline (HWL)" &
                              response > 2.0)) %>%
                     select(GPU,
                            experiment_type,
                            experiment_id,
                            response) %>%
                     group_by(experiment_id) %>%
                     summarise(mean_baseline = mean(response)) %>%
                     ungroup(),
                     experiments_df %>%
                     distinct() %>%
                     select(GPU,
                            experiment_type,
                            experiment_id,
                            response) %>%
                     group_by(experiment_id) %>%
                     summarise(mean_predicted = mean(response)) %>%
                     ungroup() %>%
                     select(-experiment_id)) %>%
    mutate(speedup = mean_baseline / mean_predicted) %>%
    mutate(experiment_id = gsub("Baseline (",
                                "",
                                experiment_id,
                                fixed = TRUE)) %>%
    mutate(experiment_id = gsub(")",
                                "",
                                experiment_id,
                                fixed = TRUE))

titan_screening_speedups = speedups %>%
    mutate(GPU = "Titan X")

p_speedup_titan = ggplot() +
    geom_point(data = speedups,
               size = 4,
               alpha = 1,
               aes(x = experiment_id,
                   y = speedup,
                   color = experiment_id),
               show.legend = FALSE) +
    geom_hline(data = speedups,
               aes(x = experiment_id),
               linetype = 2,
               yintercept = 1) +
    geom_segment(data = speedups,
                 aes(x = experiment_id,
                     xend = experiment_id,
                     y = 1.0,
                     yend = speedup),
                 linetype = 2) +
    ylab("Speedup vs. -O3") +
    ggtitle("Titan X") +
    scale_color_brewer(palette = "Dark2") +
    theme_bw(base_size = 37) +
    theme(plot.title = element_text(size = 27),
          axis.title.x = element_blank())

p_speedup_titan
#+end_SRC

#+RESULTS:
[[file:./img/speedups_screening_titanx.pdf]]
***** Loading OpenTuner Data
****** Quadro M1200
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)

read_ot_df <- function(path, experiment_id) {
    read.csv(path, header = TRUE) %>%
        mutate(experiment_type = "OT",
               experiment_id = experiment_id) %>%
        group_by(run_id) %>%
        mutate(mean_r = mean(response)) %>%
        ungroup() %>%
        filter(mean_r == min(mean_r)) %>%
        select(-run_id) %>%
        mutate(ci95 = 1.96 * sd(response) / sqrt(n()))
}

paths = list(c("autotuning_screening_experiment/data/needle_opentuner_quadrom1200",
               "size_default_time_20/run_0/measurements.csv", "NDL"),
             c("autotuning_screening_experiment/data/gaussian_opentuner_quadrom1200",
               "size_default_time_20/run_0/measurements.csv", "GAU"),
             c("autotuning_screening_experiment/data/heartwall_opentuner_quadrom1200",
               "size_default_time_20/run_0/measurements.csv", "HWL"))

ot_df = bind_rows(lapply(paths, function(x) {
    read_ot_df(paste(x[1], x[2], sep = "/"), x[3])
    }))

str(ot_df)
quadro_ot_df = ot_df %>%
    mutate(GPU = "Quadro M1200")
#+end_SRC

#+RESULTS:
: tibble [30 × 5] (S3: tbl_df/tbl/data.frame)
:  $ response       : num [1:30] 0.12 0.105 0.104 0.105 0.104 ...
:  $ experiment_type: chr [1:30] "OT" "OT" "OT" "OT" ...
:  $ experiment_id  : chr [1:30] "NDL" "NDL" "NDL" "NDL" ...
:  $ mean_r         : num [1:30] 0.106 0.106 0.106 0.106 0.106 ...
:  $ ci95           : num [1:30] 0.00307 0.00307 0.00307 0.00307 0.00307 ...

****** Titan X
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)

read_ot_df <- function(path, experiment_id) {
    read.csv(path, header = TRUE) %>%
        mutate(experiment_type = "OT",
               experiment_id = experiment_id) %>%
        group_by(run_id) %>%
        mutate(mean_r = mean(response)) %>%
        ungroup() %>%
        filter(mean_r == min(mean_r)) %>%
        select(-run_id) %>%
        mutate(ci95 = 1.96 * sd(response) / sqrt(n()))
}

paths = list(c("autotuning_screening_experiment/data/needle_opentuner_titanx",
               "size_default_time_20/run_0/measurements.csv", "NDL"),
             c("autotuning_screening_experiment/data/gaussian_opentuner_titanx",
               "size_default_time_20/run_0/measurements.csv", "GAU"),
             c("autotuning_screening_experiment/data/heartwall_opentuner_titanx",
               "size_default_time_20/run_0/measurements.csv", "HWL"))

titan_ot_df = bind_rows(lapply(paths, function(x) {
    read_ot_df(paste(x[1], x[2], sep = "/"), x[3])
    }))

str(titan_ot_df)

titan_ot_df = titan_ot_df %>%
    mutate(GPU = "Titan X")
#+end_SRC

#+RESULTS:
: tibble [30 × 5] (S3: tbl_df/tbl/data.frame)
:  $ response       : num [1:30] 0.215 0.193 0.19 0.208 0.154 ...
:  $ experiment_type: chr [1:30] "OT" "OT" "OT" "OT" ...
:  $ experiment_id  : chr [1:30] "NDL" "NDL" "NDL" "NDL" ...
:  $ mean_r         : num [1:30] 0.186 0.186 0.186 0.186 0.186 ...
:  $ ci95           : num [1:30] 0.0108 0.0108 0.0108 0.0108 0.0108 ...

***** Loading Longer OpenTuner Data
****** Quadro M1200
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)

read_ot_df <- function(path, experiment_id) {
    read.csv(path, header = TRUE) %>%
        mutate(experiment_type = "OT:200",
               experiment_id = experiment_id) %>%
        group_by(run_id) %>%
        mutate(mean_r = mean(response)) %>%
        ungroup() %>%
        filter(mean_r == min(mean_r)) %>%
        select(-run_id) %>%
        mutate(ci95 = 1.96 * sd(response) / sqrt(n()))
}

paths = list(c("autotuning_screening_experiment/data/needle_opentuner_long_quadrom1200",
               "size_default_time_200/run_0/measurements.csv", "NDL"),
             c("autotuning_screening_experiment/data/gaussian_opentuner_long_quadrom1200",
               "size_default_time_200/run_0/measurements.csv", "GAU"),
             c("autotuning_screening_experiment/data/heartwall_opentuner_long_quadrom1200",
               "size_default_time_200/run_0/measurements.csv", "HWL"))

ot_longer_df = bind_rows(lapply(paths, function(x) {
    read_ot_df(paste(x[1], x[2], sep = "/"), x[3])
    }))

str(ot_longer_df)
#+end_SRC

#+RESULTS:
: tibble [30 × 5] (S3: tbl_df/tbl/data.frame)
:  $ response       : num [1:30] 0.104 0.104 0.104 0.105 0.105 ...
:  $ experiment_type: chr [1:30] "OT:200" "OT:200" "OT:200" "OT:200" ...
:  $ experiment_id  : chr [1:30] "NDL" "NDL" "NDL" "NDL" ...
:  $ mean_r         : num [1:30] 0.104 0.104 0.104 0.104 0.104 ...
:  $ ci95           : num [1:30] 0.000213 0.000213 0.000213 0.000213 0.000213 ...

****** Titan X
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)

read_ot_df <- function(path, experiment_id) {
    read.csv(path, header = TRUE) %>%
        mutate(experiment_type = "OT:200",
               experiment_id = experiment_id) %>%
        group_by(run_id) %>%
        mutate(mean_r = mean(response)) %>%
        ungroup() %>%
        filter(mean_r == min(mean_r)) %>%
        select(-run_id) %>%
        mutate(ci95 = 1.96 * sd(response) / sqrt(n()))
}

paths = list(c("autotuning_screening_experiment/data/needle_opentuner_long_titanx",
               "size_default_time_200/run_0/measurements.csv", "NDL"),
             c("autotuning_screening_experiment/data/gaussian_opentuner_long_titanx",
               "size_default_time_200/run_0/measurements.csv", "GAU"),
             c("autotuning_screening_experiment/data/heartwall_opentuner_long_titanx",
               "size_default_time_200/run_0/measurements.csv", "HWL"))

titan_ot_longer_df = bind_rows(lapply(paths, function(x) {
    read_ot_df(paste(x[1], x[2], sep = "/"), x[3])
    }))

str(titan_ot_longer_df)
#+end_SRC

#+RESULTS:
: tibble [30 × 5] (S3: tbl_df/tbl/data.frame)
:  $ response       : num [1:30] 0.201 0.18 0.174 0.18 0.164 ...
:  $ experiment_type: chr [1:30] "OT:200" "OT:200" "OT:200" "OT:200" ...
:  $ experiment_id  : chr [1:30] "NDL" "NDL" "NDL" "NDL" ...
:  $ mean_r         : num [1:30] 0.177 0.177 0.177 0.177 0.177 ...
:  $ ci95           : num [1:30] 0.00714 0.00714 0.00714 0.00714 0.00714 ...

***** Composing Figures
****** Main Effects
#+begin_SRC R :results graphics output :session *R* :file "./img/effects_gpu_screening.pdf" :width 14 :height 21 :eval no-export
library(ggplot2)
library(patchwork)

p_effects_titan / p_effects_quadro
#+end_SRC

#+RESULTS:
[[file:./img/effects_gpu_screening.pdf]]

****** Timing
#+begin_SRC R :results graphics output :session *R* :file "./img/timing_gpu_screening.pdf" :width 22 :height 10.5 :eval no-export
library(ggplot2)
library(patchwork)

p_timing_ot_quadro = p_timing_quadro +
    geom_jitter(data = ot_df,
                size = 4,
                shape = 1,
                alpha = 1,
                aes(x = experiment_type,
                    y = response,
                    color = experiment_type),
                width = 0.3,
                height = 0.0,
                show.legend = FALSE) +
    geom_errorbar(data = ot_df,
                  aes(x = experiment_type,
                      ymin = mean_r - ci95,
                      ymax = mean_r + ci95,
                      color = experiment_type),
                  show.legend = FALSE,
                  width = 0.3) +
    geom_point(data = ot_df,
               size = 4,
               aes(x = experiment_type,
                   y = mean_r,
                   color = experiment_type),
               show.legend = FALSE) +
    geom_jitter(data = ot_longer_df,
                size = 4,
                shape = 1,
                alpha = 1,
                aes(x = experiment_type,
                    y = response,
                    color = experiment_type),
                width = 0.3,
                height = 0.0,
                show.legend = FALSE) +
    geom_errorbar(data = ot_longer_df,
                  aes(x = experiment_type,
                      ymin = mean_r - ci95,
                      ymax = mean_r + ci95,
                      color = experiment_type),
                  show.legend = FALSE,
                  width = 0.3) +
    geom_point(data = ot_longer_df,
               size = 4,
               aes(x = experiment_type,
                   y = mean_r,
                   color = experiment_type),
               show.legend = FALSE)

p_timing_ot_titan = p_timing_titan +
    geom_jitter(data = titan_ot_df,
                size = 4,
                shape = 1,
                alpha = 1,
                aes(x = experiment_type,
                    y = response,
                    color = experiment_type),
                width = 0.3,
                height = 0.0,
                show.legend = FALSE) +
    geom_errorbar(data = titan_ot_df,
                  aes(x = experiment_type,
                      ymin = mean_r - ci95,
                      ymax = mean_r + ci95,
                      color = experiment_type),
                  show.legend = FALSE,
                  width = 0.3) +
    geom_point(data = titan_ot_df,
               size = 4,
               aes(x = experiment_type,
                   y = mean_r,
                   color = experiment_type),
               show.legend = FALSE) +
    geom_jitter(data = titan_ot_longer_df,
                size = 4,
                shape = 1,
                alpha = 1,
                aes(x = experiment_type,
                    y = response,
                    color = experiment_type),
                width = 0.3,
                height = 0.0,
                show.legend = FALSE) +
    geom_errorbar(data = titan_ot_longer_df,
                  aes(x = experiment_type,
                      ymin = mean_r - ci95,
                      ymax = mean_r + ci95,
                      color = experiment_type),
                  show.legend = FALSE,
                  width = 0.3) +
    geom_point(data = titan_ot_longer_df,
               size = 4,
               aes(x = experiment_type,
                   y = mean_r,
                   color = experiment_type),
               show.legend = FALSE)

p_timing_ot_titan | p_timing_ot_quadro
#+end_SRC

#+RESULTS:
[[file:./img/timing_gpu_screening.pdf]]

****** Speedup
#+begin_SRC R :results graphics output :session *R* :file "./img/speedup_gpu_screening.pdf" :width 22 :height 10.5 :eval no-export
library(ggplot2)
library(patchwork)

p_speedup_titan | p_speedup_quadro
#+end_SRC

#+RESULTS:
[[file:./img/speedup_gpu_screening.pdf]]

*** [2021-01-27 Wed]
**** Math Calendar 25 January
#+begin_SRC R :results graphics output :session *R* :file "img/primes_math_calendar.png" :width 1080 :height 1080 :eval no-export
library(ggplot2)
library(primes)

prime_list = generate_n_primes(10)
combinations = expand.grid(p = prime_list, q = prime_list)
combinations$is_prime = is_prime((as.double(combinations$p) ^
                                  as.double(combinations$q)) + 1.0)

ggplot() +
    geom_tile(data = combinations,
              aes(x = as.factor(p),
                  y = as.factor(q),
                  fill = is_prime),
              show.legend = FALSE) +
    scale_fill_brewer(palette = "Greys") +
    theme_void()
#+end_SRC

#+RESULTS:
[[file:img/primes_math_calendar.png]]
** February
*** [2021-02-03 Wed]
**** Redoing CUDA Tuning Graphics
***** Cloning and Updating the Repository
#+begin_SRC shell :results output :session *Shell* :eval no-export :exports results
git clone --depth=1 git@github.com:phrb/gpu-autotuning.git ||
    (cd gpu-autotuning && git pull)
#+end_SRC
***** Parsing and Saving Data
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)
library(stringr)

parse_size <- function(path) {
    return(str_split(str_split(path,
                               pattern = "size_")[[1]][2],
                     "_")[[1]][1])
}

parse_time <- function(path) {
    return(str_split(str_split(path,
                               pattern = "time_")[[1]][2],
                     "/")[[1]][1])
}

parse_gpu <- function(path) {
    return(str_split(str_split(path,
                               pattern = "experiments/")[[1]][2],
                     "//")[[1]][1])
}

parse_kernel <- function(path) {
    return(str_split(str_split(path,
                               pattern = "//")[[1]][2],
                     "/")[[1]][1])
}

parse_olevel <- function(path) {
    return(str_split(str_split(path,
                               pattern = "opt_")[[1]][2],
                     "\\.")[[1]][1])
}

parse_run <- function(path) {
    return(str_split(str_split(path,
                               pattern = "run_")[[1]][2],
                     "/")[[1]][1])
}

read_benchmarks <- function(path) {
    return(read.csv(path, header = FALSE, sep = " ") %>%
           mutate(gpu = parse_gpu(path),
                  kernel = parse_kernel(path),
                  time = parse_time(path),
                  size = parse_size(path),
                  run = parse_run(path),
                  olevel = "-1",
                  baseline_measurement = NA,
                  id = "benchmark") %>%
           rename(tuned_measurement = V1))
}

read_baselines <- function(path) {
    return(read.csv(path, header = FALSE, sep = " ") %>%
           mutate(gpu = parse_gpu(path),
                  kernel = parse_kernel(path),
                  time = "-1",
                  size = parse_size(path),
                  olevel = parse_olevel(path),
                  tuned_measurement = NA,
                  id = "baseline") %>%
           rename(baseline_measurement = V1))
}

read_logbest <- function(path) {
    return(read.csv(path, header = FALSE, sep = " ") %>%
           mutate(gpu = parse_gpu(path),
                  kernel = parse_kernel(path),
                  time = parse_time(path),
                  run = parse_run(path),
                  size = parse_size(path)) %>%
           rename(tuning_time = V1,
                  measurement = V2))
}

list_targets <- function(path, pattern) {
    return(list.files(path,
                      recursive = TRUE,
                      full.names = TRUE,
                      pattern = pattern))
}

read_experiments <- function(path) {
    return(bind_rows(lapply(list_targets(path, "benchmark.txt"),
                            function (x) { read_benchmarks(x) }),
                     lapply(list_targets(path, "opt_"),
                            function (x) { read_baselines(x) })))
}

read_timing <- function(path_list) {
    return(bind_rows(lapply(path_list,
                            function (x) { read_experiments(x) })))
}

read_progression <- function(path) {
    return(bind_rows(lapply(list_targets(path, "logbest"),
                            function (x) { read_logbest(x) })))
}

read_all_progression <- function(path_list) {
    return(bind_rows(lapply(path_list,
                            function(x) { read_progression(x) })))
}

path_list = c("gpu-autotuning/experiments/GTX-980/",
              "gpu-autotuning/experiments/GTX-750/",
              "gpu-autotuning/experiments/GTX-750-outliers/",
              "gpu-autotuning/experiments/GTX-680/",
              "gpu-autotuning/experiments/Tesla-K40/",
              "gpu-autotuning/experiments/Tesla-K40-nvcc65/",
              "gpu-autotuning/experiments/Tesla-K20/")

baseline_tuned_timing = read_timing(path_list)

write.csv(baseline_tuned_timing,
          "gpu-autotuning/experiments/baseline_tuned_timing.csv",
          row.names = FALSE)

progression = read_all_progression(path_list)

write.csv(progression,
          "gpu-autotuning/experiments/tuning_progression.csv",
          row.names = FALSE)
#+end_SRC

#+RESULTS:

***** Loading Data
****** Baseline and Tuned
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)

df = read.csv("gpu-autotuning/experiments/baseline_tuned_timing.csv")

rodinia_kernels = c("backprop", "gaussian", "hotspot", "lud", "bfs", "b+tree",
                    "heartwall", "lavaMD", "myocyte", "Pathfinder", "needle",
                    "kmeans", "ParticleFilterFloat", "ParticleFilterNaive")

adhoc_kernels = c("MatMulGPU", "MatMulShared", "MatMulSharedUn", "MatMulUn",
                  "SubSeqMax", "Bitonic", "Quicksort", "VecAdd")

times = c("3600", "7200")

not_gpus = c("GTX-750-outliers")

speedups_df = bind_rows(
    df %>%
    filter(!(gpu %in% not_gpus),
           is.na(tuned_measurement) | run == 0,
           kernel %in% rodinia_kernels) %>%
    group_by(kernel, gpu) %>%
    mutate(speedup = mean(na.omit(baseline_measurement)) /
               min(na.omit(tuned_measurement))) %>%
    distinct(gpu, kernel, size, time, speedup) %>%
    filter(time %in% times,
           time == max(time),
           size == max(size)) %>%
    ungroup() %>%
    mutate(id = "Rodinia"),
    df %>%
    filter(!(gpu %in% not_gpus),
           is.na(tuned_measurement) | run == 0,
           kernel %in% adhoc_kernels) %>%
    group_by(kernel, gpu) %>%
    mutate(speedup = mean(na.omit(baseline_measurement)) /
               min(na.omit(tuned_measurement))) %>%
    distinct(gpu, kernel, size, time, speedup) %>%
    filter(time %in% times,
           time == max(time),
           size == max(size)) %>%
    ungroup() %>%
    mutate(id = "Independent"))
#+end_SRC

#+RESULTS:
#+begin_example

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Warning message:
replacing previous import ‘vctrs::data_frame’ by ‘tibble::data_frame’ when loading ‘dplyr’
#+end_example

****** Tuning Progress
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)

df = read.csv("gpu-autotuning/experiments/tuning_progression.csv")
baseline_df = read.csv("gpu-autotuning/experiments/baseline_tuned_timing.csv")

rodinia_kernels = c("backprop", "gaussian", "hotspot", "lud", "bfs", "b+tree",
                    "heartwall", "lavaMD", "myocyte", "Pathfinder", "needle",
                    "kmeans", "ParticleFilterFloat", "ParticleFilterNaive")

adhoc_kernels = c("MatMulGPU", "MatMulShared", "MatMulSharedUn", "MatMulUn",
                  "SubSeqMax", "Bitonic", "Quicksort", "VecAdd")

times = c("3600", "7200")

not_gpus = c("GTX-750-outliers")

get_baseline <- function(df, gpu, kernel) {
    df %>%
        filter(gpu == gpu, kernel == kernel) %>%
        select(baseline_measurement) %>%
        print()
    return()
}

baselines = bind_rows(
    baseline_df %>%
    filter(!(gpu %in% not_gpus),
           kernel %in% rodinia_kernels |
           kernel %in% adhoc_kernels) %>%
    group_by(kernel, gpu) %>%
    distinct(gpu, kernel, size, baseline_measurement) %>%
    filter(size == max(size),
           !(is.na(baseline_measurement))) %>%
    mutate(baseline_measurement = mean(baseline_measurement)) %>%
    distinct() %>%
    select(-size) %>%
    ungroup())

progression_df = df %>%
    filter(!(gpu %in% not_gpus),
           run == 0,
           kernel %in% rodinia_kernels |
           kernel %in% adhoc_kernels) %>%
    group_by(kernel, gpu) %>%
    filter(time %in% times,
           time == max(time),
           size == max(size)) %>%
    ungroup()

progression = left_join(progression_df,
                        baselines,
                        by = c("gpu", "kernel")) %>%
    mutate(progression = baseline_measurement / measurement,
           id = ifelse(kernel %in% adhoc_kernels,
                       "Independent",
                       "Rodinia"))
#+end_SRC

#+RESULTS:
***** Speedup Plots
****** Rodinia
#+begin_SRC R :results graphics output :session *R* :file "./img/rodinia_speedups.pdf" :width 14 :height 10 :eval no-export
library(dplyr)
library(ggplot2)
library(latex2exp)
library(stringr)

plot_df = speedups_df %>%
    filter(id == "Rodinia",
           gpu != "Tesla-K40-nvcc65",
           kernel != "ParticleFilterFloat",
           kernel != "ParticleFilterNaive") %>%
    mutate(kernel = gsub("Pathfinder", "pathfinder", kernel, fixed = TRUE),
           kernel = factor(kernel,
                           levels = c("b+tree", "backprop", "bfs", "gaussian",
                                      "heartwall", "hotspot", "kmeans",
                                      "lavaMD", "lud", "myocyte", "needle",
                                      "pathfinder"),
                           labels = c("BPT", "BCK", "BFS", "GAU", "HWL",
                                      "HOT", "KMN", "LMD", "LUD", "MYO",
                                      "NDL", "PTF")))

ggplot() +
    geom_point(data = plot_df,
               aes(y = kernel,
                   x = speedup,
                   color = gpu),
               size = 5,
               position = position_dodge(width = 0.8)) +
    geom_linerange(data = plot_df,
                   aes(y = kernel,
                       xmin = speedup,
                       xmax = 1.0,
                       color = gpu),
                   linetype = 2,
                   position = position_dodge(width = 0.8)) +
    scale_color_brewer(palette = "Set1") +
    geom_vline(xintercept = 1,
               linetype = 2,
               size = 0.8) +
    xlab(TeX("Speedup against \\textit{-O2}")) +
    theme_bw(base_size = 30) +
    theme(legend.position = c(0.9, 0.1),
          legend.title = element_blank(),
          legend.background = element_blank(),
          axis.title.y = element_blank(),
          axis.text.y = element_text(face = "italic"))
#+end_SRC

#+RESULTS:
[[file:./img/rodinia_speedups.pdf]]
****** Independent Kernels
#+begin_SRC R :results graphics output :session *R* :file "./img/adhoc_speedups.pdf" :width 14 :height 10 :eval no-export
library(dplyr)
library(ggplot2)
library(latex2exp)
library(stringr)

plot_df = speedups_df %>%
    filter(id == "Independent",
           gpu != "Tesla-K40-nvcc65") %>%
    mutate(kernel = factor(kernel,
                           levels = c("Bitonic", "MatMulGPU", "MatMulShared",
                                      "MatMulSharedUn", "MatMulUn", "Quicksort",
                                      "SubSeqMax", "VecAdd"),
                           labels = c("BTN", "MMG", "MMS", "MSU", "MMU", "QKS",
                                      "MSA", "VAD")))
    #mutate(kernel = str_to_title(kernel))

ggplot() +
    geom_point(data = plot_df,
               aes(y = kernel,
                   x = speedup,
                   color = gpu),
               size = 5,
               position = position_dodge(width = 0.8)) +
    geom_linerange(data = plot_df,
                   aes(y = kernel,
                       xmin = speedup,
                       xmax = 1.0,
                       color = gpu),
                   linetype = 2,
                   position = position_dodge(width = 0.8)) +
    scale_color_brewer(palette = "Set1") +
    geom_vline(xintercept = 1,
               linetype = 2,
               size = 0.8) +
    xlab(TeX("Speedup against \\textit{-O2}")) +
    theme_bw(base_size = 30) +
    theme(legend.position = c(0.89, 0.12),
          legend.title = element_blank(),
          legend.background = element_blank(),
          axis.title.y = element_blank(),
          axis.text.y = element_text(face = "italic"))
#+end_SRC

#+RESULTS:
[[file:./img/adhoc_speedups.pdf]]
***** Tuning Progress
****** Rodinia
#+begin_SRC R :results graphics output :session *R* :file "./img/rodinia_tuning_progress.pdf" :width 14.5 :height 10 :eval no-export
library(dplyr)
library(ggplot2)
library(latex2exp)
library(stringr)

prolong_max = progression %>%
    filter(measurement < 9999,
           gpu != "Tesla-K40-nvcc65",
           kernel != "ParticleFilterFloat",
           kernel != "ParticleFilterNaive",
           id == "Rodinia") %>%
    mutate(kernel = gsub("Pathfinder",
                         "pathfinder",
                         kernel,
                         fixed = TRUE),
           kernel = factor(kernel,
                           levels = c("b+tree", "backprop", "bfs", "gaussian",
                                      "heartwall", "hotspot", "kmeans",
                                      "lavaMD", "lud", "myocyte", "needle",
                                      "pathfinder"),
                           labels = c("BPT", "BCK", "BFS", "GAU", "HWL",
                                      "HOT", "KMN", "LMD", "LUD", "MYO",
                                      "NDL", "PTF"))) %>%
    group_by(gpu, kernel) %>%
    summarize(tuning_time = 7200,
              progression = max(progression)) %>%
    ungroup()

plot_df = bind_rows(progression %>%
                    filter(measurement < 9999,
                           gpu != "Tesla-K40-nvcc65",
                           kernel != "ParticleFilterFloat",
                           kernel != "ParticleFilterNaive",
                           id == "Rodinia") %>%
                    mutate(kernel = gsub("Pathfinder",
                                         "pathfinder",
                                         kernel,
                                         fixed = TRUE),
                           kernel = factor(kernel,
                                           levels = c("b+tree", "backprop",
                                                      "bfs", "gaussian",
                                                      "heartwall", "hotspot",
                                                      "kmeans", "lavaMD", "lud",
                                                      "myocyte", "needle",
                                                      "pathfinder"),
                                           labels = c("BPT", "BCK", "BFS",
                                                      "GAU", "HWL", "HOT",
                                                      "KMN", "LMD", "LUD",
                                                      "MYO", "NDL", "PTF"))) %>%
                    select(gpu, kernel, progression, tuning_time),
                    prolong_max)

ggplot() +
    geom_hline(yintercept = 1.0,
               linetype = 2,
               size = 1.1,
               color = "gray50") +
    geom_line(data = plot_df,
              size = 1.8,
              alpha = 0.8,
              aes(x = tuning_time,
                  y = progression,
                  color = gpu)) +
    facet_wrap(. ~ kernel, scales = "free_y", ncol = 4) +
    #facet_wrap(. ~ kernel, ncol = 4) +
    scale_color_brewer(palette = "Set1") +
    ylab(TeX("Speedup vs \\textit{-O2}")) +
    xlab("Tuning Time (s)") +
    #ylim(1.0, NA) +
    theme_bw(base_size = 19) +
    theme(legend.position = c(0.9, 0.2),
          legend.title = element_blank(),
          legend.background = element_blank(),
          legend.text = element_text(size = 18),
          strip.background = element_rect(fill = "white"),
          axis.title.x = element_text(size = 24),
          strip.text = element_text(face = "italic", size = 17))
#+end_SRC

#+RESULTS:
[[file:./img/rodinia_tuning_progress.pdf]]
****** Independent Kernels
#+begin_SRC R :results graphics output :session *R* :file "./img/adhoc_tuning_progress.pdf" :width 14.5 :height 6.9 :eval no-export
library(dplyr)
library(ggplot2)
library(latex2exp)
library(stringr)

prolong_max = progression %>%
    filter(measurement < 9999,
           gpu != "Tesla-K40-nvcc65",
           kernel != "ParticleFilterFloat",
           kernel != "ParticleFilterNaive",
           id == "Independent") %>%
    mutate(kernel = gsub("Pathfinder",
                         "pathfinder",
                         kernel,
                         fixed = TRUE),
           kernel = factor(kernel,
                           levels = c("Bitonic", "MatMulGPU", "MatMulShared",
                                      "MatMulSharedUn", "MatMulUn", "Quicksort",
                                      "SubSeqMax", "VecAdd"),
                           labels = c("BTN", "MMG", "MMS", "MSU", "MMU", "QKS",
                                      "MSA", "VAD"))) %>%
    group_by(gpu, kernel) %>%
    summarize(tuning_time = 7200,
              progression = max(progression)) %>%
    ungroup()

plot_df = bind_rows(progression %>%
                    filter(measurement < 9999,
                           gpu != "Tesla-K40-nvcc65",
                           kernel != "ParticleFilterFloat",
                           kernel != "ParticleFilterNaive",
                           id == "Independent") %>%
                    mutate(kernel = gsub("Pathfinder",
                                         "pathfinder",
                                         kernel,
                                         fixed = TRUE),
                           kernel = factor(kernel,
                                           levels = c("Bitonic", "MatMulGPU",
                                                      "MatMulShared",
                                                      "MatMulSharedUn",
                                                      "MatMulUn", "Quicksort",
                                                      "SubSeqMax", "VecAdd"),
                                           labels = c("BTN", "MMG", "MMS",
                                                      "MSU", "MMU", "QKS",
                                                      "MSA", "VAD"))) %>%
                    select(gpu, kernel, progression, tuning_time),
                    prolong_max)

ggplot() +
    geom_line(data = plot_df,
              size = 1.5,
              alpha = 0.8,
              aes(x = tuning_time,
                  y = progression,
                  color = gpu)) +
    geom_hline(yintercept = 1.0,
               linetype = 2,
               size = 1.1,
               color = "gray40") +
    facet_wrap(. ~ kernel, scales = "free_y", ncol = 4) +
    #facet_wrap(. ~ kernel, ncol = 4) +
    scale_color_brewer(palette = "Set1") +
    ylab(TeX("Speedup vs \\textit{-O2}")) +
    xlab("Tuning Time (s)") +
    #ylim(1.0, NA) +
    theme_bw(base_size = 19) +
    theme(legend.position = c(0.9, 0.21),
          legend.title = element_blank(),
          legend.text = element_text(size = 18),
          legend.background = element_blank(),
          strip.background = element_rect(fill = "white"),
          axis.title.x = element_text(size = 24),
          strip.text = element_text(face = "italic", size = 17))
#+end_SRC

#+RESULTS:
[[file:./img/adhoc_tuning_progress.pdf]]
** March
*** [2021-03-04 Thu]
**** Computing Roofline, Peak Performance for SPAPT's DGEMV on the Xeon 2630v3 :ATTACH:
:PROPERTIES:
:Attachments: Screenshot_2021-03-02%20BigBlueButton%20-%20Réunion%20Hebdomadaire%20Pedro(5).png
:ID:       bc7d06ad-e454-4bf7-8d84-fd4df9507cb9
:END:
***** Specs
- Processor: Xeon E5-2630V3
- Single Core Turbo Clock: 3.2e9 Hz
- DGEMV Input Size: M = 20000, N = 20000

***** Old Discussion
- Run MKL with 20000 at Xeon 2630v3
- Verify if matrix initialization is accounted for

Finalement, EGO explore bien mais ne  gagne pas beaucoup par rapport au sampling
initial. En même temps, il n'y a p-e pas grand chose à gagner.

Xeon
xeon_e5_2630_v3. https://ranker.sisoftware.co.uk/top_device.php?q=c2ffc9f1d7bad7eadafc8eb383a5ccf1c1e78fb282a4dce1d1f792f7cafdcbfddba895a492&l=en
annonce 26.14GFLOPS mais bon..

- 2 inst/cycle * 2 (FMA) = 4 flops/cycle * la taille du vecteur (4 pour l'AVX-2,
  265 bits)
- 2.4 GHz * 8 cores -> 307.2 GFLOPs
- 2.8    GHz    (Turbo     all    cores)    *    8     cores->    358.4    Gflop
  https://www.cpu-monkey.com/fr/compare_cpu-intel_xeon_e5_2630_v3-492-vs-intel_xeon_e3_1225_v3-75
- 3.2 GHz (1 core)

La bonne ref pour tout ça, c'est :
https://ark.intel.com/content/www/us/en/ark/products/83356/intel-xeon-processor-e5-2630-v3-20m-cache-2-40-ghz.html

Pour "mm" (DGEMM):

Les matrices font 2,000 de côté

Une  mult+une add  donc: $2*2,000^3/307.2E9$  = 0,052  secondes... :(  C'est pas
possible, que ça soit un produit de matrices pour cette taille là.

bon, finalement,c  'est un DGEMV  donc on peut  toujours calculer la  borne flop
$2*20,000^2/307.2E9$ = 2 milisecondes... mais  c'est memory bound :) En mémoire:
$20,000^2*8/ 59 E9 $ = 54 milisecondes.  On est de l'ordre de la seconde (1.13s)
donc un facteur 20 par rapport à l'optimal.

2 types de RAM. Si c'est un serveur avec de la RAM 1600, on perd 15% donc on est
loin de la crète.

Il faudrait  se comparer à la  MKL pour bien faire  mais il est possible  que le
kernel paramétré  de SPAPT soit incapable  d'atteindre cette crète (qui  dans le
cas du DGEMV devrait être proche d'un memcopy).

Orio utilise gcc en interne;

On pourrait réessayer  avec DGEMM mais on  peut avoir le même  problème. Si leur
kernel paramétré est mal foutu on sera loin de la crète...

Le set de benchmark est mal fichu (badly designed) au final. :(

***** Some Calculations
#+begin_SRC R :results output :session *R* :eval no-export :exports results
(2 * 20000 ^ 3) / 307.2e9
#+end_SRC

#+RESULTS:
: [1] 52.08333

#+begin_SRC R :results output :session *R* :eval no-export :exports results
20000 * 20000 * 2
#+end_SRC

#+RESULTS:
: [1] 8e+08

#+begin_SRC R :results output :session *R* :eval no-export :exports results
(20000 * 20000) + 20000
#+end_SRC

#+RESULTS:
: [1] 400020000

#+begin_SRC R :results output :session *R* :eval no-export :exports results
0.8 / 51.2
#+end_SRC

#+RESULTS:
: [1] 0.015625

#+begin_SRC R :results output :session *R* :eval no-export :exports results
3.2 / 59
#+end_SRC

#+RESULTS:
: [1] 0.05423729

Time taken: max(mem, cpu)
#+begin_SRC R :results output :session *R* :eval no-export :exports results
0.054
#+end_SRC

#+RESULTS:
: [1] 0.054

#+begin_SRC R :results output :session *R* :eval no-export :exports results
51.2 / 59
#+end_SRC

#+RESULTS:
: [1] 0.8677966

#+begin_SRC R :results output :session *R* :eval no-export :exports results
1.13 / 0.054
#+end_SRC

#+RESULTS:
: [1] 20.92593

***** Theoretical Roofline Model for the Xeon E5 2630 v3
#+begin_SRC R :results graphics output :session *R* :file "img/theoretical_roofline_xeonE52630v3.pdf" :width 15 :height 10 :eval no-export
library(ggplot2)
library(dplyr)
library(directlabels)
library(ggrepel)
library(latex2exp)

roofline <- function(peak_perf, peak_mem, arithm_intensity) {
    return(min(peak_mem * arithm_intensity, peak_perf))
}

perf_gemv <- function(size) {
    return(((size ^ 2) * 2) / 1e9)
}

mem_gemv <- function(size) {
    return((((size ^ 2) + size) * 8) / 1e9)
}

peak_perf_8core = 307.2

freq_8core = 2.4
freq_1core = 3.2
cores = 8

peak_perf_1core = ((peak_perf_8core / freq_8core) *
                   freq_1core) / cores

peak_mem = 59

arithm_intensity = seq(0, 2, length.out = 1000)

roofline_df = data.frame(arithmetic_intensity = arithm_intensity,
                         performance = sapply(arithm_intensity,
                                              function(x) {
                                                  roofline(peak_perf_1core, peak_mem, x) }))

roofline_df = roofline_df %>%
    mutate(memory_bound = factor(performance < peak_perf_1core,
                                 levels = c(TRUE, FALSE),
                                 labels = c("Memory Bound",
                                            "Compute Bound")))
gemv_size = 20000
gemv_perf = perf_gemv(gemv_size)
gemv_mem = mem_gemv(gemv_size)

gemv_peak_perf = max(gemv_perf / peak_perf_1core,
                     gemv_mem / peak_mem)

fastest_time = gemv_perf / 1.160198

gemv_df = data.frame(id = "GEMV",
                     peak_theoretical = gemv_peak_perf,
                     arithmetic_intensity = gemv_perf / gemv_mem,
                     peak_achieved = fastest_time)

ggplot() +
    geom_line(data = roofline_df,
              aes(x = arithmetic_intensity,
                  y = performance,
                  color = memory_bound),
              size = 2.4) +
    geom_dl(data = roofline_df %>%
                filter(performance < peak_perf_1core),
            aes(x = arithmetic_intensity,
                y = performance,
                color = memory_bound,
                label = paste(peak_mem, "GB/s")),
            method = list("smart.grid", rot = 53, cex = 2.5, vjust = 0)) +
    geom_dl(data = roofline_df %>%
                filter(performance >= peak_perf_1core),
            aes(x = arithmetic_intensity,
                y = performance,
                color = memory_bound,
                label = paste(peak_perf_1core, "GFLOPs/s")),
            method = list("smart.grid", rot = 0, cex = 2.5, vjust = 2.7)) +
    geom_point(data = gemv_df,
               aes(x = arithmetic_intensity,
                   y = arithmetic_intensity * peak_mem),
               size = 6) +
    geom_text_repel(data = gemv_df,
               aes(x = arithmetic_intensity,
                   y = arithmetic_intensity * peak_mem,
                   label = "Theoretical GEMV (N = 2e4)"),
               size = 11,
               hjust = -0.15) +
    geom_point(data = gemv_df,
               aes(x = arithmetic_intensity,
                   y = peak_achieved),
               size = 6) +
    geom_text_repel(data = gemv_df,
               aes(x = arithmetic_intensity,
                   y = peak_achieved,
                   label = "Best Achieved GEMV (20x slower)"),
               size = 11,
               hjust = -0.15) +
    ylab("Single Core GFLOPs/s") +
    xlab("FLOPs/byte") +
    scale_color_brewer(palette = "Dark2") +
    theme_bw(base_size = 28) +
    theme(legend.position = c(0.86, 0.1),
          legend.background = element_blank(),
          legend.title = element_blank(),
          legend.text = element_text(size = 30))
#+end_SRC

#+RESULTS:
[[file:img/theoretical_roofline_xeonE52630v3.pdf]]

*** [2021-03-15 Mon]
**** Files for the Microsoft Latin America PhD Award Application
***** Application to the Microsoft Latin America PhD Award (didn't pan out)
****** Search Heuristics and Statistical Learning methods for Autotuning HPC Programs
:PROPERTIES:
:EXPORT_DATE:
:EXPORT_TITLE: @@latex: Search Heuristics and Statistical Learning \\ Methods for Program Autotuning@@
:EXPORT_FILE_NAME: application.pdf
:EXPORT_AUTHOR: Pedro Bruel
:END:

#+latex: \vspace{-4em}

High Performance Computing  has been a cornerstone of  collective scientific and
industrial progress  for at least  five decades.   Paying the cost  of increased
complexity,  software and  hardware  engineering advances  continue to  overcome
several challenges on the way of the sustained performance improvements observed
during the last  fifty years.  This mounting complexity means  that reaching the
advertised hardware  performance for  a given program  requires not  only expert
knowledge  of a  given hardware  architecture, but  also mastery  of programming
models  and  languages for  parallel  and  distributed  computing.

If we state performance optimization problems as /search/ or /learning/ problems, by
converting implementation  and configuration  choices to /parameters/  which might
affect  performance,  we  can  draw   and  adapt  proven  methods  from  search,
mathematical  optimization and  statistics. The  effectiveness of  these adapted
methods  on autotuning  problems varies  greatly,  and hinges  on practical  and
mathematical properties of the problem and the corresponding /search space/.

When  adapting methods  for autotuning,  we must  face challenges  emerging from
practical properties  such as restricted  time and cost budgets,  constraints on
feasible  parameter values,  and the  need to  mix /categorical/,  /continuous/, and
/discrete/ parameters. To achieve useful results, we must also choose methods that
make hypotheses compatible with problem search  spaces, such as the existence of
discoverable,  or at  least  exploitable, relationships  between parameters  and
performance.   Choosing  an autotuning  method  requires  determining a  balance
between the exploration of a problem, when we would seek to discover and explain
relationships between  parameters and performance,  and the exploitation  of the
best optimizations we can find, when we would seek only to minimize performance.

The    effectiveness   of    search    heuristics   on    autotuning   can    be
limited\nbsp{}\cite{seymour2008comparison,balaprakash2011can,balaprakash2012experimental},
between other factors, by underlying hypotheses  about the search space, such as
the  reachability of  the  global optimum  and the  smoothness  of search  space
surfaces, which  are frequently not  respected. The derivation  of relationships
between  parameters  and  performance  from search  heuristic  optimizations  is
greatly hindered,  if not rendered impossible,  by the biased way  these methods
explore  parameters.   Some  parametric  learning methods,  such  as  Design  of
Experiments,  are  not widely  applied  to  autotuning.  These  methods  perform
structured  parameter  exploration,  and  can  be used  to  build  and  validate
performance     models,     generating    transparent     and     cost-effective
optimizations\nbsp{}\cite{mametjanov2015autotuning,bruel2019autotuning}.   Other
methods  from  the parametric  family  are  more  widely  used, such  as  Bandit
Algorithms\nbsp{}\cite{xu2017parallel}.  Nonparametric learning methods, such as
Decision   Trees\nbsp{}\cite{balaprakash2016automomml}   and  Gaussian   Process
Regression\nbsp{}\cite{parsa2019pabo}, are able to reduce model bias greatly, at
the  expense  of   increased  prediction  variance.  Figure\nbsp{}\ref{fig:tree}
categorizes some autotuning methods according to  some of the key hypotheses and
branching questions underlying each method.

During this  thesis I have  adapted and  studied the effectiveness  of different
search heuristics and statistical learning  methods on optimizing performance on
several autotuning domains.  During the beginning of my PhD at the University of
São Paulo (USP), I have published a paper on optimizing the configuration of the
CUDA compiler\nbsp{}\cite{bruel2017autotuning},  where we have  reached up to  4 times
performance improvement  in comparison with a  high-level compiler optimization.
In collaboration with researchers from  Hewlett Packard Enterprise (HPE) in Palo
Alto, I wrote a  paper on the autotuning of a  compiler for High-Level Synthesis
for FPGAs\nbsp{}\cite{bruel2017autotuninghls}, where we  have reached, on average, 25%
improvements on  performance, size, and  complexity of  designs.

At the  end of 2017,  I joined  the /cotutelle/ PhD  program at the  University of
Grenoble Alpes  (UGA) and  became a member  of the POLARIS  Inria team,  where I
applied  Design  of   Experiments  to  the  autotuning   of  a  source-to-source
transformation  compiler\nbsp{}\cite{bruel2019autotuning},  where  we  showed  we  can
achieve significant speedup by exploiting  search space structure using a strict
budget.   I also  have  collaborated with  HPE on  another  paper, providing  an
analysis  of the  applicability  of autotuning  methods  to a  Hardware-Software
Co-design  problem\nbsp{}\cite{bruel2017generalize}.   During  my  Teaching  Assistant
internships,  I  have  published one  paper\nbsp{}\cite{bruel2017openmp}  on  parallel
programming  teaching, and  collaborated on  another\nbsp{}\cite{goncalves2016openmp},
where we showed that teaching lower level programming models, despite being more
challenging at first, provides a stronger core understanding.

I continue to collaborate with HPE  researchers on the application of autotuning
methods to  optimize Neural Networks,  hardware accelerators for  Deep Learning,
and  algorithms  for dealing  with  network  congestion.   With my  advisors,  I
currently manage  1 undergraduate and 4  masters students, who are  applying the
statistical  learning autotuning  methods  I studied  and  adapted to  different
domains  in the  context of  a joint  USP/HPE research  project.  I  am strongly
motivated to continue pursuing a career  on Computer Science research, aiming to
produce  rigorous and  value-adding  contributions. I  hereby  submit my  thesis
proposal and application to the Microsoft Latin America PhD Award.
#+begin_export latex
\begin{center}
  \begin{figure}[t]
    \resizebox{.9\textwidth}{!}{%
      \begin{forest}
        for tree={%
          anchor = north,
          align = center,
          l sep+=1em
        },
        [{Minimize $f: \mathcal{X} \to \mathbb{R}$,\\$Y = f(X = (x_1,\dots,x_k) \in \mathcal{X}) + \varepsilon$},
          draw,
          [{Constructs surrogate estimate $\hat{f}(\cdot, \theta(X))$?},
            draw,
            color = NavyBlue
            [{Search Heuristics},
              draw,
              color = BurntOrange,
              edge label = {node[midway, fill=white, font = \scriptsize]{No}}
              [{\textbf{Random} \textbf{Sampling}}, draw]
              [{Reachable Optima},
                draw,
                color = BurntOrange
                [, phantom]
                [{Underlying Hypotheses \\ \textbf{Heuristics}}, draw]]]
            [{Statistical Learning},
              draw,
              color = BurntOrange,
              edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
              [{Parametric Learning},
                draw,
                color = BurntOrange
                [{$\forall{}i: x_i \in X$ is discrete\\$\hat{f}(X) \approx f_1(x_1) + \dots + f_k(x_k)$},
                  draw,
                  color = BurntOrange
                  [{\textbf{Independent Bandits}\\for each $x_i$:\textbf{UCB},\textbf{EXP3},$\dots$}, draw]
                  [, phantom]]
                [{Linear Model\\$\hat{f} = \mathcal{M}(X)\theta{}(X) + \varepsilon$},
                  draw,
                  color = BurntOrange
                  [, phantom]
                  [{Check for model adequacy?},
                    draw,
                    alias = adequacy,
                    color = NavyBlue
                    [{Consider interactions?\\{$\exists x_i \neq x_j:\; \theta(x_ix_j) \neq 0$}},
                      draw,
                      alias = interactions,
                      color = NavyBlue,
                      edge label = {node[midway, fill=white, font = \scriptsize]{No}}
                      [{$\forall x_i \in X: x_i \in \{-1, 1\}$\\\textbf{Screening} \textbf{Designs}},
                        edge label = {node[midway, fill=white, font = \scriptsize]{No}},
                        draw
                        [, phantom]
                        [{Select $\hat{X}_{*}$, reduce dimension of $\mathcal{X}$},
                          edge = {-stealth, ForestGreen, semithick},
                          edge label = {node[midway, fill=white, font = \scriptsize]{Exploit}},
                          draw,
                          alias = estimate,
                          color = ForestGreen]]
                      [{\textbf{Optimal} \textbf{Design}},
                        draw,
                        alias = optimal,
                        edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}]]
                    [, phantom]
                    [, phantom]
                    [, phantom]
                    [, phantom]
                    [, phantom]
                    [, phantom]
                    [{\textbf{Space-filling} \textbf{Designs}},
                      draw,
                      edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
                      [, phantom]
                      [{Model selection},
                        edge = {-stealth, ForestGreen, semithick},
                        edge label = {node[midway, fill=white, font = \scriptsize]{Explore}},
                        draw,
                        alias = selection,
                        color = ForestGreen]]]]]
              [{Nonparametric Learning},
                draw,
                color = BurntOrange
                [{Splitting rules on X\\\textbf{Decision} \textbf{Trees}},
                  draw
                  [, phantom]
                  [{Estimate $\hat{f}(\cdot)$ and $uncertainty(\hat{f}(\cdot))$},
                    edge = {-stealth, ForestGreen, semithick},
                    draw,
                    alias = uncertainty,
                    color = ForestGreen
                    [{Minimize $uncertainty(\hat{f}(X))$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Explore}},
                      draw,
                      color = ForestGreen]
                    [{Minimize $\hat{f}(X)$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Exploit}},
                      draw,
                      color = ForestGreen]
                    [{Minimize $\hat{f}(X) - uncertainty(\hat{f}(X))$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Exploit$+$Explore}},
                      draw,
                      color = ForestGreen]]]
                [{\textbf{Gaussian} \textbf{Process Regression}},
                  alias = gaussian,
                  draw]
                [{\textbf{Neural} \textbf{Networks}}, draw]]]]]
        \draw [-stealth, semithick, ForestGreen](selection) to [bend left=27] node[near start, fill=white, font = \scriptsize] {Exploit} (adequacy.south);
        \draw [-stealth, semithick, ForestGreen](estimate.east) to [bend right=37] node[near start, fill=white, font = \scriptsize] {Explore} (adequacy.south) ;
        \draw [-stealth, semithick, ForestGreen](gaussian) to (uncertainty);
        \draw [-stealth, semithick, ForestGreen](optimal) to node[midway, fill=white, font = \scriptsize] {Exploit} (estimate) ;
      \end{forest}
    }
    \caption{A high-level view of autotuning methods, where \textcolor{NavyBlue}{\textbf{blue}} boxes
      denote branching questions, \textcolor{BurntOrange}{\textbf{orange}} boxes
      denote key hypotheses, \textcolor{ForestGreen}{\textbf{green}} boxes
      highlight exploration and exploitation choices, and \textbf{bold} boxes denote methods.}
    \label{fig:tree}
  \end{figure}
\end{center}
#+end_export

#+latex: \newpage

#+LATEX: \bibliographystyle{IEEEtran}
#+LATEX: \bibliography{references}
****** (Short) Search Heuristics and Statistical Learning methods for Autotuning HPC Programs
:PROPERTIES:
:EXPORT_DATE:
:EXPORT_TITLE: @@latex: Search Heuristics and Statistical Learning \\ Methods for Program Autotuning@@
:EXPORT_FILE_NAME: short-application.pdf
:EXPORT_AUTHOR: Pedro Bruel
:END:

#+latex: \vspace{-3em}

High Performance Computing  has been a cornerstone of  collective scientific and
industrial progress  for at least  five decades.   Paying the cost  of increased
complexity,  software and  hardware  engineering advances  continue to  overcome
several challenges on the way of the sustained performance improvements observed
during the last  fifty years.  This mounting complexity means  that reaching the
advertised hardware  performance for  a given program  requires not  only expert
knowledge  of a  given hardware  architecture, but  also mastery  of programming
models  and  languages for  parallel  and  distributed  computing.

If we state performance optimization problems as /search/ or /learning/ problems, by
converting implementation  and configuration  choices to /parameters/  which might
affect  performance,  we  can  draw   and  adapt  proven  methods  from  search,
mathematical  optimization and  statistics. The  effectiveness of  these adapted
methods  on autotuning  problems varies  greatly,  and hinges  on practical  and
mathematical properties of the problem and the corresponding /search space/.

When  adapting methods  for autotuning,  we must  face challenges  emerging from
practical properties  such as restricted  time and cost budgets,  constraints on
feasible  parameter values,  and the  need to  mix /categorical/,  /continuous/, and
/discrete/ parameters. To achieve useful results, we must also choose methods that
make hypotheses compatible with problem search  spaces, such as the existence of
discoverable,  or at  least  exploitable, relationships  between parameters  and
performance.   Choosing  an autotuning  method  requires  determining a  balance
between the exploration of a problem, when we would seek to discover and explain
relationships between  parameters and performance,  and the exploitation  of the
best optimizations we can find, when we would seek only to minimize performance.

During this  thesis I have  adapted and  studied the effectiveness  of different
search heuristics and statistical learning  methods on optimizing performance on
several autotuning domains.  During the beginning of my PhD at the University of
São Paulo (USP), I have published a paper on optimizing the configuration of the
CUDA compiler\nbsp{}\cite{bruel2017autotuning},  where we have  reached up to  4 times
performance improvement  in comparison with a  high-level compiler optimization.
In collaboration with researchers from  Hewlett Packard Enterprise (HPE) in Palo
Alto, I wrote a  paper on the autotuning of a  compiler for High-Level Synthesis
for FPGAs\nbsp{}\cite{bruel2017autotuninghls}, where we  have reached, on average, 25%
improvements on  performance, size, and  complexity of  designs.

At the  end of 2017,  I joined  the /cotutelle/ PhD  program at the  University of
Grenoble Alpes  (UGA) and  became a member  of the POLARIS  Inria team,  where I
applied  Design  of   Experiments  to  the  autotuning   of  a  source-to-source
transformation  compiler\nbsp{}\cite{bruel2019autotuning},  where  we  showed  we  can
achieve significant speedup by exploiting  search space structure using a strict
budget.   I also  have  collaborated with  HPE on  another  paper, providing  an
analysis  of the  applicability  of autotuning  methods  to a  Hardware-Software
Co-design  problem\nbsp{}\cite{bruel2017generalize}.

I continue to collaborate with HPE  researchers on the application of autotuning
methods to  optimize Neural Networks,  hardware accelerators for  Deep Learning,
and  algorithms  for dealing  with  network  congestion.   With my  advisors,  I
currently manage  1 undergraduate and 4  masters students, who are  applying the
statistical  learning autotuning  methods  I studied  and  adapted to  different
domains  in the  context of  a joint  USP/HPE research  project.  I  am strongly
motivated to continue pursuing a career  on Computer Science research, aiming to
produce  rigorous and  value-adding  contributions. I  hereby  submit my  thesis
proposal and application to the Microsoft Latin America PhD Award.

#+LATEX: \bibliographystyle{IEEEtran}
#+LATEX: \bibliography{references}
**** Arnaud and Brice: March 15th Meeting
***** Postdoc training sessions @ Inria
- Registration OK
- Project, lab, advisor?
- Can it be Arnaud, or someone at LIG?
***** Empirical Roofline
- Almost 2x peak when using march=native
- Despite that, no improvement in the best configuration for dgemv kernel
  - Around 20% improvement for the -O3 kernel version
- Good argument that the kernel is not capable of leveraging the parameters
***** Laplacian
- Looking at a specific semi-automatic example
- Factors were not always eliminated
- Later, experiments were automated
