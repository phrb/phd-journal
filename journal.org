# -*- mode: org -*-
# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages logdrawer
#+TITLE:  Pedro's Journal
#+AUTHOR:      Pedro H R Bruel
#+LANGUAGE:    en
#+TAGS: LIG(L) HOME(H) Europe(E) Blog(B) noexport(n) Stats(S)
#+TAGS: Epistemology(E) Vulgarization(V) Teaching(T) R(R) OrgMode(O) Python(P)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w@) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

* Reading Fisher's Design & Montgomery's Design
** Quotes for key concepts
- "Every experiment may be said to exist only in order to give the
    facts a chance of disproving the null hypothesis"
- "The null hypothesis must be exact, that is free from vagueness and
    ambiguity"
** A null hipothesis for autotuning techniques
*** Definitions
- A base autotuning technique t_b
- A new autotuning technique t_n
- A set of autotuning problems P
- A metric M
*** An exact null hipothesis H 
- We can state H as: The improvement of M produced by t_n is equal to t_b for all
  problems p \in P, that is, t_n performance is equal to t_b for P.
*** Problems 
- What is the chance of disproving H? In other words, to be considered better for P,
  for how many problems p \in P must t_n perform better than t_b?
- The set P must be very well chosen for this experiment to make sense. 
* Studying "Learning with Bandit Feedback in Potential Games"
** Reading "Learning with Bandit Feedback in Potential Games" 
The [[file:~/Dropbox/papers/bandit-problem/cohen2017learning.pdf][pdf file]] is in my paper library.
*** Managing Autotuning Techniques as an N-Player Game
- Understanding applicability will require studying the implementation
  in C++ shared by AmÃ©lie.
- The players are distributed processes
- The actions are changing, keeping, restarting or reconfiguring
  search techniques
- The payoff is finding better configurations
  - Related to the Area Under the Curve Credit Assignment
  - The 'full bandit' case is very similar to MAB AUC
- Gaming strategies could consist of policies to select
  techniques based on the number of processes, past results,
  and maybe characteristics of the search space
- In this context, what would be equivalent to the *Nash Equilibrium*?
  - No process "wants" to change its policy for selecting techniques
  - No process "wants" to change its current technique
** Studying the code from "Learning with Bandit Feedback in Potential Games"
The [[file:~/code/bandit-johanne/][source code]] is located in my code library.  
*** General Questions & Considerations
It seems the game has only 2 players, but the paper considers N-player
games. From the paper, it seems that the N-player implementation would
work without much change.

Payoffs seem to be pre-computed for each strategy but this does not,
at first, imply that needing to compute the payoffs would change
anything.

To adapt this code to the selection of search algorithms by Julia
processes we would need a way to implement the strategies.
*** Questions about specific points in code
**** =main.cpp=
Questions and execution flow related to the [[file:~/code/bandit-johanne/code/main.cpp][main file]].

***** Questions

- Why weren't random payoffs used?
- How are strategies represented in the =evol= array?

***** Execution Flow

1. Declare payoff and strategy arrays
2. Initialize pre-computed payoffs
3. Initialize seeds array
4. Instantiate a new =Game=
5. Call =Game->Play=
6. Save output to file
   
**** =game.h= & =game.cpp=
Questions and execution flow related to the [[file:~/code/bandit-johanne/code/game.h][header]] and the [[file:~/code/bandit-johanne/code/game.cpp][implementation]].

***** Questions

Re-read [[file:~/Dropbox/papers/bandit-problem/cohen2017learning.pdf][the paper]] to understand:

- What is a potential game?
- What does the =potential_function= do?
- What are the constraints on payoff arrays?
- What are =gamma= & =utility=?
- What is =res= used for inside =Game->play=? And inside =Game=?

***** Execution Flow

1. Instantiated by =main.cpp=
2. =void Game->play= is called by =main.cpp=
3. Open output file
4. Loop for the number of steps:
   1. Registers player strategies in =evol= for step =i= such that:
      #+BEGIN_SRC C
evol[i][(int)floor(P1->proba_strat[0]*100)][(int)floor(P2->proba_strat[0]*100)]++;
      #+END_SRC
   
      Where =P1= and =P2= are =Player= objects and the =proba_strat= arrays store
      the current strategy of each player.
   2. Calls =play_one_turn= (see below)
5. Save output to file

****** Execution Flow of =play_one_turn=

1. Called by =Game->play=
2. Initializes =epsilon=, =gamma= and =utility=
3. Set strategies for each player using =draw_proba=
4. Update =utility= arrays
5. Update =y_strat= arrays with =utility= and =gamma=
6. Calls =update_proba(epsilon)= for each player

**** =player.h= & =player.cpp=
Questions and execution flow related to the
[[file:~/code/bandit-johanne/code/player.h][header]] and the
[[file:~/code/bandit-johanne/code/player.cpp][implementation]].

***** Questions

- What are the arrays =proba_strat= & =y_strat=?

* NODAL Development
** Installing NODAL in Julia Nightly
[[https://github.com/phrb/NODAL.jl][NODAL]] is the autotuning library I am developing in the [[https://julialang.org/][Julia]] language.
The idea is to provide tools for the implementation of parallel and
distributed autotuners for various problem domains.
*** Download Julia Nightly
**** [[https://julialang.org/downloads/][Download Generic Binary]]
**** Downloading from the CLI
You can run the following to install the latest *Julia* version:
#+BEGIN_SRC bash
cd ~ && mkdir .bin && cd .bin
wget https://julialangnightlies-s3.julialang.org/bin/linux/x64/julia-latest-linux64.tar.gz
tar xvf julia-latest-linux64.tar.gz
mv julia-* julia
rm julia-latest-linux64.tar.gz
#+END_SRC
This will put the *Julia* binary at =~/.bin/julia/bin/julia=.
You can use it like that or add an =alias= to your shell.
*** Installing the unregistered version
This will not be needed after registering NODAL to METADATA.
**** [[https://docs.julialang.org/en/latest/manual/packages/#Installing-Unregistered-Packages-1][Documentation]]
**** Julia Commands
#+BEGIN_SRC julia
Pkg.clone("https://github.com/phrb/NODAL.jl")
Pkg.build("NODAL")
Pkg.test("NODAL")
#+END_SRC
*** Installing from the Julia package manager
**** Julia commands
#+BEGIN_SRC julia
Pkg.add("NODAL")
Pkg.build("NODAL")
Pkg.test("NODAL")
#+END_SRC
** Setting up a new Release
*** Using Attobot
[[https://github.com/attobot][Attobot]] integrates with *GitHub* to automatically register a new package
or a package version to *Julia*'s =METADATA= package repository.  Attobot
only needs a new *GitHub* release to work.
*** Using *Julia*'s =PkgDev=
Check the [[https://docs.julialang.org/en/latest/manual/packages/#Tagging-and-Publishing-Your-Package-1][documentation]] to learn how to register and publish user
packages to =METADATA=.
** Development Workflow
The process of fixing an [[https://github.com/phrb/NODAL.jl/issues][issue]] or submitting a new
feature is:
0. Fork [[https://github.com/phrb/NODAL.jl][NODAL on GitHub]]
   
   You will need a GitHub account for this.

1. Make sure you have the latest version
   #+BEGIN_SRC bash
git checkout master
git fetch
   #+END_SRC

   New branches must be made from the =dev= branch:
   #+BEGIN_SRC bash
git checkout dev
   #+END_SRC
2. Checkout a new branch
   #+BEGIN_SRC bash
git checkout -b fix-or-feature
   #+END_SRC
3. Write code and commit to your new branch
   
   Make sure you write short and descriptive commit
   messages. Something similar to [[https://udacity.github.io/git-styleguide/][Udacity's guidelines]] is preferred
   but not strictly necessary.

4. Open a [[https://github.com/phrb/NODAL.jl/pulls][pull request]] to the =dev= branch
